[{"categories":["生活记录"],"content":" 规划区vscode use alt + c to mark done – 昨天遗留 – 粗读 kubernetes 官方文档 - 概念：概念 | Kubernetes概念 | Kubernetes 概述 架构 容器 工作负载 服务、负载均衡 存储 配置 安全 策略 调度、抢占、驱逐 集群管理 – 新计划 – – 明天 – 整理 5 月份日记录，写月记录 ","date":"2023-05-30","objectID":"/2023-05-30-daily-note/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-30-daily-note","uri":"/2023-05-30-daily-note/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录 算法每日一题 英语 单词 口语 ","date":"2023-05-30","objectID":"/2023-05-30-daily-note/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-30-daily-note","uri":"/2023-05-30-daily-note/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-重要事记","date":"2023-05-30","objectID":"/2023-05-30-daily-note/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-30-daily-note","uri":"/2023-05-30-daily-note/#记录区-重要事记"},{"categories":["生活记录"],"content":" 记录区-随手记 “that was a joke, it’s funny, because it’s true.” – The Big Bang Theory 写写字： 为了避免在粗读网页的时候频繁切到笔记区（通常记不到几个字），使用 hypothesis 插件来标注句子或者添加注解 皮格马利翁效应 - 维基百科，自由的百科全书 ","date":"2023-05-30","objectID":"/2023-05-30-daily-note/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-30-daily-note","uri":"/2023-05-30-daily-note/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） ","date":"2023-05-30","objectID":"/2023-05-30-daily-note/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-30-daily-note","uri":"/2023-05-30-daily-note/#记录区-总结"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 type _type struct { size uintptr ptrdata uintptr // size of memory prefix holding all pointers hash uint32 tflag tflag align uint8 fieldAlign uint8 kind uint8 // function for comparing objects of this type // (ptr to object A, ptr to object B) -\u003e ==? equal func(unsafe.Pointer, unsafe.Pointer) bool // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte str nameOff ptrToThis typeOff } 在 Golang 源码中，_type 结构体的每个字段分别代表以下内容： size：类型的大小（字节）。 ptrdata：指向类型的指针所需的前缀大小（字节）。 hash：类型的哈希值。 tflag：类型标志位，用于描述类型的一些特性，如是否为指针、是否可比较等。 align：类型的对齐方式（字节）。 fieldAlign：结构体字段的对齐方式（字节）。 kind：类型的种类，如 int、string、struct 等。 equal：比较两个对象是否相等的函数指针。 gcdata：垃圾回收器使用的类型数据。如果 kind 中设置了 KindGCProg 标志位，则 gcdata 是一个 GC 程序；否则它是一个 ptrmask 位图。 str：类型名称在字符串表中的偏移量。 ptrToThis：指向该类型的指针的类型信息在类型表中的偏移量。 其中，size 字段的单位是字节。 ","date":"2023-05-29","objectID":"/2023052919-golang-%E4%B8%AD%E7%9A%84-_type-%E7%BB%93%E6%9E%84/:0:0","series":["card"],"tags":[],"title":"Golang 中的 _type 结构","uri":"/2023052919-golang-%E4%B8%AD%E7%9A%84-_type-%E7%BB%93%E6%9E%84/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#golang #变量逃逸 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-29","objectID":"/2023052914-golang-%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8/:0:0","series":["card"],"tags":[],"title":"golang 中的变量逃逸","uri":"/2023052914-golang-%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" draft 如何查看某个变量是否发生了逃逸 // 这里 n 为什么没有发生变量逃逸 // 我的理解：函数内部没有将这个指针存储在全局变量中，也没有返回这个指针 func test1(n *int) { *n++ return } func test2() int { ans := 1 return ans } func main() { n := 1 test1(\u0026n) //n does not escape a := test2() fmt.Println(a) } 使用 go build 查看变量是否逃逸 go build -gcflags '-m -l' main.go # command-line-arguments .\\main.go:7:12: n does not escape .\\main.go:23:13: ... argument does not escape .\\main.go:23:14: a escapes to heap 逃逸分析是怎么进行的 | Go 程序员面试笔试宝典 ","date":"2023-05-29","objectID":"/2023052914-golang-%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8/:1:0","series":["card"],"tags":[],"title":"golang 中的变量逃逸","uri":"/2023052914-golang-%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8/#draft"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#个人记录 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-29","objectID":"/2023052901-golang-%E7%AB%99%E7%82%B9%E8%A7%84%E5%88%92/:0:0","series":["card"],"tags":[],"title":"Golang 站点规划","uri":"/2023052901-golang-%E7%AB%99%E7%82%B9%E8%A7%84%E5%88%92/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" draft初步构想： 主要用来记录 Golang 相关的更深层次的学习，目的是希望针对 Golang 这门语言，不只是停留在会用上，希望能够真正用好这门语言，感受一些设计哲学、编码规范，帮助自己写出更简洁高效的代码，提升对于隐晦bug定位的能力！ ","date":"2023-05-29","objectID":"/2023052901-golang-%E7%AB%99%E7%82%B9%E8%A7%84%E5%88%92/:1:0","series":["card"],"tags":[],"title":"Golang 站点规划","uri":"/2023052901-golang-%E7%AB%99%E7%82%B9%E8%A7%84%E5%88%92/#draft"},{"categories":["生活记录"],"content":" 规划区vscode use alt + c to mark done mindmap root Go「40%」 ))today is focus on go(( Kubernetes「0%」 Algorithm「30%」 work「0%」 network「0%」 os「0%」 ... some new gRPC「0%」 go redis「20%」 ... – 昨天遗留 – 「golang - 1h30m」golang PMG 模型 「kubernetes」整理 kubernetes 相关学习内容 「golang」 context 粗读：Changkun Ou | Go 语言原本 写的太复杂，有空闲时间再看看吧 粗读：Go 程序员面试笔试宝典 | Go 程序员面试笔试宝典 如果还有时间，看下：6455. 使所有字符相等的最小成本 重新规划博客关于 Golang 相关系列 – 新计划 – 粗度：Go 语言设计与实现 | Go 语言设计与实现 内容有点重复，空闲再看 粗读 kubernetes 官方文档 - 概念：概念 | Kubernetes概念 | Kubernetes 概述 架构 容器 工作负载 服务、负载均衡 存储 配置 安全 策略 调度、抢占、驱逐 集群管理 – 明天 – ","date":"2023-05-29","objectID":"/2023-05-29-daily-note/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-29-daily-note","uri":"/2023-05-29-daily-note/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录 算法每日一题 英语 单词 口语 ","date":"2023-05-29","objectID":"/2023-05-29-daily-note/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-29-daily-note","uri":"/2023-05-29-daily-note/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-重要事记","date":"2023-05-29","objectID":"/2023-05-29-daily-note/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-29-daily-note","uri":"/2023-05-29-daily-note/#记录区-重要事记"},{"categories":["生活记录"],"content":" 记录区-随手记今天看到一篇挺有意思的文章：Money Oriented Programming | 面向金钱的编程 ","date":"2023-05-29","objectID":"/2023-05-29-daily-note/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-29-daily-note","uri":"/2023-05-29-daily-note/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） ","date":"2023-05-29","objectID":"/2023-05-29-daily-note/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-29-daily-note","uri":"/2023-05-29-daily-note/#记录区-总结"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#数组 #切片 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-28","objectID":"/2023052814-go-%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AF%95%E5%AE%9D%E5%85%B8/:0:0","series":["card"],"tags":[],"title":"Go 程序员面试笔试宝典","uri":"/2023052814-go-%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AF%95%E5%AE%9D%E5%85%B8/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" draft 数组与切片的关系 修改切片： 当切片长度已经达到容量，继续添加元素会重新开辟一个空间 新的切片的容量是如何增长的？ Go 的后发优势：支持静态语言的类型检查，又有动态语言的便利 接口的动态类型和动态值 context 可以用来实现 goroutine 之间的退出通知、元数据传递的功能 反射的性能不高，如果是项目的效率性关键代码，应该尽量避免使用反射 代码段 var r io.Reader 中，声明了 r 的类型是 io.Reader（这是 r 的静态类型）此时他的动态类型为 nil，动态值也是 nil go 与 c++ 的一个比较：在 c++ 中，返回一个指针类型可能是危险的（可能忘记delete、或者继续传递给别的方法），在 go 中是安全的（编译器的功劳） goroutine 的切换成本比 thread 小得多，goroutine 与 thread 相互独立，但是 goroutine 要依赖于 thread 才能执行 Go 使用的 GC 方式是：不分代、不整理、并发的三色标记清扫算法 ","date":"2023-05-28","objectID":"/2023052814-go-%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AF%95%E5%AE%9D%E5%85%B8/:1:0","series":["card"],"tags":[],"title":"Go 程序员面试笔试宝典","uri":"/2023052814-go-%E7%A8%8B%E5%BA%8F%E5%91%98%E9%9D%A2%E8%AF%95%E7%AC%94%E8%AF%95%E5%AE%9D%E5%85%B8/#draft"},{"categories":["生活记录"],"content":" 规划区vscode use alt + c to mark done – 昨天遗留 – 「golang - 1h30m」golang GMP 模型 「kubernetes」整理 kubernetes 相关学习内容 「golang」 context – 新计划 – 整理「算法笔记」专题：关于 - HHQ算法笔记 粗读：Changkun Ou | Go 语言原本 粗读：Go 程序员面试笔试宝典 | Go 程序员面试笔试宝典 如果还有时间，看下：6455. 使所有字符相等的最小成本 – 明天 – 粗度：Go 语言设计与实现 | Go 语言设计与实现 ","date":"2023-05-28","objectID":"/2023-05-28-daily-note/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-28-daily-note","uri":"/2023-05-28-daily-note/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录 算法每日一题 英语 单词 口语 ","date":"2023-05-28","objectID":"/2023-05-28-daily-note/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-28-daily-note","uri":"/2023-05-28-daily-note/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-重要事记","date":"2023-05-28","objectID":"/2023-05-28-daily-note/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-28-daily-note","uri":"/2023-05-28-daily-note/#记录区-重要事记"},{"categories":["生活记录"],"content":" 记录区-随手记","date":"2023-05-28","objectID":"/2023-05-28-daily-note/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-28-daily-note","uri":"/2023-05-28-daily-note/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） ","date":"2023-05-28","objectID":"/2023-05-28-daily-note/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-28-daily-note","uri":"/2023-05-28-daily-note/#记录区-总结"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#vscode #foam #写作流 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 之前使用 obsidian 写作了有段时间了，整体体验下来其实还不错 支持卡片盒写作 不同的 workspace 之间可以有不同的设置 图片会全局查找（引用缺失地址前缀也是能够找到图片的） … 优点挺多的，但是后来还是觉得使用 vscode 来写作吧，由于 vscode 插件库很丰富，如果有什么需求都能够用插件来实现，也就省去了之后可能更换写作工具的麻烦。经过一番捣鼓，vscode 也大致都满足了我想要的一些需求，在此做个记录。 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:0:0","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一、主要插件列表 Foam | A personal knowledge management and sharing system for VSCode 通过这个插件实现 vscode 支持卡片盒写作方式 Image preview - Visual Studio Marketplace Markdown Image - Visual Studio Marketplace 上面这两个插件用来解决图片的插入和预览 其他插件不赘述，根据个人习惯 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:1:0","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#一主要插件列表"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 二、插件配置 foamfoam 的配置主要用 .foam/templates/ 目录下的两个模板来实现： card.md 正常的记录文档通过这个模板来创建 --- title: \"${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [] series: [] categories: [灵感、文献笔记（非永久笔记）] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/box/$FOAM_DATE_YEAR$FOAM_DATE_MONTH$FOAM_DATE_DATE$FOAM_DATE_HOUR $FOAM_TITLE.md' --- \u003c!--more--\u003e ${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}: 将文件的名称分成三个部分 第一部分 ^[0-9]+，第二部分 一个空格，第三部分(.*)，并且将第三部分捕获到第一个捕获组中，然后使用这个捕获组作为文件的名字（在博客中显示的名字） 参考教程：Snippets in Visual Studio Code date 使用的变量参考：Snippets in Visual Studio Code filepath 的配置决定了文件创建在哪个文件夹以及文件名称，配置参考：Note Templates | Foam dialy-note.md --- title: \"${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}-daily-note\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [个人记录] series: [日规划-记录] categories: [生活记录] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/life/diary/$FOAM_DATE_YEAR/$FOAM_DATE_MONTH/$FOAM_DATE_YEAR-$FOAM_DATE_MONTH-$FOAM_DATE_DATE-daily-note.md' --- \u003c!--more--\u003e 在项目中的位置： markdown image主要配置： Path 确定图片放在项目中的路径 Reference Path 确定图片加入文档的时候的引用路径，比如下面这种形式 ![图 2](images/posts/20230527-222647775.png) 这个路径是博客需要定位的路径 到这已经实现了图片的插入，但是因为 Path 跟 Reference Path 的配置不一样，在 vscode 中查看的时候，是看不到图片的，因此需要用到下面的扩展 image preview主要配置： 相当于再把前面确实的路径加上，达到本地可见的效果 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:1:1","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#二插件配置"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 二、插件配置 foamfoam 的配置主要用 .foam/templates/ 目录下的两个模板来实现： card.md 正常的记录文档通过这个模板来创建 --- title: \"${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [] series: [] categories: [灵感、文献笔记（非永久笔记）] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/box/$FOAM_DATE_YEAR$FOAM_DATE_MONTH$FOAM_DATE_DATE$FOAM_DATE_HOUR $FOAM_TITLE.md' --- ${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}: 将文件的名称分成三个部分 第一部分 ^[0-9]+，第二部分 一个空格，第三部分(.*)，并且将第三部分捕获到第一个捕获组中，然后使用这个捕获组作为文件的名字（在博客中显示的名字） 参考教程：Snippets in Visual Studio Code date 使用的变量参考：Snippets in Visual Studio Code filepath 的配置决定了文件创建在哪个文件夹以及文件名称，配置参考：Note Templates | Foam dialy-note.md --- title: \"${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}-daily-note\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [个人记录] series: [日规划-记录] categories: [生活记录] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/life/diary/$FOAM_DATE_YEAR/$FOAM_DATE_MONTH/$FOAM_DATE_YEAR-$FOAM_DATE_MONTH-$FOAM_DATE_DATE-daily-note.md' --- 在项目中的位置： markdown image主要配置： Path 确定图片放在项目中的路径 Reference Path 确定图片加入文档的时候的引用路径，比如下面这种形式 ![图 2](images/posts/20230527-222647775.png) 这个路径是博客需要定位的路径 到这已经实现了图片的插入，但是因为 Path 跟 Reference Path 的配置不一样，在 vscode 中查看的时候，是看不到图片的，因此需要用到下面的扩展 image preview主要配置： 相当于再把前面确实的路径加上，达到本地可见的效果 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:1:1","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#foam"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 二、插件配置 foamfoam 的配置主要用 .foam/templates/ 目录下的两个模板来实现： card.md 正常的记录文档通过这个模板来创建 --- title: \"${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [] series: [] categories: [灵感、文献笔记（非永久笔记）] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/box/$FOAM_DATE_YEAR$FOAM_DATE_MONTH$FOAM_DATE_DATE$FOAM_DATE_HOUR $FOAM_TITLE.md' --- ${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}: 将文件的名称分成三个部分 第一部分 ^[0-9]+，第二部分 一个空格，第三部分(.*)，并且将第三部分捕获到第一个捕获组中，然后使用这个捕获组作为文件的名字（在博客中显示的名字） 参考教程：Snippets in Visual Studio Code date 使用的变量参考：Snippets in Visual Studio Code filepath 的配置决定了文件创建在哪个文件夹以及文件名称，配置参考：Note Templates | Foam dialy-note.md --- title: \"${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}-daily-note\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [个人记录] series: [日规划-记录] categories: [生活记录] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/life/diary/$FOAM_DATE_YEAR/$FOAM_DATE_MONTH/$FOAM_DATE_YEAR-$FOAM_DATE_MONTH-$FOAM_DATE_DATE-daily-note.md' --- 在项目中的位置： markdown image主要配置： Path 确定图片放在项目中的路径 Reference Path 确定图片加入文档的时候的引用路径，比如下面这种形式 ![图 2](images/posts/20230527-222647775.png) 这个路径是博客需要定位的路径 到这已经实现了图片的插入，但是因为 Path 跟 Reference Path 的配置不一样，在 vscode 中查看的时候，是看不到图片的，因此需要用到下面的扩展 image preview主要配置： 相当于再把前面确实的路径加上，达到本地可见的效果 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:1:1","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#markdown-image"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 二、插件配置 foamfoam 的配置主要用 .foam/templates/ 目录下的两个模板来实现： card.md 正常的记录文档通过这个模板来创建 --- title: \"${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [] series: [] categories: [灵感、文献笔记（非永久笔记）] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/box/$FOAM_DATE_YEAR$FOAM_DATE_MONTH$FOAM_DATE_DATE$FOAM_DATE_HOUR $FOAM_TITLE.md' --- ${TM_FILENAME_BASE/^[0-9]+ (.*)$/$1/}: 将文件的名称分成三个部分 第一部分 ^[0-9]+，第二部分 一个空格，第三部分(.*)，并且将第三部分捕获到第一个捕获组中，然后使用这个捕获组作为文件的名字（在博客中显示的名字） 参考教程：Snippets in Visual Studio Code date 使用的变量参考：Snippets in Visual Studio Code filepath 的配置决定了文件创建在哪个文件夹以及文件名称，配置参考：Note Templates | Foam dialy-note.md --- title: \"${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}-daily-note\" subtitle: \"\" description: \"\" date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:00+08:00 draft: false authors: [索隆不喝酒] tags: [个人记录] series: [日规划-记录] categories: [生活记录] series_weight: 1 seriesNavigation: true featuredImage: \"\" featuredImagePreview: \"\" foam_template: filepath: 'content/posts/life/diary/$FOAM_DATE_YEAR/$FOAM_DATE_MONTH/$FOAM_DATE_YEAR-$FOAM_DATE_MONTH-$FOAM_DATE_DATE-daily-note.md' --- 在项目中的位置： markdown image主要配置： Path 确定图片放在项目中的路径 Reference Path 确定图片加入文档的时候的引用路径，比如下面这种形式 ![图 2](images/posts/20230527-222647775.png) 这个路径是博客需要定位的路径 到这已经实现了图片的插入，但是因为 Path 跟 Reference Path 的配置不一样，在 vscode 中查看的时候，是看不到图片的，因此需要用到下面的扩展 image preview主要配置： 相当于再把前面确实的路径加上，达到本地可见的效果 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:1:1","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#image-preview"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 三、快捷操作备忘vscode 命令菜单：ctrl + alt + p foam 使用 foam 提供的命令实现从模板创建文档，创建日记的操作 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:2:0","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#三快捷操作备忘"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 四、好用的插件记录 markdown-link-expander - Visual Studio Marketplace 根据网址生成 md 链接格式 ","date":"2023-05-27","objectID":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/:3:0","series":["card"],"tags":[],"title":"使用 vscode 结合 foam 等插件来写文档","uri":"/2023052721-%E4%BD%BF%E7%94%A8-vscode-%E7%BB%93%E5%90%88-foam-%E7%AD%89%E6%8F%92%E4%BB%B6%E6%9D%A5%E5%86%99%E6%96%87%E6%A1%A3/#四好用的插件记录"},{"categories":["生活记录"],"content":" 规划区vscode use alt + c to mark done – 昨天遗留 – 「golang - 1h30m」golang GMP 模型 「kubernetes」整理 kubernetes 相关学习内容 「golang」 context – 新计划 – 使用 vscode 一劳永逸吧 ","date":"2023-05-27","objectID":"/2023-05-27-daily-note/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27-daily-note","uri":"/2023-05-27-daily-note/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录 算法每日一题 英语 单词 口语 ","date":"2023-05-27","objectID":"/2023-05-27-daily-note/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27-daily-note","uri":"/2023-05-27-daily-note/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-重要事记","date":"2023-05-27","objectID":"/2023-05-27-daily-note/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27-daily-note","uri":"/2023-05-27-daily-note/#记录区-重要事记"},{"categories":["生活记录"],"content":" 记录区-随手记","date":"2023-05-27","objectID":"/2023-05-27-daily-note/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27-daily-note","uri":"/2023-05-27-daily-note/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） ","date":"2023-05-27","objectID":"/2023-05-27-daily-note/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27-daily-note","uri":"/2023-05-27-daily-note/#记录区-总结"},{"categories":["生活记录"],"content":" 规划区– 昨天遗留 – 「golang - 1h30m」golang GMP 模型 「kubernetes」整理 kubernetes 相关学习内容 「golang」 context – 新计划 – ","date":"2023-05-27","objectID":"/2023-05-27/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27 日记录","uri":"/2023-05-27/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录 算法每日一题 英语 单词 口语 ","date":"2023-05-27","objectID":"/2023-05-27/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27 日记录","uri":"/2023-05-27/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-重要事记","date":"2023-05-27","objectID":"/2023-05-27/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27 日记录","uri":"/2023-05-27/#记录区-重要事记"},{"categories":["生活记录"],"content":" 记录区-随手记","date":"2023-05-27","objectID":"/2023-05-27/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27 日记录","uri":"/2023-05-27/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） ","date":"2023-05-27","objectID":"/2023-05-27/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-27 日记录","uri":"/2023-05-27/#记录区-总结"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 之前使用 hugo （local 202305111342 使用 Hugo + GitHub Pages 搭建博客记录 remote 202305111342 使用 Hugo + GitHub Pages 搭建博客记录）搭建了一个用来「记录各种事情」的博客，很多东西都会往这上面写，对自己来说是一个大而全的站点，主要靠「分类」和「系列」来对文章归档，已经足够满足我的需求了，但是我还想要有一个用来记录「专题」学习的地方，比如一个学习 golang 源码的专题，或者算法刷题的专题，类似这样的站点。 为什么使用 MkDocs，之前搭建本博客使用了 hugo，就不再使用，找了找，MkDocs 也很轻量方便，关键是导航做得很符合用来写专题的需求。在主题上选用了最热门的 mkdocs-material 。 下面就搭建「算法刷题记录」站点为例来说明 跟着 mkdocs demo 熟悉一下 start mkdocs-material 根据自己的喜好、需求进行配置 一个 mkdocs.yaml 例子 site_name: HHQ算法笔记 theme: name: material # font: # code: Roboto Mono palette: - scheme: default toggle: icon: material/brightness-7 name: Switch to dark mode primary: green # 标题、侧边栏、文本链接的颜色 accent: red # 交互元素、悬停链接、按钮、滚动条 - scheme: slate toggle: icon: material/brightness-4 name: Switch to light mode # primary: green # 标题、侧边栏、文本链接的颜色 accent: red # 交互元素、悬停链接、按钮、滚动条 # logo: assets/img/zoro.png favicon: images/posts/zoro.png features: - content.code.copy - content.code.annotate - content.tabs.link - navigation.instant - navigation.tracking - navigation.tabs # - navigation.tabs.sticky - navigation.sections - navigation.expand - navigation.path - navigation.top # - navigation.indexes #nav: # - Blog: # - blog/index.md repo_url: https://github.com/904566722/algo repo_name: 904566722/algo plugins: - search: lang: - en # - blog: # enabled: !ENV [CI, false] # blog_dir: . # blog_toc: true markdown_extensions: - admonition - pymdownx.details - pymdownx.superfences - pymdownx.tabbed: alternate_style: true slugify: !!python/object/apply:pymdownx.slugs.slugify kwds: case: lower - pymdownx.highlight: anchor_linenums: true line_spans: __span pygments_lang_class: true - pymdownx.inlinehilite - pymdownx.snippets - footnotes - pymdownx.critic - pymdownx.caret - pymdownx.keys - pymdownx.mark - pymdownx.tilde - attr_list - pymdownx.emoji: emoji_index: !!python/name:materialx.emoji.twemoji emoji_generator: !!python/name:materialx.emoji.to_svg - attr_list - md_in_html - def_list - pymdownx.tasklist: custom_checkbox: true 学习一下对应的 markdown 一些特色写法 关联到 github，使用 Github Action 来发布站点 因为之前我已经绑定了域名 honghuiqiang.com，因此这里发布站点的地址是 「\\\u003cdomain\u003e/项目名称」 正常应该是 「\\\u003cusername\u003e.github.io/项目名称」 tip：一个 github 用户能够发布一个用户站点、一个项目站点，多个项目站点，这边发布的是项目站点，因此是使用后面跟 /项目名称 的方式来访问的 效果： ","date":"2023-05-27","objectID":"/202305270426-%E4%BD%BF%E7%94%A8-mkdocs-%E6%90%AD%E5%BB%BA%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9/:0:0","series":["card"],"tags":[],"title":"使用 MkDocs 搭建专题学习站点","uri":"/202305270426-%E4%BD%BF%E7%94%A8-mkdocs-%E6%90%AD%E5%BB%BA%E4%B8%93%E9%A2%98%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9/#heading"},{"categories":["Golang"],"content":"#Golang #map go version is go1.18 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:0:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#"},{"categories":["Golang"],"content":" draft 为什么要扩容？ 为什么引入装载因子，为了描述什么 发生扩容的两种情况 - 查看源码 针对两种情况的扩容方式有什么不同 扩容具体是怎么进行的？ ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:1:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#draft"},{"categories":["Golang"],"content":" 一、为什么要扩容？对于啊哈希表来说，冲突是不可避免的，当产生的冲突越来越多的时候，map 的各种性能都会下降 举一种极端情况1：每次计算的哈希值都相同的情况下，那么每次都会被放入同一个桶中，桶的 8 个空位占满之后，往后链接溢出桶，依次类推，这种情况下，查找、修改操作的时间复杂度都会退化成 O(n) 另外一种情况2：假设每个桶都已经放满了元素，那么之后往 map 中添加数据都会产生冲突，也就慢慢往情况1的场景上靠近了。 对于 go 的 map 来说，比较理想的情况应该是每个桶值存放一个数据，但是这显然是不可能的，这会造成很多的空间浪费。 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:2:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#一为什么要扩容"},{"categories":["Golang"],"content":" 二、什么时候会发生扩容？为了描述 map 保存元素的情况，引入了一个装载因子(= 元素数量/桶的数量)的概念，当这个装载因子超过 6.5 (golang) 的时候就会触发 map 的扩容。从装载因子的计算公式可以看出，装载因子没有办法识别到上面的情况1，只能避免情况2，因此还需要另外的一个触发条件来避免情况1 在 map 的 mapassign 方法中，判断是否需要扩容： if !h.growing() \u0026\u0026 (overLoadFactor(h.count+1, h.B) || tooManyOverflowBuckets(h.noverflow, h.B)) { hashGrow(t, h) goto again // Growing the table invalidates everything, so try again } 条件1 - 判断负载因子是否 \u003e 6.5 ： func overLoadFactor(count int, B uint8) bool { return count \u003e bucketCnt \u0026\u0026 uintptr(count) \u003e loadFactorNum*(bucketShift(B)/loadFactorDen) } 条件2 - 溢出桶的数量大于等于桶的数量： func tooManyOverflowBuckets(noverflow uint16, B uint8) bool { if B \u003e 15 { B = 15 } return noverflow \u003e= uint16(1)\u003c\u003c(B\u002615) } 当 B 大于 15 将 B 置为 15 的原因是支持的 map 的最大容量为 2^15 noverflow \u003e= uint16(1)\u003c\u003c(B\u002615) 相当于 noverflow \u003e= 1\u003c\u003cB，也就是当「溢出桶数量」\u003e=「桶数量」的时候，进行扩容操作。uint16(1)\u003c\u003c(B\u002615) 只是为了让编译器生成更短的代码，提高程序执行的效率，没有产生语义上的变化 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:3:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#二什么时候会发生扩容"},{"categories":["Golang"],"content":" 三、扩容的过程当 map 扩容之后，为了避免一次性的大规模的拷贝，map 的扩容是一个渐进式的过程，每次只拷贝一个桶（以及它关联的溢出桶），这个拷贝的过程是发生在增加、修改、删除操作的时候 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#三扩容的过程"},{"categories":["Golang"],"content":" hashGrow方法 - 「buckets 扩容」 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 片段解读1 bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) 这段代码主要是判断是由哪种方式引起的扩容，如果是因为装载因子过大导致的扩容，则新 buckets 的容量为原来的两倍，也就是将 bigger 设置为 1，如果是因为溢出桶过多导致的扩容，则新 buckets 的容量与原来的容量相同 原因 map容量 装载因子\u003e6.5 原来的容量 x2 溢出桶过多 = 原来的容量 片段解读2 oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } 这里是创建新桶数组的部分。首先将旧桶数组保存到 oldbuckets 变量中，然后调用 makeBucketArray 函数创建新的桶数组。如果需要扩容，则新桶数组的大小为原来的两倍；否则，新桶数组的大小与旧桶数组相同。makeBucketArray 函数还会返回一个溢出桶数组，如果有的话。 接下来，代码根据当前 map 的标志位来更新新 map 的标志位。如果当前 map 正在被迭代，则将新 map 的标志位设置为 oldIterator；否则，将其清除 片段解读3 // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 这里是提交扩容操作的部分。首先将 map 的大小增加 bigger（即扩容或横向扩展后的大小），然后更新标志位、旧桶数组和新桶数组。同时，将 nevacuate 和 noverflow 两个计数器清零，表示没有需要迁移的元素和溢出桶 片段解读4 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } 这里是处理溢出桶的部分。如果当前 map 中存在溢出桶，则将其提升到旧桶数组中。如果新桶数组中也存在溢出桶，则将其保存到 extra 字段中 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#hashgrowhttpsgithubcomgolanggoblobf90b4cd6554f4f20280aa5229cf42650ed47221dsrcruntimemapgol1058方法---buckets-扩容"},{"categories":["Golang"],"content":" hashGrow方法 - 「buckets 扩容」 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 片段解读1 bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) 这段代码主要是判断是由哪种方式引起的扩容，如果是因为装载因子过大导致的扩容，则新 buckets 的容量为原来的两倍，也就是将 bigger 设置为 1，如果是因为溢出桶过多导致的扩容，则新 buckets 的容量与原来的容量相同 原因 map容量 装载因子\u003e6.5 原来的容量 x2 溢出桶过多 = 原来的容量 片段解读2 oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } 这里是创建新桶数组的部分。首先将旧桶数组保存到 oldbuckets 变量中，然后调用 makeBucketArray 函数创建新的桶数组。如果需要扩容，则新桶数组的大小为原来的两倍；否则，新桶数组的大小与旧桶数组相同。makeBucketArray 函数还会返回一个溢出桶数组，如果有的话。 接下来，代码根据当前 map 的标志位来更新新 map 的标志位。如果当前 map 正在被迭代，则将新 map 的标志位设置为 oldIterator；否则，将其清除 片段解读3 // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 这里是提交扩容操作的部分。首先将 map 的大小增加 bigger（即扩容或横向扩展后的大小），然后更新标志位、旧桶数组和新桶数组。同时，将 nevacuate 和 noverflow 两个计数器清零，表示没有需要迁移的元素和溢出桶 片段解读4 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } 这里是处理溢出桶的部分。如果当前 map 中存在溢出桶，则将其提升到旧桶数组中。如果新桶数组中也存在溢出桶，则将其保存到 extra 字段中 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读1"},{"categories":["Golang"],"content":" hashGrow方法 - 「buckets 扩容」 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 片段解读1 bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) 这段代码主要是判断是由哪种方式引起的扩容，如果是因为装载因子过大导致的扩容，则新 buckets 的容量为原来的两倍，也就是将 bigger 设置为 1，如果是因为溢出桶过多导致的扩容，则新 buckets 的容量与原来的容量相同 原因 map容量 装载因子\u003e6.5 原来的容量 x2 溢出桶过多 = 原来的容量 片段解读2 oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } 这里是创建新桶数组的部分。首先将旧桶数组保存到 oldbuckets 变量中，然后调用 makeBucketArray 函数创建新的桶数组。如果需要扩容，则新桶数组的大小为原来的两倍；否则，新桶数组的大小与旧桶数组相同。makeBucketArray 函数还会返回一个溢出桶数组，如果有的话。 接下来，代码根据当前 map 的标志位来更新新 map 的标志位。如果当前 map 正在被迭代，则将新 map 的标志位设置为 oldIterator；否则，将其清除 片段解读3 // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 这里是提交扩容操作的部分。首先将 map 的大小增加 bigger（即扩容或横向扩展后的大小），然后更新标志位、旧桶数组和新桶数组。同时，将 nevacuate 和 noverflow 两个计数器清零，表示没有需要迁移的元素和溢出桶 片段解读4 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } 这里是处理溢出桶的部分。如果当前 map 中存在溢出桶，则将其提升到旧桶数组中。如果新桶数组中也存在溢出桶，则将其保存到 extra 字段中 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读2"},{"categories":["Golang"],"content":" hashGrow方法 - 「buckets 扩容」 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 片段解读1 bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) 这段代码主要是判断是由哪种方式引起的扩容，如果是因为装载因子过大导致的扩容，则新 buckets 的容量为原来的两倍，也就是将 bigger 设置为 1，如果是因为溢出桶过多导致的扩容，则新 buckets 的容量与原来的容量相同 原因 map容量 装载因子\u003e6.5 原来的容量 x2 溢出桶过多 = 原来的容量 片段解读2 oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } 这里是创建新桶数组的部分。首先将旧桶数组保存到 oldbuckets 变量中，然后调用 makeBucketArray 函数创建新的桶数组。如果需要扩容，则新桶数组的大小为原来的两倍；否则，新桶数组的大小与旧桶数组相同。makeBucketArray 函数还会返回一个溢出桶数组，如果有的话。 接下来，代码根据当前 map 的标志位来更新新 map 的标志位。如果当前 map 正在被迭代，则将新 map 的标志位设置为 oldIterator；否则，将其清除 片段解读3 // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 这里是提交扩容操作的部分。首先将 map 的大小增加 bigger（即扩容或横向扩展后的大小），然后更新标志位、旧桶数组和新桶数组。同时，将 nevacuate 和 noverflow 两个计数器清零，表示没有需要迁移的元素和溢出桶 片段解读4 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } 这里是处理溢出桶的部分。如果当前 map 中存在溢出桶，则将其提升到旧桶数组中。如果新桶数组中也存在溢出桶，则将其保存到 extra 字段中 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读3"},{"categories":["Golang"],"content":" hashGrow方法 - 「buckets 扩容」 func hashGrow(t *maptype, h *hmap) { // If we've hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and \"grow\" laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } // the actual copying of the hash table data is done incrementally // by growWork() and evacuate(). } 片段解读1 bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) 这段代码主要是判断是由哪种方式引起的扩容，如果是因为装载因子过大导致的扩容，则新 buckets 的容量为原来的两倍，也就是将 bigger 设置为 1，如果是因为溢出桶过多导致的扩容，则新 buckets 的容量与原来的容量相同 原因 map容量 装载因子\u003e6.5 原来的容量 x2 溢出桶过多 = 原来的容量 片段解读2 oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) flags := h.flags \u0026^ (iterator | oldIterator) if h.flags\u0026iterator != 0 { flags |= oldIterator } 这里是创建新桶数组的部分。首先将旧桶数组保存到 oldbuckets 变量中，然后调用 makeBucketArray 函数创建新的桶数组。如果需要扩容，则新桶数组的大小为原来的两倍；否则，新桶数组的大小与旧桶数组相同。makeBucketArray 函数还会返回一个溢出桶数组，如果有的话。 接下来，代码根据当前 map 的标志位来更新新 map 的标志位。如果当前 map 正在被迭代，则将新 map 的标志位设置为 oldIterator；否则，将其清除 片段解读3 // commit the grow (atomic wrt gc) h.B += bigger h.flags = flags h.oldbuckets = oldbuckets h.buckets = newbuckets h.nevacuate = 0 h.noverflow = 0 这里是提交扩容操作的部分。首先将 map 的大小增加 bigger（即扩容或横向扩展后的大小），然后更新标志位、旧桶数组和新桶数组。同时，将 nevacuate 和 noverflow 两个计数器清零，表示没有需要迁移的元素和溢出桶 片段解读4 if h.extra != nil \u0026\u0026 h.extra.overflow != nil { // Promote current overflow buckets to the old generation. if h.extra.oldoverflow != nil { throw(\"oldoverflow is not nil\") } h.extra.oldoverflow = h.extra.overflow h.extra.overflow = nil } if nextOverflow != nil { if h.extra == nil { h.extra = new(mapextra) } h.extra.nextOverflow = nextOverflow } 这里是处理溢出桶的部分。如果当前 map 中存在溢出桶，则将其提升到旧桶数组中。如果新桶数组中也存在溢出桶，则将其保存到 extra 字段中 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读4"},{"categories":["Golang"],"content":" evacuate方法 - 「数据迁移」 片段解读1 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { 获得旧 bucket，判断这个 bucket 是否需要进行迁移（是否迁移完成） 片段解读2 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } ... } 这段代码的作用是为哈希表进行扩容时，计算出旧桶中键值对需要迁移到的新桶的位置。具体来说： 首先定义了一个长度为2的数组xy，用于存储两个疏散目的地（evacDst）。 然后通过指针x指向xy[0]，并将其b字段设置为旧桶中第oldbucket个桶的地址，k字段设置为该桶中数据区域的起始地址，e字段设置为该桶中数据区域的结束地址。 如果哈希表不是同等大小的扩容，则还需要计算第二个疏散目的地y的位置。此时通过指针y指向xy[1]，并将其b、k、e字段分别设置为新桶中第(oldbucket+newbit)个桶的地址、该桶中数据区域的起始地址和结束地址。 当发生的是两倍容量扩容的时候，原先一个桶中的元素会裂变到两个桶中，因为原先使用低 B 位来判断映射到哪个桶，现在需要根据低 B+1 位来判断映射到哪个桶，因此当第 B+1 位为 0 的时候，桶的相对位置与原先的桶是一样的，当第 B+1 位为 1 时，就需要放到两外一个桶中 总之，这段代码的作用是为哈希表扩容时计算出旧桶中键值对需要迁移到的新桶的位置，并将这些位置信息存储在xy数组中。 片段解读3 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That's ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } 该代码中的循环遍历了当前哈希表中所有的桶（bucket），并将其中的元素重新分配到新的哈希表中。具体来说，对于每个桶，它的 tophash 数组中存储了该桶中每个元素的哈希值的前 8 位，如果某个元素的 tophash 值为 evacuatedEmpty，则表示该元素已经被迁移到新的哈希表中；如果 tophash 值小于 minTopHash，则表示哈希表状态错误。 对于每个非空元素，首先根据其键的哈希值计算出它应该被迁移到新哈希表的哪个桶中。如果新哈希表的大小和旧哈希表相同，则直接将元素复制到新哈希表中对应的桶中；否则，需要根据元素的哈希值判断它","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#evacuatehttpsgithubcomgolanggoblobf90b4cd6554f4f20280aa5229cf42650ed47221dsrcruntimemapgol1169方法---数据迁移"},{"categories":["Golang"],"content":" evacuate方法 - 「数据迁移」 片段解读1 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { 获得旧 bucket，判断这个 bucket 是否需要进行迁移（是否迁移完成） 片段解读2 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } ... } 这段代码的作用是为哈希表进行扩容时，计算出旧桶中键值对需要迁移到的新桶的位置。具体来说： 首先定义了一个长度为2的数组xy，用于存储两个疏散目的地（evacDst）。 然后通过指针x指向xy[0]，并将其b字段设置为旧桶中第oldbucket个桶的地址，k字段设置为该桶中数据区域的起始地址，e字段设置为该桶中数据区域的结束地址。 如果哈希表不是同等大小的扩容，则还需要计算第二个疏散目的地y的位置。此时通过指针y指向xy[1]，并将其b、k、e字段分别设置为新桶中第(oldbucket+newbit)个桶的地址、该桶中数据区域的起始地址和结束地址。 当发生的是两倍容量扩容的时候，原先一个桶中的元素会裂变到两个桶中，因为原先使用低 B 位来判断映射到哪个桶，现在需要根据低 B+1 位来判断映射到哪个桶，因此当第 B+1 位为 0 的时候，桶的相对位置与原先的桶是一样的，当第 B+1 位为 1 时，就需要放到两外一个桶中 总之，这段代码的作用是为哈希表扩容时计算出旧桶中键值对需要迁移到的新桶的位置，并将这些位置信息存储在xy数组中。 片段解读3 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That's ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } 该代码中的循环遍历了当前哈希表中所有的桶（bucket），并将其中的元素重新分配到新的哈希表中。具体来说，对于每个桶，它的 tophash 数组中存储了该桶中每个元素的哈希值的前 8 位，如果某个元素的 tophash 值为 evacuatedEmpty，则表示该元素已经被迁移到新的哈希表中；如果 tophash 值小于 minTopHash，则表示哈希表状态错误。 对于每个非空元素，首先根据其键的哈希值计算出它应该被迁移到新哈希表的哪个桶中。如果新哈希表的大小和旧哈希表相同，则直接将元素复制到新哈希表中对应的桶中；否则，需要根据元素的哈希值判断它","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读1-1"},{"categories":["Golang"],"content":" evacuate方法 - 「数据迁移」 片段解读1 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { 获得旧 bucket，判断这个 bucket 是否需要进行迁移（是否迁移完成） 片段解读2 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } ... } 这段代码的作用是为哈希表进行扩容时，计算出旧桶中键值对需要迁移到的新桶的位置。具体来说： 首先定义了一个长度为2的数组xy，用于存储两个疏散目的地（evacDst）。 然后通过指针x指向xy[0]，并将其b字段设置为旧桶中第oldbucket个桶的地址，k字段设置为该桶中数据区域的起始地址，e字段设置为该桶中数据区域的结束地址。 如果哈希表不是同等大小的扩容，则还需要计算第二个疏散目的地y的位置。此时通过指针y指向xy[1]，并将其b、k、e字段分别设置为新桶中第(oldbucket+newbit)个桶的地址、该桶中数据区域的起始地址和结束地址。 当发生的是两倍容量扩容的时候，原先一个桶中的元素会裂变到两个桶中，因为原先使用低 B 位来判断映射到哪个桶，现在需要根据低 B+1 位来判断映射到哪个桶，因此当第 B+1 位为 0 的时候，桶的相对位置与原先的桶是一样的，当第 B+1 位为 1 时，就需要放到两外一个桶中 总之，这段代码的作用是为哈希表扩容时计算出旧桶中键值对需要迁移到的新桶的位置，并将这些位置信息存储在xy数组中。 片段解读3 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That's ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } 该代码中的循环遍历了当前哈希表中所有的桶（bucket），并将其中的元素重新分配到新的哈希表中。具体来说，对于每个桶，它的 tophash 数组中存储了该桶中每个元素的哈希值的前 8 位，如果某个元素的 tophash 值为 evacuatedEmpty，则表示该元素已经被迁移到新的哈希表中；如果 tophash 值小于 minTopHash，则表示哈希表状态错误。 对于每个非空元素，首先根据其键的哈希值计算出它应该被迁移到新哈希表的哪个桶中。如果新哈希表的大小和旧哈希表相同，则直接将元素复制到新哈希表中对应的桶中；否则，需要根据元素的哈希值判断它","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读2-1"},{"categories":["Golang"],"content":" evacuate方法 - 「数据迁移」 片段解读1 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { 获得旧 bucket，判断这个 bucket 是否需要进行迁移（是否迁移完成） 片段解读2 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } ... } 这段代码的作用是为哈希表进行扩容时，计算出旧桶中键值对需要迁移到的新桶的位置。具体来说： 首先定义了一个长度为2的数组xy，用于存储两个疏散目的地（evacDst）。 然后通过指针x指向xy[0]，并将其b字段设置为旧桶中第oldbucket个桶的地址，k字段设置为该桶中数据区域的起始地址，e字段设置为该桶中数据区域的结束地址。 如果哈希表不是同等大小的扩容，则还需要计算第二个疏散目的地y的位置。此时通过指针y指向xy[1]，并将其b、k、e字段分别设置为新桶中第(oldbucket+newbit)个桶的地址、该桶中数据区域的起始地址和结束地址。 当发生的是两倍容量扩容的时候，原先一个桶中的元素会裂变到两个桶中，因为原先使用低 B 位来判断映射到哪个桶，现在需要根据低 B+1 位来判断映射到哪个桶，因此当第 B+1 位为 0 的时候，桶的相对位置与原先的桶是一样的，当第 B+1 位为 1 时，就需要放到两外一个桶中 总之，这段代码的作用是为哈希表扩容时计算出旧桶中键值对需要迁移到的新桶的位置，并将这些位置信息存储在xy数组中。 片段解读3 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That's ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } 该代码中的循环遍历了当前哈希表中所有的桶（bucket），并将其中的元素重新分配到新的哈希表中。具体来说，对于每个桶，它的 tophash 数组中存储了该桶中每个元素的哈希值的前 8 位，如果某个元素的 tophash 值为 evacuatedEmpty，则表示该元素已经被迁移到新的哈希表中；如果 tophash 值小于 minTopHash，则表示哈希表状态错误。 对于每个非空元素，首先根据其键的哈希值计算出它应该被迁移到新哈希表的哪个桶中。如果新哈希表的大小和旧哈希表相同，则直接将元素复制到新哈希表中对应的桶中；否则，需要根据元素的哈希值判断它","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读3-1"},{"categories":["Golang"],"content":" evacuate方法 - 「数据迁移」 片段解读1 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { 获得旧 bucket，判断这个 bucket 是否需要进行迁移（是否迁移完成） 片段解读2 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } ... } 这段代码的作用是为哈希表进行扩容时，计算出旧桶中键值对需要迁移到的新桶的位置。具体来说： 首先定义了一个长度为2的数组xy，用于存储两个疏散目的地（evacDst）。 然后通过指针x指向xy[0]，并将其b字段设置为旧桶中第oldbucket个桶的地址，k字段设置为该桶中数据区域的起始地址，e字段设置为该桶中数据区域的结束地址。 如果哈希表不是同等大小的扩容，则还需要计算第二个疏散目的地y的位置。此时通过指针y指向xy[1]，并将其b、k、e字段分别设置为新桶中第(oldbucket+newbit)个桶的地址、该桶中数据区域的起始地址和结束地址。 当发生的是两倍容量扩容的时候，原先一个桶中的元素会裂变到两个桶中，因为原先使用低 B 位来判断映射到哪个桶，现在需要根据低 B+1 位来判断映射到哪个桶，因此当第 B+1 位为 0 的时候，桶的相对位置与原先的桶是一样的，当第 B+1 位为 1 时，就需要放到两外一个桶中 总之，这段代码的作用是为哈希表扩容时计算出旧桶中键值对需要迁移到的新桶的位置，并将这些位置信息存储在xy数组中。 片段解读3 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That's ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } 该代码中的循环遍历了当前哈希表中所有的桶（bucket），并将其中的元素重新分配到新的哈希表中。具体来说，对于每个桶，它的 tophash 数组中存储了该桶中每个元素的哈希值的前 8 位，如果某个元素的 tophash 值为 evacuatedEmpty，则表示该元素已经被迁移到新的哈希表中；如果 tophash 值小于 minTopHash，则表示哈希表状态错误。 对于每个非空元素，首先根据其键的哈希值计算出它应该被迁移到新哈希表的哪个桶中。如果新哈希表的大小和旧哈希表相同，则直接将元素复制到新哈希表中对应的桶中；否则，需要根据元素的哈希值判断它","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读4-1"},{"categories":["Golang"],"content":" evacuate方法 - 「数据迁移」 片段解读1 b := (*bmap)(add(h.oldbuckets, oldbucket*uintptr(t.bucketsize))) newbit := h.noldbuckets() if !evacuated(b) { 获得旧 bucket，判断这个 bucket 是否需要进行迁移（是否迁移完成） 片段解读2 if !evacuated(b) { // TODO: reuse overflow buckets instead of using new ones, if there // is no iterator using the old buckets. (If !oldIterator.) // xy contains the x and y (low and high) evacuation destinations. var xy [2]evacDst x := \u0026xy[0] x.b = (*bmap)(add(h.buckets, oldbucket*uintptr(t.bucketsize))) x.k = add(unsafe.Pointer(x.b), dataOffset) x.e = add(x.k, bucketCnt*uintptr(t.keysize)) if !h.sameSizeGrow() { // Only calculate y pointers if we're growing bigger. // Otherwise GC can see bad pointers. y := \u0026xy[1] y.b = (*bmap)(add(h.buckets, (oldbucket+newbit)*uintptr(t.bucketsize))) y.k = add(unsafe.Pointer(y.b), dataOffset) y.e = add(y.k, bucketCnt*uintptr(t.keysize)) } ... } 这段代码的作用是为哈希表进行扩容时，计算出旧桶中键值对需要迁移到的新桶的位置。具体来说： 首先定义了一个长度为2的数组xy，用于存储两个疏散目的地（evacDst）。 然后通过指针x指向xy[0]，并将其b字段设置为旧桶中第oldbucket个桶的地址，k字段设置为该桶中数据区域的起始地址，e字段设置为该桶中数据区域的结束地址。 如果哈希表不是同等大小的扩容，则还需要计算第二个疏散目的地y的位置。此时通过指针y指向xy[1]，并将其b、k、e字段分别设置为新桶中第(oldbucket+newbit)个桶的地址、该桶中数据区域的起始地址和结束地址。 当发生的是两倍容量扩容的时候，原先一个桶中的元素会裂变到两个桶中，因为原先使用低 B 位来判断映射到哪个桶，现在需要根据低 B+1 位来判断映射到哪个桶，因此当第 B+1 位为 0 的时候，桶的相对位置与原先的桶是一样的，当第 B+1 位为 1 时，就需要放到两外一个桶中 总之，这段代码的作用是为哈希表扩容时计算出旧桶中键值对需要迁移到的新桶的位置，并将这些位置信息存储在xy数组中。 片段解读3 for ; b != nil; b = b.overflow(t) { k := add(unsafe.Pointer(b), dataOffset) e := add(k, bucketCnt*uintptr(t.keysize)) for i := 0; i \u003c bucketCnt; i, k, e = i+1, add(k, uintptr(t.keysize)), add(e, uintptr(t.elemsize)) { top := b.tophash[i] if isEmpty(top) { b.tophash[i] = evacuatedEmpty continue } if top \u003c minTopHash { throw(\"bad map state\") } k2 := k if t.indirectkey() { k2 = *((*unsafe.Pointer)(k2)) } var useY uint8 if !h.sameSizeGrow() { // Compute hash to make our evacuation decision (whether we need // to send this key/elem to bucket x or bucket y). hash := t.hasher(k2, uintptr(h.hash0)) if h.flags\u0026iterator != 0 \u0026\u0026 !t.reflexivekey() \u0026\u0026 !t.key.equal(k2, k2) { // If key != key (NaNs), then the hash could be (and probably // will be) entirely different from the old hash. Moreover, // it isn't reproducible. Reproducibility is required in the // presence of iterators, as our evacuation decision must // match whatever decision the iterator made. // Fortunately, we have the freedom to send these keys either // way. Also, tophash is meaningless for these kinds of keys. // We let the low bit of tophash drive the evacuation decision. // We recompute a new random tophash for the next level so // these keys will get evenly distributed across all buckets // after multiple grows. useY = top \u0026 1 top = tophash(hash) } else { if hash\u0026newbit != 0 { useY = 1 } } } if evacuatedX+1 != evacuatedY || evacuatedX^1 != evacuatedY { throw(\"bad evacuatedN\") } b.tophash[i] = evacuatedX + useY // evacuatedX + 1 == evacuatedY dst := \u0026xy[useY] // evacuation destination if dst.i == bucketCnt { dst.b = h.newoverflow(t, dst.b) dst.i = 0 dst.k = add(unsafe.Pointer(dst.b), dataOffset) dst.e = add(dst.k, bucketCnt*uintptr(t.keysize)) } dst.b.tophash[dst.i\u0026(bucketCnt-1)] = top // mask dst.i as an optimization, to avoid a bounds check if t.indirectkey() { *(*unsafe.Pointer)(dst.k) = k2 // copy pointer } else { typedmemmove(t.key, dst.k, k) // copy elem } if t.indirectelem() { *(*unsafe.Pointer)(dst.e) = *(*unsafe.Pointer)(e) } else { typedmemmove(t.elem, dst.e, e) } dst.i++ // These updates might push these pointers past the end of the // key or elem arrays. That's ok, as we have the overflow pointer // at the end of the bucket to protect against pointing past the // end of the bucket. dst.k = add(dst.k, uintptr(t.keysize)) dst.e = add(dst.e, uintptr(t.elemsize)) } } 该代码中的循环遍历了当前哈希表中所有的桶（bucket），并将其中的元素重新分配到新的哈希表中。具体来说，对于每个桶，它的 tophash 数组中存储了该桶中每个元素的哈希值的前 8 位，如果某个元素的 tophash 值为 evacuatedEmpty，则表示该元素已经被迁移到新的哈希表中；如果 tophash 值小于 minTopHash，则表示哈希表状态错误。 对于每个非空元素，首先根据其键的哈希值计算出它应该被迁移到新哈希表的哪个桶中。如果新哈希表的大小和旧哈希表相同，则直接将元素复制到新哈希表中对应的桶中；否则，需要根据元素的哈希值判断它","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#片段解读5"},{"categories":["Golang"],"content":" 两种扩容方式 原因 map容量 装载因子\u003e6.5 原来的容量 x2 溢出桶过多 = 原来的容量 ","date":"2023-05-26","objectID":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/:4:3","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的扩容机制","uri":"/202305261624-golang-%E4%B8%AD-map-%E7%9A%84%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/#两种扩容方式"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#dlv #Golang #调试 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 生成汇编文件（如果需要查看一些底层的函数调用，可以使用这个方式来查看） go build -gcflags \"-N -l -S\" main.go 2\u003e main.s 开始调试 dlv debug main.go 使用 help 查看支持的命令： 运行程序： call ------------------------ 恢复进程，注入一个函数调用（实验性的！！）。 continue (别名: c) --------- 运行到断点或程序终止。 next (alias: n) ------------- 跨越到下一个源代码行。 rebuild --------------------- 重建目标可执行文件并重新启动它。如果该可执行文件不是由delve构建的，它就不起作用。 restart (alias: r) ---------- 重新启动进程。 step (别名: s) ------------- 在程序中进行单步操作。 step-instruction (alias: si) 单步执行一条cpu指令。 stepout (alias: so) --------- 走出当前函数。 操纵断点： break (alias: b) ------- 设置一个断点。 breakpoints (alias: bp) 打印出活动断点的信息。 clear ------------------ 删除断点。 clearall --------------- 删除多个断点。 condition (别名: cond) 设置断点条件。 on --------------------- 当断点被击中时，执行一条命令。 toggle ----------------- 开启或关闭一个断点。 trace (alias: t) ------- 设置跟踪点。 watch ------------------ 设置观察点。 查看程序变量和内存： args ----------------- 打印函数参数。 display -------------- 每次程序停止时打印表达式的值。 examinemem (alias: x) 检查指定地址的原始内存。 locals --------------- 打印局部变量。 print (alias: p) ----- 评估一个表达式。 regs ----------------- 打印CPU寄存器的内容。 set ------------------ 改变一个变量的值。 vars ----------------- 打印软件包变量。 whatis --------------- 打印一个表达式的类型。 列出并在线程和goroutine之间切换： goroutine (alias: gr) -- 显示或改变当前的goroutine goroutines (alias: grs) 列出程序的goroutine。 thread (alias: tr) ----- 切换到指定的线程。 threads ---------------- 打印出每个被追踪的线程的信息。 查看调用栈和选择帧： deferred --------- 在一个延迟调用的背景下执行命令。 down ------------- 将当前帧向下移动。 frame ------------ 设置当前帧，或在不同的帧上执行命令。 stack (alias: bt) 打印堆栈跟踪。 up --------------- 将当前帧向上移动。 其他命令： config --------------------- 更改配置参数。 disassemble (alias: disass) 反汇编程序。 dump ----------------------- 从当前进程状态创建一个核心转储。 edit (alias: ed) ----------- 打开你在$DELVE_EDITOR或$EDITOR中的位置 exit (alias: quit | q) ----- 退出调试器。 funcs ---------------------- 打印函数的列表。 help (alias: h) ------------ 打印帮助信息。 libraries ------------------ 列出加载的动态库 list (alias: ls | l) ------- 显示源代码。 source --------------------- 执行一个包含delve命令列表的文件 sources -------------------- 打印源文件的列表。 transcript ----------------- 将命令输出附加到一个文件中。 types ---------------------- 打印类型列表 熟悉一些常用的操作就行了： break main.main —\u003e 使用 break 给 main 函数打一个断点 c —\u003e continue，继续执行程序，「直到下一个断点」 s —\u003e step，继续执行，「进入函数」 n —\u003e next，继续执行，「不进入函数」 bp —\u003e breakpoints 查看「断点列表」 vars main —\u003e 查看包级变量 locals —\u003e 查看局部变量 display -a val —\u003e 每一步都显示变量 val 的值 ","date":"2023-05-26","objectID":"/202305261503-%E4%BD%BF%E7%94%A8-dlv-%E5%91%BD%E4%BB%A4%E6%9D%A5%E8%B0%83%E8%AF%95-golang-%E7%A8%8B%E5%BA%8F/:0:0","series":["card"],"tags":[],"title":"使用 dlv 命令来调试 golang 程序","uri":"/202305261503-%E4%BD%BF%E7%94%A8-dlv-%E5%91%BD%E4%BB%A4%E6%9D%A5%E8%B0%83%E8%AF%95-golang-%E7%A8%8B%E5%BA%8F/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 场景实操记录","date":"2023-05-26","objectID":"/202305261503-%E4%BD%BF%E7%94%A8-dlv-%E5%91%BD%E4%BB%A4%E6%9D%A5%E8%B0%83%E8%AF%95-golang-%E7%A8%8B%E5%BA%8F/:1:0","series":["card"],"tags":[],"title":"使用 dlv 命令来调试 golang 程序","uri":"/202305261503-%E4%BD%BF%E7%94%A8-dlv-%E5%91%BD%E4%BB%A4%E6%9D%A5%E8%B0%83%E8%AF%95-golang-%E7%A8%8B%E5%BA%8F/#场景实操记录"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 调试 for 循环的例子通常使用 break + condition func main() { testFor() } func testFor() { cnt := 0 for i := 0; i \u003c 10; i++ { cnt ++ } return } 调试过程： dlv debug main.go Type 'help' for list of commands. (dlv) break main.main Breakpoint 1 set at 0xf9ef46 for main.main() d:/code/hhq-notes/算法/leetcode/main.go:3 (dlv) c \u003e main.main() d:/code/hhq-notes/算法/leetcode/main.go:3 (hits goroutine(1):1 total:1) (PC: 0xf9ef46) 1: package main 2: =\u003e 3: func main() { 4: testFor() 5: } 6: 7: func testFor() { 8: cnt := 0 ... 略 (dlv) s \u003e main.testFor() d:/code/hhq-notes/算法/leetcode/main.go:8 (PC: 0xf9ef8e) ... 7: func testFor() { =\u003e 8: cnt := 0 9: for i := 0; i \u003c 10; i++ { 10: cnt ++ 11: } 12: return 13: } (dlv) break main.go:10 Breakpoint 2 set at 0xf9efab for main.testFor() d:/code/hhq-notes/算法/leetcode/main.go:10 (dlv) condition 2 i==2 (dlv) c \u003e main.testFor() d:/code/hhq-notes/算法/leetcode/main.go:10 (hits goroutine(1):1 total:1) (PC: 0xf9efab) 5: } 6: 7: func testFor() { 8: cnt := 0 9: for i := 0; i \u003c 10; i++ { =\u003e 10: cnt ++ 11: } 12: return 13: } (dlv) locals cnt = 2 i = 2 ... 其中第 28 行表示设置第二个断点生效的条件是当 i = 2 顺带看一下 stack、goroutines 的结果： (dlv) stack 0 0x0000000000f9efba in main.testFor at d:/code/hhq-notes/算法/leetcode/main.go:9 1 0x0000000000f9ef57 in main.main at d:/code/hhq-notes/算法/leetcode/main.go:4 2 0x0000000000f75088 in runtime.main at c:/go/go1.18/src/runtime/proc.go:250 3 0x0000000000f998c1 in runtime.goexit at c:/go/go1.18/src/runtime/asm_amd64.s:1571 (dlv) goroutines * Goroutine 1 - User: d:/code/hhq-notes/算法/leetcode/main.go:9 main.testFor (0xf9efba) (thread 18412) Goroutine 2 - User: c:/go/go1.18/src/runtime/proc.go:362 runtime.gopark (0xf75472) [force gc (idle)] Goroutine 3 - User: c:/go/go1.18/src/runtime/proc.go:362 runtime.gopark (0xf75472) [GC sweep wait] Goroutine 4 - User: c:/go/go1.18/src/runtime/proc.go:362 runtime.gopark (0xf75472) [GC scavenge wait] [4 goroutines] ","date":"2023-05-26","objectID":"/202305261503-%E4%BD%BF%E7%94%A8-dlv-%E5%91%BD%E4%BB%A4%E6%9D%A5%E8%B0%83%E8%AF%95-golang-%E7%A8%8B%E5%BA%8F/:1:1","series":["card"],"tags":[],"title":"使用 dlv 命令来调试 golang 程序","uri":"/202305261503-%E4%BD%BF%E7%94%A8-dlv-%E5%91%BD%E4%BB%A4%E6%9D%A5%E8%B0%83%E8%AF%95-golang-%E7%A8%8B%E5%BA%8F/#调试-for-循环的例子"},{"categories":["生活记录"],"content":"🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-26","objectID":"/2023-05-26/:0:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-26 日记录","uri":"/2023-05-26/#"},{"categories":["生活记录"],"content":" 规划区 「效率」学习、记录流程优化，减少学习、记录之间切换的频繁程度，一方面减少思维转换，另一方面减少浪费的时间，提高效率 「golang - 1h」使用 dlv 命令来调试 golang 程序，熟悉新的调试方式中的「流程控制」字符以及界面「输出方式」 「golang - 2h」学习 go map 的扩容机制 「golang - 1h30m」golang GMP 模型 「kubernetes」整理 kubernetes 相关学习内容 「信息搜索 - 1h」搜索一些kubernetes、计算机网络、操作系统的一些「学习站点」、「面经」 「golang」 context Tomorrow： nil ","date":"2023-05-26","objectID":"/2023-05-26/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-26 日记录","uri":"/2023-05-26/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 216. 组合总和 III 547. 省份数量 1679. K 和数对的最大数目 英语 单词 口语 ","date":"2023-05-26","objectID":"/2023-05-26/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-26 日记录","uri":"/2023-05-26/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-26","objectID":"/2023-05-26/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-26 日记录","uri":"/2023-05-26/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） 看了这篇文章之后真有感触啊，不太清楚自己到底是不是适合做软件工程这行的工作，「技术总是学不完的」在近期的知识学习中越来越深感自己的无知，技术相关的东西那么多，可能我穷极一生都是学不完的，旧的东西已经很多了，新的东西一直在出来，如果自己一直以学习技术为信条，恐怕永远都只能够这样子，受限于学习技术，而很难有创新。当然，这也并非绝对的，创造也要基于一些基础，知识感觉自己需要流出更多的空间来多思考一些新奇的想法，如果觉得好玩、有意义就去实现它。 学习流程能否优化？ 「分类」「系列」「专题」「标签」 现在博客中可以使用分类、系列、标签来归档文章了。 Goland 2023.1 版本激活：https://blog.idejihuo.com/jetbrains/intellij-idea-2023-1-the-latest-crack-tutorial-permanent-activation-graphic-crack-tutorial.html ","date":"2023-05-26","objectID":"/2023-05-26/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-26 日记录","uri":"/2023-05-26/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） ","date":"2023-05-26","objectID":"/2023-05-26/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-26 日记录","uri":"/2023-05-26/#记录区-总结"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#k8s #故障排除 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 https://learnk8s.io/troubleshooting-deployments ","date":"2023-05-25","objectID":"/202305252359-kubernetes-%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97/:0:0","series":["card"],"tags":[],"title":"Kubernetes 故障排除可视化指南","uri":"/202305252359-kubernetes-%E6%95%85%E9%9A%9C%E6%8E%92%E9%99%A4%E5%8F%AF%E8%A7%86%E5%8C%96%E6%8C%87%E5%8D%97/#"},{"categories":["Golang"],"content":"#golang #map #底层原理 ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:0:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#"},{"categories":["Golang"],"content":" 一、对哈希表的回顾一种最简单的情况，是使用数组来实现哈希表： 哈希冲突 的产生：多个 key 经过哈希函数之后的结果相同 哈希冲突如何解决： 扩大容量 优化哈希表的表示来缓解哈希冲突 链式地址 开放寻址 负载因子：元素数量/桶数量，通常用负载因子来描述哈希表中冲突产生的严重程度 通常当负载因子 ——大于 0.75—–\u003e 扩容 ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:1:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#一对哈希表的回顾"},{"categories":["Golang"],"content":" 冲突解决 - 链式地址当冲突发生，即不同的 key 被映射到同一个值，将 单个元素转变成链表，发生冲突的元素都被放在这个链表中。跟开放寻址的方式比较，链式地址引入新的数据结构，每个元素除了要保存 (key, value) 键值对，还需要 保存指向下一个节点的指针，增加了空间开销 相当于图的邻接表实现 local 202305040737 图基础 操作 描述 查询 计算哈希函数结果得到索引，再遍历链表寻找元素 增加 计算哈希函数结果得到索引，添加到链表头节点 删除 计算哈希函数结果得到索引，再遍历链表删除元素 可以发现在得到索引后都会有一个遍历链表的操作，可以通过优化链表的表现形式，来减少操作的时间，比如：将链表转化成 平衡二叉搜索树 或者 红黑树 local 202305222352 平衡二叉搜索树-AVL ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:1:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#冲突解决---链式地址"},{"categories":["Golang"],"content":" 冲突解决 - 开放寻址开放寻址不引入额外数据结构，通过「多次探测」来解决冲突 探测的方式通常有： 线性探测 平方探测 多次哈希 探测方式 冲突产生时步骤 缺点 线性探测 从冲突位置向后遍历（步长通常为 1），知道找到空位 伪删除、元素聚集 多次哈希 如果第一个哈希函数结果冲突，尝试使用第二个哈希函数来计算，直到不冲突 额外计算 ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:1:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#冲突解决---开放寻址"},{"categories":["Golang"],"content":" 二、Golang 如何实现 mapgo 语言中，解决冲突采用链式地址的方式，规定每个桶最多存储 8 个键值对，超出容量则链接一个溢出桶，当溢出桶过多，执行一次特殊的等量扩容，当 map 的装载因子 \u003e 6.5，执行一次 2 倍容量的扩容 ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:2:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#二golang-如何实现-map"},{"categories":["Golang"],"content":" 2.1 hmap 和 bmap这是包含 hmap 和 bmap 的一个抽象模型图： hmap 结构体： type hmap struct { count int flags uint8 B uint8 noverflow uint16 hash0 uint32 buckets unsafe.Pointer oldbuckets unsafe.Pointer nevacuate uintptr extra *mapextra } type mapextra struct { overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap } 上图中 hmap.buckets 指向的是一个 bmap 的列表，大小为 2^B 一个桶 bmap 的结构体： type bmap struct { tophash [bucketCnt]uint8 } 在编译期间，会产生一个新的 bmap 结构： type bmap struct { topbits [8]uint8 keys [8]keytype values [8]valuetype pad uintptr overflow uintptr } 假设当有 9 个元素被放到同一个桶，会创建一个新的「溢出桶」，用来存放溢出的元素。 看一下 bmap 具体是如何保存键值对的，这是一个 bmap 的内存模型图： hob hash 指的是 top hash，也就是哈希值的「高 8 位」，同时 key 与 value 的存放是分别连续的，而不是 key-value-key-value… 的形式，为的是避免字节对齐带来的内存浪费，假设一个哈希值高 8 位对应的是桶的第一个位置，那么它保存的元素应该是： ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:2:1","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#21-hmap-和-bmap"},{"categories":["Golang"],"content":" 2.2 哈希函数 与 key 的定位// todo 哈希函数的 选择 在经过哈希函数处理后得到的哈希值有 64 bit（在 64 位的机器上），假设下面是一个哈希值 其中最低的 B 位用来确定在哪个桶，高 8 位用来确定在桶的哪个位置。上面这个例子中，B 为 5，map 中有 2^5 = 32 个 bucket，01010 代表的二进制数为 10，也就说明这个 key 应该落在 10 号桶，当元素找到属于的桶之后，会从前往后遍历桶的八个位置，找到一个空的位置就放入，如果不存在空位置，那么就按同样的方法在 overflow 中寻找。 ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:2:2","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#22-哈希函数-与-key-的定位"},{"categories":["Golang"],"content":" 总结心得相比于传统的哈希表采用的链地址法来解决哈希冲突，go map 的实现也采用到了这个方法，传统的链地址法中，每个节点保存的是一个元素，每个节点都需要一个额外的内存来保存下一个节点的指针，造成了不少的空间开销，go 采用了短数组+链表的形式，相当于每个节点保存的是一个桶，每个桶中可以保存 8 个元素，但与链地址法不同的是，Go 中是不会让这个链表变得太长的，具体涉及到 map 的扩容机制。 https://www.hello-algo.com/chapter_hashing/hash_map/`` https://segmentfault.com/a/1190000039101378 https://blog.csdn.net/xiaodaoge_it/article/details/121297144 ","date":"2023-05-25","objectID":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/:3:0","series":["Golang底层分析、源码学习"],"tags":["map"],"title":"Golang 中 map 的实现","uri":"/202305251159-golang-%E4%B8%AD-map-%E7%9A%84%E5%AE%9E%E7%8E%B0/#总结心得"},{"categories":["生活记录"],"content":" 规划区 学习生成 go 的汇编文件，并使用 dlv 来调试 回溯算法 go map 的底层实现 ","date":"2023-05-25","objectID":"/2023-05-25/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-25 日记录","uri":"/2023-05-25/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-25","objectID":"/2023-05-25/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-25 日记录","uri":"/2023-05-25/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-25","objectID":"/2023-05-25/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-25 日记录","uri":"/2023-05-25/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-25","objectID":"/2023-05-25/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-25 日记录","uri":"/2023-05-25/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） 202305250952 回溯算法 202305251159 Golang 中 map 的实现 ","date":"2023-05-25","objectID":"/2023-05-25/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-25 日记录","uri":"/2023-05-25/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天 看一下 go map 的扩容机制 ","date":"2023-05-25","objectID":"/2023-05-25/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-25 日记录","uri":"/2023-05-25/#记录区-明天"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#算法 #回溯 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-25","objectID":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/:0:0","series":["card"],"tags":["回溯"],"title":"回溯算法","uri":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一、什么是回溯算法回溯算法Backtracking的本质就是穷举可能的情况，将符合的预期的情况加入结果集的方法 回溯算法通常分为两个步骤：「尝试」与「回退」 尝试：选择下一种可能 回退：当某个状态无法继续前进，或者已经能够判断无法得到满足的解时，回到之前的状态，继续尝试其他可能 回溯算法的优化： 剪枝：通过题目给定的约束条件，减少穷举的情况 比如： ","date":"2023-05-25","objectID":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/:1:0","series":["card"],"tags":["回溯"],"title":"回溯算法","uri":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/#一什么是回溯算法"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 二、回溯通用化模版 /* 回溯算法框架 */func backtrack(state *State, choices []Choice, res *[]State) { // 判断是否为解 if isSolution(state) { // 记录解 recordSolution(state, res) return } // 遍历所有选择 for _, choice := range choices { // 剪枝：判断选择是否合法 if !isValid(state, choice) { continue } // 尝试：做出选择，更新状态 makeChoice(state, choice) backtrack(state, choices, res) // 回退：撤销选择，恢复到之前的状态 undoChoice(state, choice) } } state：已经作出的选择组合成的状态 choices：可以作出的选择 一个通用的模版应该包括：检查 - 剪枝 - 尝试 - 回退 ","date":"2023-05-25","objectID":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/:2:0","series":["card"],"tags":["回溯"],"title":"回溯算法","uri":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/#二回溯通用化模版"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 三、例题 在二叉树中搜索所有值为 7 的节点，返回根节点到这些节点的路径。条件：路径中不能包含值为 3 的节点 func backtracking1(state *[]*treeNode, choices *[]*treeNode, ans *[][]*treeNode) { /* 检查是否符合解的条件 */ if len(*state) != 0 \u0026\u0026 (*state)[len(*state)-1].val == 7 { tmpState := make([]*treeNode, len(*state)) copy(tmpState, *state) *ans = append(*ans, tmpState) return } for _, choice := range *choices { /* 根据给定条件剪枝 */ if !(choice != nil \u0026\u0026 choice.val != 3) { continue } *state = append(*state, choice) // 尝试 backtracking1(state, \u0026[]*treeNode{choice.left, choice.right}, ans) // 回退 *state = (*state)[:len(*state)-1] } } 测试： func TestBT01() { root := \u0026treeNode{ val: 1, left: \u0026treeNode{ val: 7, left: \u0026treeNode{ val: 4, }, right: \u0026treeNode{ val: 5, }, }, right: \u0026treeNode{ val: 5, left: \u0026treeNode{ val: 6, left: \u0026treeNode{ val: 3, }, }, right: \u0026treeNode{val: 7}, }, } var state []*treeNode var ans [][]*treeNode backtracking1(\u0026state, \u0026[]*treeNode{root}, \u0026ans) for _, path := range ans { fmt.Print(\"path:\\t\") for _, node := range path { fmt.Print(node.val, \",\") } fmt.Println() } } out: path: 1,7, path: 1,5,7, 17. 电话号码的字母组合 func letterCombinations(digits string) []string { if digits == \"\" { return []string{} } var state []byte digitsBs := []byte(digits) var ans []string helper(\u0026state, digitsBs, \u0026ans) return ans } var number2chs = map[int][]byte{ 2: {'a', 'b', 'c'}, 3: {'d', 'e', 'f'}, 4: {'g', 'h', 'i'}, 5: {'j', 'k', 'l'}, 6: {'m', 'n', 'o'}, 7: {'p', 'q', 'r', 's'}, 8: {'t', 'u', 'v'}, 9: {'w', 'x', 'y', 'z'}, } func helper(state *[]byte, digits []byte, ans *[]string) { /*检查是否符合解的条件*/ if len(digits) == 0 { *ans = append(*ans, string(*state)) return } num, _ := strconv.Atoi(string(digits[0])) choices := number2chs[num] for _, choice := range choices { /*没有剪枝条件*/ //if !() { // continue //} /*尝试*/ *state = append(*state, choice) helper(state, digits[1:], ans) /*回退*/ *state = (*state)[:len(*state)-1] } } https://www.hello-algo.com/chapter_backtracking/backtracking_algorithm/#1211 ","date":"2023-05-25","objectID":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/:3:0","series":["card"],"tags":["回溯"],"title":"回溯算法","uri":"/202305250952-%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/#三例题"},{"categories":["Golang"],"content":" 观察测试结果测试来自项目go-tutorial的其中一个片段： https://github.com/jincheng9/go-tutorial/blob/main/workspace/senior/p28/pointer/pointer_test.go 先给出这个基准测试的一些结果： honghuiqiang@192 pointer % go test -bench . goos: darwin goarch: arm64 pkg: pointer BenchmarkByPointer-8 25197861 48.82 ns/op BenchmarkByValue-8 37650502 31.92 ns/op PASS ok pointer 3.511s honghuiqiang@192 pointer % go test -bench . goos: darwin goarch: arm64 pkg: pointer BenchmarkByPointer-8 25348558 48.21 ns/op BenchmarkByValue-8 37798746 31.40 ns/op PASS ok pointer 3.525 结果： 使用 指针传递更节省内存，这是显然的 使用指针传递比使用值传递更慢，这是为什么？既然省去了新开辟内存的时间，不应该更快吗？ ","date":"2023-05-24","objectID":"/202305241402-%E4%BD%BF%E7%94%A8%E5%80%BC%E6%8C%87%E9%92%88%E4%BD%9C%E4%B8%BA%E6%96%B9%E6%B3%95%E7%9A%84%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%80%E7%82%B9%E5%8C%BA%E5%88%AB/:1:0","series":["Golang底层分析、源码学习"],"tags":["指针参数"],"title":"使用值、指针作为方法的参数的一点区别","uri":"/202305241402-%E4%BD%BF%E7%94%A8%E5%80%BC%E6%8C%87%E9%92%88%E4%BD%9C%E4%B8%BA%E6%96%B9%E6%B3%95%E7%9A%84%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%80%E7%82%B9%E5%8C%BA%E5%88%AB/#观察测试结果"},{"categories":["Golang"],"content":" 为什么指针传递比值传递更慢？给出该测试具体的代码： type foo struct { ID string `json:\"_id\"` Index int `json:\"index\"` GUID string `json:\"guid\"` IsActive bool `json:\"isActive\"` Balance string `json:\"balance\"` Picture string `json:\"picture\"` Age int `json:\"age\"` EyeColor string `json:\"eyeColor\"` Name string `json:\"name\"` Gender string `json:\"gender\"` Company string `json:\"company\"` Email string `json:\"email\"` Phone string `json:\"phone\"` Address string `json:\"address\"` About string `json:\"about\"` Registered string `json:\"registered\"` Latitude float64 `json:\"latitude\"` Longitude float64 `json:\"longitude\"` Greeting string `json:\"greeting\"` FavoriteFruit string `json:\"favoriteFruit\"` } type bar struct { ID string Index int GUID string IsActive bool Balance string Picture string Age int EyeColor string Name string Gender string Company string Email string Phone string Address string About string Registered string Latitude float64 Longitude float64 Greeting string FavoriteFruit string } var input foo func init() { err := json.Unmarshal([]byte(`{ \"_id\": \"5d2f4fcf76c35513af00d47e\", \"index\": 1, \"guid\": \"ed687a14-590b-4d81-b0cb-ddaa857874ee\", \"isActive\": true, \"balance\": \"$3,837.19\", \"picture\": \"http://placehold.it/32x32\", \"age\": 28, \"eyeColor\": \"green\", \"name\": \"Rochelle Espinoza\", \"gender\": \"female\", \"company\": \"PARLEYNET\", \"email\": \"rochelleespinoza@parleynet.com\", \"phone\": \"+1 (969) 445-3766\", \"address\": \"956 Little Street, Jugtown, District Of Columbia, 6396\", \"about\": \"Excepteur exercitation labore ut cupidatat laboris mollit ad qui minim aliquip nostrud anim adipisicing est. Nisi sunt duis occaecat aliquip est irure Lorem irure nulla tempor sit sunt. Eiusmod laboris ex est velit minim ut cillum sunt laborum labore ad sunt.\\r\\n\", \"registered\": \"2016-03-20T12:07:25 -00:00\", \"latitude\": 61.471517, \"longitude\": 54.01596, \"greeting\": \"Hello, Rochelle Espinoza!You have 9 unread messages.\", \"favoriteFruit\": \"banana\" }`), \u0026input) if err != nil { panic(err) } } func byPointer(in *foo) *bar { return \u0026bar{ ID: in.ID, Address: in.Address, Email: in.Email, Index: in.Index, Name: in.Name, About: in.About, Age: in.Age, Balance: in.Balance, Company: in.Company, EyeColor: in.EyeColor, FavoriteFruit: in.FavoriteFruit, Gender: in.Gender, Greeting: in.Greeting, GUID: in.GUID, IsActive: in.IsActive, Latitude: in.Latitude, Longitude: in.Longitude, Phone: in.Phone, Picture: in.Picture, Registered: in.Registered, } } func byValue(in foo) bar { return bar{ ID: in.ID, Address: in.Address, Email: in.Email, Index: in.Index, Name: in.Name, About: in.About, Age: in.Age, Balance: in.Balance, Company: in.Company, EyeColor: in.EyeColor, FavoriteFruit: in.FavoriteFruit, Gender: in.Gender, Greeting: in.Greeting, GUID: in.GUID, IsActive: in.IsActive, Latitude: in.Latitude, Longitude: in.Longitude, Phone: in.Phone, Picture: in.Picture, Registered: in.Registered, } } var pointerResult *bar func BenchmarkByPointer(b *testing.B) { var r *bar b.ResetTimer() for i := 0; i \u003c b.N; i++ { r = byPointer(\u0026input) } pointerResult = r } var valueResult bar func BenchmarkByValue(b *testing.B) { var r bar b.ResetTimer() for i := 0; i \u003c b.N; i++ { r = byValue(input) } valueResult = r } 两个方法： func byPointer(in *foo) *bar { // 访问 in 的所有字段 } func byValue(in foo) bar { // 访问 in 的所有字段 } 设传递指针的方法花费的时间 pTime, 值传递的方法花费的时间 vTime，结构体的字段数量 m pTime = 拷贝一次指针 + m * (指针解引用 + 访问字段) vTime = 拷贝一次结构体 + m * 访问字段 当传递的是结构体指针类型，访问字段需要两个步骤，一次是指针解引用，一次是访问字段，而传递结构体值，不需要指针解引用，因此两个方法时间的不同主要体现在 拷贝参数的时间 以及传递指针需要额外的 m 次 指针解引用 的时间。 上面的例子中 vTime \u003c pTime 是因为 拷贝一次结构体 \u003c 拷贝一次指针 + m 次指针解引用，这种情况通常发生在结构体的尺寸较小的情况下，那么如果让结构体的尺寸变得很大，增加拷贝结构体的时间，能否达到指针方法用时更短的效果 稍微做一下修改，传参分别使用保存指针的切片跟保存值的数组，观察一下结果： const N = 10000 var inputs [N]foo var inputsPtr []*foo func init() { testTxt := []byte(`{ \"_id\": \"5d2f4fcf76c35513af00d47e\", \"index\": 1, \"guid\": \"ed687a14-590b-4d81-b0cb-ddaa857874ee\", \"isActive\": true, \"balance\": \"$3,837.19\", \"picture\": \"http://placehold.it/32x32\", \"age\": 28, \"eyeColor\": \"green\", \"name\": \"Rochelle Espinoza\", \"gender\": \"female\", \"company\": \"PAR","date":"2023-05-24","objectID":"/202305241402-%E4%BD%BF%E7%94%A8%E5%80%BC%E6%8C%87%E9%92%88%E4%BD%9C%E4%B8%BA%E6%96%B9%E6%B3%95%E7%9A%84%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%80%E7%82%B9%E5%8C%BA%E5%88%AB/:2:0","series":["Golang底层分析、源码学习"],"tags":["指针参数"],"title":"使用值、指针作为方法的参数的一点区别","uri":"/202305241402-%E4%BD%BF%E7%94%A8%E5%80%BC%E6%8C%87%E9%92%88%E4%BD%9C%E4%B8%BA%E6%96%B9%E6%B3%95%E7%9A%84%E5%8F%82%E6%95%B0%E7%9A%84%E4%B8%80%E7%82%B9%E5%8C%BA%E5%88%AB/#为什么指针传递比值传递更慢"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 知识交流 1.整理一个跟阿能交流信息的地方:done, 19:00, 1h section 习惯 算法每日一题:done, 1h ","date":"2023-05-24","objectID":"/2023-05-24/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-24 日记录","uri":"/2023-05-24/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 797. 所有可能的路径 （跟题目： 剑指 Offer II 110. 所有路径 是一样的） 剑指 Offer II 086. 分割回文子字符串 ","date":"2023-05-24","objectID":"/2023-05-24/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-24 日记录","uri":"/2023-05-24/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-24","objectID":"/2023-05-24/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-24 日记录","uri":"/2023-05-24/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） 「我已经尝到了活在这个世界上的幸福」 ","date":"2023-05-24","objectID":"/2023-05-24/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-24 日记录","uri":"/2023-05-24/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） local 202305240057 图的遍历 remote 202305240057 图的遍历 local 202305241402 使用值、指针作为方法的参数的一点区别 ","date":"2023-05-24","objectID":"/2023-05-24/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-24 日记录","uri":"/2023-05-24/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-24","objectID":"/2023-05-24/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-24 日记录","uri":"/2023-05-24/#记录区-明天"},{"categories":["数据结构与算法"],"content":" 一、两种遍历方式 BFSBreadth First Search：广度优先 DFSDepth First Search：深度优先 ","date":"2023-05-24","objectID":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/:1:0","series":["数据结构"],"tags":["图"],"title":"图的遍历","uri":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/#一两种遍历方式"},{"categories":["数据结构与算法"],"content":" 1.1 广度优先 ","date":"2023-05-24","objectID":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/:1:1","series":["数据结构"],"tags":["图"],"title":"图的遍历","uri":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/#11-广度优先"},{"categories":["数据结构与算法"],"content":" 1.2 深度优先 ","date":"2023-05-24","objectID":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/:1:2","series":["数据结构"],"tags":["图"],"title":"图的遍历","uri":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/#12-深度优先"},{"categories":["数据结构与算法"],"content":" 二、代码实现","date":"2023-05-24","objectID":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/:2:0","series":["数据结构"],"tags":["图"],"title":"图的遍历","uri":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/#二代码实现"},{"categories":["数据结构与算法"],"content":" 2.1 BFS func (g *graphAdjMp) bfs(startVt vertex) []vertex { if g.adjMp == nil { fmt.Println(\"graph is nil\") } var queue []vertex visited := make(map[vertex]struct{}) var visitRst []vertex // visitRst 用来存储访问结果 visitRst = append(visitRst, startVt) // 标记已经访问 visited[startVt] = struct{}{} queue = append(queue, startVt) for len(queue) \u003e 0 { cur := queue[0] queue = queue[1:] // 遍历相邻节点，如果还没访问，就访问，并加入队列 for toVt, _ := range g.adjMp[cur] { if _, ok := visited[toVt]; ok { // 节点已经访问过，跳过 continue } visitRst = append(visitRst, toVt) visited[toVt] = struct{}{} queue = append(queue, toVt) } } return visitRst } 时间复杂度，所有的节点都会入队列一次，时间 O(|V|)，每条边都会遍历两次，时间 O(2|E|)，总的时间复杂度 O(|V|+|E|) 测试 var edges = [][]vertex { {vertex{val: 1},vertex{val: 2}}, {vertex{val: 1},vertex{val: 3}}, {vertex{val: 2},vertex{val: 1}}, {vertex{val: 2},vertex{val: 4}}, {vertex{val: 2},vertex{val: 5}}, {vertex{val: 3},vertex{val: 1}}, {vertex{val: 3},vertex{val: 4}}, {vertex{val: 4},vertex{val: 3}}, {vertex{val: 4},vertex{val: 2}}, {vertex{val: 4},vertex{val: 5}}, } func TestGraphBFS() { g := newGraphAdjMp(edges) if g.adjMp == nil { return } // 从某个节点开始遍历 for vt := range g.adjMp { // 标记为已访问 visitRst := g.bfs(vt) for _, vt := range visitRst { fmt.Println(\"visit rst:\", vt) } break } } visit rst: {5} visit rst: {2} visit rst: {4} visit rst: {1} visit rst: {3} ","date":"2023-05-24","objectID":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/:2:1","series":["数据结构"],"tags":["图"],"title":"图的遍历","uri":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/#21-bfs"},{"categories":["数据结构与算法"],"content":" 2.2 DFS func (g *graphAdjMp) dfs(startVt vertex) []vertex { visited := make(map[vertex]struct{}) var visitRst []vertex g.dfsHelper(startVt, visited, \u0026visitRst) return visitRst } func (g *graphAdjMp) dfsHelper(startVt vertex, visited map[vertex]struct{}, visitRst *[]vertex) { *visitRst = append(*visitRst, startVt) visited[startVt] = struct{}{} for toVt := range g.adjMp[startVt] { if _, ok := visited[toVt]; ok { continue } g.dfsHelper(toVt, visited, visitRst) } } https://www.hello-algo.com/chapter_graph/graph_traversal/#932 ","date":"2023-05-24","objectID":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/:2:2","series":["数据结构"],"tags":["图"],"title":"图的遍历","uri":"/202305240057-%E5%9B%BE%E7%9A%84%E9%81%8D%E5%8E%86/#22-dfs"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 算法 1.avl: done, 12:00, 3h 2.图、基础操作重新整理一下: done, 21:00, 1h section 习惯 算法每日一题: 1h ","date":"2023-05-23","objectID":"/2023-05-23/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-23 日记录","uri":"/2023-05-23/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-23","objectID":"/2023-05-23/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-23 日记录","uri":"/2023-05-23/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-23","objectID":"/2023-05-23/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-23 日记录","uri":"/2023-05-23/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-23","objectID":"/2023-05-23/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-23 日记录","uri":"/2023-05-23/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容：（这部分应该是必须的！后续如果想要使用艾宾浩斯方法来回顾，这里会是一个很好的入口） local 202305222352 平衡二叉搜索树-AVL remote 202305222352 平衡二叉搜索树-AVL ","date":"2023-05-23","objectID":"/2023-05-23/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-23 日记录","uri":"/2023-05-23/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-23","objectID":"/2023-05-23/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-23 日记录","uri":"/2023-05-23/#记录区-明天"},{"categories":["数据结构与算法"],"content":"#树 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:0:0","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#"},{"categories":["数据结构与算法"],"content":" 一、概念 二叉搜索树：left \u003c root \u003c right 平衡二叉搜索树：在二叉搜索树的基础上，具有良好的平衡性（在插入的时候，需要借助一次或者多次树旋转），避免出现极端不平衡的情况 树类型 最坏情况下的时间复杂度 插入、删除、查找 二叉搜索树 O(n)(当整棵树只有左节点或者只有右节点的情况) 平衡二叉搜索树 O(logn) 效率更高(都为O(logn)) 常见的平衡二叉搜索树 AVL 红黑树 B 树- B+ 树 … 本文主要介绍 AVL 树 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:1:0","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#一概念"},{"categories":["数据结构与算法"],"content":" 二、AVL 的概念以及旋转分析 |h(ls) - h(rs)|平衡因子 \u003c= 1：左右树高的差值不大于 1 空树是 AVL 树 通过一张动态图观察树的几种旋转情况 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:0","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#二avl-的概念以及旋转分析"},{"categories":["数据结构与算法"],"content":" 2.1 节点高度、平衡因子为了能够计算节点的平衡因子，节点结构中加入一个高度字段： type treeNode struct { val int height int // 节点高度 left *treeNode right *treeNode } 节点高度 表示节点到最远叶子节点的举例（也就是边的数量） 叶子节点的高度 = 0 空节点的高度 = -1 定义两个分别用来获取节点高度、更新节点高度的方法： func (t *avlTree) getHeight(node *treeNode) int { // 空节点高度为 -1 if node == nil { return -1 } return node.height } func (t *avlTree) updateHeight(node *treeNode) { // 节点高度等于最高子树的高度 + 1 t.height = max(t.getHeight(node.left), t.getHeight(node.right)) + 1 } 获取节点的平衡因子 // balanceFactor 获取平衡因子 // 设平衡因子为 f，平衡二叉树的平衡因子需满足：-1 \u003c= f \u003c= 1 func (t *avlTree) balanceFactor(node *treeNode) int { // 空节点的平衡因子为 0 if node == nil { return 0 } // 节点平衡因子 = 左子树高度 - 右子树高度 return t.getHeight(node.left) - t.getHeight(node.right) } ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:1","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#21-节点高度平衡因子"},{"categories":["数据结构与算法"],"content":" 2.2 四种旋转类型AVL 的特点就在于旋转（Roration），通过旋转可以让二叉树不失衡，根据节点的失衡情况，可以将分为四种旋转方式：左旋、右旋、先左旋再右旋、先右旋再左旋 2.2.1 左旋具体图示分析与右旋类似 func (t *avlTree) leftRotate(node *treeNode) *treeNode { child := node.right // 消除碰撞，执行旋转 node.right = child.left child.left = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.2 右旋step1. 下面这棵树是 AVL 树 step2. 添加一个节点之后失衡 step3. 聚焦失衡子树 step4. 旋转操作 step4.a 这里的 child 节点是没有右节点的，因此 node 节点的右旋过程是顺利的。在右旋操作中，如果 child 存在右节点，是会产生碰撞（碰撞只是为了个人方便记住存在这种情况引入的一个概念）的，那么在旋转之前，就必须消除碰撞：让 grandchild 作为 node 的左节点： step5. 子节点上移 右旋代码： // 右旋，返回平衡子树的根节点 func (t *avlTree) rightRotate(node *treeNode) *treeNode { child := node.left // 消除碰撞，执行旋转 node.left = child.right child.right = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.3 先左旋后右旋下面是同样的一颗 AVL 树，如果新节点添加在最左叶子节点的左节点，是能够通过一次右旋操作恢复平衡的，但是如果新节点添加在最左叶子节点的右节点，需要先通过一次左旋（这次左旋是不会产生碰撞的）达到类似于新节点是添加在最左边的效果，然后就能通过上面提到的右旋操作来恢复平衡 2.2.4 先右旋后左旋相当于「先左旋后右旋」的镜像操作 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:2","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#22-四种旋转类型"},{"categories":["数据结构与算法"],"content":" 2.2 四种旋转类型AVL 的特点就在于旋转（Roration），通过旋转可以让二叉树不失衡，根据节点的失衡情况，可以将分为四种旋转方式：左旋、右旋、先左旋再右旋、先右旋再左旋 2.2.1 左旋具体图示分析与右旋类似 func (t *avlTree) leftRotate(node *treeNode) *treeNode { child := node.right // 消除碰撞，执行旋转 node.right = child.left child.left = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.2 右旋step1. 下面这棵树是 AVL 树 step2. 添加一个节点之后失衡 step3. 聚焦失衡子树 step4. 旋转操作 step4.a 这里的 child 节点是没有右节点的，因此 node 节点的右旋过程是顺利的。在右旋操作中，如果 child 存在右节点，是会产生碰撞（碰撞只是为了个人方便记住存在这种情况引入的一个概念）的，那么在旋转之前，就必须消除碰撞：让 grandchild 作为 node 的左节点： step5. 子节点上移 右旋代码： // 右旋，返回平衡子树的根节点 func (t *avlTree) rightRotate(node *treeNode) *treeNode { child := node.left // 消除碰撞，执行旋转 node.left = child.right child.right = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.3 先左旋后右旋下面是同样的一颗 AVL 树，如果新节点添加在最左叶子节点的左节点，是能够通过一次右旋操作恢复平衡的，但是如果新节点添加在最左叶子节点的右节点，需要先通过一次左旋（这次左旋是不会产生碰撞的）达到类似于新节点是添加在最左边的效果，然后就能通过上面提到的右旋操作来恢复平衡 2.2.4 先右旋后左旋相当于「先左旋后右旋」的镜像操作 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:2","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#221-左旋"},{"categories":["数据结构与算法"],"content":" 2.2 四种旋转类型AVL 的特点就在于旋转（Roration），通过旋转可以让二叉树不失衡，根据节点的失衡情况，可以将分为四种旋转方式：左旋、右旋、先左旋再右旋、先右旋再左旋 2.2.1 左旋具体图示分析与右旋类似 func (t *avlTree) leftRotate(node *treeNode) *treeNode { child := node.right // 消除碰撞，执行旋转 node.right = child.left child.left = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.2 右旋step1. 下面这棵树是 AVL 树 step2. 添加一个节点之后失衡 step3. 聚焦失衡子树 step4. 旋转操作 step4.a 这里的 child 节点是没有右节点的，因此 node 节点的右旋过程是顺利的。在右旋操作中，如果 child 存在右节点，是会产生碰撞（碰撞只是为了个人方便记住存在这种情况引入的一个概念）的，那么在旋转之前，就必须消除碰撞：让 grandchild 作为 node 的左节点： step5. 子节点上移 右旋代码： // 右旋，返回平衡子树的根节点 func (t *avlTree) rightRotate(node *treeNode) *treeNode { child := node.left // 消除碰撞，执行旋转 node.left = child.right child.right = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.3 先左旋后右旋下面是同样的一颗 AVL 树，如果新节点添加在最左叶子节点的左节点，是能够通过一次右旋操作恢复平衡的，但是如果新节点添加在最左叶子节点的右节点，需要先通过一次左旋（这次左旋是不会产生碰撞的）达到类似于新节点是添加在最左边的效果，然后就能通过上面提到的右旋操作来恢复平衡 2.2.4 先右旋后左旋相当于「先左旋后右旋」的镜像操作 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:2","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#222-右旋"},{"categories":["数据结构与算法"],"content":" 2.2 四种旋转类型AVL 的特点就在于旋转（Roration），通过旋转可以让二叉树不失衡，根据节点的失衡情况，可以将分为四种旋转方式：左旋、右旋、先左旋再右旋、先右旋再左旋 2.2.1 左旋具体图示分析与右旋类似 func (t *avlTree) leftRotate(node *treeNode) *treeNode { child := node.right // 消除碰撞，执行旋转 node.right = child.left child.left = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.2 右旋step1. 下面这棵树是 AVL 树 step2. 添加一个节点之后失衡 step3. 聚焦失衡子树 step4. 旋转操作 step4.a 这里的 child 节点是没有右节点的，因此 node 节点的右旋过程是顺利的。在右旋操作中，如果 child 存在右节点，是会产生碰撞（碰撞只是为了个人方便记住存在这种情况引入的一个概念）的，那么在旋转之前，就必须消除碰撞：让 grandchild 作为 node 的左节点： step5. 子节点上移 右旋代码： // 右旋，返回平衡子树的根节点 func (t *avlTree) rightRotate(node *treeNode) *treeNode { child := node.left // 消除碰撞，执行旋转 node.left = child.right child.right = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.3 先左旋后右旋下面是同样的一颗 AVL 树，如果新节点添加在最左叶子节点的左节点，是能够通过一次右旋操作恢复平衡的，但是如果新节点添加在最左叶子节点的右节点，需要先通过一次左旋（这次左旋是不会产生碰撞的）达到类似于新节点是添加在最左边的效果，然后就能通过上面提到的右旋操作来恢复平衡 2.2.4 先右旋后左旋相当于「先左旋后右旋」的镜像操作 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:2","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#223-先左旋后右旋"},{"categories":["数据结构与算法"],"content":" 2.2 四种旋转类型AVL 的特点就在于旋转（Roration），通过旋转可以让二叉树不失衡，根据节点的失衡情况，可以将分为四种旋转方式：左旋、右旋、先左旋再右旋、先右旋再左旋 2.2.1 左旋具体图示分析与右旋类似 func (t *avlTree) leftRotate(node *treeNode) *treeNode { child := node.right // 消除碰撞，执行旋转 node.right = child.left child.left = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.2 右旋step1. 下面这棵树是 AVL 树 step2. 添加一个节点之后失衡 step3. 聚焦失衡子树 step4. 旋转操作 step4.a 这里的 child 节点是没有右节点的，因此 node 节点的右旋过程是顺利的。在右旋操作中，如果 child 存在右节点，是会产生碰撞（碰撞只是为了个人方便记住存在这种情况引入的一个概念）的，那么在旋转之前，就必须消除碰撞：让 grandchild 作为 node 的左节点： step5. 子节点上移 右旋代码： // 右旋，返回平衡子树的根节点 func (t *avlTree) rightRotate(node *treeNode) *treeNode { child := node.left // 消除碰撞，执行旋转 node.left = child.right child.right = node // 更新节点高度 t.updateHeight(node) t.updateHeight(child) return child } 2.2.3 先左旋后右旋下面是同样的一颗 AVL 树，如果新节点添加在最左叶子节点的左节点，是能够通过一次右旋操作恢复平衡的，但是如果新节点添加在最左叶子节点的右节点，需要先通过一次左旋（这次左旋是不会产生碰撞的）达到类似于新节点是添加在最左边的效果，然后就能通过上面提到的右旋操作来恢复平衡 2.2.4 先右旋后左旋相当于「先左旋后右旋」的镜像操作 ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:2","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#224-先右旋后左旋"},{"categories":["数据结构与算法"],"content":" 2.3 如何选择旋转类型通过 2.2 的分析，我们可以总结得到： 设平衡因子为 f 左偏树：f \u003e 1 右偏树：f \u003c -1 我们可以通过分别判断 node 和 child 的平衡因子来选择执行哪种旋转操作 失衡节点的 f 子节点的 f 操作 \u003e1 \u003e=0 右旋 \u003e1 \u003c0 先左旋后右旋 \u003c-1 \u003c=0 左旋 \u003c-1 \u003e0 先右旋后左旋 func (t *avlTree) rotate(node *treeNode) *treeNode { // 失衡节点的平衡因子 bf := t.balanceFactor(node) if bf \u003e 1 { if t.balanceFactor(node.left) \u003e= 0 { return t.rightRotate(node) } else { // 先左旋，后右旋 node.left = t.leftRotate(node.left) return t.rightRotate(node) } } else if bf \u003c -1 { if t.balanceFactor(node.right) \u003c= 0 { return t.leftRotate(node) } else { // 先右旋，后左旋 node.right = t.rightRotate(node.right) return t.leftRotate(node) } } // 已经是平衡状态 return node } ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:2:3","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#23-如何选择旋转类型"},{"categories":["数据结构与算法"],"content":" 三、其他操作","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:3:0","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#三其他操作"},{"categories":["数据结构与算法"],"content":" 3.1 插入节点平衡二叉搜索树在节点插入之后要维持树的平衡，从插入的节点开始，需要 自底向上执行旋转操作，使所有失衡节点恢复平衡 func (t *avlTree) insert(val int) { t.root = t.insertHelper(t.root, val) } func (t *avlTree) insertHelper(node *treeNode, val int) *treeNode { if node == nil { return \u0026treeNode{ val: val, } } /* 1. 插入 */ if val \u003c node.val { node.left = t.insertHelper(node.left, val) } else if val \u003e node.val { node.right = t.insertHelper(node.right, val) } else { // 重复节点不插入 return node } // 更新节点高度 t.updateHeight(node) /* 2.执行旋转，恢复平衡 */ node = t.rotate(node) return node } ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:3:1","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#31-插入节点"},{"categories":["数据结构与算法"],"content":" 3.2 删除节点 func (t *avlTree) remove(val int) { t.removeHelper(t.root, val) } func (t *avlTree) removeHelper(node *treeNode, val int) *treeNode { if node == nil { return nil } if val \u003c node.val { node.left = t.removeHelper(node.left, val) } else if val \u003e node.val { node.right = t.removeHelper(node.right, val) } else { if node.left == nil || node.right == nil { child := node.left if node.right != nil { child = node.right } if child == nil { // 没有子树，直接删除节点即可 return nil } else { // 有至多一个节点，返回该节点 return child } } else { // 子节点的数量为 2，删除当前节点的后继节点，并用后继节点的值替换当前节点 tmp := node.right for tmp.left != nil { tmp = tmp.left } // 递归删除这个后继节点 node.right = t.removeHelper(node.right, tmp.val) // 替换当前节点 node.val = tmp.val } } // 更新节点高度 t.updateHeight(node) /* 执行旋转，保持平衡 */ node = t.rotate(node) return node } https://www.hello-algo.com/chapter_tree/avl_tree/#751-avl ","date":"2023-05-22","objectID":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/:3:2","series":["数据结构"],"tags":["树","平衡二叉搜索树","AVL"],"title":"平衡二叉搜索树-AVL","uri":"/202305222352-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-avl/#32-删除节点"},{"categories":["生活记录"],"content":"#阅读 人类生来就会制造神话。对于优秀的人物身上发生的未解事件，人们往往喜欢编造出各类神话传奇来解释。这大概是因为日常生活太过平淡无奇，人们渴望给它增添一抹浪漫主义色彩 为了心灵获得宁静，一个人必须每天做两件不喜欢的事情 他们看似热情，但是实际上缺乏热血沸腾的劲儿 善于同情他人本身就是很难得的事情，但是有很多人会滥用自己的同情心，看到朋友遭受不幸时，他们恨不得把自己的爱心全掏出来，这样反而惹人生厌。同情心理应是一口油井，自己就能喷出油来；但是喜欢把同情显露在脸上的人却总是让这口井喷得像火山一样奔放，导致对方陷入难堪的境地 当时的我太年轻了，还不清楚人性本来就充满了矛盾，这个世界不是非黑即白的，真挚中也包含着一些做作，高尚中也有一些卑鄙，即使是邪恶，也蕴藏着一些美德。 感情总是理智无法理解的 其实，一个人可以兼具卑鄙与伟大、邪恶与善良 她是个聪明的女人，深知一个道理：她如果总是把不幸挂在嘴边，摆出一副可怜相，反而会招人厌烦的。所以当同情她的朋友邀请她去做客时，她总是表现得十分得体。比起诉说自己的不幸，她更愿意倾听别人的心事 一般人认为，在灾难面前，人性就会格外高贵起来。但我知道，她说要帮助他，这绝对不是因为她是个宽容仁慈的人。高尚之举的背后，可能是一颗狭隘之心。灾难往往会让人们的报复心更强 他其实很喜欢吃喝享受，但又不在乎这些。他不觉得忍饥受冻是一种苦难。比起物质生活的享受，他更注重精神世界的完满。可以说，他的世界里精神生活占据了全部，你不得不被他感动。 有一种观点是，我们要是想知道一个人的性格，最好是和他对弈一局 护士用慈祥的目光看着他，因为曾经见到过世间最可怖的景象，所以她的眼神是如此的清澈 这个世界是残酷的。我们生来就不知道活着的意义，我们死后也不知道会去往何方。我们必须向生活低下头颅，体味孤独的真谛。我们最好在生活中默默无闻，不要引起命运的关注。淳朴的爱情最动人，我们应该追求的正是这种爱情。比起知识，还是愚昧更能让爱情维持到地久天长。我们应该沉默不语，待在自己的一方小天地里，做一个性情温顺的人。生活的智慧就在于此。 他以前走上这个楼梯，因为体力不好，总要先大喘几口气，待心跳恢复正常后才走进这个画室，但是每次又因为想早点见到勃朗什，导致心跳总是半天缓不下来。 人们总是对美大谈特谈，其实根本不了解美的含义；“美”这个词用得太频繁，已经失去了原先的崇高含义了。人们能说出一件衣服的美，一只动物的美，一篇文章的美，人们可以用“美”来形容任何事物，但当他们见到真正的美时，却辨认不出它了。因为他们习惯了夸大那些本就不美的事物，所以感受力已经变得十分迟钝了 尽管我们可能没有意识到，也许我们对于自己影响别人的能力还是很关注的。如果我们发现自己对某个人的意见能够被他本人重视，就会得意扬扬。如果他对我们的意见根本不放在心上，我们就会不喜欢这个人 通常来说，在进行社交的时候，人们只会让你看到他希望别人看到他的样子，所以你只能从他无意识的一些小动作、小习惯，或者不经意间在面颊上流露过的一丝情绪来对他进行推断和揣测。一个人倘若将面具戴久了，可能就摘不下来了，久而久之就会变成和自己的面具一样的人。 假装自己具有独一无二的特性并没有办法掩盖平庸的本质。 我无法认同他的观点，亚伯拉罕真的毁了自己吗？他只不过是去做自己想做的事，在一个宁静的环境里，不追名逐利，过好自己的生活，这真的是毁了自己吗？反之，成为一个有名的医生，娶一位貌美的妻子，过着优越的生活，难道就是成功？我认为，关键在于他认为生活具有怎样的意义，在于他认为自己应该尽怎样的社会义务，在于他对自己是怎样的要求。不过我一句话都没有说，关于成功的定义，我怎么有资格和一位爵士争论呢？ 世界上很多人为了他们的理想而奋斗一生，但最终能达到目标的人只有少数。我们没有野心，过着简单淳朴的生活。我们也有自己的骄傲。我们现在的生活是凭自己的双手打拼出来的，我们想到这一点时，就会感到无比的骄傲。我们从不嫉妒别人，因为我们对自己的生活已经心满意足 因为人们无法消除心中的恐惧，所以才会变得残酷无情… ","date":"2023-05-22","objectID":"/202305222017-%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/:0:0","series":["读书记录"],"tags":["阅读"],"title":"《月亮与六便士》","uri":"/202305222017-%E6%9C%88%E4%BA%AE%E4%B8%8E%E5%85%AD%E4%BE%BF%E5%A3%AB/#"},{"categories":["生活记录"],"content":"#阅读 其实也没有发生什么决定性的条件，我只是隐隐约约地感觉到，许多事情已经在水面下悄悄酝酿。但即便如此，我却故意装作什么都不知道。直到我真的搞清楚的时候，我的人生已经往后翻了好几页，再也无法回头挽救什么。因为，那时，我已经失去了我的父母。 感觉从那之后已经经过了漫长的岁月。“当初若是这么做的话”或是“如果换成现在的我就能做得更…”之类的感伤，至今仍会不时地席上我心头，感伤伴随着时间沉淀、混浊，最终甚至遮蔽了时间的流动。在这段不断失去的日子中，如果我还得到过一点什么，应该就是：人生总是有那么一点来不及—这么一种近似于认命的教训吧。 顺着眼前的状况随波逐流，事后却反悔不已…这是我的坏习惯。 “小良你喜欢棒球吗？” 这句话听起来像是在说：你竟然会喜欢棒球那种运动，混杂着某种惊讶与轻蔑的语气。 “以前啦，很久以前。”我像是否定自己的童年似的，慌张地回答 会对她这样的准备心存感激，是在很久以后了。曾经，母亲的一举一动，都只让我觉得她好施小惠而令我心烦。 我提着西瓜打开洗手间的门时，第一个映入眼帘的是摆在洗衣机上的一排牙刷。一支是蓝色，一支是粉红色，还有一支略短的儿童用的青蛙造型的绿色牙刷摆在中间。应该是昨天我打完电话之后，母亲匆匆忙忙跑去买的吧。 她可能是因为很在意自己戴假牙，所以每年的贺年卡上面最后也一定会加一句“记得去看牙医”。 记得当母亲住院时，我去探望她，她反而还担心起我的牙齿。蛛网膜下出血的母亲在手术成功后，开始慢慢出现痴呆症状。明明那时父亲已经过世，她有时还会问起：“你爸今天怎么没来？”有时她会把医院跟自己家搞错。听到隔壁病床的家属来了，还会突然问：“家里有客人吗？”然后坐起身子很慌乱地想要去泡茶。又过了一段时间后，不要说是由香里，连姐姐的名字她都记不起来了。虽然她勉强还记得我，但到了最后，竟把我和大哥搞混在一起，让我特别不甘心。当我无法再跟她继续对话时，忽然灵光乍现，把嘴张得大大的，凑近病床上的母亲。 “我最近好像有蛀牙呢。” 听到这个的母亲突然恢复正常似的皱起眉头。 那是我所熟悉的母亲，如假包换。 然后我开始感觉到，那样的母亲正一点一滴地从我眼前消失。这想法令我不寒而栗。 母亲过世之后，我才开始去看牙医。 “不能只靠想象来画画。老师说过，要花足够的时间观察眼前的东西才行。” 虽然她如此亲切地招呼，但还是一定会在客人离开之后挑人家的毛病。 人生总会犯下不管付出多少代码都无法挽回的过错。但我真正领悟到这点，又是更以后的事情了。 因为正是在这一天，我第一次感觉到父母不可能永远都像以前一样。这是件理所当然的事情。但即便我眼看着父母年华老去，我却什么都没有做。我只能不知所措地远远看着同样不知所措的父母。而第二天，我甚至忘记了这些事件，仍对他们的存在感到厌烦，然后马上回到了属于我自己的、与他们毫不相干的日常生活。双亲会老，是无可奈何的事情；会死，多半也是无可奈何的。但是，没能与他们的衰老或死亡发生一点联系这件事，对我来说如鲠在喉。 “要去看牙医哦。” 并肩在站牌等公交车的母亲又重复着同样的话，从昨天起已经是第二次了。 “嗯…改天我会去看。” 虽然明知道不会看到父母，我还是回头看了一下。我从公交车后窗看着沿海的道路，叹了一口气。 “每次都这样。总是有那么一点来不及…” 人生，总有那么一点来不及。那就是我失去父亲还有母亲之后，我最真实的感受。 或许还会在回程路上指着看到的蝴蝶，向牵着我的手的女儿说：“看那只黄色的蝴蝶。听说啊，只要纹白蝶活过了冬天，第二年就能变成黄色的蝴蝶飞回来呢…” 然后想起母亲，可能会哭，也可能会笑吧。 ","date":"2023-05-22","objectID":"/202305221947-%E6%AD%A5%E5%B1%A5%E4%B8%8D%E5%81%9C%E6%AD%A9%E3%81%84%E3%81%A6%E3%82%82%E6%AD%A9%E3%81%84%E3%81%A6%E3%82%82/:0:0","series":["读书记录"],"tags":["阅读"],"title":"《步履不停（歩いても、歩いても）》","uri":"/202305221947-%E6%AD%A5%E5%B1%A5%E4%B8%8D%E5%81%9C%E6%AD%A9%E3%81%84%E3%81%A6%E3%82%82%E6%AD%A9%E3%81%84%E3%81%A6%E3%82%82/#"},{"categories":["生活记录"],"content":" 就像玩一副里面全是A的牌。你什么都有，但又什么都没有。你只知道坐在那儿自我欣赏。难怪特里不找你帮忙。感觉就像找妓女借钱。 “我是作家。”韦德说，“我应该理解其他人的行为动机，但我对任何人都他妈屁也不懂。” 普通人活得疲惫而惶恐，一个疲惫而惶恐的人负担不了理想。他必须养家糊口 大规模生产没有品质可言。你不希望货物的品质太好，因为品质好就会太耐用。于是你用式样代替品质，这是一种商业欺诈，旨在人工营造过时的感觉。 “我？我无药可救？这位女士，好好看一眼你家老头子。和他相比，我就是个拿着崭新拨浪鼓的蓝眼睛小宝宝。” 我应该问他书写得怎么样了。也许和作家说话就一定要问他书写得怎么样了，但话也说回来，作家也许早就被这个问题烦得要死要活了。 所有形式的赌博在某些地方全都合法，某些形式的赌博在所有地方全都合法，因此谁也无法阻止赌博。 既然受害人已经死亡，找出实施罪行的人又有什么好处呢？当然什么都没有了，除了正义和真相。 说一声再见，就是死去一点点。 ","date":"2023-05-22","objectID":"/202305221944-%E6%BC%AB%E9%95%BF%E7%9A%84%E5%91%8A%E5%88%AB/:0:0","series":["读书记录"],"tags":["阅读"],"title":"《漫长的告别》","uri":"/202305221944-%E6%BC%AB%E9%95%BF%E7%9A%84%E5%91%8A%E5%88%AB/#heading"},{"categories":["task-bugfix"],"content":" 流程图 ","date":"2023-05-22","objectID":"/202305221900-iscsi-%E6%8C%82%E8%BD%BD%E6%96%B9%E5%BC%8F%E6%95%B4%E4%BD%93%E9%87%8D%E6%9E%84/:1:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"iscsi 挂载方式整体重构","uri":"/202305221900-iscsi-%E6%8C%82%E8%BD%BD%E6%96%B9%E5%BC%8F%E6%95%B4%E4%BD%93%E9%87%8D%E6%9E%84/#流程图"},{"categories":["task-bugfix"],"content":" 一、iscsid、multipathd 运行的节点 {{- if .Values.request.imageImporterNodeSelector}} nodeSelector: {{- range $key, $value := .Values.request.imageImporterNodeSelector }} {{ $key }}: {{ $value | quote}} {{- end }} {{- end }} # 传入 iscsiAffinityNodeSelectors: [\"role/controller\", \"role/tenants-ecs\"] # 使用 affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: {{- range .Values.iscsiAffinityNodeSelectors }} - matchExpressions: - key: {{ . }} operator: In values: - \"true\" {{- end }} 实际结果： affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: role/controller operator: In values: - \"true\" - matchExpressions: - key: role/tenants-ecs operator: In values: - \"true\" ","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:1:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#一iscsidmultipathd-运行的节点"},{"categories":["task-bugfix"],"content":" 二、场景验证","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:2:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#二场景验证"},{"categories":["task-bugfix"],"content":" 2.1 物理机、容器中均有 iscsid、multipathd 服务，是否冲突用于测试的 iscsid 服务 apiVersion: apps/v1 kind: DaemonSet metadata: name: iscsid-hhq-test namespace: product-ebs spec: revisionHistoryLimit: 10 selector: matchLabels: name: iscsid-hhq-test template: metadata: creationTimestamp: null labels: name: iscsid-hhq-test spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: role/controller operator: In values: - \"true\" - matchExpressions: - key: role/tenants-ecs operator: In values: - \"true\" containers: - command: - sh - -c - /start-iscsi.sh env: - name: HOST_IP valueFrom: fieldRef: apiVersion: v1 fieldPath: status.hostIP image: harbor.ceclouddyn.com/iaas_pub/iscsi-multipath:CECStack3.1.0-beta1 imagePullPolicy: Always name: iscsid-con resources: {} securityContext: privileged: true volumeMounts: - mountPath: /lib/modules name: lib-modules - mountPath: /dev name: dev - mountPath: /sys name: sys - mountPath: /run name: run - mountPath: /etc/iscsi name: etc-iscsi dnsPolicy: ClusterFirstWithHostNet enableServiceLinks: true hostNetwork: true hostPID: true priority: 0 restartPolicy: Alwaysr terminationGracePeriodSeconds: 30 volumes: - hostPath: path: /dev type: \"\" name: dev - hostPath: path: /lib/modules type: \"\" name: lib-modules - hostPath: path: /sys type: \"\" name: sys - hostPath: path: /run type: \"\" name: run - hostPath: path: /etc/iscsi type: DirectoryOrCreate name: etc-iscsi 物理机 iscsid 状态 pod iscsid 描述 failed 未起 在物理机上能够使用 systemctl start 正常启动服务；且使用 iscsiadm 命令挂载成功 active 启动 pod 中的脚本执行成功；且在物理环境也能够使用 iscsiadm 正常挂卸载 dead 未启动 挂卸载失败 dead 启动 挂卸载成功 ","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:2:1","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#21-物理机容器中均有-iscsidmultipathd-服务是否冲突"},{"categories":["task-bugfix"],"content":" 2.2 容器中运行 iscsid -d 8 -f 命令验证各种场景下是否能拉起来线程容器启动之后，线程情况： 在容器中实行 iscsiadm 结果： 脚本实际放到 pod 中运行： 思考： 以前使用 iscsid 命令来运行，现在换成 iscsid -d 8 -f 来运行，之后还是有可能再换命令的，应该把这个命令放到环境变量里面，读取这个变量来运行，不至于更改代码 ","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:3:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#22-容器中运行-iscsid--d-8--f-命令验证各种场景下是否能拉起来线程"},{"categories":["task-bugfix"],"content":" 脑图 ","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:4:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#脑图"},{"categories":["task-bugfix"],"content":" Q\u0026A","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:5:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#qa"},{"categories":["task-bugfix"],"content":" 1. 镜像缓存过程中 multipathd 不存在job 执行结果： 可能的原因： 物理机没有 multipathd 服务 容器没有 multipathd 服务 实际定位：因为管控节点没有 multipath，而计算节点有 multipath，如果 importer 中不安装 multipath 包，那么 importer job 起到管控节点是能正常运行的，原因是管控节点没有 multipath，那么挂载过来的盘是单路径的，job 中不会执行到 multipath 相关的内容，因此缓存镜像能够成功创建，但是如果有个节点既有管控节点标签，又有计算节点标签，这个时候节点是有multipath服务的，跑iscsiadm -R就会将挂过来的盘映射成为多路径，脚本会走到多路径的逻辑，执行multipath命令就会报错，因此，把节点的计算标签去掉就行了 ","date":"2023-05-22","objectID":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/:5:1","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi","multipath"],"title":"iscsid、multipathd 容器化","uri":"/202305221908-iscsidmultipathd-%E5%AE%B9%E5%99%A8%E5%8C%96/#1-镜像缓存过程中-multipathd-不存在"},{"categories":["生活记录"],"content":" 记录了书籍阅读的一些相关内容 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:0:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#heading"},{"categories":["生活记录"],"content":" 小说 文学 《步履不停（歩いても、歩いても）》- [日] 是枝裕和 《月亮与六便士》- [英] 威廉·萨默塞特·毛姆 《房思琪的初恋乐园》- [中国] 林奕含 《活着》 - [中国] 余华 《山月记》 - [日本] 中岛敦 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:1:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#小说-文学"},{"categories":["生活记录"],"content":" 方法 《非暴力沟通》- [美] 马歇尔·卢森堡 《卡片笔记写作法：如何实现从阅读到写作》 - []申克·阿伦斯 《终身成长》- []卡罗尔·德韦克 《活出生命的意义》 - [美国] 维克多·弗兰克尔 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:2:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#方法"},{"categories":["生活记录"],"content":" 知识 《DDIA》 《Go 语言精进之路》 《Kubernetes 权威指南》 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:3:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#知识"},{"categories":["生活记录"],"content":" 历史 《南京大屠杀》 - [中国] 张纯如 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:4:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#历史"},{"categories":["生活记录"],"content":" 随笔 《生活蒙太奇》 - [中国] 天然 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:5:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#随笔"},{"categories":["生活记录"],"content":" 寓言故事 《小王子》- [法] 安托万·德·圣·埃克苏佩里 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:6:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#寓言故事"},{"categories":["生活记录"],"content":" ？ 《笑场》 - [中国] 李诞 《岩田先生：任天堂传奇社长如是说》- [] HOBO日刊ITOI新闻 ","date":"2023-05-22","objectID":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/:7:0","series":["目录"],"tags":["阅读"],"title":"阅读记录【入口】","uri":"/202305221950-%E9%98%85%E8%AF%BB%E8%AE%B0%E5%BD%95%E7%9B%AE%E5%BD%95/#heading-1"},{"categories":["task-bugfix"],"content":" 问题描述容器化的 pod 运行起来之后，正常情况下的进程情况是这样的： 在物理机上查看两个服务的情况： 如果物理机的这两个服务是运行着的，那么容器中服务的情况是这样的： 上面无论哪种情况，服务都是能够正常运行的，但是如果在物理机开启 iscsid、multipathd 服务的情况下，通过手动的方式将物理机上的两个服务停掉，容器中也没有相关线程了，就无法提供 iscsid、multipathd 的服务 ","date":"2023-05-22","objectID":"/202305221801-iscsidmultipathd%E5%AE%B9%E5%99%A8%E5%8C%96%E5%88%A4%E6%96%AD%E6%9C%8D%E5%8A%A1%E6%98%AF%E5%90%A6%E8%BF%90%E8%A1%8C%E7%9A%84bug/:1:0","series":["偏工作性质记录"],"tags":["工作记录","bugfix","工作记录"],"title":"iscsid、multipathd容器化判断服务是否运行的bug","uri":"/202305221801-iscsidmultipathd%E5%AE%B9%E5%99%A8%E5%8C%96%E5%88%A4%E6%96%AD%E6%9C%8D%E5%8A%A1%E6%98%AF%E5%90%A6%E8%BF%90%E8%A1%8C%E7%9A%84bug/#问题描述"},{"categories":["task-bugfix"],"content":" 解决通过修改容器中服务的执行脚本得以解决： #!/bin/bash psAuxOutput=$(ps aux | grep iscsid | grep -v grep | grep -v kubectl) if [ -z \"$psAuxOutput\" ]; then echo \"ps aux do not have iscsid process\" iscsid || true else echo \"have iscsid process\" echo $psAuxOutput fi ","date":"2023-05-22","objectID":"/202305221801-iscsidmultipathd%E5%AE%B9%E5%99%A8%E5%8C%96%E5%88%A4%E6%96%AD%E6%9C%8D%E5%8A%A1%E6%98%AF%E5%90%A6%E8%BF%90%E8%A1%8C%E7%9A%84bug/:2:0","series":["偏工作性质记录"],"tags":["工作记录","bugfix","工作记录"],"title":"iscsid、multipathd容器化判断服务是否运行的bug","uri":"/202305221801-iscsidmultipathd%E5%AE%B9%E5%99%A8%E5%8C%96%E5%88%A4%E6%96%AD%E6%9C%8D%E5%8A%A1%E6%98%AF%E5%90%A6%E8%BF%90%E8%A1%8C%E7%9A%84bug/#解决"},{"categories":["task-bugfix"],"content":" 一些了解 qemu-img：QEMU 的磁盘管理工具 QEMU：模拟计算的自由软件（纯软件），QEMU 有整套的虚拟机实现（CPU 虚拟化、内存虚拟化、I/O 设备虚拟化） QEMU 是一个运行在用户态的进程，通过 KVM 模块提供的系统调用接口进行内核操作 qcow2 格式：当客户系统实际写入内容的时候，才会分配镜像空间 格式 优点 缺点 raw i/o 开销小1 浪费空间 qcow2 节省空间 性能差 ","date":"2023-05-22","objectID":"/202305221812-qemu-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5/:1:0","series":["偏工作性质记录"],"tags":["qemu","工作记录"],"title":"qemu 简单实践","uri":"/202305221812-qemu-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5/#一些了解"},{"categories":["task-bugfix"],"content":" 实际使用命令： qemu-img convert [-c] [-p] [-q] [-n] [-f fmt] [-t cache] [-T src_cache] [-O output_fmt] [-o options] [-s snapshot_name] [-S sparse_size] filename [filename2 [...]] output_filename c 目标图像必须被压缩（仅qcow格式） p 显示命令的进展情况 n 跳过目标卷的创建（如果卷是在运行qemu-img之前创建的，则非常有用） t cache 写入输出磁盘镜像的缓存模式 T src_cache 读取输入磁盘镜像的缓存模式 O output_fmt 输出文件格式 例子： qemu-img create -f qcow2 centos7.4-disk.qcow2 20G # 创建 20G 大小的 qcow2 格式文件 centos7.4-disk.qcow2 qemu-img info centos7.4-disk.qcow2 --output=json # 以 json 格式输出文件信息 qemu-img create -f qcow2 -o backing_file=disk1.qcow2 disk1-a.qcow2 # 创建 disk1-a.qcow2 文件，并以 disk1.qcow2 为后端镜像文件（disk1-a.qcow2 记录与后端镜像的差异部分，在使用 commit 命令的时候才将修改提交到后端镜像文件） 这是因为Raw格式的镜像不需要进行额外的解压或解密操作，也不需要对数据进行任何转换或处理。当系统需要访问Raw格式的镜像时，它可以直接读取文件中的二进制数据，并将其映射到内存中，从而避免了额外的IO开销和CPU负担。 ↩︎ ","date":"2023-05-22","objectID":"/202305221812-qemu-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5/:2:0","series":["偏工作性质记录"],"tags":["qemu","工作记录"],"title":"qemu 简单实践","uri":"/202305221812-qemu-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5/#实际使用"},{"categories":["task-bugfix"],"content":" 任务描述 qemu-img convert -t none -p -n -W -O raw \"json: {\\\"file.driver\\\": \\\"http\\\", \\\"file.url\\\": \\\"${IMAGE_URL}\\\", \\\"file.timeout\\\": 3600}\" $dev_path 如上面命令行所示，通过 qemu-img 将一个镜像导入到 /dev/*** 设备中，其中 /dev/*** 通过 iscsi 挂载到容器中，完成工作后卸载 ","date":"2023-05-22","objectID":"/202305221827-%E5%88%9B%E5%BB%BA-iscsi-%E7%9A%84%E9%95%9C%E5%83%8F%E7%BC%93%E5%AD%98/:1:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"创建 iscsi 的镜像缓存","uri":"/202305221827-%E5%88%9B%E5%BB%BA-iscsi-%E7%9A%84%E9%95%9C%E5%83%8F%E7%BC%93%E5%AD%98/#任务描述"},{"categories":["task-bugfix"],"content":" 实现步骤 制作镜像 制作一个镜像，安装好 iscsi-initiator-utils、libgcrypt、qemu-kvm-block-curl 等工具，编一个 convert.sh 脚本，脚本主要做镜像导入的工作 编写代码 通过 client-go 调用 k8s 相关 api 来创建 job，job 中执行 convert.sh 脚本 ","date":"2023-05-22","objectID":"/202305221827-%E5%88%9B%E5%BB%BA-iscsi-%E7%9A%84%E9%95%9C%E5%83%8F%E7%BC%93%E5%AD%98/:2:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"创建 iscsi 的镜像缓存","uri":"/202305221827-%E5%88%9B%E5%BB%BA-iscsi-%E7%9A%84%E9%95%9C%E5%83%8F%E7%BC%93%E5%AD%98/#实现步骤"},{"categories":["task-bugfix"],"content":" 任务概览原先的磁盘卸载逻辑： 先执行 terminate 操作（断开磁盘与主机的连接） 执行 dettach 操作（实际卸载磁盘） 可能产生问题： terminate - initialize - dettach - attach 这样可能会把已经卸载的盘再挂载回来 terminate - initialize - attach - dettach 这样可能会把挂载过来的盘卸载掉。假设上面初始化连接（initialize）的盘是一个虚机需要的启动盘，那么这个盘最终会被卸载掉，导致虚机启动失败 ","date":"2023-05-22","objectID":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/:1:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"修改 iscsi 磁盘挂载逻辑：按照 lun id 来挂载","uri":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/#任务概览"},{"categories":["task-bugfix"],"content":" 如何避免 限制性 dettach 操作，将盘实际从虚机上卸载 执行 terminate 操作，断开磁盘跟主机的连接 ","date":"2023-05-22","objectID":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/:2:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"修改 iscsi 磁盘挂载逻辑：按照 lun id 来挂载","uri":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/#如何避免"},{"categories":["task-bugfix"],"content":" linux 上挂卸载的操作卸载磁盘的命令 echo 1 \u003e /sys/block/sd*/device/delete 如何使用 lun id 的方式来挂载？ echo C T L \u003e /sys/class/scsi_host/hostH/scan 如何获得 HCTL？通过初始化连接的响应中的 session id 来寻找 以 session6 为例： session6 目录存在于 /sys/class/iscsi_host/host3/device 目录下 : H：根据路径获得H：xxx/iscsi_host/host3H/device C、T：根据 target 目录获得 CT：target:3:0C:0T L：发送初始化连接的时候由服务端返回的：1L ","date":"2023-05-22","objectID":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/:3:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"修改 iscsi 磁盘挂载逻辑：按照 lun id 来挂载","uri":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/#linux-上挂卸载的操作"},{"categories":["task-bugfix"],"content":" 一些命令备忘 ll /dev/disk/by-path/ip-10.255.245.36:3260-iscsi-iqn.2004-12.com.inspur:mcs.ipsan.b200.fsp.node2-lun-0 iscsiadm -m discovery -t st -p 10.255.245.65:3260 iscsiadm -m node -T 10.255.245.65:3260 -l iscsiadm -m node -T iqn.2004-12.com.inspur:mcs.ipsan.b200.fsp.node1 -p 10.255.245.65:3260 --login ","date":"2023-05-22","objectID":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/:4:0","series":["偏工作性质记录"],"tags":["工作记录","task","iscsi"],"title":"修改 iscsi 磁盘挂载逻辑：按照 lun id 来挂载","uri":"/202305221832-%E4%BF%AE%E6%94%B9-iscsi-%E7%A3%81%E7%9B%98%E6%8C%82%E8%BD%BD%E9%80%BB%E8%BE%91%E6%8C%89%E7%85%A7-lun-id-%E6%9D%A5%E6%8C%82%E8%BD%BD/#一些命令备忘"},{"categories":["MySQL"],"content":" ACID AAtomicity：原子性，事务要么全部成功，要么全部失败 CConsistency：一致性，数据库的状态总是在一致性状态之间转换 IIsolation：隔离性，一个事务的操作对其他事务是不可见的 DDurability：持久性，事务一旦提交，产生的变化是持久的 他们是如何得到保证的？ 原子性：undo log 一致性：代码层面 隔离性：锁、MVCC（多版本并发控制） 持久性：内存 + redo log redo log redo log（重做日志）是数据库中的一种机制，用于记录数据库中的修改操作。它主要用于保证事务的持久性和恢复能力。 具体来说，当一个事务对数据库进行修改时，系统会将这些修改操作记录到redo log中，而不是直接写入磁盘上的数据文件。这样可以避免频繁地写入磁盘，提高数据库的性能。同时，redo log还可以用于在系统崩溃或断电等异常情况下，恢复数据库中未提交的修改操作。 当系统重新启动时，它会读取redo log中的记录，并将其中的修改操作重新应用到数据库中，从而恢复数据库的状态。如果某个事务已经提交，那么它对应的redo log记录就可以被删除，因为这些修改操作已经被写入了磁盘上的数据文件中。 总之，redo log是数据库中的一种机制，用于记录数据库中的修改操作，以保证事务的持久性和恢复能力。 ","date":"2023-05-22","objectID":"/202305221620-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:1:0","series":["MySQL使用"],"tags":["数据库"],"title":"数据库的一些概念","uri":"/202305221620-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/#acid"},{"categories":["MySQL"],"content":" 并发计算中的一致性问题 丢失修改：两个事务对一个数据修改，其中一个被覆盖了 读脏数据（为什么叫脏数据？因为这个数据是不应该存在的，或者叫做垃圾）：A修改后回滚了，B读到了A修改后的值 不可重复度：B两次读操作中间，A对数据进行了修改 幻影读：指在同一事务中，多次查询时，由于其他事务插入或删除了数据，导致查询结果出现了新的行或者少了原有的行 丢失修改和读脏数据： 不可重复读： ","date":"2023-05-22","objectID":"/202305221620-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:2:0","series":["MySQL使用"],"tags":["数据库"],"title":"数据库的一些概念","uri":"/202305221620-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/#并发计算中的一致性问题"},{"categories":["MySQL"],"content":" 事务隔离级别跟一致性问题之间的关系下表列出了不同的事务隔离级别和它们可能导致的数据库一致性问题： 隔离级别 脏读 不可重复读 幻影读 读未提交（Read Uncommitted） 可能发生 可能发生 可能发生 读已提交（Read Committed） 不会发生 可能发生 可能发生 可重复读（Repeatable Read） 不会发生 不会发生 可能发生 串行化（Serializable） 不会发生 不会发生 不会发生 总之，隔离级别越高，数据库的一致性就越好，但是并发性能也会降低。因此，在实际应用中，需要根据具体情况选择合适的隔离级别来平衡一致性和性能的需求。 ","date":"2023-05-22","objectID":"/202305221620-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/:3:0","series":["MySQL使用"],"tags":["数据库"],"title":"数据库的一些概念","uri":"/202305221620-%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E4%B8%80%E4%BA%9B%E6%A6%82%E5%BF%B5/#事务隔离级别跟一致性问题之间的关系"},{"categories":["MySQL"],"content":" 数值类型 类型 描述 TINYINT 范围为 -128 到 127 的有符号整数或 0 到 255 的无符号整数。 SMALLINT 范围为 -32768 到 32767 的有符号整数或 0 到 65535 的无符号整数。 MEDIUMINT 范围为 -8388608 到 8388607 的有符号整数或 0 到 16777215 的无符号整数。 INT 或 INTEGER 范围为 -2147483648 到 2147483647 的有符号整数或 0 到 4294967295 的无符号整数。 BIGINT 范围为 -9223372036854775808 到 9223372036854775807 的有符号整数或 0 到 18446744073709551615 的无符号整数。 FLOAT 单精度浮点数，占用 4 字节。 DOUBLE 或 REAL 双精度浮点数，占用 8 字节。 DECIMAL 或 NUMERIC 定点数，支持可变精度，最大精度为 65 个数字。 ","date":"2023-05-22","objectID":"/202305221317-mysql-%E7%B1%BB%E5%9E%8B/:1:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"mysql 类型","uri":"/202305221317-mysql-%E7%B1%BB%E5%9E%8B/#数值类型"},{"categories":["MySQL"],"content":" 日期和时间类型 类型 描述 DATE 表示年月日，格式为 ‘YYYY-MM-DD’。 YEAR 表示年份，范围为 1901 到 2155 年。 TIME 表示时分秒，格式为 ‘HH:MM:SS’。 DATETIME 表示年月日时分秒，格式为 ‘YYYY-MM-DD HH:MM:SS’。 TIMESTAMP 与 DATETIME 类型类似，但是范围更广，可以存储从 1970 年到 2038 年之间的任意时间。 ","date":"2023-05-22","objectID":"/202305221317-mysql-%E7%B1%BB%E5%9E%8B/:2:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"mysql 类型","uri":"/202305221317-mysql-%E7%B1%BB%E5%9E%8B/#日期和时间类型"},{"categories":["MySQL"],"content":" 字符串类型 类型 描述 CHAR 定长字符串，最大长度为 255 个字符。 VARCHAR 变长字符串，最大长度为 65535 个字符。 BINARY 定长二进制字符串，最大长度为 255 个字节。 VARBINARY 变长二进制字符串，最大长度为 65535 个字节。 TINYBLOB 最大长度为 255 个字节的 BLOB 数据。 BLOB 最大长度为 65535 个字节的 BLOB 数据。 MEDIUMBLOB 最大长度为 16777215 个字节的 BLOB 数据。 LONGBLOB 最大长度为 4294967295 个字节的 BLOB 数据。 TEXT 可变长度的文本数据，最大长度为 65535 个字符。 ENUM 枚举类型，支持多个值中选择一个。 SET 集合类型，支持多个值中选择多个。 ","date":"2023-05-22","objectID":"/202305221317-mysql-%E7%B1%BB%E5%9E%8B/:3:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"mysql 类型","uri":"/202305221317-mysql-%E7%B1%BB%E5%9E%8B/#字符串类型"},{"categories":["MySQL"],"content":" 一些概念数据库设计中，范式是一种规范化的方法，用于确保关系型数据库中的数据不会出现冗余或不一致的情况。范式定义了关系模型中属性之间的依赖关系，并提供了一组规则来检查和优化这些依赖关系。 在数据库设计中，通常使用前四个范式（1NF、2NF、3NF和BCNF）来规范化关系模型。每个范式都有其特定的规则和要求，以确保关系模型中的数据具有最小的冗余和最高的一致性。 通过遵循范式规则，可以使数据库设计更加规范化和优化，从而提高数据库的性能和可维护性。但是，在实际应用中，过度规范化也可能会导致查询效率下降，因此需要根据具体情况进行权衡和选择。 高阶范式一定符合低阶范式的要求 一般来说，数据库设计尽量满足 3NF。但这也不是绝对的，有时为了查询效率，也会出现反范式的设计 ","date":"2023-05-22","objectID":"/202305221331-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%8C%83%E5%BC%8F/:1:0","series":["MySQL使用"],"tags":["数据库"],"title":"数据库设计的范式","uri":"/202305221331-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%8C%83%E5%BC%8F/#一些概念"},{"categories":["MySQL"],"content":" 范式设计 1NF：字段原子性，字段的设计应该是不可再拆分的 2NF：非主属性都要和主键有直接依赖关系 3NF：非主属性之间不能有依赖关系 假设有一张订单表（订单id，商品id，用户id，用户姓名） 其中用户姓名与用户id相关联，不满足 3NF ","date":"2023-05-22","objectID":"/202305221331-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%8C%83%E5%BC%8F/:2:0","series":["MySQL使用"],"tags":["数据库"],"title":"数据库设计的范式","uri":"/202305221331-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%8C%83%E5%BC%8F/#范式设计"},{"categories":["MySQL"],"content":" 反范式设计有时为了查询效率，可以牺牲一定的空间，反范式允许通过少量的冗余，来达到查询性能上的提升 ","date":"2023-05-22","objectID":"/202305221331-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%8C%83%E5%BC%8F/:3:0","series":["MySQL使用"],"tags":["数据库"],"title":"数据库设计的范式","uri":"/202305221331-%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1%E7%9A%84%E8%8C%83%E5%BC%8F/#反范式设计"},{"categories":["MySQL"],"content":" 一、查询","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:1:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#一查询"},{"categories":["MySQL"],"content":" 1.1 用法 SELECT [DISTINCT] column_name,column_name FROM table_name [WHERE Clause] [LIMIT N][ OFFSET M] ORDER BY field1 [ASC [DESC][默认 ASC]], [field2...] [ASC [DESC][默认 ASC]] GROUP BY column_name HAVING condition WHERE op: 操作符 描述 = !=,\u003c\u003e \u003e,\u003e= \u003c,\u003c= IS NULL IS NOT NULL \u003c=\u003e 比较的两个值相等 或者 都为NULL 时返回true LIKE e.g field LIKE ‘%aaa%’ where 判断中，可能会用到一些方法 方法 描述 LENGTH() 字节数 CHAR_LENGTH() 字符数 ORDER BY：排序 ASC DESC DISTINCT：去重 GROUP BY：分组 HAVING：通常跟 GROUP BY 一起使用，用于筛选分组 ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:1:1","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#11-用法"},{"categories":["MySQL"],"content":" 1.2 练习 1757. 可回收且低脂的产品 584. 寻找用户推荐人 SELECT name FROM customer WHERE referee_id \u003c\u003e 2 OR referee_id IS NULL 595. 大的国家 1148. 文章浏览 I SELECT DISTINCT author_id AS id FROM Views WHERE author_id = viewer_id ORDER BY id ASC ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:1:2","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#12-练习"},{"categories":["MySQL"],"content":" 1.3 一些错误例子 在 select 中，select 是最后执行的，给字段取了别名是不能在 where 中使用的 SELECT author_id AS id FROM Views WHERE id = viewer_id ORDER BY id ASC ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:1:3","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#13-一些错误例子"},{"categories":["MySQL"],"content":" 二、更新","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:2:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#二更新"},{"categories":["MySQL"],"content":" 2.1 用法 UPDATE table_name SET field1=new-value1, field2=new-value2 [WHERE Clause] ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:2:1","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#21-用法"},{"categories":["MySQL"],"content":" 三、插入","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:3:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#三插入"},{"categories":["MySQL"],"content":" 3.1 用法 INSERT INTO table_name ( field1, field2,...fieldN ) VALUES ( value1, value2,...valueN ); ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:3:1","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#31-用法"},{"categories":["MySQL"],"content":" 四、删除","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:4:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#四删除"},{"categories":["MySQL"],"content":" 4.1 用法 DELETE FROM table_name [WHERE Clause] ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:4:1","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#41-用法"},{"categories":["MySQL"],"content":" 五、连接","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:5:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#五连接"},{"categories":["MySQL"],"content":" 5.1 用法 连接方式 图示 INNER JOIN LEFT JOIN RIGHT JOIN SELECT a.runoob_id, a.runoob_author, b.runoob_count FROM runoob_tbl a INNER JOIN tcount_tbl b ON a.runoob_author = b.runoob_author ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:5:1","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#51-用法"},{"categories":["MySQL"],"content":" 5.2 练习 1378. 使用唯一标识码替换员工ID 1068. 产品销售分析 I 570. 至少有5名直接下属的经理 SELECT t1.name FROM Employee as t1 JOIN ( SELECT managerId FROM Employee a GROUP BY a.managerId HAVING count(id) \u003e= 5 ) as t2 ON t1.id = t2.managerId 2356. 每位教师所教授的科目种类的数量 ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:5:2","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#52-练习"},{"categories":["MySQL"],"content":" 六、聚合函数","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:6:0","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#六聚合函数"},{"categories":["MySQL"],"content":" 6.1 用法 聚合函数 举例 说明 COUNT() SELECT COUNT(*) FROM users; 计算指定列中的行数 SUM() SELECT SUM(amount) FROM orders; 计算指定列中所有值的总和 AVG() SELECT AVG(amount) FROM orders; 计算指定列中所有值的平均值 MAX() SELECT MAX(amount) FROM orders; 计算指定列中所有值的最大值 MIN() SELECT MIN(amount) FROM orders; 计算指定列中所有值的最小值 还有一些数值计算相关的聚合函数： 聚合函数 举例 说明 ABS() SELECT ABS(-10) FROM data; 返回指定数值的绝对值 CEIL() SELECT CEIL(3.14) FROM data; 返回不小于指定数值的最小整数 FLOOR() SELECT FLOOR(3.14) FROM data; 返回不大于指定数值的最大整数 MOD() SELECT MOD(10, 3) FROM data; 返回指定两个数值相除的余数 POWER() SELECT POWER(2, 3) FROM data; 返回指定数值的指定次幂 ROUND() SELECT ROUND(3.14159, 2) FROM data; 返回指定数值的四舍五入值 SIGN() SELECT SIGN(-10) FROM data; 返回指定数值的符号（1 表示正数，-1 表示负数，0 表示零） SQRT() SELECT SQRT(16) FROM data; 返回指定数值的平方根 ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:6:1","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#61-用法"},{"categories":["MySQL"],"content":" 6.2 练习 620. 有趣的电影 SELECT * FROM cinema WHERE description \u003c\u003e 'boring' AND MOD(id, 2) = 1 ORDER BY rating DESC ","date":"2023-05-22","objectID":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/:6:2","series":["MySQL使用"],"tags":["数据库","mysql"],"title":"sql 基本语法回顾","uri":"/202305221118-sql-%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%E5%9B%9E%E9%A1%BE/#62-练习"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 存储 1.阅读《DDIA》:done,09:00, 2h section mysql 1.sql基本语法回顾: done,90m section 文档迁移 1. ebs、ecs工作期间的文档: done, 90m section 习惯 算法每日一题:done, 1h ","date":"2023-05-22","objectID":"/2023-05-22/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-22 日记录","uri":"/2023-05-22/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-22","objectID":"/2023-05-22/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-22 日记录","uri":"/2023-05-22/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-22","objectID":"/2023-05-22/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-22 日记录","uri":"/2023-05-22/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） “普通人活得疲惫而惶恐，一个疲惫而惶恐的人负担不了理想。他必须养家糊口” – 《漫长的告别》 ","date":"2023-05-22","objectID":"/2023-05-22/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-22 日记录","uri":"/2023-05-22/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-22","objectID":"/2023-05-22/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-22 日记录","uri":"/2023-05-22/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-22","objectID":"/2023-05-22/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-22 日记录","uri":"/2023-05-22/#记录区-明天"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-21","objectID":"/202305212117-golang-%E5%86%85%E5%AD%98%E5%9D%97/:0:0","series":["card"],"tags":[],"title":"golang 内存块","uri":"/202305212117-golang-%E5%86%85%E5%AD%98%E5%9D%97/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一、一些事实 Go 支持自动的内存管理，比如：自动内存开辟、自动垃圾回收 内存块的尺寸是什么决定的？是由他们所承载的数据值部的尺寸所决定的，因此不同的内存块大小可能是不同的 内存被开辟在哪里？（local 202305212124 内存被开辟在哪里 remote 202305212124 内存被开辟在哪里） 使用 new 分配的内存块可能在栈上，也可能在堆上（对于尺寸较大的实例，通常分配在堆上，对于尺寸较小的实例，通常分配在栈上） 每个协程的栈在协程退出的时候被整体回收 ","date":"2023-05-21","objectID":"/202305212117-golang-%E5%86%85%E5%AD%98%E5%9D%97/:1:0","series":["card"],"tags":[],"title":"golang 内存块","uri":"/202305212117-golang-%E5%86%85%E5%AD%98%E5%9D%97/#一一些事实"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 Go 程序运行的时候，每个协程维护一个栈，开辟在栈上的内存块只能在此协程内部使用 每个程序有一个堆，堆是一个虚拟的概念，开辟在堆上的内存块所有的协程都能够访问 如何决定开辟在栈还是堆上？ 如果编译器察觉到一个内存块可能会被多个协程访问，或者无法保证一个内存块只被一个协程访问，那么这个内存块就会被开辟在堆上，这是保守且安全的。 栈让 Go 的运行效率更高 在栈上开辟内存更快 栈上的内存块不需要垃圾回收（栈式内存管理：当函数被调用时，编译器会将栈帧压入栈中，当函数执行完毕后，编译器会将栈帧从栈中弹出，这样就自动释放了该函数所使用的所有内存空间） 对 CPU 缓存更友好 ","date":"2023-05-21","objectID":"/202305212124-%E5%86%85%E5%AD%98%E8%A2%AB%E5%BC%80%E8%BE%9F%E5%9C%A8%E5%93%AA%E9%87%8C/:0:0","series":["card"],"tags":[],"title":"内存被开辟在哪里","uri":"/202305212124-%E5%86%85%E5%AD%98%E8%A2%AB%E5%BC%80%E8%BE%9F%E5%9C%A8%E5%93%AA%E9%87%8C/#heading"},{"categories":["Golang"],"content":" 通道关闭的原则 通用的通道关闭的原则是：不要关闭一个已经关闭的通道，因为这将导致一个恐慌 另外一个常用的相对容易遵守的原则： 不要在数据的接收方或者在有多个发送者的情况下关闭通道，换句话说，最好让一个通道唯一的发送者来关闭通道 ❌ 不要在数据的接收方关闭通道 ❌ 不要在有多个发送者的情况下关闭通道 如果一定要在上面的两种场景下关闭通道，记得使用 recover 来防止程序崩溃 ✅最好让通道的唯一发送者来关闭 ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:1:0","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#通道关闭的原则"},{"categories":["Golang"],"content":" 礼貌地关闭通道的方法（不能完全避免数据竞争）可以通过 sync.Once 或者 sync.Mutex 来实现 实现1： type MyChannel struct { C chan T once sync.Once } func NewMyChannel() *MyChannel { return \u0026MyChannel{C: make(chan T)} } func (mc *MyChannel) SafeClose() { mc.once.Do(func() { close(mc.C) }) } 实现2： type MyChannel struct { C chan T closed bool mutex sync.Mutex } func NewMyChannel() *MyChannel { return \u0026MyChannel{C: make(chan T)} } func (mc *MyChannel) SafeClose() { mc.mutex.Lock() defer mc.mutex.Unlock() if !mc.closed { close(mc.C) mc.closed = true } } func (mc *MyChannel) IsClosed() bool { mc.mutex.Lock() defer mc.mutex.Unlock() return mc.closed } ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:2:0","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#礼貌地关闭通道的方法不能完全避免数据竞争"},{"categories":["Golang"],"content":" 优雅地关闭通道的办法","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:3:0","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#优雅地关闭通道的办法"},{"categories":["Golang"],"content":" M接收者 - 1发送者 func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) // ... const Max = 100000 const NumReceivers = 100 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int) // 发送者 go func() { for { if value := rand.Intn(Max); value == 0 { // 此唯一的发送者可以安全地关闭此数据通道。 close(dataCh) return } else { dataCh \u003c- value } } }() // 接收者 for i := 0; i \u003c NumReceivers; i++ { go func() { defer wgReceivers.Done() // 接收数据直到通道dataCh已关闭 // 并且dataCh的缓冲队列已空。 for value := range dataCh { log.Println(value) } }() } wgReceivers.Wait() } 变种1. 通过K第三方协程来关闭通道可能由多个第三方协程中的任意一个协程来通知关闭 dataCh 通道 func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) // ... const Max = 100000 const NumReceivers = 100 const NumThirdParties = 15 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int) closing := make(chan struct{}) // 信号通道 closed := make(chan struct{}) // 此stop函数可以被安全地多次调用。 stop := func() { select { case closing\u003c-struct{}{}: \u003c-closed case \u003c-closed: } } // 一些第三方协程 for i := 0; i \u003c NumThirdParties; i++ { go func() { r := 1 + rand.Intn(3) time.Sleep(time.Duration(r) * time.Second) stop() }() } // 发送者 go func() { defer func() { close(closed) close(dataCh) }() for { select{ case \u003c-closing: return default: } select{ case \u003c-closing: return case dataCh \u003c- rand.Intn(Max): } } }() // 接收者 for i := 0; i \u003c NumReceivers; i++ { go func() { defer wgReceivers.Done() for value := range dataCh { log.Println(value) } }() } wgReceivers.Wait() } 代码片段解析： // 此stop函数可以被安全地多次调用。 stop := func() { select { case closing\u003c-struct{}{}: \u003c-closed case \u003c-closed: } } 当调用 stop 方法的时候，会执行： 向 closing 通道发送开始关闭的通知，如果发送成功，就等待 closed 通道的关闭，表示协程已经退出 如果发送失败，说明 closing 已经关闭，直接从 closed 通道接收一个值 closing ch ：第三方协程用来通知发送方关闭通道 closed ch：发送方用来通知第三方协程通道已经关闭 ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:3:1","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#m接收者---1发送者"},{"categories":["Golang"],"content":" M接收者 - 1发送者 func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) // ... const Max = 100000 const NumReceivers = 100 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int) // 发送者 go func() { for { if value := rand.Intn(Max); value == 0 { // 此唯一的发送者可以安全地关闭此数据通道。 close(dataCh) return } else { dataCh \u003c- value } } }() // 接收者 for i := 0; i \u003c NumReceivers; i++ { go func() { defer wgReceivers.Done() // 接收数据直到通道dataCh已关闭 // 并且dataCh的缓冲队列已空。 for value := range dataCh { log.Println(value) } }() } wgReceivers.Wait() } 变种1. 通过K第三方协程来关闭通道可能由多个第三方协程中的任意一个协程来通知关闭 dataCh 通道 func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) // ... const Max = 100000 const NumReceivers = 100 const NumThirdParties = 15 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int) closing := make(chan struct{}) // 信号通道 closed := make(chan struct{}) // 此stop函数可以被安全地多次调用。 stop := func() { select { case closing\u003c-struct{}{}: \u003c-closed case \u003c-closed: } } // 一些第三方协程 for i := 0; i \u003c NumThirdParties; i++ { go func() { r := 1 + rand.Intn(3) time.Sleep(time.Duration(r) * time.Second) stop() }() } // 发送者 go func() { defer func() { close(closed) close(dataCh) }() for { select{ case \u003c-closing: return default: } select{ case \u003c-closing: return case dataCh \u003c- rand.Intn(Max): } } }() // 接收者 for i := 0; i \u003c NumReceivers; i++ { go func() { defer wgReceivers.Done() for value := range dataCh { log.Println(value) } }() } wgReceivers.Wait() } 代码片段解析： // 此stop函数可以被安全地多次调用。 stop := func() { select { case closing\u003c-struct{}{}: \u003c-closed case \u003c-closed: } } 当调用 stop 方法的时候，会执行： 向 closing 通道发送开始关闭的通知，如果发送成功，就等待 closed 通道的关闭，表示协程已经退出 如果发送失败，说明 closing 已经关闭，直接从 closed 通道接收一个值 closing ch ：第三方协程用来通知发送方关闭通道 closed ch：发送方用来通知第三方协程通道已经关闭 ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:3:1","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#变种1-通过k第三方协程来关闭通道"},{"categories":["Golang"],"content":" 1接收者 - N发送者新建一个用来通知发送者别再发送数据的通道，这个通道的发送者是这个场景下的接收者 func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) // ... const Max = 100000 const NumSenders = 1000 wgReceivers := sync.WaitGroup{} wgReceivers.Add(1) // ... dataCh := make(chan int) stopCh := make(chan struct{}) // stopCh是一个额外的信号通道。它的 // 发送者为dataCh数据通道的接收者。 // 它的接收者为dataCh数据通道的发送者。 // 发送者 for i := 0; i \u003c NumSenders; i++ { go func() { for { // 这里的第一个尝试接收用来让此发送者 // 协程尽早地退出。对于这个特定的例子， // 此select代码块并非必需。 select { case \u003c- stopCh: return default: } // 即使stopCh已经关闭，此第二个select // 代码块中的第一个分支仍很有可能在若干个 // 循环步内依然不会被选中。如果这是不可接受 // 的，则上面的第一个select代码块是必需的。 select { case \u003c- stopCh: return case dataCh \u003c- rand.Intn(Max): } } }() } // 接收者 go func() { defer wgReceivers.Done() for value := range dataCh { if value == Max-1 { // 此唯一的接收者同时也是stopCh通道的 // 唯一发送者。尽管它不能安全地关闭dataCh数 // 据通道，但它可以安全地关闭stopCh通道。 close(stopCh) return } log.Println(value) } }() // ... wgReceivers.Wait() } 这个例子中有两个通道 stopCh：通过接收者来关闭 dataCh：用来传输数据的通道，这个通道并没有关闭，但是通过 stopCh 通道的关闭，使用 dataCh 通道的协程都将退出，那么这个通道最终会被垃圾回收，这也正是优雅性的体现（不关闭一个通道也实现了停用一个通道，没遵守通道关闭原则，也没违背？） ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:3:2","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#1接收者---n发送者"},{"categories":["Golang"],"content":" M接收者 - N发送者引入一个调解协程，让其关闭一个额外的信号通道，来通知所有的接收者和发送者结束工作 func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) // ... const Max = 100000 const NumReceivers = 10 const NumSenders = 1000 wgReceivers := sync.WaitGroup{} wgReceivers.Add(NumReceivers) // ... dataCh := make(chan int) stopCh := make(chan struct{}) // stopCh是一个额外的信号通道。它的发送 // 者为中间调解者。它的接收者为dataCh // 数据通道的所有的发送者和接收者。 toStop := make(chan string, 1) // toStop是一个用来通知中间调解者让其 // 关闭信号通道stopCh的第二个信号通道。 // 此第二个信号通道的发送者为dataCh数据 // 通道的所有的发送者和接收者，它的接收者 // 为中间调解者。它必须为一个缓冲通道。 var stoppedBy string // 中间调解者 go func() { stoppedBy = \u003c-toStop close(stopCh) }() // 发送者 for i := 0; i \u003c NumSenders; i++ { go func(id string) { for { value := rand.Intn(Max) if value == 0 { // 为了防止阻塞，这里使用了一个尝试 // 发送操作来向中间调解者发送信号。 select { case toStop \u003c- \"发送者#\" + id: default: } return } // 此处的尝试接收操作是为了让此发送协程尽早 // 退出。标准编译器对尝试接收和尝试发送做了 // 特殊的优化，因而它们的速度很快。 select { case \u003c- stopCh: return default: } // 即使stopCh已关闭，如果这个select代码块 // 中第二个分支的发送操作是非阻塞的，则第一个 // 分支仍很有可能在若干个循环步内依然不会被选 // 中。如果这是不可接受的，则上面的第一个尝试 // 接收操作代码块是必需的。 select { case \u003c- stopCh: return case dataCh \u003c- value: } } }(strconv.Itoa(i)) } // 接收者 for i := 0; i \u003c NumReceivers; i++ { go func(id string) { defer wgReceivers.Done() for { // 和发送者协程一样，此处的尝试接收操作是为了 // 让此接收协程尽早退出。 select { case \u003c- stopCh: return default: } // 即使stopCh已关闭，如果这个select代码块 // 中第二个分支的接收操作是非阻塞的，则第一个 // 分支仍很有可能在若干个循环步内依然不会被选 // 中。如果这是不可接受的，则上面尝试接收操作 // 代码块是必需的。 select { case \u003c- stopCh: return case value := \u003c-dataCh: if value == Max-1 { // 为了防止阻塞，这里使用了一个尝试 // 发送操作来向中间调解者发送信号。 select { case toStop \u003c- \"接收者#\" + id: default: } return } log.Println(value) } } }(strconv.Itoa(i)) } // ... wgReceivers.Wait() log.Println(\"被\" + stoppedBy + \"终止了\") } 注意： toStop 的容量必须为 1。如果它的容量为 0，那么如果调解协程未就绪，就已经有某个协程往 toStop 发送信号，这个信号会被忽略掉 ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:3:3","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#m接收者---n发送者"},{"categories":["Golang"],"content":" N发送者的变种：dataCh 必须被关闭// todo https://gfw.go101.org/article/channel-closing.html ","date":"2023-05-21","objectID":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/:3:4","series":["Golang语言使用"],"tags":["通道"],"title":"如何优雅地关闭一个通道","uri":"/202305211358-%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%85%B3%E9%97%AD%E4%B8%80%E4%B8%AA%E9%80%9A%E9%81%93/#n发送者的变种datach-必须被关闭"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section leetcode 1.周赛: done,10:30, 90m section 《Go101》 看完通道相关的内容: done, 3h 粗读并发编程的其他内容:done, 3h 粗读《内存相关》的内容:done, 90m section 博客 1.整理box的文档:done, 15m section 习惯 算法每日一题:done, 1h ","date":"2023-05-21","objectID":"/2023-05-21/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-21 日记录","uri":"/2023-05-21/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-21","objectID":"/2023-05-21/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-21 日记录","uri":"/2023-05-21/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-21","objectID":"/2023-05-21/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-21 日记录","uri":"/2023-05-21/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-21","objectID":"/2023-05-21/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-21 日记录","uri":"/2023-05-21/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-21","objectID":"/2023-05-21/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-21 日记录","uri":"/2023-05-21/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-21","objectID":"/2023-05-21/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-21 日记录","uri":"/2023-05-21/#记录区-明天"},{"categories":["Golang"],"content":" 采用最快回应从多个数据源获取数据，只需采用最快的回应，并舍弃其他较慢的回应 N 个数据源，防止被舍弃的其他协程永久阻塞，通道应该是一个容量至少为 N-1 的缓冲通道 func source(c chan\u003c- int32) { ra, rb := rand.Int31(), rand.Intn(3) + 1 // 睡眠1秒/2秒/3秒 time.Sleep(time.Duration(rb) * time.Second) c \u003c- ra } func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 startTime := time.Now() c := make(chan int32, 5) // 必须用一个缓冲通道 for i := 0; i \u003c cap(c); i++ { go source(c) } rnd := \u003c- c // 只有第一个回应被使用了 fmt.Println(time.Since(startTime)) fmt.Println(rnd) } 阅读了下面的 尝试机制 后，最快回应还可以这么来实现： func source(c chan\u003c- int32) { ra, rb := rand.Int31(), rand.Intn(3)+1 // 休眠1秒/2秒/3秒 time.Sleep(time.Duration(rb) * time.Second) select { case c \u003c- ra: default: } } func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 c := make(chan int32, 1) // 此通道容量必须至少为1 for i := 0; i \u003c 5; i++ { go source(c) } rnd := \u003c-c // 只采用第一个成功发送的回应数据 fmt.Println(rnd) } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#采用最快回应"},{"categories":["Golang"],"content":" 单对单通知 func main() { values := make([]byte, 32 * 1024 * 1024) if _, err := rand.Read(values); err != nil { fmt.Println(err) os.Exit(1) } done := make(chan struct{}) // 也可以是缓冲的 // 排序协程 go func() { sort.Slice(values, func(i, j int) bool { return values[i] \u003c values[j] }) done \u003c- struct{}{} // 通知排序已完成 }() // 并发地做一些其它事情... \u003c- done // 等待通知 fmt.Println(values[0], values[len(values)-1]) } 通过 done \u003c- struct{}{} 往 done 通道发送数据来表示协程的计算已经完成（也可以使用接收的方式来通知，不过使用的比较少） ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:2:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#单对单通知"},{"categories":["Golang"],"content":" 多对单、单对多通知（较少使用的代码片段） type T = struct{} func worker(id int, ready \u003c-chan T, done chan\u003c- T) { \u003c-ready // 阻塞在此，等待通知 log.Print(\"Worker#\", id, \"开始工作\") // 模拟一个工作负载。 time.Sleep(time.Second * time.Duration(id+1)) log.Print(\"Worker#\", id, \"工作完成\") done \u003c- T{} // 通知主协程（N-to-1） } func main() { log.SetFlags(0) ready, done := make(chan T), make(chan T) go worker(0, ready, done) go worker(1, ready, done) go worker(2, ready, done) // 模拟一个初始化过程 time.Sleep(time.Second * 3 / 2) // 单对多通知 ready \u003c- T{}; ready \u003c- T{}; ready \u003c- T{} // 等待被多对单通知 \u003c-done; \u003c-done; \u003c-done } 不过多对单的通知通常会使用 sync.WaitGroup 来实现 ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:3:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#多对单单对多通知较少使用的代码片段"},{"categories":["Golang"],"content":" 通过关闭通道来实现群发通知 ... close(ready) // 群发通知 ... ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:4:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#通过关闭通道来实现群发通知"},{"categories":["Golang"],"content":" 定时通知 func AfterDuration(d time.Duration) \u003c- chan struct{} { c := make(chan struct{}, 1) go func() { time.Sleep(d) c \u003c- struct{}{} }() return c } func main() { fmt.Println(\"Hi!\") \u003c- AfterDuration(time.Second) fmt.Println(\"Hello!\") \u003c- AfterDuration(time.Second) fmt.Println(\"Bye!\") } 也就是 \u003c-time.After() ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:5:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#定时通知"},{"categories":["Golang"],"content":" 将通道用做互斥锁（mutex） 效率不如 sync 来得高 通道的容量必须为 1 func increase1000(v *int, mutex chan struct{}) { for i := 0; i \u003c 1000; i++ { mutex \u003c- struct{}{} // 往通道发送数据获取锁，由于通道的容量为 1，其他协程发送数据的时候进入阻塞状态 *v++ \u003c- mutex // 释放锁 } wg.Done() } func main() { cnt := 0 mutex := make(chan struct{}, 1) wg.Add(2) go increase1000(\u0026cnt, mutex) go increase1000(\u0026cnt, mutex) wg.Wait() fmt.Println(cnt) } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:6:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#将通道用做互斥锁mutex"},{"categories":["Golang"],"content":" 将通道用作计数信号量（counting semaphore）-常用来限制最大并发数 计数信号量可被视为多主锁 假设缓冲通道的容量为 N，那么可以将这个通道看作同一时刻最多可以有 N 个主人的锁 举例一个场景：一个酒吧，拥有 10 个座位，同一时刻最多只能有 10 个人在喝酒，其他人只能等待 代码实现： func cusEvent(cusNo int, seat chan int) { log.Println(\"顾客#\", cusNo, \"进入酒吧\") chairNo := \u003c- seat // 获得一张椅子 log.Println(\"\\t\\t顾客#\", cusNo, \"在\", chairNo, \"号椅子上开始喝酒\") time.Sleep(time.Second * 1) log.Println(\"\\t\\t\\t\\t顾客#\", cusNo, \"离开了酒吧\") seat \u003c- chairNo // 顾客动作完成，让出椅子 wg.Done() } func main() { // 创建一个 10 容量的缓冲通道，用来代表 10 个座位 // 通道的值 -- 椅子的编号 seat := make(chan int, 10) for i := 0; i \u003c cap(seat); i++ { seat \u003c- i + 1 } // 模拟有 50 个客人进入酒吧 for i := 0; i \u003c 30; i++ { wg.Add(1) go cusEvent(i+1, seat) } wg.Wait() } 上面程序的输出可能为： 2023/05/20 18:25:32 顾客# 1 进入酒吧 2023/05/20 18:25:32 顾客# 1 在 1 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 2 进入酒吧 2023/05/20 18:25:32 顾客# 11 进入酒吧 2023/05/20 18:25:32 顾客# 11 在 3 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 4 进入酒吧 2023/05/20 18:25:32 顾客# 4 在 4 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 5 进入酒吧 2023/05/20 18:25:32 顾客# 5 在 5 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 6 进入酒吧 2023/05/20 18:25:32 顾客# 6 在 6 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 7 进入酒吧 2023/05/20 18:25:32 顾客# 7 在 7 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 8 进入酒吧 2023/05/20 18:25:32 顾客# 8 在 8 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 9 进入酒吧 2023/05/20 18:25:32 顾客# 9 在 9 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 10 进入酒吧 2023/05/20 18:25:32 顾客# 10 在 10 号椅子上开始喝酒 2023/05/20 18:25:32 顾客# 17 进入酒吧 2023/05/20 18:25:32 顾客# 12 进入酒吧 2023/05/20 18:25:32 顾客# 13 进入酒吧 2023/05/20 18:25:32 顾客# 14 进入酒吧 2023/05/20 18:25:32 顾客# 15 进入酒吧 2023/05/20 18:25:32 顾客# 16 进入酒吧 2023/05/20 18:25:32 顾客# 20 进入酒吧 2023/05/20 18:25:32 顾客# 18 进入酒吧 2023/05/20 18:25:32 顾客# 19 进入酒吧 2023/05/20 18:25:32 顾客# 22 进入酒吧 2023/05/20 18:25:32 顾客# 21 进入酒吧 2023/05/20 18:25:32 顾客# 24 进入酒吧 2023/05/20 18:25:32 顾客# 23 进入酒吧 2023/05/20 18:25:32 顾客# 25 进入酒吧 2023/05/20 18:25:32 顾客# 26 进入酒吧 2023/05/20 18:25:32 顾客# 3 进入酒吧 2023/05/20 18:25:32 顾客# 27 进入酒吧 2023/05/20 18:25:32 顾客# 28 进入酒吧 2023/05/20 18:25:32 顾客# 29 进入酒吧 2023/05/20 18:25:32 顾客# 30 进入酒吧 2023/05/20 18:25:32 顾客# 2 在 2 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 2 离开了酒吧 2023/05/20 18:25:33 顾客# 11 离开了酒吧 2023/05/20 18:25:33 顾客# 9 离开了酒吧 2023/05/20 18:25:33 顾客# 7 离开了酒吧 2023/05/20 18:25:33 顾客# 8 离开了酒吧 2023/05/20 18:25:33 顾客# 10 离开了酒吧 2023/05/20 18:25:33 顾客# 4 离开了酒吧 2023/05/20 18:25:33 顾客# 17 在 2 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 5 离开了酒吧 2023/05/20 18:25:33 顾客# 1 离开了酒吧 2023/05/20 18:25:33 顾客# 19 在 1 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 15 在 8 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 14 在 7 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 6 离开了酒吧 2023/05/20 18:25:33 顾客# 13 在 9 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 12 在 3 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 16 在 10 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 20 在 4 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 18 在 5 号椅子上开始喝酒 2023/05/20 18:25:33 顾客# 22 在 6 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 19 离开了酒吧 2023/05/20 18:25:34 顾客# 20 离开了酒吧 2023/05/20 18:25:34 顾客# 13 离开了酒吧 2023/05/20 18:25:34 顾客# 23 在 9 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 21 在 1 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 15 离开了酒吧 2023/05/20 18:25:34 顾客# 25 在 8 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 22 离开了酒吧 2023/05/20 18:25:34 顾客# 26 在 6 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 18 离开了酒吧 2023/05/20 18:25:34 顾客# 3 在 5 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 17 离开了酒吧 2023/05/20 18:25:34 顾客# 27 在 2 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 14 离开了酒吧 2023/05/20 18:25:34 顾客# 12 离开了酒吧 2023/05/20 18:25:34 顾客# 16 离开了酒吧 2023/05/20 18:25:34 顾客# 29 在 3 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 30 在 10 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 28 在 7 号椅子上开始喝酒 2023/05/20 18:25:34 顾客# 24 在 4 号椅子上开始喝酒 2023/05/20 18:25:35 顾客# 25 离开了酒吧 2023/05/20 18:25:35 顾客# 30 离开了酒吧 2023/05/20 18:25:35 顾客# 21 离开了酒吧 2023/05/20 18:25:35 顾客# 24 离开了酒吧 2023/05/20 18:25:35 顾客# 26 离开了酒吧 2023/05/20 18:25:35 顾客# 28 离开了酒吧 2023/05/20 18:25:35 顾客# 23 离开了酒吧 2023/05/20 18:25:35 顾客# 3 离开了酒吧 2023/05/20 18:25:35 顾客# 27 离开了酒吧 2023/05/20 18:25:35 顾客# 29 离开了酒吧 上面的程序达到了预期的效果：同一时刻最多只有 10 位客人在喝酒 但是通过输出就可以直观的看出来，如果等待的人过多，(问题1)会创建出非常多的协程一直在阻塞状态 改进代码1： func cusEvent(cusNo int, seat chan int, chairNo int) { log.Println(\"顾客#\", cusNo, \"进入酒吧\") //chairNo := \u003c- seat // 获得一张","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:7:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#将通道用作计数信号量counting-semaphore-常用来限制最大并发数"},{"categories":["Golang"],"content":" 对话（乒乓） type Ball uint32 func play(playerName string, table chan Ball) { var lastValue Ball = 1 defer wg.Done() for { ball := \u003c-table fmt.Println(playerName, ball) ball += lastValue if ball \u003c lastValue { os.Exit(0) } lastValue = ball table \u003c- ball time.Sleep(100) } } func main() { table := make(chan Ball) wg.Add(2) go play(\"player1\", table) go play(\"player2\", table) table \u003c- 1 wg.Wait() close(table) } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:8:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#对话乒乓"},{"categories":["Golang"],"content":" 使当前协程永久阻塞使用 select{} 来实现是最简单的 func main() { go ... go ... select{} } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:9:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#使当前协程永久阻塞"},{"categories":["Golang"],"content":" 尝试发送和尝试接收 func main() { type Book struct{id int} bookshelf := make(chan Book, 3) for i := 0; i \u003c cap(bookshelf) * 2; i++ { select { case bookshelf \u003c- Book{id: i}: fmt.Println(\"成功将书放在书架上\", i) default: fmt.Println(\"书架已经被占满了\") } } for i := 0; i \u003c cap(bookshelf) * 2; i++ { select { case book := \u003c-bookshelf: fmt.Println(\"成功从书架上取下一本书\", book.id) default: fmt.Println(\"书架上已经没有书了\") } } } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:10:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#尝试发送和尝试接收"},{"categories":["Golang"],"content":" 峰值限制结合前面提到的 通道用作计数信号量 和 通道尝试（发送、接收） ,可以实现峰值限制 峰值限制的目的是防止过大的并发请求数 ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:11:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#峰值限制"},{"categories":["Golang"],"content":" 超时机制 func requestWithTimeout(timeout time.Duration) (int, error) { c := make(chan int) go doRequest(c) // 可能需要超出预期的时长回应 select { case data := \u003c-c: return data, nil case \u003c-time.After(timeout): return 0, errors.New(\"超时了！\") } } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:12:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#超时机制"},{"categories":["Golang"],"content":" 定时器（ticker）","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:13:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#定时器ticker"},{"categories":["Golang"],"content":" 速率限制（rate limiting）通过 峰值限制 和 定时器 配合，实现速率限制，用来限制在一段时间内的资源使用不超标 // 定义一个 Request 接口 type Request interface{} // 处理 Request 的函数，将 Request 中的整数打印出来 func handle(r Request) { fmt.Println(r.(int)) } // 限制处理请求的频率不超过 RateLimitPeriod 时间内处理 RateLimit 个请求 const RateLimitPeriod = time.Minute const RateLimit = 200 // 处理请求的函数，传入一个 Request 类型的通道，每次从中取出一个请求处理 func handleRequests(requests \u003c-chan Request) { // 用一个缓冲为 RateLimit 的时间类型通道作为额度的限制器 quotas := make(chan time.Time, RateLimit) // 在 goroutine 中，每隔一段时间往限额通道中发送一个时间，限制处理请求的速度 // 如果通道已满，则丢弃当前时间，让通道继续阻塞，等待下一个可用的时间发送 go func() { tick := time.NewTicker(RateLimitPeriod / RateLimit) defer tick.Stop() for t := range tick.C { select { case quotas \u003c- t: default: } } }() // 循环从 Request 通道中取出请求并处理 for r := range requests { \u003c-quotas // 等待可用的时间进行处理 go handle(r) } } func main() { requests := make(chan Request) // 创建一个 Request 类型的无缓冲通道 go handleRequests(requests) // 开启一个 goroutine 处理通道中的请求 // 循环向通道中发送请求，不断发送，直到程序被手动停止 for i := 0; ; i++ { requests \u003c- i } // 可以使用time.Sleep来让主进程休眠一段时间，模拟请求的发送 } ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:14:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#速率限制rate-limiting"},{"categories":["Golang"],"content":" todo https://gfw.go101.org/article/channel-use-cases.html ","date":"2023-05-20","objectID":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:15:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"通道使用场景","uri":"/202305201718-%E9%80%9A%E9%81%93%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#todo"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 目前 Go 支持的种类类型 ","date":"2023-05-20","objectID":"/202305201308-%E5%8F%8D%E5%B0%84-reflect/:0:0","series":["card"],"tags":[],"title":"反射 reflect","uri":"/202305201308-%E5%8F%8D%E5%B0%84-reflect/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" reflect.Typereflect.Type 为一个接口类型，指定了若干方法 需要注意的是，这一些列的方法并不是适用于所有的类型，如果属主类型调用了不合适的方法，将产生一个恐慌，举个例子： // Elem returns a type's element type.// It panics if the type's Kind is not Array, Chan, Map, Pointer, or Slice. Elem() Type Elem 防范将返回一个类型的元素类型。但是如果类型的Kind不是Array、Chan、Map、Pointer或Slice，则会出现panic。 ","date":"2023-05-20","objectID":"/202305201308-%E5%8F%8D%E5%B0%84-reflect/:1:0","series":["card"],"tags":[],"title":"反射 reflect","uri":"/202305201308-%E5%8F%8D%E5%B0%84-reflect/#reflecttype"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" reflect.Valuereflect.Value 为一个结构体类型，指定了若干方法 ","date":"2023-05-20","objectID":"/202305201308-%E5%8F%8D%E5%B0%84-reflect/:2:0","series":["card"],"tags":[],"title":"反射 reflect","uri":"/202305201308-%E5%8F%8D%E5%B0%84-reflect/#reflectvalue"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-20","objectID":"/202305201247-%E6%B3%9B%E5%9E%8B/:0:0","series":["card"],"tags":[],"title":"泛型","uri":"/202305201247-%E6%B3%9B%E5%9E%8B/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 泛型的了解 泛型Generics 是一种编程语言特性，用来在不指定具体类型的情况下编写代码，达到减少代码量、提高代码可维护性的效果 Go 语言中，没有原生支持泛型的机制，可以通过接口和反射来模拟泛型 ","date":"2023-05-20","objectID":"/202305201247-%E6%B3%9B%E5%9E%8B/:1:0","series":["card"],"tags":[],"title":"泛型","uri":"/202305201247-%E6%B3%9B%E5%9E%8B/#泛型的了解"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" Go 从 1.18 开始已经支持自定义泛型todo ","date":"2023-05-20","objectID":"/202305201247-%E6%B3%9B%E5%9E%8B/:2:0","series":["card"],"tags":[],"title":"泛型","uri":"/202305201247-%E6%B3%9B%E5%9E%8B/#go-从-118-开始已经支持自定义泛型"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-20","objectID":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/:0:0","series":["card"],"tags":["非类型安全指针"],"title":"非类型安全指针","uri":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一些事实 使用非类型安全指针一个较大的风险：使用了非类型安全指针的代码可能从今后的某个 Go 版本开始将不能通过编译，或者运行行为发生变化 非类型安全指针值是指针，但 uintptr 是整数 ","date":"2023-05-20","objectID":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/:1:0","series":["card"],"tags":["非类型安全指针"],"title":"非类型安全指针","uri":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/#一些事实"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" Pointer 的代码 type ArbitraryType int type Pointer *ArbitraryType ","date":"2023-05-20","objectID":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/:2:0","series":["card"],"tags":["非类型安全指针"],"title":"非类型安全指针","uri":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/#pointer-的代码"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 如何正确地使用非类型安全指针？unsafe 标准包的文档中列出了六种非类型安全指针的使用标准： （local 202304241708 unsafe.Pointer 的六种使用场景 remote 202304241708 unsafe.Pointer 的六种使用场景） ","date":"2023-05-20","objectID":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/:3:0","series":["card"],"tags":["非类型安全指针"],"title":"非类型安全指针","uri":"/202305201230-%E9%9D%9E%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E6%8C%87%E9%92%88/#如何正确地使用非类型安全指针"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-20","objectID":"/202305201217-%E5%86%85%E5%B5%8C%E7%B1%BB%E5%9E%8B/:0:0","series":["card"],"tags":[],"title":"内嵌类型","uri":"/202305201217-%E5%86%85%E5%B5%8C%E7%B1%BB%E5%9E%8B/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 例子 type Person struct { Name string Age int } func (p Person) PrintName() { fmt.Println(\"Name:\", p.Name) } func (p *Person) SetAge(age int) { p.Age = age } type Singer struct { Person // 通过内嵌Person类型来扩展之 works []string } func main() { t := reflect.TypeOf(Singer{}) // the Singer type fmt.Println(t, \"has\", t.NumField(), \"fields:\") for i := 0; i \u003c t.NumField(); i++ { fmt.Print(\" field#\", i, \": \", t.Field(i).Name, \"\\n\") } fmt.Println(t, \"has\", t.NumMethod(), \"methods:\") for i := 0; i \u003c t.NumMethod(); i++ { fmt.Print(\" method#\", i, \": \", t.Method(i).Name, \"\\n\") } pt := reflect.TypeOf(\u0026Singer{}) // the *Singer type fmt.Println(pt, \"has\", pt.NumMethod(), \"methods:\") for i := 0; i \u003c pt.NumMethod(); i++ { fmt.Print(\" method#\", i, \": \", pt.Method(i).Name, \"\\n\") } } 上面代码的输出结果： main.Singer has 2 fields: field#0: Person field#1: works main.Singer has 1 methods: method#0: PrintName *main.Singer has 2 methods: method#0: PrintName method#1: SetAge 输出的结果是符合预期的，但是有一个疑问：Singer 的字段并没有 Name，为什么使用 gaga.Name 是合法的？ 答：如果一个选择器的中部对应一个内嵌字段，则此项可以被省略，因此内嵌字段又被称为匿名字段 ","date":"2023-05-20","objectID":"/202305201217-%E5%86%85%E5%B5%8C%E7%B1%BB%E5%9E%8B/:1:0","series":["card"],"tags":[],"title":"内嵌类型","uri":"/202305201217-%E5%86%85%E5%B5%8C%E7%B1%BB%E5%9E%8B/#例子"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-20","objectID":"/202305200903-golang-%E6%96%B9%E6%B3%95/:0:0","series":["card"],"tags":["方法"],"title":"golang 方法","uri":"/202305200903-golang-%E6%96%B9%E6%B3%95/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一些事实 \u0026 概念 Go 语言中，我们可以为 T 或者 *T 类型声明一个方法 方法的拥有者类型称作 属主类型receiver type，可以是 T 也可以是 *T 其中 T 称作属主基类型receiver basic type ","date":"2023-05-20","objectID":"/202305200903-golang-%E6%96%B9%E6%B3%95/:1:0","series":["card"],"tags":["方法"],"title":"golang 方法","uri":"/202305200903-golang-%E6%96%B9%E6%B3%95/#一些事实--概念"},{"categories":["Golang"],"content":" 一些了解 Go 1.18版本开始，有些接口类型只能被用做类型约束。 可被用做值类型的接口类型称为基本接口类型 一个接口类型定义了一些类型条件，通过内嵌一些接口元素来定义类型条件，Go 1.20 支持两种接口元素：方法元素 和 类型元素 接口类型可以分为：基本接口类型 和 约束接口类型（自定义泛型中使用的） 基本接口类型不需要内嵌任何类型元素 如果两个接口类型的类型集相同，则他们互相实现了对方 ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:1:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#一些了解"},{"categories":["Golang"],"content":" 基本接口类型和约束接口类型示例代码 // 此接口直接指定了两个方法和内嵌了两个其它接口。 // 其中一个为类型名称，另一个为类型字面表示形式。 type ReadWriteCloser = interface { Read(buf []byte) (n int, err error) Write(buf []byte) (n int, err error) error // 一个类型名称 interface{ Close() error } // 一个类型字面表示形式 } // 此接口类型内嵌了一个近似类型。 // 它的类型集由所有底层类型为[]byte的类型组成。 type AnyByteSlice = interface { ~[]byte } // 此接口类型内嵌了一个类型并集。它的类型集包含6个类型： // uint、uint8、uint16、uint32、uint64和uintptr。 type Unsigned interface { uint | uint8 | uint16 | uint32 | uint64 | uintptr } 别名ReadWriteCloser表示的接口类型为一个基本接口类型， 但是Unsigned接口类型和别名AnyByteSlice表示的接口类型均不是基本接口类型。 后两者均只能用做约束接口类型。 ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:2:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#基本接口类型和约束接口类型"},{"categories":["Golang"],"content":" 类型实现 如果一个类型 T 实现了接口类型 X ，那么 T 类型的方法集一定是接口类型 X 的超集 Go编译器将自动在需要的时候检查两个类型之间的实现关系 ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:3:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#类型实现"},{"categories":["Golang"],"content":" 值包裹值包裹Value Wrapping 是一种将值封装到另一个类型中的技术 看一个简单例子： type Person struct { Name string Age int } type PersonWrapper struct { Person } func (pw PersonWrapper) String() string { return fmt.Sprintf(\"Name: %s, Age: %d\", pw.Name, pw.Age) } 通过值包裹，我们可以轻松地为现有类型添加新的功能，而不必修改原始类型的定义。这使得代码更加灵活和可维护。 动态值 ：当一个非接口值被包裹在一个接口中，此非接口值称作此接口值的动态值 动态类型：同上，此非接口类型称作此接口的动态类型 所以一个接口可以包裹 nil 非接口值（包裹了 nil 非接口值的接口值 != nil 接口值） ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:4:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#值包裹"},{"categories":["Golang"],"content":" 多态了解了上面值包裹的概念，就可以容易地理解如何用接口来实现多态 调用一个接口值的方法 = 调用一个接口值的动态值的方法 比如：一个非接口类型 T， 它的一个示例 t 被包裹在接口类型 I 的接口值 i 中，那么 i.m = t.m（m为定义的方法） ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:5:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#多态"},{"categories":["Golang"],"content":" 反射","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:6:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#反射"},{"categories":["Golang"],"content":" 类型断言i.(T) 断言类型为非接口类型： func main() { // 编译器将把123的类型推断为内置类型int。 var x interface{} = 123 // 情形一： n, ok := x.(int) fmt.Println(n, ok) // 123 true n = x.(int) fmt.Println(n) // 123 // 情形二： a, ok := x.(float64) fmt.Println(a, ok) // 0 false // 情形三： a = x.(float64) // 将产生一个恐慌 } 断言类型为接口类型： type Writer interface { Write(buf []byte) (int, error) } type DummyWriter struct{} func (DummyWriter) Write(buf []byte) (int, error) { return len(buf), nil } func main() { var x interface{} = DummyWriter{} // y的动态类型为内置类型string。 var y interface{} = \"abc\" var w Writer var ok bool // DummyWriter既实现了Writer，也实现了interface{}。 w, ok = x.(Writer) fmt.Println(w, ok) // {} true x, ok = w.(interface{}) fmt.Println(x, ok) // {} true // y的动态类型为string。string类型并没有实现Writer。 w, ok = y.(Writer) fmt.Println(w, ok) // false w = y.(Writer) // 将产生一个恐慌 } ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:6:1","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#类型断言"},{"categories":["Golang"],"content":" type-switch switch aSimpleStatement; v := x.(type) { case TypeA: ... case TypeB, TypeC: ... case nil: ... default: ... } ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:6:2","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#type-switch"},{"categories":["Golang"],"content":" 接口值的比较接口的内部实现可视为： type _interface struct { dynamicType *_type // 引用着接口值的动态类型 dynamicValue unsafe.Pointer // 引用着接口值的动态值 } 接口值是可以通过 == 来比较的，可以分为两种情况 非接口值跟接口值比较（非接口类型必须实现接口类型，因此也就转换成了第二种比较） 两个接口值的比较 两个接口值的比较过程： flowchart TD classDef important stroke:red, stroke-width:2px classDef success stroke:green classDef stick fill:yellow, stroke:yellow classDef stickImp fill:pink, stroke:pink, color:black a[比较两个接口值] b{是否都为 nil} end1[相同] end2[不同] end3[panic] a--\u003eb--\u003e|yes|end1 c[比较动态类型]-.-stick1 b--\u003e|no|c c--\u003e|不同的动态类型|end2 c--\u003e|相同的动态类型|d[比较动态值] d--\u003eend1 d--\u003eend2 d--\u003eend3 end3-.-stick1[如果动态类型是不能比较的将产生一个恐慌] class end1 success class end2,end3 important class stick1 stickImp 简而言之，两个接口值的比较结果只有在下面两种任一情况下才为true： 这两个接口值都为nil接口值。 这两个接口值的动态类型相同、动态类型为可比较类型、并且动态值相等。 ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:7:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#接口值的比较"},{"categories":["Golang"],"content":" 尽量包裹指针类型看下面一个具体例子： type LargeValue struct { data [1024]int } func (lv LargeValue) String() string { return fmt.Sprintf(\"%v\", lv.data[0]) } func main() { // 包裹大尺寸值 var v1 interface{} = LargeValue{} fmt.Println(v1) // 包裹指针 var v2 interface{} = \u0026LargeValue{} fmt.Println(v2) } 在上面的代码中，我们定义了一个名为 LargeValue 的结构体，其中包含了一个长度为 1024 的整型数组。然后，我们分别创建了两个接口值 v1 和 v2，并将它们分别包裹了 LargeValue 类型的值和指针。 在输出结果中，我们可以看到 v1 和 v2 的值都是相同的，但是它们的类型不同。具体来说，v1 的类型是 interface {}，而 v2 的类型是 interface {}，但是它们所包裹的值都是 \u0026{[0 0 0 ... 0]}，即 LargeValue 类型的指针。 这个例子说明了在接口值中包裹大尺寸值和包裹指针的区别。如果我们直接将 LargeValue 类型的值包裹到接口值中，那么每次复制接口值时都会复制整个 LargeValue 结构体，这会导致性能问题。而如果我们包裹指针，则只需要复制指针，而不是整个结构体，这可以提高性能并减少内存使用。因此，在处理大尺寸值时，应该尽量包裹它的指针，而不是直接包裹值。 https://gfw.go101.org/article/interface.html ","date":"2023-05-20","objectID":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/:8:0","series":["Golang语言使用"],"tags":["接口"],"title":"golang 接口","uri":"/202305200916-golang-%E6%8E%A5%E5%8F%A3/#尽量包裹指针类型"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section golang学习 4.方法:08:00,1h 5.接口:done,1h 6.类型内嵌:done,1h 7.非类型安全指针:done,1h 8.泛型:done,1h 9.反射:done,1h 10.粗读一下《GO101》的一些专题: done,2h 11.看完并发编程的内容:4h section 习惯 算法每日一题:done, 1h ","date":"2023-05-20","objectID":"/2023-05-20/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-20 日记录","uri":"/2023-05-20/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-20","objectID":"/2023-05-20/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-20 日记录","uri":"/2023-05-20/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-20","objectID":"/2023-05-20/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-20 日记录","uri":"/2023-05-20/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） “在做什么的时候，都尽力去做，可能过后什么也不记得，但是在做的时候就尽力做到最好” 今天的学习量还不错，继续保持吧 ","date":"2023-05-20","objectID":"/2023-05-20/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-20 日记录","uri":"/2023-05-20/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-20","objectID":"/2023-05-20/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-20 日记录","uri":"/2023-05-20/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天 整理一下 box 里面的文档 ","date":"2023-05-20","objectID":"/2023-05-20/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-20 日记录","uri":"/2023-05-20/#记录区-明天"},{"categories":["Golang"],"content":" 概览 通道的主要作用是用来做并发同步 Rob Pike 对于并发编程的建议：不要让计算通过共享内存来通讯，而应该通过通讯来共享内存，channel 就是这么诞生的 可以把通道看作是先进先出的队列 当一个协程往一个通道发送某个值，可以看作该协程释放了一些值的所有权 当一个协程从一个通道获取某个值，可以看作协程获得了一些值的所有权 另外几种传统的并发同步技术提供在 sync 和 sync/atomic 标准库包中 ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:1:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#概览"},{"categories":["Golang"],"content":" channel 类型 声明 说明 chan T 双向 chan\u003c- T 只能发送 \u003c-chan T 只能接收 零值： nil 容量属性：根据容量是否为 0 分为两种通道：unbuffered channel buffered channel ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:2:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#channel-类型"},{"categories":["Golang"],"content":" channel 操作 操作 语法 发送 ch \u003c- v 接收 \u003c- ch 关闭 close(ch) 获取长度 len(ch) 获取容量 cap(ch) 上面的 5 中操作都是经过 同步 的，可以在并发协程中安全运行而无需其他操作 ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:3:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#channel-操作"},{"categories":["Golang"],"content":" 通道的组成一个通道可以看作是以下三个部分组成的： 等待发送的协程队列 等待接受的协程队列 保存元素的循环队列 空槽 满槽 通道内部通过一个 互斥锁 来防止数据竞争 ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:4:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#通道的组成"},{"categories":["Golang"],"content":" 通道的操作详情先将通道做个简单归类： nil 通道 （非零）已关闭的通道 C （非零）未关闭的通道 O 操作 nil C（已关闭的通道） O（未关闭的通道） 关闭 panic panic 成功关闭3 发送 永久阻塞 panic 阻塞 or 成功发送1 接受 永久阻塞 永不阻塞4 阻塞 or 成功接受2 具体说明以上的几种情况 假设一个协程 S 往通道发送数据，S 首先去获得通道的锁，然后继续往下执行下面的其中一种情况： 非阻塞：接收的协程队列 Q2 不为空，那么 Qbuffer 一定是空的，这个时候协程往缓冲队列中写入数据，从接收的协程队列中马上弹出一个协程，接收由 S 发送的数据，然后该协程继续执行 非阻塞：接收的协程队列 Q2 为空，如果缓冲队列还没满的情况下，把数据放入缓冲队列，S 继续执行 阻塞：接收队列为空，并且缓冲队列满槽，将 S 放入发送的协程队列 Q1，进入阻塞状态。之后： 可能被一个接收数据的协程唤醒 假设一个协程 R 通过通道接收数据，R 首先获取通道的锁，然后继续往下执行下面的其中一种情况： 非阻塞：缓冲队列不为空（接收队列必为空），R 获取一个缓冲队列中的值之后继续运行；如果发送的协程队列不为空（缓冲队列满的情况），从发送队列弹出一个协程 S，将数据放入缓冲队列后，S 继续运行 非阻塞：缓冲队列为空，发送的协程队列不空，说明通道是一个非缓冲的通道，这个时候，从发送的协程队列弹出一个协程 S，R 接收到 S 发送的数据之后，两个协程均继续运行 阻塞：缓冲队列为空，发送的协程队列空，将 R 放入接收的协程队列，之后由发送的协程队列唤醒 一个协程获取到通道的锁，并且将通道关闭之后，依次执行下面的两个步骤： 如果接收队列不为空（说明缓冲队列一定是空的），将接收队列中的协程依次弹出，每个协程获取到一个缓冲队列内置元素的零值 如果发送队列不为空，将发送队列的协程依次弹出，每个协程都将产生一个 panic （由于向已关闭的通道发送数据） 从一个非零已关闭的通道接收值是永不阻塞的，可能有下面的情况 v, ok := \u003c- ch 说明 v, true v 是之前某个协程放入的 v,false v 是通道内置元素的零值 ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:5:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#通道的操作详情"},{"categories":["Golang"],"content":" 从上面的分析可以得到几个事实 如果缓冲队列不为空，那么接收队列一定是空的 如果缓冲队列不为满，那么发送队列一定是空的 如果通道关闭了，发送、接收队列一定空，但是缓冲队列不一定是空 如果通道是缓冲的，那么发送、接收队列至少有一个是空的 一个数据在从一个协程传递到另一个协程的过程中，至少被复制一次，如果存在被放入缓冲队列的情况，被复制两次 ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:5:1","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#从上面的分析可以得到几个事实"},{"categories":["Golang"],"content":" for-range 与 channel用法： for v := range aChannel { // 使用v } 结束条件：通道关闭 且 缓冲队列为空 ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:6:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#for-range-与-channel"},{"categories":["Golang"],"content":" select-case 和 channel 所有非阻塞的 case 将有一个被 随机 选择执行 如果所有的 case 都是阻塞操作，如果 default 分支存在，则 default 必定被执行，如果不存在，协程将被推入发送队列或者接收队列，并进入阻塞状态 https://gfw.go101.org/article/channel.html ","date":"2023-05-19","objectID":"/202305190910-channel-%E9%80%9A%E9%81%93/:7:0","series":["Golang语言使用"],"tags":["通道"],"title":"channel 通道","uri":"/202305190910-channel-%E9%80%9A%E9%81%93/#select-case-和-channel"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-19","objectID":"/202305190859-%E5%87%BD%E6%95%B0/:0:0","series":["card"],"tags":["函数"],"title":"函数","uri":"/202305190859-%E5%87%BD%E6%95%B0/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 关于函数的一些事实 函数类型是不可比较的，但是可以和类型不确定的 nil 比较（和 map、channel、切片类似） 函数的最后一个参数为变长参数，那么成这个函数为变长函数 当一个函数值被赋给另一个函数后，这两个函数值共享底层部分（内部的函数结构） ","date":"2023-05-19","objectID":"/202305190859-%E5%87%BD%E6%95%B0/:1:0","series":["card"],"tags":["函数"],"title":"函数","uri":"/202305190859-%E5%87%BD%E6%95%B0/#关于函数的一些事实"},{"categories":["Golang"],"content":"#string #Golang ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:0:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#"},{"categories":["Golang"],"content":" 关于字符串的一些事实 使用索引的方式 aString[i] 来获得第 i 个字节，表达式 aString[i] 是不可寻址的 使用子切片语法 aString[start:end] 来获得一个子串 使用子切片的语法来创建一个新的字符串，只会创建一个新的字符串对象（指针持有者），并不会对实际底层的字节序列做复制操作，也就是说，两个字符串对象共享部分的字节序列 ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:1:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#关于字符串的一些事实"},{"categories":["Golang"],"content":" 字符串编码和 unicode 码点字符串编码是为了将字符映射到二进制数据 unicode 编码为不同的人类语言进行了编码，使用 unicode 码点（code point）来找到对应的结果，比如： 字符 码点 A U+0041 你 U+4F60 通常情况下大部分码点对应着一个字符，大部分的汉字需要 3 个字节来保存 在 Go 中，码点用 rune 来表示，rune 的底层结构是 int32（4 个字节） ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:2:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#字符串编码和-unicode-码点"},{"categories":["Golang"],"content":" 字符串转换 flowchart LR a(字符串)\u003c--\u003eb(byte slice) a\u003c--\u003ec(rune slice) 字符串能够直接转成 byte 切片，反之亦然 字符串能够直接转成 rune 切片，反之亦然 flowchart TD b(byte slice) c(rune slice) b-.-xc []byte 和 []rune 是没法直接转换的，可以使用 unicode/utf8 库函数来实现这些转换 func Runes2Bytes(rs []rune) []byte { n := 0 for _, r := range rs { n += utf8.RuneLen(r) } n, bs := 0, make([]byte, n) for _, r := range rs { n += utf8.EncodeRune(bs[n:], r) } return bs } ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:3:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#字符串转换"},{"categories":["Golang"],"content":" 编译器对于转换是否做深拷贝的优化以下几种情况是不需要深拷贝的 从字节切片到字符串 func fc() { // 下面的四个转换都不需要深复制。 // 一个（至少有一个被衔接的字符串值为非空字符串常量的）字符串衔接表达式中的从字节切片到字符串的转换不需要深拷贝 if string(x) != string(y) { s = (\" \" + string(x) + string(y))[1:] } } func fd() { // 两个在比较表达式中的转换不需要深复制， // 但两个字符串衔接中的转换仍需要深复制。 // 请注意此字符串衔接和fc中的衔接的差别。 if string(x) != string(y) { s = string(x) + string(y) } } 从字符串到字节切片 func main() { var str = \"world\" for i, b := range []byte(str) { //... } } ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:4:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#编译器对于转换是否做深拷贝的优化"},{"categories":["Golang"],"content":" 一个语法糖 hello := []byte(\"Hello \") world := \"world!\" // helloWorld := append(hello, []byte(world)...) // 正常的语法 helloWorld := append(hello, world...) // 语法糖 ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:5:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#一个语法糖"},{"categories":["Golang"],"content":" 字符串的比较 flowchart TD classDef important stroke:red, stroke-width:2px classDef success stroke:green a[长度是否相同]--\u003e|Yes|b[持有指针是否相同] a--\u003e|No|endFailure b--\u003e|Yes|endSuccess b--\u003e|No|f[比较每个字节是否相同] f--\u003e|Yes|endSuccess f--\u003e|No|endFailure endSuccess[相同] endFailure[不相同] class endFailure important class endSuccess success 两个字符串比较的时间复杂度取决于 持有的指针 是否相同，如果相同，时间复杂度为 O(1)，如果不同，时间复杂度 O(n) ","date":"2023-05-19","objectID":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/:6:0","series":["Golang语言使用"],"tags":["string"],"title":"string 字符串学习","uri":"/202305190718-string-%E5%AD%97%E7%AC%A6%E4%B8%B2/#字符串的比较"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section golang类型系统专题学习 1.字符串:done,07:00,1h 2.函数:done,1h 3.通道:done,1h 4.方法:1h 5.接口:1h 6.类型内嵌:1h 7.非类型安全指针:1h 8.泛型:1h 9.反射:1h section 习惯 算法每日一题:done, 1h ","date":"2023-05-19","objectID":"/2023-05-19/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-19 日记录","uri":"/2023-05-19/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-19","objectID":"/2023-05-19/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-19 日记录","uri":"/2023-05-19/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-19","objectID":"/2023-05-19/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-19 日记录","uri":"/2023-05-19/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） 今天看了比较多 Go 方面的内容，感觉之前的工作中都很少能用到 channel，还是没体会到使用 Go 编程的乐趣 ","date":"2023-05-19","objectID":"/2023-05-19/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-19 日记录","uri":"/2023-05-19/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-19","objectID":"/2023-05-19/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-19 日记录","uri":"/2023-05-19/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-19","objectID":"/2023-05-19/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-19 日记录","uri":"/2023-05-19/#记录区-明天"},{"categories":["Golang"],"content":" for-range 副本的问题 func TestForRange() { arr := [3]int{1,2,3} for _, v := range arr[:] { // 转成切片 fmt.Println(v) } } （local 202305181719 for-range 中的副本拷贝 remote 202305181719 for-range 中的副本拷贝） ","date":"2023-05-18","objectID":"/202305181801-%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E4%BC%98%E5%8C%96/:1:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"Golang 提高性能的一些小优化记录","uri":"/202305181801-%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E4%BC%98%E5%8C%96/#for-range-副本的问题"},{"categories":["Golang"],"content":" 字节切片跟字符串的转换以下几种情况是不需要做深拷贝的 从字节切片到字符串 func fc() { // 下面的四个转换都不需要深复制。 // 一个（至少有一个被衔接的字符串值为非空字符串常量的）字符串衔接表达式中的从字节切片到字符串的转换不需要深拷贝 if string(x) != string(y) { s = (\" \" + string(x) + string(y))[1:] } } func fd() { // 两个在比较表达式中的转换不需要深复制， // 但两个字符串衔接中的转换仍需要深复制。 // 请注意此字符串衔接和fc中的衔接的差别。 if string(x) != string(y) { s = string(x) + string(y) } } 从字符串到字节切片 func main() { var str = \"world\" for i, b := range []byte(str) { //... } } ","date":"2023-05-18","objectID":"/202305181801-%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E4%BC%98%E5%8C%96/:2:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"Golang 提高性能的一些小优化记录","uri":"/202305181801-%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E4%BC%98%E5%8C%96/#字节切片跟字符串的转换"},{"categories":["Golang"],"content":" 字符串剪切 func f(s1 string) { s0 = (\" \" + s1[:50])[1:] } 上面这种方法可能在将来失效，可以使用一种啰嗦一点的方式： func f(s1 string) { var b strings.Builder b.Grow(50) b.WriteString(s1[:50]) s0 = b.String() } ","date":"2023-05-18","objectID":"/202305181801-%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E4%BC%98%E5%8C%96/:3:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"Golang 提高性能的一些小优化记录","uri":"/202305181801-%E6%8F%90%E9%AB%98%E6%80%A7%E8%83%BD%E7%9A%84%E4%B8%80%E4%BA%9B%E5%B0%8F%E4%BC%98%E5%8C%96/#字符串剪切"},{"categories":["Golang"],"content":" func TestForRange() { arr := [3]int{1,2,3} for _, v := range arr { arr[2] = 4 fmt.Println(v) } fmt.Println() slice := []int{1,2,3} for _, v := range slice { slice[2] = 4 fmt.Println(v) } } 以上的输出为什么是： 1 2 3 1 2 4 原因： 使用 for-range 遍历容器，实际上遍历的是容器的一个副本值，首先确定被遍历的两个对象的类型： arr：数组 slice：切片 遍历 arr 数组的时候，复制另外一份数组 arr2 用来遍历，因此就算在循环内修改 arr 的值，是不会影响到 arr2 的；遍历 slice 切片的时候，副本 slice2 仍然是切片，slice、slice2 指向的都是同一个底层的序列，slice 的修改会影响到 slice2，因此输出的结果会随着修改产生变化 那么在遍历数组的时候可以用这样的方式来提高效率： func TestForRange() { arr := [3]int{1,2,3} for _, v := range arr[:] { // 转成切片 fmt.Println(v) } } ","date":"2023-05-18","objectID":"/202305181719-for-range-%E4%B8%AD%E7%9A%84%E5%89%AF%E6%9C%AC%E6%8B%B7%E8%B4%9D/:0:0","series":["Golang语言使用"],"tags":[],"title":"for-range 中的副本拷贝","uri":"/202305181719-for-range-%E4%B8%AD%E7%9A%84%E5%89%AF%E6%9C%AC%E6%8B%B7%E8%B4%9D/#heading"},{"categories":["Golang"],"content":" 切片克隆 sClone := make([]T, len(s)) copy(sCLone, s) ","date":"2023-05-18","objectID":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/:1:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"切片的一些操作","uri":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/#切片克隆"},{"categories":["Golang"],"content":" 删除元素","date":"2023-05-18","objectID":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/:2:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"切片的一些操作","uri":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/#删除元素"},{"categories":["Golang"],"content":" 保证剩下的元素有序 s = append(s[:i], s[i+1:]...) ","date":"2023-05-18","objectID":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/:2:1","series":["Golang语言使用"],"tags":["代码片段"],"title":"切片的一些操作","uri":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/#保证剩下的元素有序"},{"categories":["Golang"],"content":" 不保证剩下的元素有序 s[i] = s[len(s)-1] s = s[:len(s)-1] ","date":"2023-05-18","objectID":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/:2:2","series":["Golang语言使用"],"tags":["代码片段"],"title":"切片的一些操作","uri":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/#不保证剩下的元素有序"},{"categories":["Golang"],"content":" tip：避免暂时性的内存泄漏如果切片元素引用着其他值（如指针、切片、映射），应该重置多出来的元素槽上的元素值，避免暂时性的内存泄漏： s[len(s) : len(s)+1][0] = t0 // 类型零值 example type Person struct { Name string Age int } func main() { people := []*Person{ {Name: \"Alice\", Age: 25}, {Name: \"Bob\", Age: 30}, {Name: \"Charlie\", Age: 35}, } // 删除第二个元素 copy(people[1:], people[2:]) people[len(people)-1] = nil // 将最后一个元素设置为零值 people = people[:len(people)-1] // 处理被删除的元素 // ... } 在上面的示例中，我们使用 copy 函数将第三个元素复制到第二个元素的位置，并将最后一个元素设置为零值。这样做可以确保被删除的元素所引用的值被及时释放，从而避免内存泄漏。 ","date":"2023-05-18","objectID":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/:2:3","series":["Golang语言使用"],"tags":["代码片段"],"title":"切片的一些操作","uri":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/#tip避免暂时性的内存泄漏"},{"categories":["Golang"],"content":" 把一个切片的所有元素插入到另一个切片 s = append(s[:i], append(elements, s[i:]...)...) ","date":"2023-05-18","objectID":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/:3:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"切片的一些操作","uri":"/202305181748-%E5%88%87%E7%89%87%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C/#把一个切片的所有元素插入到另一个切片"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-18","objectID":"/202305181645-new-%E5%92%8C-make/:0:0","series":["card"],"tags":[],"title":"new 和 make","uri":"/202305181645-new-%E5%92%8C-make/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 区别 new make 分配内存 分配内存并初始化 返回指向类型的指针 返回对象的引用 ","date":"2023-05-18","objectID":"/202305181645-new-%E5%92%8C-make/:1:0","series":["card"],"tags":[],"title":"new 和 make","uri":"/202305181645-new-%E5%92%8C-make/#区别"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 使用场景 new 用来创建值类型的对象，比如 int、float… make 用来创建指针持有者类型的对象，比如 slice、map、channel… 看下面的例子： package main import \"fmt\" func main() { a := make([]int, 1) mp := make(map[int]int, 1) b := new(int) c := new(string) d := new(float32) fmt.Println(a, b, mp, c, d) } a := make([]int, 1) main.go:6 0x6097d5 e88630faff call $runtime.makeslice 进入 runtime.makeslice 并打印 et（元素类型） (dlv) print et *runtime._type {size: 8, ptrdata: 0, hash: 3413333906, tflag: tflagUncommon|tflagExtraStar|tflagNamed|tflagRegularMemory (15), align: 8, fieldAlign: 8, kind: 2, equal: runtime.memequal64, gcdata: *0, str: 576, ptrToThis: 20480} 通过汇编可以看到调用了 makeslice 方法，返回一个 unsafe.Pointer 指向初始化的内容 runtime.makeslice: func makeslice(et *_type, len, cap int) unsafe.Pointer { ... } 其中 _type ([[2023052919 Golang 中的 _type 结构]]) 用来描述类型 mp := make(map[int]int, 1) main.go:7 0x3097f1 e88a4ef6ff call $runtime.makemap_small 由于 mp 的长度比较小，调用了 runtime.makemap_small 方法，返回一个 hmap 类型的指针 runtime.makemap_small func makemap_small() *hmap { ... } 打印 hmap 结果： *runtime.hmap { count: 0, flags: 0, B: 0, noverflow: 0, hash0: 1065545564, buckets: unsafe.Pointer(0x0), oldbuckets: unsafe.Pointer(0x0), nevacuate: 0, extra: *runtime.mapextra nil,} b := new(int) 调用了 runtime.newobject 方法，分配一个类型为 int 的零值，返回其指针 c := new(string) 调用了 runtime.newobject 方法，分配一个类型为 string 的零值，返回其指针 d := new(float32) 调用了 runtime.newobject 方法，分配一个类型为 float32 的零值，返回其指针 总的来说，make 会调用具体类型的初始化方法来初始化该类型，new 会调用 newobject 方法来初始化这个类型，返回其指针 ","date":"2023-05-18","objectID":"/202305181645-new-%E5%92%8C-make/:2:0","series":["card"],"tags":[],"title":"new 和 make","uri":"/202305181645-new-%E5%92%8C-make/#使用场景"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-18","objectID":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/:0:0","series":["card"],"tags":["MPG"],"title":"Go 的并发调度：MPG模型","uri":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/#heading"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 基本概念M-P-G 分别代表什么？ MMachine：传统意义上的线程，work thread PProcessor：认为抽象的处理器 GGoroutine：协程 ","date":"2023-05-18","objectID":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/:1:0","series":["card"],"tags":["MPG"],"title":"Go 的并发调度：MPG模型","uri":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/#基本概念"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 工作线程假设工作线程总是贪心的执行每个 G，那么可能存在下面两种情况： G 的数量 \u003e 本地线程的数量 G 的数量 \u003c 本地线程的数量 ","date":"2023-05-18","objectID":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/:1:1","series":["card"],"tags":["MPG"],"title":"Go 的并发调度：MPG模型","uri":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/#工作线程"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一个简单的工作流程在 MPG 并发模型中，调度器（Scheduler）负责管理和调度工作线程（Worker Thread），以实现协程的并发执行。MPG 调度的过程如下： 初始化：在程序启动时，调度器会初始化一个工作线程池，并将其中的每个工作线程标记为空闲状态。 协程创建：当一个协程被创建时，调度器会将该协程加入到协程队列中，并等待调度执行。 工作线程选择：当一个协程需要执行时，调度器会从工作线程池中选择一个空闲的工作线程，并将该协程绑定到该工作线程上。 协程执行：当一个协程被绑定到工作线程上后，该协程就可以开始执行了。如果该协程需要暂停或者等待 I/O 操作完成，则调度器会将该协程的状态设置为暂停状态，并将该协程所绑定的工作线程标记为空闲状态。 工作线程空闲：当一个工作线程执行完毕或者暂停时，调度器会将该工作线程标记为空闲状态，并等待下一个协程的调度。 协程恢复执行：当一个协程需要继续执行时，调度器会重新选择一个空闲的工作线程，并将该协程绑定到该工作线程上，从而实现协程的恢复执行。 通过合理地管理和调度工作线程，MPG 并发模型可以充分利用计算机资源，提高程序的性能和响应能力。同时，为了保证并发的正确性和安全性，还需要使用锁、信号量、互斥量等机制来控制对共享资源的访问 https://golang.design/under-the-hood/zh-cn/part2runtime/ch06sched/mpg/ ","date":"2023-05-18","objectID":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/:2:0","series":["card"],"tags":["MPG"],"title":"Go 的并发调度：MPG模型","uri":"/202305181327-go-%E7%9A%84%E5%B9%B6%E5%8F%91%E8%B0%83%E5%BA%A6mpg%E6%A8%A1%E5%9E%8B/#一个简单的工作流程"},{"categories":["Golang"],"content":" goroutine 并发与并行 并发：两个计算只在一小段时间内会同时运行，但大部分是分开运行的，cpu 通过不断的上下文切换让两个计算看起来是同时运行的 并行：任何时间内，两个计算都是同时运行的 类型 特点 是否共享资源 并发 交替运行，也有可能同时运行 共享 并行 同时运行 不共享 协程和线程 类型 调度 切换开销 协程 用户态 开销小 线程 系统调度 开销大 ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:1:0","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#goroutine"},{"categories":["Golang"],"content":" 并发控制❌ 先看个错误的例子： func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) time.Sleep(2 * time.Second) } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } } 上面程序的输出可能为： hi! hello! hello! hello! hi! hi! 并没有各自打印完 10 次结果，因为在程序的主协程推出之后，两个 SayGreetings 的任务也退出了，没有等到任务结束 数据竞争在并发任务中，常见的数据竞争： 一个写数据，一个读数据 两个都写数据 如果不做同步，都可能导致数据出错 WaitGroup var wg sync.WaitGroup func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) wg.Add(2) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) wg.Wait() } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } wg.Done() } 经过上面的修改，总共打印了 20 条语句，说明主协程等两个任务都完成了才退出 协程的状态 运行 阻塞 （协程不区分睡眠、就绪状态，比如通过 time.Sleep 调用让协程进入睡眠，时间到了之后应该处于就绪态，等待系统调度。协程认为睡眠、就绪为运行状态） 协程不能从阻塞状态退出 协程的阻塞状态必须是被动结束的（被另一个协程通过某种同步方法被动结束） 协程的调度同一时刻，最多同时运行的协程数量 = 逻辑 cpu 的数量。 逻辑cpu，是由计算机的处理器、超线程技术同时决定的 比如： 一个不支持超线程的双核处理器，逻辑cpu = 2 一个支持超线程的双核四线程处理器，相当于 2 个物理 cpu、4 个逻辑 cpu go 标准编译器通过 MPG 模型（local 202305181327 Go 的并发调度：MPG模型 remote 202305181327 Go 的并发调度：MPG模型）来实现协程的调度 ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:1:1","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#并发控制"},{"categories":["Golang"],"content":" 并发控制❌ 先看个错误的例子： func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) time.Sleep(2 * time.Second) } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } } 上面程序的输出可能为： hi! hello! hello! hello! hi! hi! 并没有各自打印完 10 次结果，因为在程序的主协程推出之后，两个 SayGreetings 的任务也退出了，没有等到任务结束 数据竞争在并发任务中，常见的数据竞争： 一个写数据，一个读数据 两个都写数据 如果不做同步，都可能导致数据出错 WaitGroup var wg sync.WaitGroup func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) wg.Add(2) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) wg.Wait() } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } wg.Done() } 经过上面的修改，总共打印了 20 条语句，说明主协程等两个任务都完成了才退出 协程的状态 运行 阻塞 （协程不区分睡眠、就绪状态，比如通过 time.Sleep 调用让协程进入睡眠，时间到了之后应该处于就绪态，等待系统调度。协程认为睡眠、就绪为运行状态） 协程不能从阻塞状态退出 协程的阻塞状态必须是被动结束的（被另一个协程通过某种同步方法被动结束） 协程的调度同一时刻，最多同时运行的协程数量 = 逻辑 cpu 的数量。 逻辑cpu，是由计算机的处理器、超线程技术同时决定的 比如： 一个不支持超线程的双核处理器，逻辑cpu = 2 一个支持超线程的双核四线程处理器，相当于 2 个物理 cpu、4 个逻辑 cpu go 标准编译器通过 MPG 模型（local 202305181327 Go 的并发调度：MPG模型 remote 202305181327 Go 的并发调度：MPG模型）来实现协程的调度 ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:1:1","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#数据竞争"},{"categories":["Golang"],"content":" 并发控制❌ 先看个错误的例子： func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) time.Sleep(2 * time.Second) } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } } 上面程序的输出可能为： hi! hello! hello! hello! hi! hi! 并没有各自打印完 10 次结果，因为在程序的主协程推出之后，两个 SayGreetings 的任务也退出了，没有等到任务结束 数据竞争在并发任务中，常见的数据竞争： 一个写数据，一个读数据 两个都写数据 如果不做同步，都可能导致数据出错 WaitGroup var wg sync.WaitGroup func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) wg.Add(2) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) wg.Wait() } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } wg.Done() } 经过上面的修改，总共打印了 20 条语句，说明主协程等两个任务都完成了才退出 协程的状态 运行 阻塞 （协程不区分睡眠、就绪状态，比如通过 time.Sleep 调用让协程进入睡眠，时间到了之后应该处于就绪态，等待系统调度。协程认为睡眠、就绪为运行状态） 协程不能从阻塞状态退出 协程的阻塞状态必须是被动结束的（被另一个协程通过某种同步方法被动结束） 协程的调度同一时刻，最多同时运行的协程数量 = 逻辑 cpu 的数量。 逻辑cpu，是由计算机的处理器、超线程技术同时决定的 比如： 一个不支持超线程的双核处理器，逻辑cpu = 2 一个支持超线程的双核四线程处理器，相当于 2 个物理 cpu、4 个逻辑 cpu go 标准编译器通过 MPG 模型（local 202305181327 Go 的并发调度：MPG模型 remote 202305181327 Go 的并发调度：MPG模型）来实现协程的调度 ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:1:1","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#waitgroup"},{"categories":["Golang"],"content":" 并发控制❌ 先看个错误的例子： func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) time.Sleep(2 * time.Second) } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } } 上面程序的输出可能为： hi! hello! hello! hello! hi! hi! 并没有各自打印完 10 次结果，因为在程序的主协程推出之后，两个 SayGreetings 的任务也退出了，没有等到任务结束 数据竞争在并发任务中，常见的数据竞争： 一个写数据，一个读数据 两个都写数据 如果不做同步，都可能导致数据出错 WaitGroup var wg sync.WaitGroup func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) wg.Add(2) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) wg.Wait() } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } wg.Done() } 经过上面的修改，总共打印了 20 条语句，说明主协程等两个任务都完成了才退出 协程的状态 运行 阻塞 （协程不区分睡眠、就绪状态，比如通过 time.Sleep 调用让协程进入睡眠，时间到了之后应该处于就绪态，等待系统调度。协程认为睡眠、就绪为运行状态） 协程不能从阻塞状态退出 协程的阻塞状态必须是被动结束的（被另一个协程通过某种同步方法被动结束） 协程的调度同一时刻，最多同时运行的协程数量 = 逻辑 cpu 的数量。 逻辑cpu，是由计算机的处理器、超线程技术同时决定的 比如： 一个不支持超线程的双核处理器，逻辑cpu = 2 一个支持超线程的双核四线程处理器，相当于 2 个物理 cpu、4 个逻辑 cpu go 标准编译器通过 MPG 模型（local 202305181327 Go 的并发调度：MPG模型 remote 202305181327 Go 的并发调度：MPG模型）来实现协程的调度 ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:1:1","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#协程的状态"},{"categories":["Golang"],"content":" 并发控制❌ 先看个错误的例子： func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) time.Sleep(2 * time.Second) } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } } 上面程序的输出可能为： hi! hello! hello! hello! hi! hi! 并没有各自打印完 10 次结果，因为在程序的主协程推出之后，两个 SayGreetings 的任务也退出了，没有等到任务结束 数据竞争在并发任务中，常见的数据竞争： 一个写数据，一个读数据 两个都写数据 如果不做同步，都可能导致数据出错 WaitGroup var wg sync.WaitGroup func main() { rand.Seed(time.Now().UnixNano()) // Go 1.20之前需要 log.SetFlags(0) wg.Add(2) go SayGreetings(\"hi!\", 10) go SayGreetings(\"hello!\", 10) wg.Wait() } func SayGreetings(greeting string, times int) { for i := 0; i \u003c times; i++ { log.Println(greeting) d := time.Second * time.Duration(rand.Intn(5)) / 2 time.Sleep(d) // 睡眠片刻（随机0到2.5秒） } wg.Done() } 经过上面的修改，总共打印了 20 条语句，说明主协程等两个任务都完成了才退出 协程的状态 运行 阻塞 （协程不区分睡眠、就绪状态，比如通过 time.Sleep 调用让协程进入睡眠，时间到了之后应该处于就绪态，等待系统调度。协程认为睡眠、就绪为运行状态） 协程不能从阻塞状态退出 协程的阻塞状态必须是被动结束的（被另一个协程通过某种同步方法被动结束） 协程的调度同一时刻，最多同时运行的协程数量 = 逻辑 cpu 的数量。 逻辑cpu，是由计算机的处理器、超线程技术同时决定的 比如： 一个不支持超线程的双核处理器，逻辑cpu = 2 一个支持超线程的双核四线程处理器，相当于 2 个物理 cpu、4 个逻辑 cpu go 标准编译器通过 MPG 模型（local 202305181327 Go 的并发调度：MPG模型 remote 202305181327 Go 的并发调度：MPG模型）来实现协程的调度 ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:1:1","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#协程的调度"},{"categories":["Golang"],"content":" defer一个延迟调用的语句被执行时，其中的延迟函数不会马上被执行，而是推入由当前协程维护的一个栈中，在方法退出之前再依次执行 注意点： 如果发生了 panic，defer 的内容是不会执行的 传入的参数是注册时求值，而不是执行时求值 func main() { defer fmt.Println(\"The third line.\") defer fmt.Println(\"The second line.\") fmt.Println(\"The first line.\") } 输出结果： The first line. The second line. The third line. 关于估值的问题： 延迟调用的实参在注册的时候估值 匿名函数体内的表达式实在函数被执行的时候估值 例子1 func main() { func() { for i := 0; i \u003c 3; i++ { defer fmt.Println(\"a:\", i) } }() fmt.Println() func() { for i := 0; i \u003c 3; i++ { defer func() { fmt.Println(\"b:\", i) }() } }() } 因此上面的程序输出： a: 2 a: 1 a: 0 b: 3 b: 3 b: 3 例子2 func main() { var f = func () { fmt.Println(false) } defer f() f = func () { fmt.Println(true) } } 上面函数的输出是：false 例子3 type T int func (t T) M(n int) T { print(n) return t } func main() { var t T // t.M(1)是方法调用M(2)的属主实参，因此它 // 将在M(2)调用被推入延迟调用队列时被估值。 defer t.M(1).M(2) //1 t.M(3).M(4) // 34 // 最后执行 defer x.M(2)} 上面这段代码的输出结果： 1342 defer 一个 nil 函数值，将产生恐慌 https://gfw.go101.org/article/control-flows-more.html ","date":"2023-05-18","objectID":"/202305181209-goroutinedefer/:2:0","series":["Golang语言使用"],"tags":["goroutine","defer"],"title":"goroutine、defer","uri":"/202305181209-goroutinedefer/#defer"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#heading"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#11-盛最多水的容器httpsleetcodecnproblemscontainer-with-most-water"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#15-三数之和httpsleetcodecnproblems3sum"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#438-找到字符串中所有字母异位词httpsleetcodecnproblemsfind-all-anagrams-in-a-string"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#560-和为-k-的子数组httpsleetcodecnproblemssubarray-sum-equals-k"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#139-单词拆分httpsleetcodecnproblemsword-break"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#739-每日温度httpsleetcodecnproblemsdaily-temperatures"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#797-所有可能的路径httpsleetcodecnproblemsall-paths-from-source-to-target"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#剑指-offer-ii-086-分割回文子字符串httpsleetcodecnproblemsm99oja"},{"categories":["数据结构与算法"],"content":" 废弃 使用新站点记录 11. 盛最多水的容器#双指针 func maxArea(height []int) int { l, r := 0, len(height) - 1 ans := math.MinInt for l \u003c r { ans = max(ans, (r-l) * min(height[l], height[r])) // calc area if height[l] \u003c height[r] { l++ } else { r-- } } return ans } func max(a, b int) int { if a \u003c b { return b } return a } func min(a, b int) int { if a \u003c b { return a } return b } 看到一条有趣的评论： 15. 三数之和 func threeSum(nums []int) [][]int { // 先将数组从小到达排序 sort.Ints(nums) n := len(nums) var ans [][]int lastA := nums[0] - 1 for i := 0; i \u003c n; i++ { // 如果第一个数跟上一次循环的数一致，跳过该循环 cIdx := n - 1 if nums[i] == lastA { continue } // 第二个数在往后寻找的时候 // 如果下一个数跟上一个数相同，也应该跳过，否则会出现重复的三元组 lastB := nums[0] - 1 for j := i + 1; j \u003c cIdx; j++ { if lastB == nums[j] { continue } for ; cIdx \u003e j; cIdx-- { sum := nums[i] + nums[j] + nums[cIdx] if sum \u003c 0 { // 如果和小于0，不必继往前遍历找第三个数 // 让第二个数增大，才有可能让 sum 为零 break } else if sum == 0 { elem := []int{nums[i], nums[j], nums[cIdx]} ans = append(ans, elem) break } } lastB = nums[j] } lastA = nums[i] } return ans } 438. 找到字符串中所有字母异位词 func findAnagrams(s string, p string) []int { var ans []int m, n := len(p), len(s) if m \u003e n { return ans } var pCnt, sCnt [26]int for i := range p { pCnt[p[i]-'a'] ++ sCnt[s[i]-'a'] ++ } if sCnt == pCnt { ans = append(ans, 0) } for i := m; i \u003c n; i++ { sCnt[s[i]-'a']++ sCnt[s[i-m]-'a']-- if sCnt == pCnt { ans = append(ans, i-m+1) } } return ans } 560. 和为 K 的子数组#前缀和 // start end // x x x x x x x x x x x x // 假设 end 为这个连续子数组的终点 // start 为起点 // pre[i] 为前缀和，pre[0] = nums[0] // 求：pre[end] - pre[start-1] = k // end 遍历 nums，此时 pre[end]，k 已知，只需要找到前面有几个 pre[i] 等于 pre[end] - k 即可 func subarraySum(nums []int, k int) int { preCnt := map[int]int{} // pre := make([]int, len(nums)) pre := 0 cnt := 0 preCnt[0] = 1 for end := 0; end \u003c len(nums); end ++ { pre += nums[end] cnt += preCnt[pre - k] // 统计前缀和出现的次数 preCnt[pre]++ } return cnt } 139. 单词拆分#动态规划 // 字典中的字符串按长度从大到小排列 // 假设：aaaopen,open，aaaa // 如果字符串中有 aaaopen，一定要先用 aaaopen 来构成，而不是 open + aaa// s：aaaaopen，裁剪 aaaopen 之后剩下 a，但是 s 是可以由 aaaa + open 组成的 // 所以上面的思路行不通！ // // 如果用递归的思路来做 // 按照给定的字典，把所有可能的情况都裁剪一遍 // 如果最后 s 为 “” true// 如果没有可以裁剪的子字符串，false // 超时！ // // 如果列举出所有 wordDict 能够组成的单词，再来比较怎么样？ n \u003c= 1000// 比递归还慢吧 // // 动态规划 // i-len(word)+1 // s： x x x x x x x x x x x x// i 想要判断 s[:i+1] 是否合法，遍历字典， // | - | // 如果存在一个 word，当 s[:i+1] - word 剩下的字符串是合法的，那么 s[:i+1] 就合法 // 使用 dp[i] 来保存 s[:i+1] 是否合法 // success func wordBreak(s string, wordDict []string) bool { n := len(s) dp := make([]int, n) for i := 0; i \u003c n; i++ { for _, word := range wordDict { m := len(word) if i-m+1 \u003c 0 { continue } if s[i-m+1:i+1] == word \u0026\u0026 i-m+1 == 0 { // 考虑第一个字母为一个单词的情况 dp[i] = 1 break } else if s[i-m+1:i+1] == word \u0026\u0026 dp[i-m] == 1 { dp[i] = 1 break } } } return dp[n-1] == 1 } // 递归 func cut(s string, wordDict []string) bool { if s == \"\" { return true } for _, word := range wordDict { idx := strings.Index(s, word) if idx \u003e= 0 { if cut(s[:idx], wordDict) \u0026\u0026 cut(s[idx+len(word):], wordDict) { return true } } } return false } 739. 每日温度#单调栈 // 数组从后往前遍历 // 使用一个栈保存温度的下标 // 如果当前温度 \u003e= 栈顶的温度 --》出栈 // 否则 --》 入栈 func dailyTemperatures(temperatures []int) []int { var stack []int var ans []int n := len(temperatures) if n == 0 { return ans } stack = append(stack, n-1) ans = append(ans, 0) for i := n-2; i \u003e= 0; i-- { t := temperatures[i] for len(stack) != 0 \u0026\u0026 t \u003e= temperatures[stack[len(stack)-1]] { stack = stack[:len(stack)-1] } if len(stack) == 0 { ans = append(ans, 0) } else { ans = append(ans, stack[len(stack)-1] - i) } stack = append(stack, i) } for i := 0; i \u003c n/2; i++ { ans[i], ans[n-i-1] = ans[n-i-1], ans[i] } return ans } 797. 所有可能的路径#图 #寻找路径 // 寻找路径 // 思路1 使用 DFS，当「节点是最后一个节点」或者「没有下一个节点」的时候回溯 func allPathsSourceTarget(graph [][]int) [][]int { var path []int var ans [][]int dfsHelper(graph, 0, \u0026path, \u0026ans) return ans } func dfsHelper(graph [][]int, startVt int, path *[]int, ans *[][]int) { // 标记为已访问 *path = append(*path, startVt) for _, toVt := range graph[startVt] { if startVt == len(graph)-1 { break } /* 因为一个节点可能存在与多条不同的路","date":"2023-05-18","objectID":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/:0:0","series":["leetcode"],"tags":[],"title":"leetcode 做题记录 v2","uri":"/202305181153-leetcode-%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95-v2/#216-组合总和-iiihttpsleetcodecnproblemscombination-sum-iii"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 学习 1.整理一些golang常见问题:done, 09:00, 3h 2.GO类型系统、结构体等内容学习:done, 3h 3.channel: 1h section 习惯 算法每日一题:done, 1h ","date":"2023-05-18","objectID":"/2023-05-18/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-18 日记录","uri":"/2023-05-18/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-18","objectID":"/2023-05-18/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-18 日记录","uri":"/2023-05-18/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-18","objectID":"/2023-05-18/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-18 日记录","uri":"/2023-05-18/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-18","objectID":"/2023-05-18/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-18 日记录","uri":"/2023-05-18/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-18","objectID":"/2023-05-18/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-18 日记录","uri":"/2023-05-18/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-18","objectID":"/2023-05-18/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-18 日记录","uri":"/2023-05-18/#记录区-明天"},{"categories":["Golang"],"content":" Go 语言中，结构体中长度为 0 的字段为什么会影响结构体的大小？ ans 举个例子： type A struct { a int32 b struct{} } 结构体 A.a 为 4 个字节，b 的尺寸为 0 ，但是结构体 A 的尺寸为 8，说明 b 的字段影响到了结构体的尺寸，为什么？ 结论：为了防止访问字段的时候发生越界 假设结构体 A 的尺寸为 4，那么当 b 的字段不为空的时候，访问字段 b 就会访问到 A 对象内存之外的空间，这是不可知的 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:1:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#go-语言中结构体中长度为-0-的字段为什么会影响结构体的大小"},{"categories":["Golang"],"content":" 赋值是原子操作吗？ ans 不是。 flowchart LR a[寄存器 or 内存]--\u003e|读取|b[寄存器] b--\u003e|写入|c[\"内存地址(变量)\"] 可以将赋值分为两步： 从寄存器或者内存中读取右侧变量的值，读到寄存器中 将寄存器中的值写入左侧变量所在的内存地址 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:2:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#赋值是原子操作吗"},{"categories":["Golang"],"content":" time.Sleep(d) 的状态转换？ and stateDiagram-v2 [*]--\u003e运行 运行--\u003e阻塞: time.Sleep(d) 阻塞--\u003e就绪: 到达指定的 d 时间 就绪--\u003e运行: 被调度器重新调度 t 从上面的状态转换可以看出来，使用 time.Sleep(d) 并不能精确的达到 d 时间之后继续执行的效果，还需要考虑上被调度器重新调度的时间 t ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:3:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#timesleepd-的状态转换"},{"categories":["Golang"],"content":" 标准库包math/rand和crypto/rand生成的随机数之间有什么区别？ ans 通过math/rand标准库包生成的伪随机数序列对于给定的种子是确定的。 这样生成的随机数不适用于安全敏感的环境中。 crypto/rand 包提供了一个安全的随机数生成器，它可以用于生成密码学上安全的伪随机序列。这个伪随机序列是根据操作系统提供的熵池（entropy pool）中的随机数据生成的。 熵池是由操作系统维护的一些随机数据的集合，包括硬件事件（如键盘输入、鼠标移动、磁盘访问等）和软件事件（如进程调度、网络流量等）。这些事件产生的随机数据被混合在一起，并经过加密哈希函数处理，生成一个种子值。然后，这个种子值被输入到伪随机数生成算法中，生成伪随机序列。 由于熵池中的随机数据是由多个不可预测的源产生的，因此生成的伪随机序列具有高度的随机性和不可预测性，可以满足密码学上的安全要求。 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:4:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#标准库包mathrand和cryptorand生成的随机数之间有什么区别"},{"categories":["Golang"],"content":" Go 语言中，哪些类型是不能比较的？ 引用 Go 语言中，引用类型不能比较，值类型可以比较 引用类型：map、slice、function 值类型：int、bool、float、string、array… 对于引用类型来说，他们通常指向一个底层的数据，如果直接对引用类型进行比较，比较的是他们的地址，而不是实际的底层数据，这是不符合期望的 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:5:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#go-语言中哪些类型是不能比较的"},{"categories":["Golang"],"content":" 定义可寻址跟不可寻址的出发点是什么 example 在 Go 语言中，定义可寻址和不可寻址的出发点是为了保证程序的安全性和正确性。 可寻址的值是指可以通过取地址符 \u0026 获取其内存地址的值。在 Go 语言中，变量、数组元素、结构体字段以及通过指针间接引用的值都是可寻址的。 不可寻址的值是指不能通过取地址符 \u0026 获取其内存地址的值。在 Go 语言中，常量、字面量、表达式结果以及函数返回值等都是不可寻址的。 这种区分可寻址和不可寻址的值的做法可以避免一些潜在的问题，例如： 防止对常量进行修改：常量是不可寻址的，因此无法通过指针来修改常量的值，从而保证了常量的不可变性。 避免对临时变量进行取地址操作：临时变量是不可寻址的，如果对其进行取地址操作，则可能会导致程序崩溃或者产生不可预期的结果。 确保函数返回值的安全性：如果函数返回值是不可寻址的，那么就可以避免在函数外部对其进行修改，从而保证了函数返回值的安全性。 总之，Go 语言中定义可寻址和不可寻址的出发点是为了保证程序的安全性和正确性，避免一些潜在的问题。 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:6:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#定义可寻址跟不可寻址的出发点是什么"},{"categories":["Golang"],"content":" 列举一些可寻址类型、不可寻址类型 example 可寻址的类型： 指针类型 var p *int = new(int) 数组类型 var arr [3]int 切片类型 var s []int 结构体类型 var p Person 数组指针类型 var p *[3]int = new([3]int) 结构体指针类型 var p *Person = new(Person) 不可寻址的类型： 常量 const PI = 3.14 字面量 var p *int = \u002610 // error:cannot take the address of 10 表达式结果 var x int = 1 + 2 // 错误：cannot take the address of 1 + 2 接口类型 var i interface{} = 42 // 错误：cannot take the address of i ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:7:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#列举一些可寻址类型不可寻址类型"},{"categories":["Golang"],"content":" \u0026T{} 的写法是允许的，能够说明 T{} 是能够被寻址的吗？ example T{} 并不能被寻址 \u0026T{} 实际上是一个语法糖： tmp := T{} (\u0026tmp) 由于变量是能够被寻址的，因此上面的写法是允许的 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:8:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#t-的写法是允许的能够说明-t-是能够被寻址的吗"},{"categories":["Golang"],"content":" 为什么 map（映射）元素不可被取地址 example 映射元素的地址可能改变 可能是零值 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:9:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#为什么-map映射元素不可被取地址"},{"categories":["Golang"],"content":" 在 Go 中，为什么返回一个局部变量的地址是安全的 example 当一个函数返回局部变量的地址时，会将该变量的值赋值到堆上，并返回该变量的地址 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:10:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#在-go-中为什么返回一个局部变量的地址是安全的"},{"categories":["Golang"],"content":" 一个值的地址在程序运行的过程中为什么会发生改变 example 比如当一个协程的栈的大小发生改变时，开辟在此栈上的内存块需要移动，因此地址就会发生改变 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:11:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#一个值的地址在程序运行的过程中为什么会发生改变"},{"categories":["Golang"],"content":" Go 101 中的一些总结https://gfw.go101.org/article/summaries.html#type-with-underlyings ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:12:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#go-101-中的一些总结"},{"categories":["Golang"],"content":" 为什么遍历 map 是无序的 example map 扩容之后，key 的位置会发生变化 在 1. 的认知上，是不是只要给定一个只读的 map，遍历结果就会是有序的？不是的，go 为了防止新手勿用 map，甚至设定了这样一个机制：每次开始遍历的桶是随机的，并不是每次都从第一个桶开始遍历 ","date":"2023-05-17","objectID":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:13:0","series":["Golang语言使用"],"tags":["问题收罗"],"title":"golang 一些问题记录","uri":"/202305171836-golang-%E4%B8%80%E4%BA%9B%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#为什么遍历-map-是无序的"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 学习 1.重新梳理一下之前的规划:done, 06:30, 4h 2.golang学习: done, 3h section 习惯 算法每日一题: 1h ","date":"2023-05-17","objectID":"/2023-05-17/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-17 日记录","uri":"/2023-05-17/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-17","objectID":"/2023-05-17/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-17 日记录","uri":"/2023-05-17/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-17","objectID":"/2023-05-17/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-17 日记录","uri":"/2023-05-17/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-17","objectID":"/2023-05-17/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-17 日记录","uri":"/2023-05-17/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-17","objectID":"/2023-05-17/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-17 日记录","uri":"/2023-05-17/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-17","objectID":"/2023-05-17/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-17 日记录","uri":"/2023-05-17/#记录区-明天"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 八股文方面","date":"2023-05-17","objectID":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/:1:0","series":["偏工作性质记录"],"tags":["个人记录"],"title":"面经收集","uri":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/#八股文方面"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 认识性质的提问 说一下 docker 说一下 kubernetes 说一下 redis 为什么有 http 还要有 rpc k8s 的架构 ","date":"2023-05-17","objectID":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/:1:1","series":["偏工作性质记录"],"tags":["个人记录"],"title":"面经收集","uri":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/#认识性质的提问"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 深究 golang go 的 gc go 的协程怎么实现的 ","date":"2023-05-17","objectID":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/:1:2","series":["偏工作性质记录"],"tags":["个人记录"],"title":"面经收集","uri":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/#深究"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 深究 golang go 的 gc go 的协程怎么实现的 ","date":"2023-05-17","objectID":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/:1:2","series":["偏工作性质记录"],"tags":["个人记录"],"title":"面经收集","uri":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/#golang"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 深究知识点的提问","date":"2023-05-17","objectID":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/:1:3","series":["偏工作性质记录"],"tags":["个人记录"],"title":"面经收集","uri":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/#深究知识点的提问"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 开放性问题 最近读了什么书，有没有压力大的情况 个人如何做情绪管理的？ 个人的职业规划？你进来能做什么工作？ 项目里感觉最困难的是什么？ 你有什么要问我的吗？ 离职原因 离职期间的规划？ 离职期间没有做一个很具体的规划，但是在这段时间里面，我是有要求自己做到一些事情的：在专业知识的方面，我需要对之前工作上用到的、接触到的内容再做一个回顾，对当时不太理解的一些东西做适当的扩展、补充之类的，然后对一些可能已经遗忘的知识稍微做一下回顾，比如说算法、操作系统之类的，然后就是专业知识之外的一些东西，像阅读、爱好、旅游之类的，调整一下自己的状态 ","date":"2023-05-17","objectID":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/:2:0","series":["偏工作性质记录"],"tags":["个人记录"],"title":"面经收集","uri":"/202305170654-%E9%9D%A2%E7%BB%8F%E6%94%B6%E9%9B%86/#开放性问题"},{"categories":["task-bugfix"],"content":" cke ","date":"2023-05-17","objectID":"/202305170617-%E4%B8%80%E4%BA%9B%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9%E8%AE%B0%E5%BD%95%E6%80%BB%E8%A7%88/:1:0","series":["偏工作性质记录"],"tags":["工作记录"],"title":"一些工作内容记录总览","uri":"/202305170617-%E4%B8%80%E4%BA%9B%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9%E8%AE%B0%E5%BD%95%E6%80%BB%E8%A7%88/#cke"},{"categories":["task-bugfix"],"content":" ecs、ebs ","date":"2023-05-17","objectID":"/202305170617-%E4%B8%80%E4%BA%9B%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9%E8%AE%B0%E5%BD%95%E6%80%BB%E8%A7%88/:2:0","series":["偏工作性质记录"],"tags":["工作记录"],"title":"一些工作内容记录总览","uri":"/202305170617-%E4%B8%80%E4%BA%9B%E5%B7%A5%E4%BD%9C%E5%86%85%E5%AE%B9%E8%AE%B0%E5%BD%95%E6%80%BB%E8%A7%88/#ecsebs"},{"categories":["OpenShift"],"content":" 场景实践","date":"2023-05-16","objectID":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/:1:0","series":["偏工作性质记录"],"tags":[],"title":"App Operator 安装脚本化（cdp）","uri":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/#场景实践"},{"categories":["OpenShift"],"content":" Operator install手动安装，记录发送的api： https://console-ccos-console.apps.hhqcluster.hhqdomain/api/kubernetes/apis/operators.coreos.com/v1alpha1/namespaces/ccos-operators/subscriptions POST {\"apiVersion\":\"operators.coreos.com/v1alpha1\",\"kind\":\"Subscription\",\"metadata\":{\"name\":\"xsky-operator\",\"namespace\":\"ccos-operators\"},\"spec\":{\"source\":\"ceake-operators\",\"sourceNamespace\":\"ccos-marketplace\",\"name\":\"xsky-operator\",\"startingCSV\":\"xsky-operator.v1.0.0\",\"channel\":\"alpha\",\"installPlanApproval\":\"Automatic\"}} 需要的两个 Header：cookie、X-CSRFToken 返回的结果： { \"apiVersion\": \"operators.coreos.com/v1alpha1\", \"kind\": \"Subscription\", \"metadata\": { \"creationTimestamp\": \"2022-09-05T06:23:06Z\", \"generation\": 1, \"managedFields\": [ { \"apiVersion\": \"operators.coreos.com/v1alpha1\", \"fieldsType\": \"FieldsV1\", \"fieldsV1\": { \"f:spec\": { \".\": {}, \"f:channel\": {}, \"f:installPlanApproval\": {}, \"f:name\": {}, \"f:source\": {}, \"f:sourceNamespace\": {}, \"f:startingCSV\": {} } }, \"manager\": \"ApiPOST Runtime +https:\", \"operation\": \"Update\", \"time\": \"2022-09-05T06:23:06Z\" } ], \"name\": \"xsky-operator\", \"namespace\": \"ccos-operators\", \"resourceVersion\": \"3039592\", \"uid\": \"08282869-7cf5-4a7a-b33a-ce71821282bb\" }, \"spec\": { \"channel\": \"alpha\", \"installPlanApproval\": \"Automatic\", \"name\": \"xsky-operator\", \"source\": \"ceake-operators\", \"sourceNamespace\": \"ccos-marketplace\", \"startingCSV\": \"xsky-operator.v1.0.0\" } } convert to yaml: apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: xsky-operator namespace: ccos-operators spec: channel: alpha installPlanApproval: Automatic name: xsky-operator source: ceake-operators sourceNamespace: ccos-marketplace startingCSV: xsky-operator.v1.0.0 ","date":"2023-05-16","objectID":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/:1:1","series":["偏工作性质记录"],"tags":[],"title":"App Operator 安装脚本化（cdp）","uri":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/#operator-install"},{"categories":["OpenShift"],"content":" 发送 api 创建 CR 资源","date":"2023-05-16","objectID":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/:1:2","series":["偏工作性质记录"],"tags":[],"title":"App Operator 安装脚本化（cdp）","uri":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/#发送-api-创建-cr-资源"},{"categories":["OpenShift"],"content":" 脚本化 安装operator、创建自定义的 CR 等在测试前需要做的操作都可以通过创建所需的 yaml 资源来完成 ","date":"2023-05-16","objectID":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/:2:0","series":["偏工作性质记录"],"tags":[],"title":"App Operator 安装脚本化（cdp）","uri":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/#脚本化"},{"categories":["OpenShift"],"content":" yaml Namespace OperatorGroup Subscription apiVersion: v1 kind: Namespace metadata: name: ccos-adp --- apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: generateName: ccos-adp- generation: 1 name: ccos-adp-cj4jr namespace: ccos-adp spec: targetNamespaces: - ccos-adp --- apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: oadp-operator namespace: ccos-adp spec: channel: stable installPlanApproval: Automatic name: oadp-operator source: hhq-operators sourceNamespace: ccos-marketplace startingCSV: oadp-operator.v1.0.0 Secret apiVersion: v1 data: cloud: W2RlZmF1bHRdCmF3c19hY2Nlc3Nfa2V5X2lkPW1pbmlvCmF3c19zZWNyZXRfYWNjZXNzX2tleT1taW5pbzEyMw== kind: Secret metadata: name: cloud-credentials namespace: ccos-adp type: Opaque DPA apiVersion: oadp.ccos.io/v1alpha1 kind: DataProtectionApplication metadata: name: velero-sample namespace: ccos-adp spec: backupLocations: - velero: config: insecureSkipTLSVerify: \"true\" profile: default region: minio s3ForcePathStyle: \"true\" s3Url: http://10.253.11.215:9000 credential: key: cloud name: cloud-credentials default: true objectStorage: bucket: velero prefix: single provider: aws configuration: restic: enable: true velero: defaultPlugins: - aws - csi - ccos ","date":"2023-05-16","objectID":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/:2:1","series":["偏工作性质记录"],"tags":[],"title":"App Operator 安装脚本化（cdp）","uri":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/#yaml"},{"categories":["OpenShift"],"content":" 在流程中的位置 每个Application Operator 对应一个自动化安装脚本 如 oadp-operator 的自动化安装脚本：oadp-operator.sh 自动化脚本仓库：10.253.6.101:/root/ApplicationOperatorScripts ","date":"2023-05-16","objectID":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/:2:2","series":["偏工作性质记录"],"tags":[],"title":"App Operator 安装脚本化（cdp）","uri":"/202305161542-app-operator-%E5%AE%89%E8%A3%85%E8%84%9A%E6%9C%AC%E5%8C%96cdp/#在流程中的位置"},{"categories":["task-bugfix"],"content":" iscsi 磁盘卸载有残留的 bugfix（参考 os-brick 卸载方式） https://www.processon.com/diagraming/6231a55ef346fb07f931b183 ","date":"2023-05-16","objectID":"/202305161550-iscsi-%E7%A3%81%E7%9B%98%E5%8D%B8%E8%BD%BD%E6%9C%89%E6%AE%8B%E7%95%99%E7%9A%84%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90/:0:0","series":["偏工作性质记录"],"tags":["bugfix","工作记录"],"title":"iSCSI 磁盘卸载有残留的原因分析","uri":"/202305161550-iscsi-%E7%A3%81%E7%9B%98%E5%8D%B8%E8%BD%BD%E6%9C%89%E6%AE%8B%E7%95%99%E7%9A%84%E5%8E%9F%E5%9B%A0%E5%88%86%E6%9E%90/#"},{"categories":["OpenShift"],"content":" 一、需求背景","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:1:0","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#一需求背景"},{"categories":["OpenShift"],"content":" 1.1 提出问题目前越来越多的应用往 Kubernetes 上迁移，包括需要进行大量计算的人工智能、机器学习，而想要以原生的 Kubernetes 来运行这些任务，在调度策略上并不能完全满足，存在以下问题： 多个 TFJob 同时提交产生的资源竞争可能导致死锁，多个任务都无法完成 单个大资源任务长期抢占或者不合理分配资源，导致小任务无法获得资源 同一个任务中需要频繁交流的几个子任务分布到了不同节点，导致训练效率低下 … ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:1:1","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#11-提出问题"},{"categories":["OpenShift"],"content":" 1.2 问题场景举例 多个 TFJob 同时作业导致死锁的场景 TFJob1 与 TFJob2 均需要 4 个 GPU 资源，需要其四个子任务 Pod 同时运行才能开始作业，如果 TFJob1 与 TFJob2 同时提交，各自只有两个 Pod 获取到了 GPU 资源，便出现互相等待对方释放资源的情况，形成死锁，无法完成作业，也造成了 GPU 资源的浪费 Kubernetes 默认调度策略下，产生较多碎片资源的场景 Kubernetes 默认使用的 LeastRequestedPriority 优先级策略会将 Pod 优先调度到消耗资源少的节点上，让各节点的资源使用率尽量均匀，但这样容易产生碎片，如上图所示，在集群的角度，还可以提供 2 个 GPU 资源，但无法调度一个需要 2 GPU 资源的 Pod … ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:1:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#12-问题场景举例"},{"categories":["OpenShift"],"content":" 1.3 需求 https://wiki.cestc.cn/pages/viewpage.action?pageId=190216766 至少需要支持以下两种调度策略： Gang Scheduling 作业的所有子任务都能满足资源需求才整体分配，否则不分配任务资源。避免由于资源死锁，导致大作业挤占小作业 Binpack Scheduling 作业优先集中分配在某个节点，当节点资源不足时，依次在下一节点集中分配，适合单机多卡训练任务，避免跨机数据传输，防止资源碎片 ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:1:3","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#13-需求"},{"categories":["OpenShift"],"content":" 二、*友商方案对比","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:2:0","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#二友商方案对比"},{"categories":["OpenShift"],"content":" 2.1 Kubernetes Scheduler 扩展方式简单对比 扩展调度的方式 特点 缺点 Scheduler Extender 支持 Filter、Preempt、Prioritize、Bind 的扩展； 首先执行 Kubernetes 内置的调度策略，通过 http 调用 Extender 注册的 webhook 运行扩展逻辑，影响调度结果 使用 http 请求获取自定义的调度结果，受网络影响，性能不及本地函数调用； 扩展点有限，较不灵活； 必须执行完 Kubernetes 默认的 Filter 策略后才调用自定义的策略 Multiple schedulers 调度性能强于 Scheduler Extender 可扩展性强 与默认调度器同时部署会导致资源冲突 研发、维护成本较高 Scheduling Framework Kubernetes 调度器的可插拔架构 Scheduler Extender Multiple Schedulers Scheduling Framework ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:2:1","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#21-kubernetes-scheduler-扩展方式简单对比"},{"categories":["OpenShift"],"content":" 2.2 友商已有解决方案对比 2.2.1 华为云 - Volcano https://volcano.sh/zh/ Volcano是CNCF 下首个也是唯一的基于Kubernetes的容器批量计算平台，主要用于高性能计算场景。它提供了Kubernetes目前缺 少的一套机制，这些机制通常是机器学习大数据应用、科学计算、特效渲染等多种高性能工作负载所需的。作为一个通用批处理平台，Volcano与几乎所有的主流计算框 架无缝对接，如Spark 、TensorFlow 、PyTorch 、 Flink 、Argo 、MindSpore 、 PaddlePaddle 等。它还提供了包括基于各种主流架构的CPU、GPU在内的异构设备混合调度能力。Volcano的设计 理念建立在15年来多种系统和平台大规模运行各种高性能工作负载的使用经验之上，并结合来自开源社区的最佳思想和实践。(https://volcano.sh/zh/docs/#%E7%AE%80%E4%BB%8B) 支持的调度策略： Gang-scheduling Binpack-scheduling Fair-share scheduling Queue scheduling Preemption scheduling Topology-based scheduling Reclaims Backfill Resource Reservation (Volcano支持用户自定义plugin和action以支持更多调度算法) 支持的计算框架： TensoFlow Pytorch MindSpore PaddlePaddle Spark Flink OpenMPI Horovod MXNet Kubeflow Argo KubeGene 2.2.2 阿里云方案 阿里云 Gang scheduling 阿里云 Capacity Scheduling 只找到相关的一些实现思路、解决方案，没有已有的开源项目 ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#22-友商已有解决方案对比"},{"categories":["OpenShift"],"content":" 2.2 友商已有解决方案对比 2.2.1 华为云 - Volcano https://volcano.sh/zh/ Volcano是CNCF 下首个也是唯一的基于Kubernetes的容器批量计算平台，主要用于高性能计算场景。它提供了Kubernetes目前缺 少的一套机制，这些机制通常是机器学习大数据应用、科学计算、特效渲染等多种高性能工作负载所需的。作为一个通用批处理平台，Volcano与几乎所有的主流计算框 架无缝对接，如Spark 、TensorFlow 、PyTorch 、 Flink 、Argo 、MindSpore 、 PaddlePaddle 等。它还提供了包括基于各种主流架构的CPU、GPU在内的异构设备混合调度能力。Volcano的设计 理念建立在15年来多种系统和平台大规模运行各种高性能工作负载的使用经验之上，并结合来自开源社区的最佳思想和实践。(https://volcano.sh/zh/docs/#%E7%AE%80%E4%BB%8B) 支持的调度策略： Gang-scheduling Binpack-scheduling Fair-share scheduling Queue scheduling Preemption scheduling Topology-based scheduling Reclaims Backfill Resource Reservation (Volcano支持用户自定义plugin和action以支持更多调度算法) 支持的计算框架： TensoFlow Pytorch MindSpore PaddlePaddle Spark Flink OpenMPI Horovod MXNet Kubeflow Argo KubeGene 2.2.2 阿里云方案 阿里云 Gang scheduling 阿里云 Capacity Scheduling 只找到相关的一些实现思路、解决方案，没有已有的开源项目 ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#221-华为云---volcano"},{"categories":["OpenShift"],"content":" 2.2 友商已有解决方案对比 2.2.1 华为云 - Volcano https://volcano.sh/zh/ Volcano是CNCF 下首个也是唯一的基于Kubernetes的容器批量计算平台，主要用于高性能计算场景。它提供了Kubernetes目前缺 少的一套机制，这些机制通常是机器学习大数据应用、科学计算、特效渲染等多种高性能工作负载所需的。作为一个通用批处理平台，Volcano与几乎所有的主流计算框 架无缝对接，如Spark 、TensorFlow 、PyTorch 、 Flink 、Argo 、MindSpore 、 PaddlePaddle 等。它还提供了包括基于各种主流架构的CPU、GPU在内的异构设备混合调度能力。Volcano的设计 理念建立在15年来多种系统和平台大规模运行各种高性能工作负载的使用经验之上，并结合来自开源社区的最佳思想和实践。(https://volcano.sh/zh/docs/#%E7%AE%80%E4%BB%8B) 支持的调度策略： Gang-scheduling Binpack-scheduling Fair-share scheduling Queue scheduling Preemption scheduling Topology-based scheduling Reclaims Backfill Resource Reservation (Volcano支持用户自定义plugin和action以支持更多调度算法) 支持的计算框架： TensoFlow Pytorch MindSpore PaddlePaddle Spark Flink OpenMPI Horovod MXNet Kubeflow Argo KubeGene 2.2.2 阿里云方案 阿里云 Gang scheduling 阿里云 Capacity Scheduling 只找到相关的一些实现思路、解决方案，没有已有的开源项目 ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#222-阿里云方案"},{"categories":["OpenShift"],"content":" 三、整体方案架构/组件架构","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:3:0","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#三整体方案架构组件架构"},{"categories":["OpenShift"],"content":" 3.1选用开源项目 Volcano 以支持多种调度策略选用已有的，由华为开源的 Volcano 项目，满足我们的需求，提供了丰富的调度策略与 Job 控制能力。Volcano 与 Kubernetes 天然兼容，其系统架构如下图所示： Volcano 主要由 Scheduler、ControllerManager、Admission 组成： Scheduler：通过一些列 action、plugin 调度 Job，为其找到最合适的节点，与 Kubernetes default-scheduler 相比，Volcano 支持 Job 的多种调度算法 action：定义了调度各环节中执行的动作 plugin：根据不同的场景提供了 action 中算法的具体细节 scheduler 具体工作流程：https://volcano.sh/zh/docs/schduler_introduction/#%E5%B7%A5%E4%BD%9C%E6%B5%81 ControllerManager：管理 CRD 资源的生命周期。主要由 Queue CM、PodGroup CM、VCJob CM 组成 Admission：负责对 CRD API 资源进行校验 ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:3:1","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#31选用开源项目-volcano-以支持多种调度策略"},{"categories":["OpenShift"],"content":" 3.2 如何对接到我们的集群通过 Application Operator 的形式，用户在 OperatorHub 界面通过安装 volcano-operator，将 Volcano 的相关资源安装到集群中： ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:3:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#32-如何对接到我们的集群"},{"categories":["OpenShift"],"content":" 四、方案流程详细设计","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:4:0","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#四方案流程详细设计"},{"categories":["OpenShift"],"content":" 4.1 流程主要分为三大部分 （具体图示见 3.2） volcano 的安装：由 volcano-operator 来完成 volcano 所需资源的安装 volcano 的使用 通过 volcano-operator 在界面上提供 volcano APIs 的操作入口 对于具体调度逻辑的验证 volcano 的卸载 删除用于触发创建 volcano 资源的 VolcanoBackend CR 实例，触发 volcano-operator 完成 volcano 相关资源的卸载 卸载 volcano-operator ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:4:1","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#41-流程主要分为三大部分-具体图示见-32"},{"categories":["OpenShift"],"content":" 4.2 该方案具体需要完成工作 任务项 todo 调度逻辑支持 使用 volcano 开源项目（huawei） volcano 资源安装、卸载 volcano-operator 开发 组件 e2e 新增特性，ceake-origin 需新增对应的测试例 需具体了解 volcano 项目相关特性，完成测试例开发 ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:4:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#42-该方案具体需要完成工作"},{"categories":["OpenShift"],"content":" 五、API 接口设计/参考目前 volcano-operator 提供的 api 主要是 1 个自身的 API + volcano 项目提供的 5 个 API 共 6 个 API ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:0","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#五api-接口设计参考"},{"categories":["OpenShift"],"content":" 5.1 VolcanoBackend VolcanoBackend 是 volcano-operator 本身提供的 api volcano-operator 在安装的时候会自己创建一个默认的 VolcanoBackend 资源，位于default命名空间下，名称为default该资源主要有两个作用： 触发 VolcanoBackendReconcile 逻辑，从而安装 volcano 的相关资源 卸载 volcano-operator 之前需要删除该默认资源，卸载 volcano 的相关资源 用户无需创建该资源 Property Type Description metav1.TypeMeta metav1.TypeMeta metav1.ObjectMeta metav1.ObjectMeta Spec VolcanoBackendSpec Status VolcanoBackendStatus VolcanoBackendSpec: Property Type Description Description string 可选的描述字段 e.g. apiVersion: operator.volcano.sh/v1 kind: VolcanoBackend metadata: finalizers: - operator.volcano.sh/finalizer name: default namespace: default spec: description: 'func: triggering volcano resources creation' ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:1","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#51-volcanobackendhttp10253112156060pkgcodecestccnccosceavolcano-operatorapisoperatorv1volcanobackend"},{"categories":["OpenShift"],"content":" 5.2 Job Job 是 volcano 项目提供的 API，通过 OperatorHub 中的 volcano-operator 给用户提供界面上的操作入口 Property Type Description metav1.TypeMeta metav1.TypeMeta metav1.ObjectMeta metav1.ObjectMeta Spec vcv1alpha1.JobSpec Specification of the desired behavior of the volcano job, including the minAvailable Status vcv1alpha1.JobStatus Current status of the volcano Job vcv1alpha1.JobSpec: Property Type Description SchedulerName string SchedulerName is the default value of tasks.template.spec.schedulerName. MinAvailable int32 The minimal available pods to run for this Job Defaults to the summary of tasks’ replicas Volumes [] VolumeSpec The volumes mount on Job Tasks [] TaskSpec Tasks specifies the task specification of Job Policies [] LifecyclePolicy Specifies the default lifecycle of tasks Plugins map [string] []string Specifies the plugin of job Key is plugin name, value is the arguments of the plugin RunningEstimate *metav1.Duration Running Estimate is a user running duration estimate for the job Default to nil Queue string Specifies the queue that will be used in the scheduler, “default” queue is used this leaves empty. MaxRetry int32 Specifies the maximum number of retries before marking this Job failed. Defaults to 3. TTLSecondsAfterFinished *int32 ttlSecondsAfterFinished limits the lifetime of a Job that has finished execution (either Completed or Failed). If this field is set, ttlSecondsAfterFinished after the Job finishes, it is eligible to be automatically deleted. If this field is unset, the Job won’t be automatically deleted. If this field is set to zero, the Job becomes eligible to be deleted immediately after it finishes. PriorityClassName string If specified, indicates the job’s priority. MinSuccess *int32 The minimal success pods to run for this Job Minimum=1 e.g. // TODO ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:2","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#52-jobhttp10253112156060pkgcodecestccnccosceavolcano-operatorapisbatchv1alpha1job"},{"categories":["OpenShift"],"content":" 5.3 Command Command 是 volcano 项目提供的 API，通过 OperatorHub 中的 volcano-operator 给用户提供界面上的操作入口 Property Type Description metav1.TypeMeta metav1.TypeMeta metav1.ObjectMeta metav1.ObjectMeta Action string Action defines the action that will be took to the target object. TargetObject *metav1.OwnerReference TargetObject defines the target object of this command. Reason string Unique, one-word, CamelCase reason for this command. Message string Human-readable message indicating details of this command. e.g. // TODO ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:3","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#53-commandhttp10253112156060pkgvolcanoshapispkgapisbusv1alpha1command"},{"categories":["OpenShift"],"content":" 5.4 Numatopology Numatopology 是 volcano 项目提供的 API，通过 OperatorHub 中的 volcano-operator 给用户提供界面上的操作入口 Property Type Description metav1.TypeMeta metav1.TypeMeta metav1.ObjectMeta metav1.ObjectMeta Spec NumatopoSpec Specification of the numa information of the worker node NumatopoSpec: Property Type Description Policies map[ PolicyName ] string Specifies the policy of the manager ResReserved map[ string ] string Specifies the reserved resource of the node Key is resource name NumaResMap map[ string ] ResourceInfo Specifies the numa info for the resource Key is resource name CPUDetail map[ string ] CPUInfo Specifies the cpu topology info Key is cpu id e.g. // TODO ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:4","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#54-numatopologyhttp10253112156060pkgvolcanoshapispkgapisnodeinfov1alpha1numatopology"},{"categories":["OpenShift"],"content":" 5.5 Queue Queue 是 volcano 项目提供的 API，通过 OperatorHub 中的 volcano-operator 给用户提供界面上的操作入口 Property Type Description metav1.TypeMeta metav1.TypeMeta metav1.ObjectMeta metav1.ObjectMeta Spec QueueSpec Specification of the desired behavior of the queue. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status Status QueueStatus The status of queue. QueueSpec: Property Type Description Weight int32 Capability v1.ResourceList Reclaimable *bool Reclaimable indicate whether the queue can be reclaimed by other queue ExtendClusters [] Cluster extendCluster indicate the jobs in this Queue will be dispatched to these clusters. Guarantee Guarantee Guarantee indicate configuration about resource reservation e.g. // TODO ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:5","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#55-queuehttp10253112156060pkgvolcanoshapispkgapisschedulingv1beta1queue"},{"categories":["OpenShift"],"content":" 5.6 PodGroup PodGroup 是 volcano 项目提供的 API，通过 OperatorHub 中的 volcano-operator 给用户提供界面上的操作入口 Property Type Description metav1.TypeMeta metav1.TypeMeta metav1.ObjectMeta metav1.ObjectMeta Spec PodGroupSpec Specification of the desired behavior of the pod group. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#spec-and-status Status PodGroupStatus Status represents the current information about a pod group. This data may not be up to date. PodGroupSpec: Property Type Description MinMember int32 MinMember defines the minimal number of members/tasks to run the pod group; if there’s not enough resources to start all tasks, the scheduler will not start anyone. MinTaskMember map[ string ] int32 MinTaskMember defines the minimal number of pods to run each task in the pod group; if there’s not enough resources to start each task, the scheduler will not start anyone. Queue string Queue defines the queue to allocate resource for PodGroup; if queue does not exist, the PodGroup will not be scheduled. Defaults to default Queue with the lowest weight. PriorityClassName string If specified, indicates the PodGroup’s priority. “system-node-critical” and “system-cluster-critical” are two special keywords which indicate the highest priorities with the former being the highest priority. Any other name must be defined by creating a PriorityClass object with that name. If not specified, the PodGroup priority will be default or zero if there is no MinResources v1.ResourceList MinResources defines the minimal resource of members/tasks to run the pod group; if there’s not enough resources to start all tasks, the scheduler will not start anyone. e.g. // TODO ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:5:6","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#56-podgrouphttp10253112156060pkgvolcanoshapispkgapisschedulingv1beta1podgroup"},{"categories":["OpenShift"],"content":" *、参考资料 https://www.6aiq.com/article/1628641646793 https://support.huaweicloud.com/bestpractice-cce/cce_bestpractice_0075.html#section1 https://volcano.sh/ https://developer.aliyun.com/article/766998 https://www.cncf.io/wp-content/uploads/2020/08/%E9%98%BF%E9%87%8C%E5%B7%B4%E5%B7%B4%E5%A6%82%E4%BD%95%E6%89%A9%E5%B1%95Kubernetes-%E8%B0%83%E5%BA%A6%E5%99%A8%E6%94%AF%E6%8C%81-AI-%E5%92%8C%E5%A4%A7%E6%95%B0%E6%8D%AE%E4%BD%9C%E4%B8%9A%EF%BC%9F1-xi-jiang.pdf https://github.com/kubernetes-sigs/scheduler-plugins/blob/master/kep/9-capacity-scheduling/README.md ","date":"2023-05-16","objectID":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/:6:0","series":["偏工作性质记录"],"tags":["高性能计算","方案","volcano"],"title":"高性能计算-支持作业高级调度策略方案","uri":"/202305161508-%E9%AB%98%E6%80%A7%E8%83%BD%E8%AE%A1%E7%AE%97-%E6%94%AF%E6%8C%81%E4%BD%9C%E4%B8%9A%E9%AB%98%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AD%96%E7%95%A5%E6%96%B9%E6%A1%88/#参考资料"},{"categories":["OpenShift"],"content":" 一、为什么要支持计算节点健康检查问题：有很多节点问题会影响到节点上正在运行的pod，比如内核死锁、OOM、文件系统损坏、容器运行时异常…，在集群中，有些问题对于上层来说不可见，pod还是有可能会调度到有问题的节点。Kubelet 默认对节点的 PIDPressure、MemoryPressure、DiskPressure 等资源状态进行监控，但是存在当 Kubelet 上报状态时节点已处于不可用状态的情况，甚至 Kubelet 可能已开始驱逐 Pod 为了解决上面的问题，引入节点健康检查，添加更细致化的指标，在人工干预之前，及早发现问题，提前预知节点的资源压力，反馈给集群，在业务pod不可用之前提前发现节点异常，并作出相应的补救策略 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:1:0","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#一为什么要支持计算节点健康检查"},{"categories":["OpenShift"],"content":" 二、如何来做节点的健康检查","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:2:0","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#二如何来做节点的健康检查"},{"categories":["OpenShift"],"content":" 2.1 相关技术 Node Problem Detector（NPD，节点健康检查） Node Health Check Operator （NHC，监听节点状态，触发修复）+ Self Node Remediation Operator（SNR，修复） ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:2:1","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#21-相关技术"},{"categories":["OpenShift"],"content":" 2.2 整体节点检查、修复流程 2.2.1 概览 2.2.2 整体流程 NPD 在每个节点上运行守护进程，检测并报告节点的健康状况 NPD 组件检测节点上的故障，如 Linux Kernel Hang、容器运行时异常、文件描述符异常等，并转换为节点的事件（Event）或者 Condition上报给集群 监控项：每个 NPD 创建子守护进程，监视对应类型的节点问题： SystemLogMonitor：用于监控系统和内核的日志，根据预定义的规则来报告问题、指标。支持基于文件的日志、journald、kmsg SystemStatusMonitor：从不通的系统组件收集预定义的相关健康指标，支持的组件：cpu、disk、host、memory CuntomPluginMonitor：自定义插件 HealthChecker：检查kubelet和容器运行时的健康状况 NPD 支持自定义监控脚本，可自定义检测期望发现的节点问题 每个监控项通过配置文件来修改、扩展规则，e.g. { \"plugin\": \"kmsg\", \"logPath\": \"/dev/kmsg\", \"lookback\": \"5m\", \"bufferSize\": 10, \"source\": \"kernel-monitor\", \"metricsReporting\": true, \"conditions\": [ { \"type\": \"KernelDeadlock\", \"reason\": \"KernelHasNoDeadlock\", \"message\": \"kernel has no deadlock\" }, { \"type\": \"ReadonlyFilesystem\", \"reason\": \"FilesystemIsNotReadOnly\", \"message\": \"Filesystem is not read-only\" } ], \"rules\": [ { \"type\": \"temporary\", \"reason\": \"OOMKilling\", \"pattern\": \"Killed process \\\\d+ (.+) total-vm:\\\\d+kB, anon-rss:\\\\d+kB, file-rss:\\\\d+kB.*\" }, { \"type\": \"temporary\", \"reason\": \"TaskHung\", \"pattern\": \"task [\\\\S ]+:\\\\w+ blocked for more than \\\\w+ seconds\\\\.\" }, { \"type\": \"temporary\", \"reason\": \"UnregisterNetDevice\", \"pattern\": \"unregister_netdevice: waiting for \\\\w+ to become free. Usage count = \\\\d+\" }, ... ] } 安装 NPD 之后，节点中会添加以下 Conditions： Condition Type 默认值 描述 ReadonlyFilesystem False 文件系统是否只读 FDPressure False 查看主机的文件描述符数量是否达到最大值的80% FrequentKubeletRestart False Kubelet 是否在20Min内重启超过5次 CorruptDockerOverlay2 False DockerImage 是否存在问题 KubeletProblem False Kubelet service 是否 Running KernelDeadlock False 内核是否存在死锁 FrequentDockerRestart False Docker 是否在20Min内重启超过5次 FrequentContainerdRestart False Containerd 是否在20Min内重启超过5次 DockerdProblem False Docker service 是否 Running（若节点运行时为 Containerd，则一直为 False） ContainerdProblem False Containerd service 是否 Running（若节点运行时为 Docker，则一直为 False） ThreadPressure False 系统目前线程数是否达到最大值的90% NetworkUnavailable False NTP service 是否 Running SerfFailed False 分布式检测节点网络健康状态 当发现问题后，将以 NodeCondition 和 Event 的形式上报给 apiserver 发现问题后，向 k8s apiserver 报告节点问题：临时问题报告为 Event，永久问题报告为 NodeCondition 问题上报之后，node 节点状态变化，NHC 根据不健康节点的判断规则 NHC 目前判断节点不健康的条件只通过节点状态以及持续时间来判断 NodeHealthCheck e.g. 则如果节点状态不为 Ready 的持续时间超过 300s，NHC 会将其判断为一个不健康节点 后续需要 NHC 能够识别由 NPD 上报的不同节点问题，识别节点不同的 Condition Type，比如：ReadonlyFilesystem、FDPressure、KubeletProblem等等，针对性地触发补救 NHC 创建 SNR 提供的补救模板之后，会触发 SNR 补救逻辑 目前 SNR 的补救策略只有 reboot 节点 后续需要根据 NHC 发送的不同的节点问题，更有针对性地进行补救 补救成功后，节点状态将被恢复为正常，NHC 删除创建的补救 CR 实例，并继续监控节点状态，形成闭环 2.2.3 修复过程与结果记录问题的发现：kube-system 命名空间下查看 NPD 对应 pod 的日志记录，通过 node 的 Event、Condition 查看上报的结果 触发修复：查看 NHC manager 日志，可知针对哪个不健康节点，创建了什么修复模板 修复结果：查看 SNR manager 的日志，可知执行了什么修复策略，调度了哪个 ds 来做的修复，查看 node 的 Event、Condition 或者相应服务的状态来确定修复是否完成 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#22-整体节点检查修复流程"},{"categories":["OpenShift"],"content":" 2.2 整体节点检查、修复流程 2.2.1 概览 2.2.2 整体流程 NPD 在每个节点上运行守护进程，检测并报告节点的健康状况 NPD 组件检测节点上的故障，如 Linux Kernel Hang、容器运行时异常、文件描述符异常等，并转换为节点的事件（Event）或者 Condition上报给集群 监控项：每个 NPD 创建子守护进程，监视对应类型的节点问题： SystemLogMonitor：用于监控系统和内核的日志，根据预定义的规则来报告问题、指标。支持基于文件的日志、journald、kmsg SystemStatusMonitor：从不通的系统组件收集预定义的相关健康指标，支持的组件：cpu、disk、host、memory CuntomPluginMonitor：自定义插件 HealthChecker：检查kubelet和容器运行时的健康状况 NPD 支持自定义监控脚本，可自定义检测期望发现的节点问题 每个监控项通过配置文件来修改、扩展规则，e.g. { \"plugin\": \"kmsg\", \"logPath\": \"/dev/kmsg\", \"lookback\": \"5m\", \"bufferSize\": 10, \"source\": \"kernel-monitor\", \"metricsReporting\": true, \"conditions\": [ { \"type\": \"KernelDeadlock\", \"reason\": \"KernelHasNoDeadlock\", \"message\": \"kernel has no deadlock\" }, { \"type\": \"ReadonlyFilesystem\", \"reason\": \"FilesystemIsNotReadOnly\", \"message\": \"Filesystem is not read-only\" } ], \"rules\": [ { \"type\": \"temporary\", \"reason\": \"OOMKilling\", \"pattern\": \"Killed process \\\\d+ (.+) total-vm:\\\\d+kB, anon-rss:\\\\d+kB, file-rss:\\\\d+kB.*\" }, { \"type\": \"temporary\", \"reason\": \"TaskHung\", \"pattern\": \"task [\\\\S ]+:\\\\w+ blocked for more than \\\\w+ seconds\\\\.\" }, { \"type\": \"temporary\", \"reason\": \"UnregisterNetDevice\", \"pattern\": \"unregister_netdevice: waiting for \\\\w+ to become free. Usage count = \\\\d+\" }, ... ] } 安装 NPD 之后，节点中会添加以下 Conditions： Condition Type 默认值 描述 ReadonlyFilesystem False 文件系统是否只读 FDPressure False 查看主机的文件描述符数量是否达到最大值的80% FrequentKubeletRestart False Kubelet 是否在20Min内重启超过5次 CorruptDockerOverlay2 False DockerImage 是否存在问题 KubeletProblem False Kubelet service 是否 Running KernelDeadlock False 内核是否存在死锁 FrequentDockerRestart False Docker 是否在20Min内重启超过5次 FrequentContainerdRestart False Containerd 是否在20Min内重启超过5次 DockerdProblem False Docker service 是否 Running（若节点运行时为 Containerd，则一直为 False） ContainerdProblem False Containerd service 是否 Running（若节点运行时为 Docker，则一直为 False） ThreadPressure False 系统目前线程数是否达到最大值的90% NetworkUnavailable False NTP service 是否 Running SerfFailed False 分布式检测节点网络健康状态 当发现问题后，将以 NodeCondition 和 Event 的形式上报给 apiserver 发现问题后，向 k8s apiserver 报告节点问题：临时问题报告为 Event，永久问题报告为 NodeCondition 问题上报之后，node 节点状态变化，NHC 根据不健康节点的判断规则 NHC 目前判断节点不健康的条件只通过节点状态以及持续时间来判断 NodeHealthCheck e.g. 则如果节点状态不为 Ready 的持续时间超过 300s，NHC 会将其判断为一个不健康节点 后续需要 NHC 能够识别由 NPD 上报的不同节点问题，识别节点不同的 Condition Type，比如：ReadonlyFilesystem、FDPressure、KubeletProblem等等，针对性地触发补救 NHC 创建 SNR 提供的补救模板之后，会触发 SNR 补救逻辑 目前 SNR 的补救策略只有 reboot 节点 后续需要根据 NHC 发送的不同的节点问题，更有针对性地进行补救 补救成功后，节点状态将被恢复为正常，NHC 删除创建的补救 CR 实例，并继续监控节点状态，形成闭环 2.2.3 修复过程与结果记录问题的发现：kube-system 命名空间下查看 NPD 对应 pod 的日志记录，通过 node 的 Event、Condition 查看上报的结果 触发修复：查看 NHC manager 日志，可知针对哪个不健康节点，创建了什么修复模板 修复结果：查看 SNR manager 的日志，可知执行了什么修复策略，调度了哪个 ds 来做的修复，查看 node 的 Event、Condition 或者相应服务的状态来确定修复是否完成 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#221-概览"},{"categories":["OpenShift"],"content":" 2.2 整体节点检查、修复流程 2.2.1 概览 2.2.2 整体流程 NPD 在每个节点上运行守护进程，检测并报告节点的健康状况 NPD 组件检测节点上的故障，如 Linux Kernel Hang、容器运行时异常、文件描述符异常等，并转换为节点的事件（Event）或者 Condition上报给集群 监控项：每个 NPD 创建子守护进程，监视对应类型的节点问题： SystemLogMonitor：用于监控系统和内核的日志，根据预定义的规则来报告问题、指标。支持基于文件的日志、journald、kmsg SystemStatusMonitor：从不通的系统组件收集预定义的相关健康指标，支持的组件：cpu、disk、host、memory CuntomPluginMonitor：自定义插件 HealthChecker：检查kubelet和容器运行时的健康状况 NPD 支持自定义监控脚本，可自定义检测期望发现的节点问题 每个监控项通过配置文件来修改、扩展规则，e.g. { \"plugin\": \"kmsg\", \"logPath\": \"/dev/kmsg\", \"lookback\": \"5m\", \"bufferSize\": 10, \"source\": \"kernel-monitor\", \"metricsReporting\": true, \"conditions\": [ { \"type\": \"KernelDeadlock\", \"reason\": \"KernelHasNoDeadlock\", \"message\": \"kernel has no deadlock\" }, { \"type\": \"ReadonlyFilesystem\", \"reason\": \"FilesystemIsNotReadOnly\", \"message\": \"Filesystem is not read-only\" } ], \"rules\": [ { \"type\": \"temporary\", \"reason\": \"OOMKilling\", \"pattern\": \"Killed process \\\\d+ (.+) total-vm:\\\\d+kB, anon-rss:\\\\d+kB, file-rss:\\\\d+kB.*\" }, { \"type\": \"temporary\", \"reason\": \"TaskHung\", \"pattern\": \"task [\\\\S ]+:\\\\w+ blocked for more than \\\\w+ seconds\\\\.\" }, { \"type\": \"temporary\", \"reason\": \"UnregisterNetDevice\", \"pattern\": \"unregister_netdevice: waiting for \\\\w+ to become free. Usage count = \\\\d+\" }, ... ] } 安装 NPD 之后，节点中会添加以下 Conditions： Condition Type 默认值 描述 ReadonlyFilesystem False 文件系统是否只读 FDPressure False 查看主机的文件描述符数量是否达到最大值的80% FrequentKubeletRestart False Kubelet 是否在20Min内重启超过5次 CorruptDockerOverlay2 False DockerImage 是否存在问题 KubeletProblem False Kubelet service 是否 Running KernelDeadlock False 内核是否存在死锁 FrequentDockerRestart False Docker 是否在20Min内重启超过5次 FrequentContainerdRestart False Containerd 是否在20Min内重启超过5次 DockerdProblem False Docker service 是否 Running（若节点运行时为 Containerd，则一直为 False） ContainerdProblem False Containerd service 是否 Running（若节点运行时为 Docker，则一直为 False） ThreadPressure False 系统目前线程数是否达到最大值的90% NetworkUnavailable False NTP service 是否 Running SerfFailed False 分布式检测节点网络健康状态 当发现问题后，将以 NodeCondition 和 Event 的形式上报给 apiserver 发现问题后，向 k8s apiserver 报告节点问题：临时问题报告为 Event，永久问题报告为 NodeCondition 问题上报之后，node 节点状态变化，NHC 根据不健康节点的判断规则 NHC 目前判断节点不健康的条件只通过节点状态以及持续时间来判断 NodeHealthCheck e.g. 则如果节点状态不为 Ready 的持续时间超过 300s，NHC 会将其判断为一个不健康节点 后续需要 NHC 能够识别由 NPD 上报的不同节点问题，识别节点不同的 Condition Type，比如：ReadonlyFilesystem、FDPressure、KubeletProblem等等，针对性地触发补救 NHC 创建 SNR 提供的补救模板之后，会触发 SNR 补救逻辑 目前 SNR 的补救策略只有 reboot 节点 后续需要根据 NHC 发送的不同的节点问题，更有针对性地进行补救 补救成功后，节点状态将被恢复为正常，NHC 删除创建的补救 CR 实例，并继续监控节点状态，形成闭环 2.2.3 修复过程与结果记录问题的发现：kube-system 命名空间下查看 NPD 对应 pod 的日志记录，通过 node 的 Event、Condition 查看上报的结果 触发修复：查看 NHC manager 日志，可知针对哪个不健康节点，创建了什么修复模板 修复结果：查看 SNR manager 的日志，可知执行了什么修复策略，调度了哪个 ds 来做的修复，查看 node 的 Event、Condition 或者相应服务的状态来确定修复是否完成 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#222-整体流程"},{"categories":["OpenShift"],"content":" 2.2 整体节点检查、修复流程 2.2.1 概览 2.2.2 整体流程 NPD 在每个节点上运行守护进程，检测并报告节点的健康状况 NPD 组件检测节点上的故障，如 Linux Kernel Hang、容器运行时异常、文件描述符异常等，并转换为节点的事件（Event）或者 Condition上报给集群 监控项：每个 NPD 创建子守护进程，监视对应类型的节点问题： SystemLogMonitor：用于监控系统和内核的日志，根据预定义的规则来报告问题、指标。支持基于文件的日志、journald、kmsg SystemStatusMonitor：从不通的系统组件收集预定义的相关健康指标，支持的组件：cpu、disk、host、memory CuntomPluginMonitor：自定义插件 HealthChecker：检查kubelet和容器运行时的健康状况 NPD 支持自定义监控脚本，可自定义检测期望发现的节点问题 每个监控项通过配置文件来修改、扩展规则，e.g. { \"plugin\": \"kmsg\", \"logPath\": \"/dev/kmsg\", \"lookback\": \"5m\", \"bufferSize\": 10, \"source\": \"kernel-monitor\", \"metricsReporting\": true, \"conditions\": [ { \"type\": \"KernelDeadlock\", \"reason\": \"KernelHasNoDeadlock\", \"message\": \"kernel has no deadlock\" }, { \"type\": \"ReadonlyFilesystem\", \"reason\": \"FilesystemIsNotReadOnly\", \"message\": \"Filesystem is not read-only\" } ], \"rules\": [ { \"type\": \"temporary\", \"reason\": \"OOMKilling\", \"pattern\": \"Killed process \\\\d+ (.+) total-vm:\\\\d+kB, anon-rss:\\\\d+kB, file-rss:\\\\d+kB.*\" }, { \"type\": \"temporary\", \"reason\": \"TaskHung\", \"pattern\": \"task [\\\\S ]+:\\\\w+ blocked for more than \\\\w+ seconds\\\\.\" }, { \"type\": \"temporary\", \"reason\": \"UnregisterNetDevice\", \"pattern\": \"unregister_netdevice: waiting for \\\\w+ to become free. Usage count = \\\\d+\" }, ... ] } 安装 NPD 之后，节点中会添加以下 Conditions： Condition Type 默认值 描述 ReadonlyFilesystem False 文件系统是否只读 FDPressure False 查看主机的文件描述符数量是否达到最大值的80% FrequentKubeletRestart False Kubelet 是否在20Min内重启超过5次 CorruptDockerOverlay2 False DockerImage 是否存在问题 KubeletProblem False Kubelet service 是否 Running KernelDeadlock False 内核是否存在死锁 FrequentDockerRestart False Docker 是否在20Min内重启超过5次 FrequentContainerdRestart False Containerd 是否在20Min内重启超过5次 DockerdProblem False Docker service 是否 Running（若节点运行时为 Containerd，则一直为 False） ContainerdProblem False Containerd service 是否 Running（若节点运行时为 Docker，则一直为 False） ThreadPressure False 系统目前线程数是否达到最大值的90% NetworkUnavailable False NTP service 是否 Running SerfFailed False 分布式检测节点网络健康状态 当发现问题后，将以 NodeCondition 和 Event 的形式上报给 apiserver 发现问题后，向 k8s apiserver 报告节点问题：临时问题报告为 Event，永久问题报告为 NodeCondition 问题上报之后，node 节点状态变化，NHC 根据不健康节点的判断规则 NHC 目前判断节点不健康的条件只通过节点状态以及持续时间来判断 NodeHealthCheck e.g. 则如果节点状态不为 Ready 的持续时间超过 300s，NHC 会将其判断为一个不健康节点 后续需要 NHC 能够识别由 NPD 上报的不同节点问题，识别节点不同的 Condition Type，比如：ReadonlyFilesystem、FDPressure、KubeletProblem等等，针对性地触发补救 NHC 创建 SNR 提供的补救模板之后，会触发 SNR 补救逻辑 目前 SNR 的补救策略只有 reboot 节点 后续需要根据 NHC 发送的不同的节点问题，更有针对性地进行补救 补救成功后，节点状态将被恢复为正常，NHC 删除创建的补救 CR 实例，并继续监控节点状态，形成闭环 2.2.3 修复过程与结果记录问题的发现：kube-system 命名空间下查看 NPD 对应 pod 的日志记录，通过 node 的 Event、Condition 查看上报的结果 触发修复：查看 NHC manager 日志，可知针对哪个不健康节点，创建了什么修复模板 修复结果：查看 SNR manager 的日志，可知执行了什么修复策略，调度了哪个 ds 来做的修复，查看 node 的 Event、Condition 或者相应服务的状态来确定修复是否完成 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#223-修复过程与结果记录"},{"categories":["OpenShift"],"content":" 三、关于迭代升级 对节点出现的不同问题做针对性补救 NPD 本身支持对许多不同类型的问题进行监控，并将其上报给集群，但 NHC 目前对不健康节点的条件判断还比较宽泛，无法针对节点出现的不同问题，做针对性的补救，只是简单将节点重启，后续需要升级 NHC 以及 SNR，以支持能够对节点出现的问题采取针对性的手段做修复 控制同一时刻修复的节点面积 需要防止同一时刻大面积节点同时触发修复的情况，NHC 需要增加限制，同一时刻只允许规定数量的节点触发修复 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:3:0","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#三关于迭代升级"},{"categories":["OpenShift"],"content":" *、方案描述这个节点健康检查方案的背景呢，就是我们的集群在运行时，可能会因为许多原因导致不可用，做这个节点健康检查的目的其实就是两个：一个是对问题监控的粒度更细一些，以及对问题的反应更提前一些，现在 kubelet 会监控节点的内存压力、磁盘压力等等，监控项还是比较少，我们希望引入 NPD 来监控更多节点的状态，监控更多指标，像文件系统只读，文件描述符数量，containerd 是不是在频繁启动之类的，做到粒度更细一些，然后反应更提前就是希望通过监控更多指标，提前感知节点的压力，在节点开始驱逐pod之前就做出相应的措施。 然后具体方案可以看下，主要采用了NPD，用来做节点健康检查，然后 NHC 对节点状态、事件做监听，触发修复，SNR用来做具体的修复。 NPD： 这是NPD自身支持的几个监控类型，通过配置文件的形式增加、修改监控的规则 NHC：在节点状态发生变化之后，NHC 会根据配置的规则来判断节点是不是不健康的 ","date":"2023-05-16","objectID":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/:4:0","series":["偏工作性质记录"],"tags":["节点健康检查","方案","npd"],"title":"计算节点健康检查方案","uri":"/202305161521-%E8%AE%A1%E7%AE%97%E8%8A%82%E7%82%B9%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5%E6%96%B9%E6%A1%88/#方案描述"},{"categories":["OpenShift"],"content":" 一、方案背景在 CeaKE 环境中许多应用会产生数据，通过应用备份，可以将期望备份的 k8s 资源、PV 进行备份、恢复等操作，防止数据的丢失 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:1:0","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#一方案背景"},{"categories":["OpenShift"],"content":" 二、如何实现","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:2:0","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#二如何实现"},{"categories":["OpenShift"],"content":" 2.1 相关技术 Velero 官方文档：https://velero.io/docs/v1.9/index.html Velero 作为提供备份和恢复 Kubernetes 集群资源和持久卷能力的工具，提供以下功能： 备份集群，并在丢失时恢复 将集群迁移到其他集群 … 持久卷备份的两种方式： 快照（条件：存储后端需要具备快照API） Restic（不支持 hostPath） oadp-operator 开源代码：https://github.com/openshift/oadp-operator 参考文档：https://access.redhat.com/documentation/zh-cn/openshift_container_platform/4.9/html/backup_and_restore/index 该 operator 实现在集群中安装 Velero，并提供 API 给用户去备份与恢复应用 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:2:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#21-相关技术"},{"categories":["OpenShift"],"content":" 2.2 整体概览 大致流程说明： 安装 oadp-operator 用户通过 OperatorHub 安装 oadp-operator 安装 Velero oadp-operator 安装成功后，创建 DPA（DataProtectionApplication）实例，触发 oadp-operator 安装 Velero 假设我拥有一个集群外的 Minio，我想将数据备份到该后端，首先创建一个带有 Minio 账号密码的 Secret DPA 样例： apiVersion: oadp.ccos.io/v1alpha1 kind: DataProtectionApplication metadata: name: velero-sample namespace: ccos-adp spec: backupLocations: - velero: config: insecureSkipTLSVerify: 'true' profile: default region: minio s3ForcePathStyle: 'true' s3Url: 'http://10.253.11.215:9000' credential: key: cloud name: cloud-credentials default: true objectStorage: bucket: velero prefix: single provider: aws configuration: restic: enable: true velero: defaultPlugins: - aws - csi - ccos DPA 创建成功后，触发 oadp-operator 创建 deployment/velero 以及 daemonset/restic（dpa 配置 restic.enable 为 true 才创建） 备份 Velero 安装成功后，用户创建 Backup 实例，指定 BSL（BackupStorageLocation）以及其他相关参数，触发 Velero 备份逻辑 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:2:2","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#22-整体概览"},{"categories":["OpenShift"],"content":" 三、实现功能（不同备份场景实践）","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:0","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#三实现功能不同备份场景实践"},{"categories":["OpenShift"],"content":" 3.1 应用备份 准备工作模拟一个 mysql 应用 apiVersion: v1 kind: Namespace metadata: name: mysql --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-storage-pvc namespace: mysql spec: accessModes: - ReadWriteOnce storageClassName: ccos-hostpath-data-stor resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: mysql-local-storage namespace: mysql labels: app: mysql-local-storage spec: selector: matchLabels: app: mysql-local-storage template: metadata: labels: app: mysql-local-storage spec: containers: - image: image.cestc.cn/ceake/mysql:5.6 name: mysql command: [\"sleep\", \"1d\"] env: - name: MYSQL_ROOT_PASSWORD value: admin123 volumeMounts: - name: mysql-persistent-storage mountPath: /data volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: local-storage-pvc 3.1.1 （集群内）备份与恢复 往挂载的目录里面写入数据 创建 Backup，对 mysql 的命名空间进行备份 删除 mysql 命名空间下的相关资源 查看 Minio 后端对应的备份数据 k8s 资源数据： pv 数据： 创建 Restore 进行恢复操作 指定要恢复的备份名称 恢复结果： 3.1.2 定时备份任务 创建 Schedule，指定每天 10:40 触发一个对于 mysql 命名空间的备份 10:40 触发备份： 3.1.3 （跨集群）备份与恢复 新集群创建与源集群相同的 DPA，Velero 会对同步 Backup 资源 资源同步完成后，创建 Restore 进行恢复 问题 1：（已解决） 查看 kube-ovn-controller 相关日志发现 ip 已被占用 （192.168.0.65 为备份的时候 pod 的 ip） 删除对应 ip 的 pod 之后重新进行恢复操作，仍未成功… 查看新的报错： restic 找不到 id（如果这个集群之前创建过 DPA，需要检查一下 ResticRepository 配置是否跟源集群的一样，如果不一样，需要手动同步） 恢复成功 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#31-应用备份"},{"categories":["OpenShift"],"content":" 3.1 应用备份 准备工作模拟一个 mysql 应用 apiVersion: v1 kind: Namespace metadata: name: mysql --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-storage-pvc namespace: mysql spec: accessModes: - ReadWriteOnce storageClassName: ccos-hostpath-data-stor resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: mysql-local-storage namespace: mysql labels: app: mysql-local-storage spec: selector: matchLabels: app: mysql-local-storage template: metadata: labels: app: mysql-local-storage spec: containers: - image: image.cestc.cn/ceake/mysql:5.6 name: mysql command: [\"sleep\", \"1d\"] env: - name: MYSQL_ROOT_PASSWORD value: admin123 volumeMounts: - name: mysql-persistent-storage mountPath: /data volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: local-storage-pvc 3.1.1 （集群内）备份与恢复 往挂载的目录里面写入数据 创建 Backup，对 mysql 的命名空间进行备份 删除 mysql 命名空间下的相关资源 查看 Minio 后端对应的备份数据 k8s 资源数据： pv 数据： 创建 Restore 进行恢复操作 指定要恢复的备份名称 恢复结果： 3.1.2 定时备份任务 创建 Schedule，指定每天 10:40 触发一个对于 mysql 命名空间的备份 10:40 触发备份： 3.1.3 （跨集群）备份与恢复 新集群创建与源集群相同的 DPA，Velero 会对同步 Backup 资源 资源同步完成后，创建 Restore 进行恢复 问题 1：（已解决） 查看 kube-ovn-controller 相关日志发现 ip 已被占用 （192.168.0.65 为备份的时候 pod 的 ip） 删除对应 ip 的 pod 之后重新进行恢复操作，仍未成功… 查看新的报错： restic 找不到 id（如果这个集群之前创建过 DPA，需要检查一下 ResticRepository 配置是否跟源集群的一样，如果不一样，需要手动同步） 恢复成功 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#准备工作"},{"categories":["OpenShift"],"content":" 3.1 应用备份 准备工作模拟一个 mysql 应用 apiVersion: v1 kind: Namespace metadata: name: mysql --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-storage-pvc namespace: mysql spec: accessModes: - ReadWriteOnce storageClassName: ccos-hostpath-data-stor resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: mysql-local-storage namespace: mysql labels: app: mysql-local-storage spec: selector: matchLabels: app: mysql-local-storage template: metadata: labels: app: mysql-local-storage spec: containers: - image: image.cestc.cn/ceake/mysql:5.6 name: mysql command: [\"sleep\", \"1d\"] env: - name: MYSQL_ROOT_PASSWORD value: admin123 volumeMounts: - name: mysql-persistent-storage mountPath: /data volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: local-storage-pvc 3.1.1 （集群内）备份与恢复 往挂载的目录里面写入数据 创建 Backup，对 mysql 的命名空间进行备份 删除 mysql 命名空间下的相关资源 查看 Minio 后端对应的备份数据 k8s 资源数据： pv 数据： 创建 Restore 进行恢复操作 指定要恢复的备份名称 恢复结果： 3.1.2 定时备份任务 创建 Schedule，指定每天 10:40 触发一个对于 mysql 命名空间的备份 10:40 触发备份： 3.1.3 （跨集群）备份与恢复 新集群创建与源集群相同的 DPA，Velero 会对同步 Backup 资源 资源同步完成后，创建 Restore 进行恢复 问题 1：（已解决） 查看 kube-ovn-controller 相关日志发现 ip 已被占用 （192.168.0.65 为备份的时候 pod 的 ip） 删除对应 ip 的 pod 之后重新进行恢复操作，仍未成功… 查看新的报错： restic 找不到 id（如果这个集群之前创建过 DPA，需要检查一下 ResticRepository 配置是否跟源集群的一样，如果不一样，需要手动同步） 恢复成功 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#311-集群内备份与恢复"},{"categories":["OpenShift"],"content":" 3.1 应用备份 准备工作模拟一个 mysql 应用 apiVersion: v1 kind: Namespace metadata: name: mysql --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-storage-pvc namespace: mysql spec: accessModes: - ReadWriteOnce storageClassName: ccos-hostpath-data-stor resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: mysql-local-storage namespace: mysql labels: app: mysql-local-storage spec: selector: matchLabels: app: mysql-local-storage template: metadata: labels: app: mysql-local-storage spec: containers: - image: image.cestc.cn/ceake/mysql:5.6 name: mysql command: [\"sleep\", \"1d\"] env: - name: MYSQL_ROOT_PASSWORD value: admin123 volumeMounts: - name: mysql-persistent-storage mountPath: /data volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: local-storage-pvc 3.1.1 （集群内）备份与恢复 往挂载的目录里面写入数据 创建 Backup，对 mysql 的命名空间进行备份 删除 mysql 命名空间下的相关资源 查看 Minio 后端对应的备份数据 k8s 资源数据： pv 数据： 创建 Restore 进行恢复操作 指定要恢复的备份名称 恢复结果： 3.1.2 定时备份任务 创建 Schedule，指定每天 10:40 触发一个对于 mysql 命名空间的备份 10:40 触发备份： 3.1.3 （跨集群）备份与恢复 新集群创建与源集群相同的 DPA，Velero 会对同步 Backup 资源 资源同步完成后，创建 Restore 进行恢复 问题 1：（已解决） 查看 kube-ovn-controller 相关日志发现 ip 已被占用 （192.168.0.65 为备份的时候 pod 的 ip） 删除对应 ip 的 pod 之后重新进行恢复操作，仍未成功… 查看新的报错： restic 找不到 id（如果这个集群之前创建过 DPA，需要检查一下 ResticRepository 配置是否跟源集群的一样，如果不一样，需要手动同步） 恢复成功 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#312-定时备份任务"},{"categories":["OpenShift"],"content":" 3.1 应用备份 准备工作模拟一个 mysql 应用 apiVersion: v1 kind: Namespace metadata: name: mysql --- apiVersion: v1 kind: PersistentVolumeClaim metadata: name: local-storage-pvc namespace: mysql spec: accessModes: - ReadWriteOnce storageClassName: ccos-hostpath-data-stor resources: requests: storage: 1Gi --- apiVersion: apps/v1 kind: Deployment metadata: name: mysql-local-storage namespace: mysql labels: app: mysql-local-storage spec: selector: matchLabels: app: mysql-local-storage template: metadata: labels: app: mysql-local-storage spec: containers: - image: image.cestc.cn/ceake/mysql:5.6 name: mysql command: [\"sleep\", \"1d\"] env: - name: MYSQL_ROOT_PASSWORD value: admin123 volumeMounts: - name: mysql-persistent-storage mountPath: /data volumes: - name: mysql-persistent-storage persistentVolumeClaim: claimName: local-storage-pvc 3.1.1 （集群内）备份与恢复 往挂载的目录里面写入数据 创建 Backup，对 mysql 的命名空间进行备份 删除 mysql 命名空间下的相关资源 查看 Minio 后端对应的备份数据 k8s 资源数据： pv 数据： 创建 Restore 进行恢复操作 指定要恢复的备份名称 恢复结果： 3.1.2 定时备份任务 创建 Schedule，指定每天 10:40 触发一个对于 mysql 命名空间的备份 10:40 触发备份： 3.1.3 （跨集群）备份与恢复 新集群创建与源集群相同的 DPA，Velero 会对同步 Backup 资源 资源同步完成后，创建 Restore 进行恢复 问题 1：（已解决） 查看 kube-ovn-controller 相关日志发现 ip 已被占用 （192.168.0.65 为备份的时候 pod 的 ip） 删除对应 ip 的 pod 之后重新进行恢复操作，仍未成功… 查看新的报错： restic 找不到 id（如果这个集群之前创建过 DPA，需要检查一下 ResticRepository 配置是否跟源集群的一样，如果不一样，需要手动同步） 恢复成功 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#313-跨集群备份与恢复"},{"categories":["OpenShift"],"content":" 3.2 集群备份（无法使用 velero 实现） 备份的对象？ etcd（备份之后的文件：etcd快照、静态pod资源压缩包） 有什么样集群坏掉的场景？ etcd异常、kube-apiserver异常等等 物理备份 \u0026 逻辑备份 物理备份：etcd 备份 逻辑备份：基于 velero 的备份 3.2.1 velero 为什么无法做集群备份？ 在集群不可用的情况下，velero 应用也无法在集群中使用，无法做恢复操作 etcd 的数据使用 hostPath 方式挂载到 etcd pod，velero 不支持 hostPath 备份，无法备份数据，只能备份 yaml 资源 3.2.2 *官方使用的备份方式实践（ing…） 执行集群备份脚本 sh /usr/local/bin/cluster-backup.sh \u003c备份目录\u003e [root@guxsve0ry7y4fhl ~]# sh /usr/local/bin/cluster-backup.sh /root/bak found latest kube-apiserver: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-15 found latest kube-controller-manager: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-7 found latest kube-scheduler: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-6 found latest etcd: /etc/kubernetes/static-pod-resources/etcd-pod-2 e714891717a1c13ce92256f0699c1918d84f696fe0491afc389f01ee3fa9f18c etcdctl version: 3.5.0 API version: 3.5 {\"level\":\"info\",\"ts\":1661246888.927277,\"caller\":\"snapshot/v3_snapshot.go:68\",\"msg\":\"created temporary db file\",\"path\":\"/root/bak/snapshot_2022-08-23_172803.db.part\"} {\"level\":\"info\",\"ts\":1661246888.9341154,\"logger\":\"client\",\"caller\":\"v3/maintenance.go:211\",\"msg\":\"opened snapshot stream; downloading\"} {\"level\":\"info\",\"ts\":1661246888.9348633,\"caller\":\"snapshot/v3_snapshot.go:76\",\"msg\":\"fetching snapshot\",\"endpoint\":\"https://10.253.10.107:2379\"} {\"level\":\"info\",\"ts\":1661246891.0776105,\"logger\":\"client\",\"caller\":\"v3/maintenance.go:219\",\"msg\":\"completed snapshot read; closing\"} {\"level\":\"info\",\"ts\":1661246894.7033532,\"caller\":\"snapshot/v3_snapshot.go:91\",\"msg\":\"fetched snapshot\",\"endpoint\":\"https://10.253.10.107:2379\",\"size\":\"332 MB\",\"took\":\"5 seconds ago\"} {\"level\":\"info\",\"ts\":1661246894.7034357,\"caller\":\"snapshot/v3_snapshot.go:100\",\"msg\":\"saved\",\"path\":\"/root/bak/snapshot_2022-08-23_172803.db\"} Snapshot saved at /root/bak/snapshot_2022-08-23_172803.db Deprecated: Use `etcdutl snapshot status` instead. {\"hash\":1726260631,\"revision\":43288532,\"totalKey\":27994,\"totalSize\":332025856} snapshot db and kube resources are successfully saved to /root/bak 生成备份文件： [root@guxsve0ry7y4fhl ~]# ll /root/bak/ total 324312 -rw-------. 1 root root 332025888 Aug 23 17:28 snapshot_2022-08-23_172803.db # etcd 快照 -rw-------. 1 root root 63022 Aug 23 17:28 static_kuberesources_2022-08-23_172803.tar.gz # 静态 pod 的资源 模拟集群出问题的情况 执行恢复脚本恢复集群 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:2","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#32-集群备份无法使用-velero-实现"},{"categories":["OpenShift"],"content":" 3.2 集群备份（无法使用 velero 实现） 备份的对象？ etcd（备份之后的文件：etcd快照、静态pod资源压缩包） 有什么样集群坏掉的场景？ etcd异常、kube-apiserver异常等等 物理备份 \u0026 逻辑备份 物理备份：etcd 备份 逻辑备份：基于 velero 的备份 3.2.1 velero 为什么无法做集群备份？ 在集群不可用的情况下，velero 应用也无法在集群中使用，无法做恢复操作 etcd 的数据使用 hostPath 方式挂载到 etcd pod，velero 不支持 hostPath 备份，无法备份数据，只能备份 yaml 资源 3.2.2 *官方使用的备份方式实践（ing…） 执行集群备份脚本 sh /usr/local/bin/cluster-backup.sh \u003c备份目录\u003e [root@guxsve0ry7y4fhl ~]# sh /usr/local/bin/cluster-backup.sh /root/bak found latest kube-apiserver: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-15 found latest kube-controller-manager: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-7 found latest kube-scheduler: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-6 found latest etcd: /etc/kubernetes/static-pod-resources/etcd-pod-2 e714891717a1c13ce92256f0699c1918d84f696fe0491afc389f01ee3fa9f18c etcdctl version: 3.5.0 API version: 3.5 {\"level\":\"info\",\"ts\":1661246888.927277,\"caller\":\"snapshot/v3_snapshot.go:68\",\"msg\":\"created temporary db file\",\"path\":\"/root/bak/snapshot_2022-08-23_172803.db.part\"} {\"level\":\"info\",\"ts\":1661246888.9341154,\"logger\":\"client\",\"caller\":\"v3/maintenance.go:211\",\"msg\":\"opened snapshot stream; downloading\"} {\"level\":\"info\",\"ts\":1661246888.9348633,\"caller\":\"snapshot/v3_snapshot.go:76\",\"msg\":\"fetching snapshot\",\"endpoint\":\"https://10.253.10.107:2379\"} {\"level\":\"info\",\"ts\":1661246891.0776105,\"logger\":\"client\",\"caller\":\"v3/maintenance.go:219\",\"msg\":\"completed snapshot read; closing\"} {\"level\":\"info\",\"ts\":1661246894.7033532,\"caller\":\"snapshot/v3_snapshot.go:91\",\"msg\":\"fetched snapshot\",\"endpoint\":\"https://10.253.10.107:2379\",\"size\":\"332 MB\",\"took\":\"5 seconds ago\"} {\"level\":\"info\",\"ts\":1661246894.7034357,\"caller\":\"snapshot/v3_snapshot.go:100\",\"msg\":\"saved\",\"path\":\"/root/bak/snapshot_2022-08-23_172803.db\"} Snapshot saved at /root/bak/snapshot_2022-08-23_172803.db Deprecated: Use `etcdutl snapshot status` instead. {\"hash\":1726260631,\"revision\":43288532,\"totalKey\":27994,\"totalSize\":332025856} snapshot db and kube resources are successfully saved to /root/bak 生成备份文件： [root@guxsve0ry7y4fhl ~]# ll /root/bak/ total 324312 -rw-------. 1 root root 332025888 Aug 23 17:28 snapshot_2022-08-23_172803.db # etcd 快照 -rw-------. 1 root root 63022 Aug 23 17:28 static_kuberesources_2022-08-23_172803.tar.gz # 静态 pod 的资源 模拟集群出问题的情况 执行恢复脚本恢复集群 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:2","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#321-font-colorredvelero-为什么无法做集群备份font"},{"categories":["OpenShift"],"content":" 3.2 集群备份（无法使用 velero 实现） 备份的对象？ etcd（备份之后的文件：etcd快照、静态pod资源压缩包） 有什么样集群坏掉的场景？ etcd异常、kube-apiserver异常等等 物理备份 \u0026 逻辑备份 物理备份：etcd 备份 逻辑备份：基于 velero 的备份 3.2.1 velero 为什么无法做集群备份？ 在集群不可用的情况下，velero 应用也无法在集群中使用，无法做恢复操作 etcd 的数据使用 hostPath 方式挂载到 etcd pod，velero 不支持 hostPath 备份，无法备份数据，只能备份 yaml 资源 3.2.2 *官方使用的备份方式实践（ing…） 执行集群备份脚本 sh /usr/local/bin/cluster-backup.sh \u003c备份目录\u003e [root@guxsve0ry7y4fhl ~]# sh /usr/local/bin/cluster-backup.sh /root/bak found latest kube-apiserver: /etc/kubernetes/static-pod-resources/kube-apiserver-pod-15 found latest kube-controller-manager: /etc/kubernetes/static-pod-resources/kube-controller-manager-pod-7 found latest kube-scheduler: /etc/kubernetes/static-pod-resources/kube-scheduler-pod-6 found latest etcd: /etc/kubernetes/static-pod-resources/etcd-pod-2 e714891717a1c13ce92256f0699c1918d84f696fe0491afc389f01ee3fa9f18c etcdctl version: 3.5.0 API version: 3.5 {\"level\":\"info\",\"ts\":1661246888.927277,\"caller\":\"snapshot/v3_snapshot.go:68\",\"msg\":\"created temporary db file\",\"path\":\"/root/bak/snapshot_2022-08-23_172803.db.part\"} {\"level\":\"info\",\"ts\":1661246888.9341154,\"logger\":\"client\",\"caller\":\"v3/maintenance.go:211\",\"msg\":\"opened snapshot stream; downloading\"} {\"level\":\"info\",\"ts\":1661246888.9348633,\"caller\":\"snapshot/v3_snapshot.go:76\",\"msg\":\"fetching snapshot\",\"endpoint\":\"https://10.253.10.107:2379\"} {\"level\":\"info\",\"ts\":1661246891.0776105,\"logger\":\"client\",\"caller\":\"v3/maintenance.go:219\",\"msg\":\"completed snapshot read; closing\"} {\"level\":\"info\",\"ts\":1661246894.7033532,\"caller\":\"snapshot/v3_snapshot.go:91\",\"msg\":\"fetched snapshot\",\"endpoint\":\"https://10.253.10.107:2379\",\"size\":\"332 MB\",\"took\":\"5 seconds ago\"} {\"level\":\"info\",\"ts\":1661246894.7034357,\"caller\":\"snapshot/v3_snapshot.go:100\",\"msg\":\"saved\",\"path\":\"/root/bak/snapshot_2022-08-23_172803.db\"} Snapshot saved at /root/bak/snapshot_2022-08-23_172803.db Deprecated: Use `etcdutl snapshot status` instead. {\"hash\":1726260631,\"revision\":43288532,\"totalKey\":27994,\"totalSize\":332025856} snapshot db and kube resources are successfully saved to /root/bak 生成备份文件： [root@guxsve0ry7y4fhl ~]# ll /root/bak/ total 324312 -rw-------. 1 root root 332025888 Aug 23 17:28 snapshot_2022-08-23_172803.db # etcd 快照 -rw-------. 1 root root 63022 Aug 23 17:28 static_kuberesources_2022-08-23_172803.tar.gz # 静态 pod 的资源 模拟集群出问题的情况 执行恢复脚本恢复集群 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:2","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#322-官方使用的备份方式实践ing"},{"categories":["OpenShift"],"content":" 3.3 其他备份场景验证 3.3.1 ccos 相关资源备份（velero-plugins） SecurityContextConstraints 备份及恢复 Route 备份及恢复 … 3.3.* 待补充","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:3","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#33-其他备份场景验证"},{"categories":["OpenShift"],"content":" 3.3 其他备份场景验证 3.3.1 ccos 相关资源备份（velero-plugins） SecurityContextConstraints 备份及恢复 Route 备份及恢复 … 3.3.* 待补充","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:3","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#331-ccos-相关资源备份velero-plugins"},{"categories":["OpenShift"],"content":" 3.3 其他备份场景验证 3.3.1 ccos 相关资源备份（velero-plugins） SecurityContextConstraints 备份及恢复 Route 备份及恢复 … 3.3.* 待补充","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:3:3","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#33-待补充"},{"categories":["OpenShift"],"content":" 四、前端相关截图","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:0","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#四前端相关截图"},{"categories":["OpenShift"],"content":" 4.1 operator 安装进入 Operator 仓库选择 OADP-Operator 进行安装 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:1","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#41-operator-安装"},{"categories":["OpenShift"],"content":" 4.2 安装 Velero 选择创建 DPA 实例 配置 DPA ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:2","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#42-安装-velero"},{"categories":["OpenShift"],"content":" 4.3 单次备份 选择创建 Backup 实例 配置 Backup 实例参数 主要配置备份名称、存储位置、命名空间等信息 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:3","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#43-单次备份"},{"categories":["OpenShift"],"content":" 4.5 定时备份 选择创建 Schedule 实例 配置 Schedule 实例参数 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:4","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#45-定时备份"},{"categories":["OpenShift"],"content":" 4.4 恢复 选择创建 Restore 实例 配置 Restore 实例参数 ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:5","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#44-恢复"},{"categories":["OpenShift"],"content":" 4.* …","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:4:6","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#4-"},{"categories":["OpenShift"],"content":" 五、关联仓库 oadp-operator velero velero-plugin-for-aws velero-plugin-for-csi velero-plugin-for-gcp velero-plugin-for-microsoft-azure ccos-velero-plugin kubevirt-velero-plugin volume-snapshot-mover index 仓库 作用 开源地址 code.cestc.cn 01 （必须）oadp-operator 安装 Velero，提供 API https://github.com/openshift/oadp-operator https://code.cestc.cn/ccos/cea/oadp-operator 02 （必须）velero 做具体备份恢复等操作 https://github.com/vmware-tanzu/velero https://code.cestc.cn/ccos/cea/velero 03 （必须）velero-plugin-for-s3 支持对象存储备份和恢复（aws s3） https://github.com/vmware-tanzu/velero-plugin-for-aws https://code.cestc.cn/ccos/cea/velero-plugin-for-s3 04 （）velero-plugin-for-csi 支持使用 csi 快照备份持久卷 https://github.com/vmware-tanzu/velero-plugin-for-csi https://code.cestc.cn/ccos/cea/velero-plugin-for-csi velero-plugin-for-gcp https://github.com/vmware-tanzu/velero-plugin-for-gcp velero-plugin-for-microsoft-azure https://github.com/vmware-tanzu/velero-plugin-for-microsoft-azure 05 （）ccos-velero-plugin 使用对象存储备份和恢复 Ccos Container Platform 资源 https://github.com/openshift/openshift-velero-plugin https://code.cestc.cn/ccos/cea/velero-plugin 06 （）kubevirt-velero-plugin 支持备份并恢复由Kubevirt和CDI管理的虚拟机，数据流和其他资源 https://github.com/kubevirt/kubevirt-velero-plugin https://code.cestc.cn/ccos/cea/kubevirt-velero-plugin 07 （）volume-snapshot-mover 将群集的快照重新定位到对象存储中 https://github.com/konveyor/volume-snapshot-mover https://code.cestc.cn/ccos/cea/volume-snapshot-mover 新增镜像： oadp-operator oadp-operator-bundle velero velero-restic-restore-helper velero-plugin-for-s3 velero-plugin-for-csi velero-plugin kubevirt-velero-plugin volume-snapshot-mover ","date":"2023-05-16","objectID":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/:5:0","series":["偏工作性质记录"],"tags":["方案","应用备份","velero"],"title":"应用备份恢复方案","uri":"/202305161528-%E5%BA%94%E7%94%A8%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E6%96%B9%E6%A1%88/#五关联仓库"},{"categories":["task-bugfix"],"content":" *、总结 节点安装 iscsi、multipath option#1. 装机的时候完成 option#2. 容器化（CSI Driver使用的镜像内没有安装 iscsi、multipath，无法容器化） 对接 xsky 存储 由 xsky-operator 拉起所需的通用资源：CRD、CSI Driver 相关资源 添加 xsky 存储后端 通过修改 xsky-cr，编辑 xsky 存储后端的相关信息，operator 创建所需的资源： secret accesspath storageclass 修改 xsky 存储后端 通过修改 xsky-cr，operator 根据 storageclass 查找到对应的 secret、accesspath、storageclass 资源，进行修改 xsky-cre.g. ... spec: xskyBackends: - scName: xsky-sc1 token: NGIyMzhmNDU5NzFhNGJhZmFmNjlmYzI3NjkxNGU0ODI= accessPaths: - name: csi-ap1 type: iSCSI clusterInfo: secret_name: xsky-sc1-secret gateway: sds01,sds02,sds03 fsType: xfs pool: pool1 xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 secretName: xsky-secret1 - ... ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:1:0","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#总结"},{"categories":["task-bugfix"],"content":" 一、准备工作","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:2:0","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#一准备工作"},{"categories":["task-bugfix"],"content":" 1.1 环境依赖：iscsid、multipathd yum install -y iscsi-initiator-utils sg3_utils device-mapper-multipath device-mapper cat \u003c\u003c EOF \u003e /etc/multipath.conf defaults { user_friendly_names yes failback immediate no_path_retry fail } blacklist { devnode \"^sda$\" } devices{ } EOF cat \u003c\u003c EOF \u003e /etc/iscsi/iscsid.conf iscsid.startup = /bin/systemctl start iscsid.socket iscsiuio.socket node.startup = automatic node.leading_login = No node.session.timeo.replacement_timeout = 20 node.conn[0].timeo.login_timeout = 15 node.conn[0].timeo.logout_timeout = 15 node.conn[0].timeo.noop_out_interval = 1 node.conn[0].timeo.noop_out_timeout = 1 node.session.err_timeo.abort_timeout = 15 node.session.err_timeo.lu_reset_timeout = 30 node.session.err_timeo.tgt_reset_timeout = 30 node.session.initial_login_retry_max = 8 node.session.cmds_max = 512 node.session.queue_depth = 512 node.session.xmit_thread_priority = -20 node.session.iscsi.InitialR2T = No node.session.iscsi.ImmediateData = Yes node.session.iscsi.FirstBurstLength = 262144 node.session.iscsi.MaxBurstLength = 16776192 node.conn[0].iscsi.MaxRecvDataSegmentLength = 262144 node.conn[0].iscsi.MaxXmitDataSegmentLength = 0 discovery.sendtargets.iscsi.MaxRecvDataSegmentLength = 32768 node.conn[0].iscsi.HeaderDigest = None node.session.nr_sessions = 1 node.session.reopen_max = 0 node.session.iscsi.FastAbort = Yes node.session.scan = auto EOF systemctl enable iscsid;systemctl start iscsid systemctl enable multipathd;systemctl start multipathd ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:2:1","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#11-环境依赖iscsidmultipathd"},{"categories":["task-bugfix"],"content":" 1.2 需要同步镜像 ## 压缩包 quay.io/k8scsi/csi-attacher:v2.0.0 quay.io/k8scsi/csi-provisioner:v1.5.0 quay.io/k8scsi/csi-node-driver-registrar:v1.1.0 quay.io/k8scsi/csi-resizer:v0.5.0 quay.io/k8scsi/csi-snapshotter:v3.0.3 quay.io/k8scsi/snapshot-controller:v3.0.3 localhost/xskydriver/csi-iscsi:3.0.301.0 # m ## 仓库 image.cestc.cn/iaas_pub/k8scsi/csi-provisioner:v1.5.0 image.cestc.cn/iaas_pub/k8scsi/csi-resizer:v0.5.0 image.cestc.cn/iaas_pub/k8scsi/xskydriver/csi-iscsi:3.0.301.0 image.cestc.cn/iaas_pub/k8scsi/csi-node-driver-registrar:v1.1.0 image.cestc.cn/iaas_pub/k8scsi/csi-snapshotter:v3.0.3 image.cestc.cn/iaas_pub/k8scsi/snapshot-controller:v3.0.3 cd offline_image/ for file in ./*; do podman load -i $file; done ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:2:2","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#12-需要同步镜像"},{"categories":["task-bugfix"],"content":" 二、CSI Driver 安装 oc apply -f accesspath-crd/crd-ap.yaml oc apply -f . ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:3:0","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#二csi-driver-安装"},{"categories":["task-bugfix"],"content":" 三、使用","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:4:0","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#三使用"},{"categories":["task-bugfix"],"content":" 3.1 在 xsky 后端创建 token，转成 base64 echo -n \"1880ecc063a54ec5a96c96a630682ad8\" | base64 # MTg4MGVjYzA2M2E1NGVjNWE5NmM5NmE2MzA2ODJhZDg= ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:4:1","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#31-在-xsky-后端创建-token转成-base64"},{"categories":["task-bugfix"],"content":" 3.2 用这个 token 创建 secret apiVersion: v1 kind: Secret metadata: name: test-secret data: token: MTg4MGVjYzA2M2E1NGVjNWE5NmM5NmE2MzA2ODJhZDg= ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:4:2","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#32-用这个-token-创建-secret"},{"categories":["task-bugfix"],"content":" 3.3 创建ap apiVersion: \"sds.xsky.com/v1\" kind: AccessPath metadata: name: cke-csi-ap1 #object name in kubernetes spec: name: cke-csi-ap1 #name in SDS type: Kubernetes #one of Kubernetes,iSCSI cluster_info: secret_name: test-secret secret_namespace: default xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 gateway: sds01,sds02,sds03 #separated by comma, vip_group: preempt: true #optional vips: [] #- vip: 10.255.68.120 # mask: 24 #optional, default 32 # default_gateway: vm39 #optional,preferred network ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:4:3","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#33-创建ap"},{"categories":["task-bugfix"],"content":" 3.4 创建sc apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: iscsi-sc parameters: accessPaths: cke-csi-ap1 fsType: xfs pool: ebs xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 csi.storage.k8s.io/provisioner-secret-name: test-secret csi.storage.k8s.io/provisioner-secret-namespace: default provisioner: iscsi.csi.xsky.com reclaimPolicy: Delete allowVolumeExpansion: true mountOptions: - _netdev ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:4:4","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#34-创建sc"},{"categories":["task-bugfix"],"content":" 3.5 创建 pvc、pod 测试pvc apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc-block namespace: default spec: #volumeMode: Filesystem volumeMode: Block storageClassName: iscsi-sc accessModes: - ReadWriteOnce resources: requests: storage: 10Gi pod apiVersion: v1 kind: Pod metadata: name: hhq-pv-pod-block spec: volumes: - name: iscsi-pvc-block-5-1 persistentVolumeClaim: claimName: xsky-iscsi-pvc-block containers: - name: hhq-pv-con image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeDevices: - devicePath: /dev/block name: iscsi-pvc-block-5-1 ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:4:5","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#35-创建-pvcpod-测试"},{"categories":["task-bugfix"],"content":" 四、xsky operator mkdir xsky-operator; cd xsky-operator operator-sdk init --domain=ceake.io --repo=code.cestc.cn/ccos/cea/xsky-operator operator-sdk create api --resource=true --controller=true --group operator --version v1 --kind XskyBackend 编辑 api make manifests 编辑 Dockerfile 编辑 controller make docker-build docker-push IMG=image.cestc.cn/ceake/xsky-operator:0.0.1 make bundle IMG=image.cestc.cn/ceake/xsky-operator:0.0.1 ## 修改 csv make bundle-build bundle-push BUNDLE_IMG=\"image.cestc.cn/ceake/xsky-operator-bundle:0.0.1\" make bundle 做的事情 opm index add --bundles image.cestc.cn/ceake/xsky-operator-bundle:0.0.1 --tag image.cestc.cn/ceake/marketplace-index:0.0.1-hhq tag=0.0.2-628;opm index add --bundles image.cestc.cn/ceake/xsky-storage-operator-bundle:${tag} --tag image.cestc.cn/ceake/marketplace-index:${tag}; podman push image.cestc.cn/ceake/marketplace-index:${tag} ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:0","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#四xsky-operator"},{"categories":["task-bugfix"],"content":" 放开 OperatorHub catalogsource apiVersion: \"operators.coreos.com/v1alpha1\" kind: \"CatalogSource\" metadata: name: \"redhat-operators\" namespace: \"openshift-marketplace\" annotations: target.workload.openshift.io/management: '{\"effect\": \"PreferredDuringScheduling\"}' spec: sourceType: grpc image: image.cestc.cn/ceake/marketplace-index:0.0.1-preZYH05 displayName: \"Red Hat Operators\" publisher: \"Red Hat\" priority: -100 updateStrategy: registryPoll: interval: 10m grpcPodConfig: nodeSelector: node-role.kubernetes.io/master: \"\" kubernetes.io/os: \"linux\" priorityClassName: \"system-cluster-critical\" tolerations: - key: \"node-role.kubernetes.io/master\" operator: Exists effect: \"NoSchedule\" - key: \"node.kubernetes.io/unreachable\" operator: \"Exists\" effect: \"NoExecute\" tolerationSeconds: 120 - key: \"node.kubernetes.io/not-ready\" operator: \"Exists\" effect: \"NoExecute\" tolerationSeconds: 120 安装的时候遇到的问题 问题1. 创建 pod 的时候出现问题 allowHostDirVolumePlugin: true allowHostIPC: true allowHostNetwork: true allowHostPID: true allowHostPorts: true allowPrivilegedContainer: true allowedCapabilities: - '*' apiVersion: security.openshift.io/v1 defaultAddCapabilities: [] fsGroup: type: RunAsAny groups: - system:authenticated kind: SecurityContextConstraints metadata: annotations: kubernetes.io/description: xsky scc name: xsky-scc priority: null readOnlyRootFilesystem: false runAsUser: type: RunAsAny seLinuxContext: type: RunAsAny supplementalGroups: type: RunAsAny volumes: - '*' oc adm policy add-scc-to-user xsky-scc system:serviceaccount:openshift-xsky: oc adm policy add-scc-to-user xsky-scc system:serviceaccount:openshift-operators:xsky-operator-controller-manager driver 有问题： TODO List: handleXskyBackendEvent() 监听 xskyBakcend 资源事件：创建、修改 学习 client 创建 CRD 整体 operator 化 e2e 梳理 make bundle 支持自定义命名空间安装 公共的部分放到安装的时候就做 ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:1","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#放开-operatorhub"},{"categories":["task-bugfix"],"content":" 为流水线做准备 ### 制作 xsky-operator 镜像 docker build -t image.cestc.cn/ceake/xsky-operator:3.0.0-hhq . vim bundle/manifests/xsky-operator.clusterserviceversion.yaml # modify image: docker build -f bundle.Dockerfile -t image.cestc.cn/ceake/xsky-operator-bundle:3.0.0-hhq . ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:2","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#为流水线做准备"},{"categories":["task-bugfix"],"content":" 更新版本需要更改 csv ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:3","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#更新版本需要更改"},{"categories":["task-bugfix"],"content":" 手动验证（MR 需要） 前置资源创建 apiVersion: \"sds.xsky.com/v1\" kind: AccessPath metadata: name: cke-csi-ap-e2e-handle #object name in kubernetes namespace: default spec: name: cke-csi-ap-e2e-handle #name in SDS type: Kubernetes #one of Kubernetes,iSCSI cluster_info: secret_name: secret-xsky-e2e secret_namespace: default xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 gateway: sds01,sds02,sds03 #separated by comma, vip_group: preempt: true #optional vips: [] --- apiVersion: v1 kind: Secret metadata: name: secret-xsky-e2e namespace: default data: token: MTg4MGVjYzA2M2E1NGVjNWE5NmM5NmE2MzA2ODJhZDg= --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: sc-xsky-e2e parameters: accessPaths: cke-csi-ap-e2e-handle fsType: xfs pool: ebs xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 csi.storage.k8s.io/provisioner-secret-name: secret-xsky-e2e csi.storage.k8s.io/provisioner-secret-namespace: default provisioner: iscsi.csi.xsky.com reclaimPolicy: Delete allowVolumeExpansion: true mountOptions: - _netdev case 1. 创建 PVC \u0026 挂载至 pod apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc-e2e namespace: default spec: volumeMode: Block storageClassName: sc-xsky-e2e accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: v1 kind: Pod metadata: name: xsky-e2e-test-pod namespace: default spec: volumes: - name: xsky-iscsi-pvc-e2e persistentVolumeClaim: claimName: xsky-iscsi-pvc-e2e containers: - name: xsky-e2e image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeDevices: - devicePath: /dev/block name: xsky-iscsi-pvc-e2e 读写 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc2-e2e namespace: default spec: storageClassName: sc-xsky-e2e accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: v1 kind: Pod metadata: name: xsky-test-write namespace: default spec: containers: - name: test image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeMounts: - name: test mountPath: /test securityContext: privileged: true restartPolicy: Never volumes: - name: test persistentVolumeClaim: claimName: xsky-iscsi-pvc2-e2e --- apiVersion: v1 kind: ConfigMap metadata: name: xsky-test-cm namespace: default data: test.sh: | #!/bin/sh id ls -al /test \u0026\u0026 \\ echo 'Hello from xsky-storage-operator' \u0026\u0026 \\ cp /config/text.txt /test/test.txt \u0026\u0026 \\ touch /test/foo \u0026\u0026 \\ ls -al /test text.txt: | hello, xsky ! ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:4","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#手动验证mr-需要"},{"categories":["task-bugfix"],"content":" 手动验证（MR 需要） 前置资源创建 apiVersion: \"sds.xsky.com/v1\" kind: AccessPath metadata: name: cke-csi-ap-e2e-handle #object name in kubernetes namespace: default spec: name: cke-csi-ap-e2e-handle #name in SDS type: Kubernetes #one of Kubernetes,iSCSI cluster_info: secret_name: secret-xsky-e2e secret_namespace: default xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 gateway: sds01,sds02,sds03 #separated by comma, vip_group: preempt: true #optional vips: [] --- apiVersion: v1 kind: Secret metadata: name: secret-xsky-e2e namespace: default data: token: MTg4MGVjYzA2M2E1NGVjNWE5NmM5NmE2MzA2ODJhZDg= --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: sc-xsky-e2e parameters: accessPaths: cke-csi-ap-e2e-handle fsType: xfs pool: ebs xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 csi.storage.k8s.io/provisioner-secret-name: secret-xsky-e2e csi.storage.k8s.io/provisioner-secret-namespace: default provisioner: iscsi.csi.xsky.com reclaimPolicy: Delete allowVolumeExpansion: true mountOptions: - _netdev case 1. 创建 PVC \u0026 挂载至 pod apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc-e2e namespace: default spec: volumeMode: Block storageClassName: sc-xsky-e2e accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: v1 kind: Pod metadata: name: xsky-e2e-test-pod namespace: default spec: volumes: - name: xsky-iscsi-pvc-e2e persistentVolumeClaim: claimName: xsky-iscsi-pvc-e2e containers: - name: xsky-e2e image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeDevices: - devicePath: /dev/block name: xsky-iscsi-pvc-e2e 读写 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc2-e2e namespace: default spec: storageClassName: sc-xsky-e2e accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: v1 kind: Pod metadata: name: xsky-test-write namespace: default spec: containers: - name: test image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeMounts: - name: test mountPath: /test securityContext: privileged: true restartPolicy: Never volumes: - name: test persistentVolumeClaim: claimName: xsky-iscsi-pvc2-e2e --- apiVersion: v1 kind: ConfigMap metadata: name: xsky-test-cm namespace: default data: test.sh: | #!/bin/sh id ls -al /test \u0026\u0026 \\ echo 'Hello from xsky-storage-operator' \u0026\u0026 \\ cp /config/text.txt /test/test.txt \u0026\u0026 \\ touch /test/foo \u0026\u0026 \\ ls -al /test text.txt: | hello, xsky ! ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:4","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#前置资源创建"},{"categories":["task-bugfix"],"content":" 手动验证（MR 需要） 前置资源创建 apiVersion: \"sds.xsky.com/v1\" kind: AccessPath metadata: name: cke-csi-ap-e2e-handle #object name in kubernetes namespace: default spec: name: cke-csi-ap-e2e-handle #name in SDS type: Kubernetes #one of Kubernetes,iSCSI cluster_info: secret_name: secret-xsky-e2e secret_namespace: default xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 gateway: sds01,sds02,sds03 #separated by comma, vip_group: preempt: true #optional vips: [] --- apiVersion: v1 kind: Secret metadata: name: secret-xsky-e2e namespace: default data: token: MTg4MGVjYzA2M2E1NGVjNWE5NmM5NmE2MzA2ODJhZDg= --- apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: sc-xsky-e2e parameters: accessPaths: cke-csi-ap-e2e-handle fsType: xfs pool: ebs xmsServers: 10.255.68.115,10.255.68.116,10.255.68.117 csi.storage.k8s.io/provisioner-secret-name: secret-xsky-e2e csi.storage.k8s.io/provisioner-secret-namespace: default provisioner: iscsi.csi.xsky.com reclaimPolicy: Delete allowVolumeExpansion: true mountOptions: - _netdev case 1. 创建 PVC \u0026 挂载至 pod apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc-e2e namespace: default spec: volumeMode: Block storageClassName: sc-xsky-e2e accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: v1 kind: Pod metadata: name: xsky-e2e-test-pod namespace: default spec: volumes: - name: xsky-iscsi-pvc-e2e persistentVolumeClaim: claimName: xsky-iscsi-pvc-e2e containers: - name: xsky-e2e image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeDevices: - devicePath: /dev/block name: xsky-iscsi-pvc-e2e 读写 apiVersion: v1 kind: PersistentVolumeClaim metadata: name: xsky-iscsi-pvc2-e2e namespace: default spec: storageClassName: sc-xsky-e2e accessModes: - ReadWriteOnce resources: requests: storage: 5Gi --- apiVersion: v1 kind: Pod metadata: name: xsky-test-write namespace: default spec: containers: - name: test image: image.cestc.cn/ceake/busybox:0.0.0-test-build command: [\"sleep\", \"1d\"] volumeMounts: - name: test mountPath: /test securityContext: privileged: true restartPolicy: Never volumes: - name: test persistentVolumeClaim: claimName: xsky-iscsi-pvc2-e2e --- apiVersion: v1 kind: ConfigMap metadata: name: xsky-test-cm namespace: default data: test.sh: | #!/bin/sh id ls -al /test \u0026\u0026 \\ echo 'Hello from xsky-storage-operator' \u0026\u0026 \\ cp /config/text.txt /test/test.txt \u0026\u0026 \\ touch /test/foo \u0026\u0026 \\ ls -al /test text.txt: | hello, xsky ! ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:4","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#case-1-创建-pvc--挂载至-pod"},{"categories":["task-bugfix"],"content":" bugfix-安装operator 的时候默认安装资源更新商店 tag=xxx; opm index add --bundles image.cestc.cn/ceake/xsky-storage-operator-bundle:${tag} --tag image.cestc.cn/ceake/hhq-index:${tag}; podman push image.cestc.cn/ceake/hhq-index:${tag}; oc -n ccos-marketplace patch catalogsource/hhq-operators -p '{\"spec\":{\"image\":image.cestc.cn/ceake/hhq-index:${tag}}}' ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:5:5","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#bugfix-安装operator-的时候默认安装资源"},{"categories":["task-bugfix"],"content":" 五、kubebuilder 注释 参考文档： https://cloudnative.to/kubebuilder/reference/markers/crd-validation.html ","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:6:0","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#五kubebuilder-注释"},{"categories":["task-bugfix"],"content":" 5.1 字段检查","date":"2023-05-16","objectID":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/:6:1","series":["偏工作性质记录"],"tags":["xsky","operator","工作记录"],"title":"支持 xsky 存储","uri":"/202305161538-%E6%94%AF%E6%8C%81-xsky-%E5%AD%98%E5%82%A8/#51-字段检查"},{"categories":["Docker"],"content":"#docker ","date":"2023-05-16","objectID":"/202305161449-busybox-%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/:0:0","series":["Docker镜像制作"],"tags":["docker"],"title":"busybox 镜像制作","uri":"/202305161449-busybox-%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/#"},{"categories":["Docker"],"content":" 命令 mkdir rootfs cd rootfs/ for module in `busybox --list-modules`; do mkdir -p `dirname \"$module\"` \u0026\u0026 ln -sf /bin/busybox \"$module\"; done cp busybox bin/ tar cpf rootfs.tar . cat \u003c\u003c EOF \u003e busybox.dockerfile FROM scratch ADD rootfs.tar / CMD [\"/bin/sh\"] EOF ","date":"2023-05-16","objectID":"/202305161449-busybox-%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/:1:0","series":["Docker镜像制作"],"tags":["docker"],"title":"busybox 镜像制作","uri":"/202305161449-busybox-%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/#命令"},{"categories":["Docker"],"content":" arm 架构 直接下载二进制文件 https://busybox.net/downloads/binaries/1.28.1-defconfig-multiarch/ 制作 tar 包 cp busybox /bin/busybox mkdir rootfs cd rootfs/ for module in `busybox --list-modules`; do mkdir -p `dirname \"$module\"` \u0026\u0026 ln -sf /bin/busybox \"$module\"; done cp /bin/busybox bin/busybox tar cpf rootfs.tar . 制作镜像 cat \u003c\u003c EOF \u003e busybox.dockerfile FROM scratch ADD rootfs.tar / CMD [\"/bin/sh\"] EOF 代码网址：https://busybox.net/downloads/ github： https://github.com/docker-library/busybox https://blog.csdn.net/liumiaocn/article/details/80458663 https://www.frytea.com/technology/docker/build-a-docker-image-from-scratch/ ","date":"2023-05-16","objectID":"/202305161449-busybox-%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/:2:0","series":["Docker镜像制作"],"tags":["docker"],"title":"busybox 镜像制作","uri":"/202305161449-busybox-%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/#arm-架构"},{"categories":["task-bugfix"],"content":"#linux #storage ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:0:0","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#"},{"categories":["task-bugfix"],"content":" 一、fcsan 如何进行挂载参考资料 https://its401.com/article/wanminxg/54342430 https://github.com/openstack/os-brick/blob/7a6a09fc84a779c3ee08d122664f941195eeab8f/os_brick/initiator/linuxfc.py#L88 https://vk.masantu.com/wiki/💻工作/存储/scstadm-cmd/ ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:1:0","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#一fcsan-如何进行挂载"},{"categories":["task-bugfix"],"content":" 存储端 激活 HBA 接口 # 查看当前 port 的状态 cat /sys/class/fc_host/host*/port_state 绑定 wwn 编号 划分 lun fdisk 设备 创建 group scstadmin -add_group **ESX** -driver qla2x00t -target **21:00:00:24:ff:5c:aa:15** 绑定 lun 进 group # 建立虚拟磁盘与物理盘的映射关系 scstadmin -open_dev **disk01** -handler vdisk_blockio -attributes filename=**/dev/sdb1** ## 执行上述命令之后，是否需要执行下述命令？ scstadmin -write_config /etc/scst.conf # 添加虚拟磁盘到 target scstadmin -add_lun **0** -driver qla2x00t -target **21:00:00:24:ff:5c:aa:15 -device disk01** scst 服务检查 scstadmin -list_session ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:1:1","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#存储端"},{"categories":["task-bugfix"],"content":" 客户端 echo 1 \u003e /sys/class/fc_host/host15/issue_lip 挂载盘过来之后，生成了目录： /sys/class/fc_transport/target15:0:0 # 挂载 lun 为 1 的盘 echo 0 0 1 \u003e /sys/class/scsi_host/host15/scan # 这个目录是在有挂盘的情况下才有的 [root@iaas-test-193-ctl-226-195 ~]# cat /sys/class/fc_transport/target15\\:0\\:0/port_name 0x56c92bfa00218005 [root@iaas-test-193-ctl-226-195 ~]# grep -Gil 0x56c92bfa00218005 /sys/class/fc_transport/target15\\:0\\:0/port_name\\ \u003e \\ \u003e /sys/class/fc_transport/target15:0:0/port_name # 上面这个结果有可能有多行？什么情况下是多行 [root@iaas-test-193-ctl-226-195 ~]# grep -Gil 0x56c92bfa00218005123 /sys/class/fc_transport/target15\\:0\\:0/port_name ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:1:2","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#客户端"},{"categories":["task-bugfix"],"content":" e.g. 浪潮 fcsan 服务端配置 ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:1:3","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#eg-浪潮-fcsan-服务端配置"},{"categories":["task-bugfix"],"content":" 二、开发方案","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:2:0","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#二开发方案"},{"categories":["task-bugfix"],"content":" 2.1 api 请求流程 sequenceDiagram ecsServer-\u003e\u003e+nodeAgent: 获取 hostiqn nodeAgent-\u003e\u003e-ecsServer: 返回 hostiqn ecsServer-\u003e\u003eebs: 初始化链接 ebs-\u003e\u003eecsServer: 初始化结果 ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:2:1","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#21-api-请求流程"},{"categories":["task-bugfix"],"content":" 2.2 虚机调度方案 虚机添加一个属性：fcsan_support 用来标识虚机是否支持 fcsan 挂卸载，该属性仅支持在关机的状态下修改 如果虚机 fcsan_support 操作 描述 true 冷热挂卸载 允许 false 冷挂卸载 允许 false 热卸载 允许 false 热挂载 提示“当前虚机不支持热挂载类型为fibre channel的云盘，请在关机状态下操作” 当虚机创建的时候就挂载了 fcsan 的盘，则设置 fcsan_support 为 true 插入 hba 卡，device plugin1 自动识别，更新节点的资源属性 简单例子 先尝试手动给 k8s 节点 打上资源信息（模拟 device plugin 给 k8s 上报 HBA 资源），然后发 api 创建虚机，看是否起到对应节点？并且资源数是否 -1 虚机pod： resources: limits: fcsan/hba: \"1\" requests: fcsan/hba: \"1\" node 节点信息： ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:2:2","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#22-虚机调度方案"},{"categories":["task-bugfix"],"content":" 2.3 挂卸载设计方案 1.0 单盘挂载 第一层虚机状态的拦截：如果虚机状态为开机，不允许挂载，状态为关机则放行 判断虚机 fcsan 属性，如果为 false，创建新的 sts，删除旧的 sts，虚机 fcsan 属性置为 true 如果为 true 无操作 单盘卸载 批量挂载 盘列表的情况：【fcsan盘、非fcsan盘】 非fcsan的盘放行，继续后续的挂载操作 fcsan的盘需要判断当前虚机状态，如果虚机状态为开机，拦截这些盘的挂载操作，返回提示：这些盘需要在关机状态下操作 如果虚机状态为关机，判断虚机的fcsan属性，如果为 false，创建新的 sts，删除旧的 sts，虚机 fcsan 属性置为 true，如果为 true，则无操作 批量卸载 # 单盘挂载 curl -H \"Content-Type: application/json\" -X POST -d '{\"volume_id\":\"vol-de2w9x9nzqwggf\",\"delete_on_termination\":false,\"device\":\"\"}' 10.151.0.147:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-de9soljuhecvky/attachVolume # 单盘卸载 curl -H \"Content-Type: application/json\" -X DELETE 10.151.0.147:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-de538f14upm1rw/detachVolume/vol-de2w9x9nzqwggf # 多盘挂载 curl -H \"Content-Type: application/json\" -X POST -d '{\"attach_volume\":[{\"volume_id\":\"vol-de2w9x9nzqwggf\",\"delete_on_termination\":false,\"device\":\"\"},{\"volume_id\":\"vol-de8dro3ezonnpg\",\"delete_on_termination\":false,\"device\":\"\"}]}' 10.151.131.90:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-des5bwski1o6pa/attachVolumes 2.0 单盘挂载 获取虚机 FcsanSupport 属性 判断 FcsanSupport == true（表明虚机当前是支持fcsan盘挂载的），则后续的操作都按正常挂载，无论虚机是开机还是关机状态都能够挂载 FcsanSupport == false （表明虚机当前不支持fcsan盘挂载），进一步获取 vtype protocol type 属性， 如果 type == “fc”，进一步判断虚机的状态， 如果 虚机状态 == 关机，支持挂载，并且改变 FcsanSupport 的值为 true，重新创建虚机的 sts 【FcsanSupport: false → true 的状态转换】 如果 虚机状态 == 开机，直接返回提示：“当前虚机的状态不支持热挂载 fcsan 的盘” 单盘卸载 FcsanSupport == true 正常卸载 FcsanSupport == false 问题：如果虚机挂载过 fcsan 的盘，后来全卸载了，虚机的 FcsanSupport 是否需要变回 false？ 如果不变回 false，好处是之后能够热挂载 fcsan 的盘，但是这样会导致挂载过 fcsan 类型盘的虚机 pod 都跑到了有 hba 的节点 如果需要变回 false，则需要在每次卸载的时候判断一下这块盘是不是虚机的最后一块fcsan的盘 【FcsanSupport：true→false 的状态转换】 批量挂载 FcsanSupport == true 正常卸载 FcsanSupport == false 判断虚机状态 虚机状态 == 开机，拦截操作，返回提示 虚机状态 == 关机，【FcsanSupport： false→true 的状态转换】 Kubernetes的Device Plugin是一种机制，用于管理和分配节点上的设备资源。它允许用户将自定义设备（如GPU、FPGA等）添加到Kubernetes集群中，并使这些设备可供容器使用。Device Plugin通过实现Kubernetes Device Plugin API来工作。该API定义了一组规范，用于插件与Kubernetes API Server进行通信，并向其报告可用设备资源。插件还可以响应Pod的请求，以便将设备资源分配给Pod。使用Device Plugin，用户可以轻松地将自定义设备添加到Kubernetes集群中，并确保这些设备在需要时可供容器使用。这有助于提高集群的利用率，并为用户提供更好的性能和灵活性。 ↩︎ ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:2:3","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#23-挂卸载设计方案"},{"categories":["task-bugfix"],"content":" 2.3 挂卸载设计方案 1.0 单盘挂载 第一层虚机状态的拦截：如果虚机状态为开机，不允许挂载，状态为关机则放行 判断虚机 fcsan 属性，如果为 false，创建新的 sts，删除旧的 sts，虚机 fcsan 属性置为 true 如果为 true 无操作 单盘卸载 批量挂载 盘列表的情况：【fcsan盘、非fcsan盘】 非fcsan的盘放行，继续后续的挂载操作 fcsan的盘需要判断当前虚机状态，如果虚机状态为开机，拦截这些盘的挂载操作，返回提示：这些盘需要在关机状态下操作 如果虚机状态为关机，判断虚机的fcsan属性，如果为 false，创建新的 sts，删除旧的 sts，虚机 fcsan 属性置为 true，如果为 true，则无操作 批量卸载 # 单盘挂载 curl -H \"Content-Type: application/json\" -X POST -d '{\"volume_id\":\"vol-de2w9x9nzqwggf\",\"delete_on_termination\":false,\"device\":\"\"}' 10.151.0.147:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-de9soljuhecvky/attachVolume # 单盘卸载 curl -H \"Content-Type: application/json\" -X DELETE 10.151.0.147:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-de538f14upm1rw/detachVolume/vol-de2w9x9nzqwggf # 多盘挂载 curl -H \"Content-Type: application/json\" -X POST -d '{\"attach_volume\":[{\"volume_id\":\"vol-de2w9x9nzqwggf\",\"delete_on_termination\":false,\"device\":\"\"},{\"volume_id\":\"vol-de8dro3ezonnpg\",\"delete_on_termination\":false,\"device\":\"\"}]}' 10.151.131.90:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-des5bwski1o6pa/attachVolumes 2.0 单盘挂载 获取虚机 FcsanSupport 属性 判断 FcsanSupport == true（表明虚机当前是支持fcsan盘挂载的），则后续的操作都按正常挂载，无论虚机是开机还是关机状态都能够挂载 FcsanSupport == false （表明虚机当前不支持fcsan盘挂载），进一步获取 vtype protocol type 属性， 如果 type == “fc”，进一步判断虚机的状态， 如果 虚机状态 == 关机，支持挂载，并且改变 FcsanSupport 的值为 true，重新创建虚机的 sts 【FcsanSupport: false → true 的状态转换】 如果 虚机状态 == 开机，直接返回提示：“当前虚机的状态不支持热挂载 fcsan 的盘” 单盘卸载 FcsanSupport == true 正常卸载 FcsanSupport == false 问题：如果虚机挂载过 fcsan 的盘，后来全卸载了，虚机的 FcsanSupport 是否需要变回 false？ 如果不变回 false，好处是之后能够热挂载 fcsan 的盘，但是这样会导致挂载过 fcsan 类型盘的虚机 pod 都跑到了有 hba 的节点 如果需要变回 false，则需要在每次卸载的时候判断一下这块盘是不是虚机的最后一块fcsan的盘 【FcsanSupport：true→false 的状态转换】 批量挂载 FcsanSupport == true 正常卸载 FcsanSupport == false 判断虚机状态 虚机状态 == 开机，拦截操作，返回提示 虚机状态 == 关机，【FcsanSupport： false→true 的状态转换】 Kubernetes的Device Plugin是一种机制，用于管理和分配节点上的设备资源。它允许用户将自定义设备（如GPU、FPGA等）添加到Kubernetes集群中，并使这些设备可供容器使用。Device Plugin通过实现Kubernetes Device Plugin API来工作。该API定义了一组规范，用于插件与Kubernetes API Server进行通信，并向其报告可用设备资源。插件还可以响应Pod的请求，以便将设备资源分配给Pod。使用Device Plugin，用户可以轻松地将自定义设备添加到Kubernetes集群中，并确保这些设备在需要时可供容器使用。这有助于提高集群的利用率，并为用户提供更好的性能和灵活性。 ↩︎ ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:2:3","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#10"},{"categories":["task-bugfix"],"content":" 2.3 挂卸载设计方案 1.0 单盘挂载 第一层虚机状态的拦截：如果虚机状态为开机，不允许挂载，状态为关机则放行 判断虚机 fcsan 属性，如果为 false，创建新的 sts，删除旧的 sts，虚机 fcsan 属性置为 true 如果为 true 无操作 单盘卸载 批量挂载 盘列表的情况：【fcsan盘、非fcsan盘】 非fcsan的盘放行，继续后续的挂载操作 fcsan的盘需要判断当前虚机状态，如果虚机状态为开机，拦截这些盘的挂载操作，返回提示：这些盘需要在关机状态下操作 如果虚机状态为关机，判断虚机的fcsan属性，如果为 false，创建新的 sts，删除旧的 sts，虚机 fcsan 属性置为 true，如果为 true，则无操作 批量卸载 # 单盘挂载 curl -H \"Content-Type: application/json\" -X POST -d '{\"volume_id\":\"vol-de2w9x9nzqwggf\",\"delete_on_termination\":false,\"device\":\"\"}' 10.151.0.147:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-de9soljuhecvky/attachVolume # 单盘卸载 curl -H \"Content-Type: application/json\" -X DELETE 10.151.0.147:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-de538f14upm1rw/detachVolume/vol-de2w9x9nzqwggf # 多盘挂载 curl -H \"Content-Type: application/json\" -X POST -d '{\"attach_volume\":[{\"volume_id\":\"vol-de2w9x9nzqwggf\",\"delete_on_termination\":false,\"device\":\"\"},{\"volume_id\":\"vol-de8dro3ezonnpg\",\"delete_on_termination\":false,\"device\":\"\"}]}' 10.151.131.90:8080/compute/ecs/ops/v1/210512031000400/servers/ecs-des5bwski1o6pa/attachVolumes 2.0 单盘挂载 获取虚机 FcsanSupport 属性 判断 FcsanSupport == true（表明虚机当前是支持fcsan盘挂载的），则后续的操作都按正常挂载，无论虚机是开机还是关机状态都能够挂载 FcsanSupport == false （表明虚机当前不支持fcsan盘挂载），进一步获取 vtype protocol type 属性， 如果 type == “fc”，进一步判断虚机的状态， 如果 虚机状态 == 关机，支持挂载，并且改变 FcsanSupport 的值为 true，重新创建虚机的 sts 【FcsanSupport: false → true 的状态转换】 如果 虚机状态 == 开机，直接返回提示：“当前虚机的状态不支持热挂载 fcsan 的盘” 单盘卸载 FcsanSupport == true 正常卸载 FcsanSupport == false 问题：如果虚机挂载过 fcsan 的盘，后来全卸载了，虚机的 FcsanSupport 是否需要变回 false？ 如果不变回 false，好处是之后能够热挂载 fcsan 的盘，但是这样会导致挂载过 fcsan 类型盘的虚机 pod 都跑到了有 hba 的节点 如果需要变回 false，则需要在每次卸载的时候判断一下这块盘是不是虚机的最后一块fcsan的盘 【FcsanSupport：true→false 的状态转换】 批量挂载 FcsanSupport == true 正常卸载 FcsanSupport == false 判断虚机状态 虚机状态 == 开机，拦截操作，返回提示 虚机状态 == 关机，【FcsanSupport： false→true 的状态转换】 Kubernetes的Device Plugin是一种机制，用于管理和分配节点上的设备资源。它允许用户将自定义设备（如GPU、FPGA等）添加到Kubernetes集群中，并使这些设备可供容器使用。Device Plugin通过实现Kubernetes Device Plugin API来工作。该API定义了一组规范，用于插件与Kubernetes API Server进行通信，并向其报告可用设备资源。插件还可以响应Pod的请求，以便将设备资源分配给Pod。使用Device Plugin，用户可以轻松地将自定义设备添加到Kubernetes集群中，并确保这些设备在需要时可供容器使用。这有助于提高集群的利用率，并为用户提供更好的性能和灵活性。 ↩︎ ","date":"2023-05-16","objectID":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/:2:3","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"fcsan 对接记录","uri":"/202305161414-fcsan-%E5%AF%B9%E6%8E%A5%E8%AE%B0%E5%BD%95/#20"},{"categories":["task-bugfix"],"content":"#linux #storage ","date":"2023-05-16","objectID":"/202305161408-%E5%88%A4%E6%96%AD-inspurfcsan-%E6%8C%82%E8%BD%BD/:0:0","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"判断 inspur、fcsan 挂载","uri":"/202305161408-%E5%88%A4%E6%96%AD-inspurfcsan-%E6%8C%82%E8%BD%BD/#"},{"categories":["task-bugfix"],"content":" 判断 inspur、fcsan 挂载 # 通过以下命令判断 ll /dev/disk/by-path/ | grep sd* e.g. [root@iaas-test-193-ctl-226-194 by-path]# ll /dev/disk/by-path/ | grep sdaq lrwxrwxrwx 1 root root 10 Feb 11 18:51 fc-0x100000109bcc0016-0x56c92bfa00228004-lun-1 -\u003e ../../sdaq lrwxrwxrwx 1 root root 10 Feb 11 18:51 pci-0000:b0:00.1-fc-0x56c92bfa00228004-lun-1 -\u003e ../../sdaq 由此判断磁盘 sdaq 是 fc 方式挂载 ","date":"2023-05-16","objectID":"/202305161408-%E5%88%A4%E6%96%AD-inspurfcsan-%E6%8C%82%E8%BD%BD/:1:0","series":["偏工作性质记录"],"tags":["linux","storage","工作记录","fcsan"],"title":"判断 inspur、fcsan 挂载","uri":"/202305161408-%E5%88%A4%E6%96%AD-inspurfcsan-%E6%8C%82%E8%BD%BD/#判断-inspurfcsan-挂载"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 文档迁移 b7.openshift文档:done,13:30, 1h b8.工作性质的文档: done,4h section 习惯 算法每日一题: 1h ","date":"2023-05-16","objectID":"/2023-05-16/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-16 日记录","uri":"/2023-05-16/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-16","objectID":"/2023-05-16/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-16 日记录","uri":"/2023-05-16/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-16","objectID":"/2023-05-16/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-16 日记录","uri":"/2023-05-16/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） 把之前剩下的没整理的工作内容文档整理了一下 ","date":"2023-05-16","objectID":"/2023-05-16/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-16 日记录","uri":"/2023-05-16/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-16","objectID":"/2023-05-16/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-16 日记录","uri":"/2023-05-16/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-16","objectID":"/2023-05-16/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-16 日记录","uri":"/2023-05-16/#记录区-明天"},{"categories":["OpenShift"],"content":"#测试 ","date":"2023-05-16","objectID":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/:0:0","series":["OpenShift初识"],"tags":["openshift","e2e"],"title":"E2E 测试","uri":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/#"},{"categories":["OpenShift"],"content":" 一、什么是 E2E 测试？E2EEnd to End ：端到端测试，模拟一个从开始到结束的流程，验证是否符合预期 比如，在一套运行的 openshift 环境上面运行测试，一系列定义好的操作链 ","date":"2023-05-16","objectID":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/:1:0","series":["OpenShift初识"],"tags":["openshift","e2e"],"title":"E2E 测试","uri":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/#一什么是-e2e-测试"},{"categories":["OpenShift"],"content":" 二、如何进行 E2E 测试假设在 openshift 的环境上执行 e2e 测试 ","date":"2023-05-16","objectID":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/:2:0","series":["OpenShift初识"],"tags":["openshift","e2e"],"title":"E2E 测试","uri":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/#二如何进行-e2e-测试"},{"categories":["OpenShift"],"content":" 2.1 编译 e2e 执行文件 https://github.com/openshift/origin 可以参考该文档来查看如何进行 openshift e2e 的操作：https://github.com/openshift/origin/blob/master/test/extended/README.md 在编写完成自己的 e2e 测试用例之后，执行编译操作，生成测试文件 # 执行编译操作，生成测试文件 make WHAT=cmd/openshift-tests ","date":"2023-05-16","objectID":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/:2:1","series":["OpenShift初识"],"tags":["openshift","e2e"],"title":"E2E 测试","uri":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/#21-编译-e2e-执行文件"},{"categories":["OpenShift"],"content":" 2.2 在环境上运行 准备一个用于测试的 OpenShift 环境（这个环境应该与生产环境尽可能相似，确保测试结果的准确性） 在 OpenShift 环境上安装应用（需要的话，比如一些 Application Operator，可能是测试用例需要依赖的） 执行二进制文件 e.g. # 执行所有并行用例 ./openshift-tests run openshift/conformance/parallel --from-repository \"image.cestc.cn/ccos-test/community-e2e-images\" --provider '{\"type\":\"local\"}' -o e2e$(date \"+%Y%m%d%H%M%S\")-cluster-paraller.log --junit-dir junit # 执行所有串行用例 ./openshift-tests run openshift/conformance/serial --from-repository \"image.cestc.cn/ccos-test/community-e2e-images\" --provider '{\"type\":\"local\"}' -o e2e$(date \"+%Y%m%d%H%M%S\")-cluster-serial.log --junit-dir junit # 指定文件执行用例 ./openshift-tests run -f minimal-serial.txt --from-repository \"image.cestc.cn/ccos-test/community-e2e-images\" --provider '{\"type\":\"local\"}' --output-file=./single-e2e-test-serial-\\${date}.log --junit-dir=./ ","date":"2023-05-16","objectID":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/:3:0","series":["OpenShift初识"],"tags":["openshift","e2e"],"title":"E2E 测试","uri":"/202305161347-e2e-%E6%B5%8B%E8%AF%95/#22-在环境上运行"},{"categories":["OpenShift"],"content":"#openshift ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:0:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#"},{"categories":["OpenShift"],"content":" 一、OpenShift 理解","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:1:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#一openshift-理解"},{"categories":["OpenShift"],"content":" 1.1 容器的发展 2008 年，LXC（Linux Container） 2013 年，Docker 引擎，起初 Docker 想要使用 LXC，但是由于 LXC 隔离性较差，Docker 开发了 Libcontainer，最终形成了 runC 2014 年，Kubernetes 发布，直接使用 Docker 2014年，随着 Docker 越来越重，CoreOS 发布 rkt（rkt 展现了更简单的运行时的优势） 2015年，随着容器运行时的变多，标准也就随之而来，该年 6 月，OCI（Open Container Initiative）成立，这个项目是对容器运行时的接口标准化（runC 第一时间通过了认证） 为了 K8s 与 容器运行时两者之间实现解耦，针对 k8s，在两者中间加入了一层标准：CRI（Container Runtime Interface），它是 k8s 与 Container Runtime 之间进行交互的接口。 CRI 与 OCI 并不冲突，CRI 针对于 k8s 而言，而 OCI 是容器运行时本身的标准 2017年，CRI-O 发布。专门为 k8s 做的一个轻量级容器运行时，重用了 runC 等基本组件来启动容器。 同时 Docker 也在研究 CRI 标准，从而出现了 containerd 运行时（从 Docker 1.12 版本开始），k8s 将 containerd 接入 CRI 标准，成为 cri-containerd。 调用结构： old: k8s → kubelet → Docker engine → containerd → runC → linux kernel new: k8s → kubelet → cri-o → runC → linux kernel ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:1:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#11-容器的发展"},{"categories":["OpenShift"],"content":" 1.2 OpenShift 的发展 2011 年，OpenShift 诞生，核心架构：Gear 2014 年，Kubernetes 发布，红帽对 OpenShift 进行重构 2014 年，OpenShift 3.0 发布（基于 Kubernetes 1.0， 早期 Kubernetes 功能尚弱，OpenShift 补充了大量的企业级功能） 2018 年，红帽收购 CoreOS 公司，随着 CoreOS 被纳入，OpenShift 也融入了 CoreOS 的优秀基因。同时也进一步推进了 k8s 的发展 ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:1:2","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#12-openshift-的发展"},{"categories":["OpenShift"],"content":" 1.3 OpenShift 与 Kubernetes 的对比OpenShift 与 Kubernetes 之间相互促进，共同进步，OpenShift 相比于 k8s 有许多增强： k8s 面向容器调度；OpenShift 面向企业 PaaS 平台，OpenShift 除了包含 k8s，也包含了许多其他组件，如：认证集成、日志监控等 一个集群，多个租户 OpenShift 在 3.0 版本（基于 k8s 1.0）就有了 RBAC 的功能，但是 k8s 在 1.6 才推出了 RBAC，得以满足许多用户该方面的需求，由此可见 OpenShift 推动着 k8s 的发展。 应用程序的简单、安全部署 简单部署：早期 k8s 的应用程序版本管理并非简单的，OpenShift 3.0 开发了 DeploymentConfig（参数化部署输入、滚动部署、回滚、自动部署…），该功能也最终成为 k8s Deployments功能集的一部分，当然 OpenShift 支持 k8s Deployments 的全部功能 安全部署：由于用户可以用任何镜像来部署应用（尽管应用的不安全的），k8s 使用 pod 安全策略来保障安全（受 OpenShift SCC（上下文安全约束）启发）；红帽为 k8s 开发了 CRI-O 容器运行时，真正实现容器镜像的安全 更多类型的应用负载（有状态、无状态） 应用的快速访问 OpenShift 3.0 中，红帽开发了 Router（k8s ingress 的前身），提供入口请求的自动负载均衡 容器镜像的便捷管理：ImageStream 通过将镜像导入 ImageStream 来使用镜像 -scheduled=true 参数：定期检查镜像库的更新 Trigger：出现新的镜像或者镜像的Tag发生变化时触发自动部署 ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:1:3","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#13-openshift-与-kubernetes-的对比"},{"categories":["OpenShift"],"content":" 1.4 OpenShift 相对 Kubernetes 的延伸 与 Jenkins 集成 开发运维一体化 Tectonic、Container Linux、Quay、Operator、Prometheus 有状态应用的全生命周期管理 OpenShift 开发了 Operator 来管理 k8s 上运行的应用，扩展了 k8s api 实现了对 IaaS 资源的管理 通过 Istio 实现微服务架构 实现 Serverless ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:1:4","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#14-openshift-相对-kubernetes-的延伸"},{"categories":["OpenShift"],"content":" 二、OpenShift 架构","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:2:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#二openshift-架构"},{"categories":["OpenShift"],"content":" 2.1 逻辑架构 底层基础设施 服务层 控制节点 计算节点 路由层 持久存储 开发 运维 ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:2:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#21-逻辑架构"},{"categories":["OpenShift"],"content":" 2.2 技术架构","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:2:2","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#22-技术架构"},{"categories":["OpenShift"],"content":" 2.3 组件架构 ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:2:3","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#23-组件架构"},{"categories":["OpenShift"],"content":" 三、基于 OpenShift 构建企业级 PaaS 平台","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:3:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#三基于-openshift-构建企业级-paas-平台"},{"categories":["OpenShift"],"content":" 3.1 整体部署架构 节点 Master 节点：有且只有 3 个 master 节点 这种情况下怎么实现高可用？ worker 节点变多 → 提高 master 的 cpu、mem，而不改变 master 的数量 api 层面 → 使用软件负载均衡实现高可用 每个节点运行一个 etcd 计算节点 Infra：运行基础组件 App：运行业务 架构图单集群高可用架构： ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:3:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#31-整体部署架构"},{"categories":["OpenShift"],"content":" 3.1 整体部署架构 节点 Master 节点：有且只有 3 个 master 节点 这种情况下怎么实现高可用？ worker 节点变多 → 提高 master 的 cpu、mem，而不改变 master 的数量 api 层面 → 使用软件负载均衡实现高可用 每个节点运行一个 etcd 计算节点 Infra：运行基础组件 App：运行业务 架构图单集群高可用架构： ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:3:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#节点"},{"categories":["OpenShift"],"content":" 3.1 整体部署架构 节点 Master 节点：有且只有 3 个 master 节点 这种情况下怎么实现高可用？ worker 节点变多 → 提高 master 的 cpu、mem，而不改变 master 的数量 api 层面 → 使用软件负载均衡实现高可用 每个节点运行一个 etcd 计算节点 Infra：运行基础组件 App：运行业务 架构图单集群高可用架构： ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:3:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#架构图"},{"categories":["OpenShift"],"content":" 3.2 实际部署要点记录 两种部署类型（Installer/User Provisioned Infrastructure） IPI：Master、Worker 节点都必须使用 RHCOS 操作系统 UPI：Master 需要使用 RHCOS 操作系统 企业版连接：https://access.redhat.com/documentation/en-us/openshift_container_platform/4.6/html-single/installing_on_bare_metal/index 安装需要的角色 管理机 容器镜像服务器 DNS 服务器 HTTP 服务器 HAproxy、F5… 负载均衡器 NFS 服务器 Bootstrap Master Worker 离线部署大致流程 4.3、4.4、4.5 部署方式相同，4.6 稍有区别 RHCOS 操作系统镜像下载地址：https://mirror.openshift.com/pub/openshift-v4/dependencies/rhcos ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:3:2","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#32-实际部署要点记录"},{"categories":["OpenShift"],"content":" *、[社区版 okd] OpenShift 安装部署实操","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#社区版-okd-openshift-安装部署实操"},{"categories":["OpenShift"],"content":" 1. 节点规划1 master \u0026 infra、2 app（node） 节点 hostname ip 规格 版本 master01 master01.example.com 192.168.58.31 4C16G 40G+50G CentOS Linux release 7.9.2009 node01 node01.example.com 192.168.58.32 4C16G 40G+20G CentOS Linux release 7.9.2009 node02 node02.example.com 192.168.58.33 4C16G 40G+20G CentOS Linux release 7.9.2009 ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#1-节点规划"},{"categories":["OpenShift"],"content":" 2. 节点前置准备3个节点配置 hosts 192.168.58.31 master01.example.com 192.168.58.32 node01.example.com 192.168.58.33 node02.example.com 上述 domain 需要与节点的 hostname 一致 3个节点都： # 开启 selinux，保证 /etc/sysconfig/selinux 为如下配置 SELINUX=enforcing SELINUXTYPE=targeted # 关闭 iptables、firewalld、NetworkManager systemctl stop NetworkManager \u0026\u0026 systemctl stop iptables \u0026\u0026 systemctl stop firewalld systemctl disable NetworkManager \u0026\u0026 systemctl disable iptables \u0026\u0026 systemctl disable firewalld 在 master01 节点生成密钥并分发到各节点 ssh-keygen -t rsa ssh-copy-id -i .ssh/id_rsa.pub master01 ssh-copy-id -i .ssh/id_rsa.pub node01 ssh-copy-id -i .ssh/id_rsa.pub node02 各节点时间同步 ntpdate time2.aliyun.com 各节点安装依赖软件包 yum update -y yum install -y wget git net-tools bind-utils yum-utils iptables-services bridge-utils bash-completion kexec-tools sos psacct java-1.8.0-openjdk-headless python-passlib yum -y install nfs-utils lrzsz gcc gcc-c++ make cmake libxml2-devel openssl-devel curl curl-devel unzip sudo ntp libaio-devel vim ncurses-devel autoconf automake zlib-devel python-devel epel-release lrzsz openssh-server socat ipvsadm conntrack yum install -y https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm master 节点安装 ansible-2.6.5、pyOpenSSL、openshift-3.10 # 安装指定版本的 ansible # https://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/ 可以到该目录下找到对应的 rpm 包，指定安装 yum install -y https://releases.ansible.com/ansible/rpm/release/epel-7-x86_64/ansible-2.6.5-1.el7.ans.noarch.rpm # 安装 sed -i -e \"s/^enabled=1/enabled=0/\" /etc/yum.repos.d/epel.repo yum -y --enablerepo=epel install pyOpenSSL # https://github.com/openshift/openshift-ansible/tags 找到对应的 openshift-ansible 版本，上传到 master 节点 各节点 docker 安装 yum install -y docker-1.13.1 # docker 配置文件 vim /etc/sysconfig/docker ## options 改成 OPTIONS='--selinux-enabled=false --signature-verification=False' ## 配置加速 vi /etc/docker/daemon.json { \"registry-mirrors\": [\"https://rsbud4vc.mirror.aliyuncs.com\",\"https://registry.docker-cn.com\",\"https://docker.mirrors.ustc.edu.cn\",\"https://dockerhub.azk8s.cn\",\"http://hub-mirror.c.163.com\",\"http://qtid6917.mirror.aliyuncs.com\"] } ## 重启docker systemctl daemon-reload systemctl restart docker.service master 节点配置docker私有仓库 docker pull registry:2.5 yum install httpd -y systemctl start httpd mkdir -p /opt/registry-var/auth/ docker run --entrypoint htpasswd registry:2.5 -Bbn admin admin \u003e\u003e /opt/registry-var/auth/htpasswd # 设置配置文件 mkdir -p /opt/registry-var/config vim /opt/registry-var/config/config.yml version: \"0.1\" log: fields: service: registry storage: delete: enabled: true cache: blobdescriptor: inmemory filesystem: rootdirectory: /var/lib/registry http: addr: :5000 headers: X-Content-Type-Options: [nosniff] health: storagedriver: enabled: true interval: 10s threshold: 3 # 启动服务 docker run -d -p 5000:5000 --restart=always --name=registry -v /opt/registry-var/config/:/etc/docker/registry/ -v /opt/registry-var/auth/:/auth/ -e \"REGISTRY_AUTH=htpasswd\" -e \"REGISTRY_AUTH_HTPASSWD_REALM=Registry Realm\" -e REGISTRY_AUTH_HTPASSWD_PATH=/auth/htpasswd -v /opt/registry-var/:/var/lib/registry/ registry:2.5 各节点配置 https 权限支持 vim /etc/docker/daemon.json { \"registry-mirrors\": [\"\"https://rsbud4vc.mirror.aliyuncs.com\",\"https://registry.docker-cn.com\",\"https://docker.mirrors.ustc.edu.cn\",\"https://dockerhub.azk8s.cn\",\"http://hub-mirror.c.163.com\",\"http://qtid6917.mirror.aliyuncs.com\"\"], \"insecure-registries\":[\"192.168.58.31:5000\"] } # 重启 docker systemctl daemon-reload systemctl restart docker.service systemctl enable docker 测试登录 docker 仓库 docker login 192.168.58.31:5000 各节点配置 dcoker-storage [~] vim /etc/sysconfig/docker-storage-setup DEVS=/dev/sdb VG=docker-vg [~] docker-storage-setup 镜像下载 master01： docker pull quay.io/coreos/etcd:v3.2.22 docker pull openshift/origin-control-plane:v3.10 docker pull docker.io/openshift/origin-service-catalog:v3.10 docker pull openshift/origin-node:v3.10 docker pull openshift/origin-deployer:v3.10 docker pull openshift/origin-deployer:v3.10.0 docker pull openshift/origin-template-service-broker:v3.10","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:2","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#2-节点前置准备"},{"categories":["OpenShift"],"content":" 3. 集群安装检查： ansible-playbook -i /etc/ansible/hosts openshift-ansible-release-3.10/playbooks/prerequisites.yml 检查没问题开始安装： ansible-playbook -i /etc/ansible/hosts openshift-ansible-release-3.10/playbooks/deploy_cluster.yml 安装过程中碰到的问题记录： 1.Control plane pods didn’t come up 查看了下 /var/log/messages 日志 搜索了下说是 ansible 版本太高导致的（安装成了 2.9 的版本），于是将 ansible 降级得到解决 2.Could not find csr for nodes:….. 要保证 /etc/hosts 、 /etc/ansible/hosts、个节点 hostname 都是一致的。 /etc/hosts dns 更改之后需要重启下 dnsmasq 卸载 ocp 集群（？） ansible-playbook -i /etc/ansible/hosts openshift-ansible-release-3.10/playbooks/adhoc/uninstall.yml ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:3","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#3-集群安装"},{"categories":["OpenShift"],"content":" 4. 创建管理员账号 htpasswd -cb /etc/origin/master/htpasswd admin admin htpasswd -b /etc/origin/master/htpasswd dev dev oc login -u system:admin oc adm policy add-cluster-role-to-user cluster-admin admin ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:4","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#4-创建管理员账号"},{"categories":["OpenShift"],"content":" 5. 登录 console 控制台https://192.168.58.31:8443 碰到的问题： 1.网页一直无响应，打不开 不知道到底哪个环节出了问题，自己写个demo服务，来探究下 OpenShift 的请求转发到后端的过程： Go 代码： func HelloHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \"Hello World\") } func main() { http.HandleFunc(\"/\", HelloHandler) if err := http.ListenAndServe(\":8000\", nil); err != nil { log.Println(\"listener failed\", err) } } 在 8000 端口提供服务 制作成 docker 镜像 192.168.58.31:5000/hello:latest ，pod运行起来后，初步验证通过： 创建对应的 svc 服务，验证通过： 通过网页也是能够访问到的： … 结果：因为访问是 https 协议，配置的 hosts 是 xx.example.com ，不要写成域名的形式就行了。 ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:5","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#5-登录-console-控制台"},{"categories":["OpenShift"],"content":" 番外 rpm 同步库https://www.ibm.com/docs/zh/cloud-pak-system-w3550/2.3.2.0?topic=pattern-openshift-container-platform-faqs http://feilunshuai.tpddns.net:8446/repos/rhel-7-server-ose-3.11-rpms/Packages/a/ https://www.jianshu.com/p/429f7cfa6089 命令行 subscription-manager register --auto-attach subscription-manager repos --enable=\"rhel-7-server-rpms\" --enable=\"rhel-7-server-extras-rpms\" --enable=\"rhel-7-server-ose-3.11-rpms\" --enable=\"rhel-7-server-ansible-2.9-rpms\" [root@master01 ~]# subscription-manager repos --list This system has no repositories available through subscriptions. # 检查服务器的所有可用订阅 subscription-manager list --available subscription-manager attach --auto subscription-manager attach --pool=8a82c6557ffabbea018020c21a4f127e ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:6","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#番外"},{"categories":["OpenShift"],"content":" 番外 rpm 同步库https://www.ibm.com/docs/zh/cloud-pak-system-w3550/2.3.2.0?topic=pattern-openshift-container-platform-faqs http://feilunshuai.tpddns.net:8446/repos/rhel-7-server-ose-3.11-rpms/Packages/a/ https://www.jianshu.com/p/429f7cfa6089 命令行 subscription-manager register --auto-attach subscription-manager repos --enable=\"rhel-7-server-rpms\" --enable=\"rhel-7-server-extras-rpms\" --enable=\"rhel-7-server-ose-3.11-rpms\" --enable=\"rhel-7-server-ansible-2.9-rpms\" [root@master01 ~]# subscription-manager repos --list This system has no repositories available through subscriptions. # 检查服务器的所有可用订阅 subscription-manager list --available subscription-manager attach --auto subscription-manager attach --pool=8a82c6557ffabbea018020c21a4f127e ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:6","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#rpm-同步库"},{"categories":["OpenShift"],"content":" 番外 rpm 同步库https://www.ibm.com/docs/zh/cloud-pak-system-w3550/2.3.2.0?topic=pattern-openshift-container-platform-faqs http://feilunshuai.tpddns.net:8446/repos/rhel-7-server-ose-3.11-rpms/Packages/a/ https://www.jianshu.com/p/429f7cfa6089 命令行 subscription-manager register --auto-attach subscription-manager repos --enable=\"rhel-7-server-rpms\" --enable=\"rhel-7-server-extras-rpms\" --enable=\"rhel-7-server-ose-3.11-rpms\" --enable=\"rhel-7-server-ansible-2.9-rpms\" [root@master01 ~]# subscription-manager repos --list This system has no repositories available through subscriptions. # 检查服务器的所有可用订阅 subscription-manager list --available subscription-manager attach --auto subscription-manager attach --pool=8a82c6557ffabbea018020c21a4f127e ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:4:6","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#命令行"},{"categories":["OpenShift"],"content":" *、[社区版 okd] master 节点服务启动详情","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:5:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#社区版-okd-master-节点服务启动详情"},{"categories":["OpenShift"],"content":" *.1 api-server启动命令 #!/bin/bash set -euo pipefail if [[ -f /etc/origin/master/master.env ]]; then set -o allexport source /etc/origin/master/master.env fi exec openshift start master api --config=/etc/origin/master/master-config.yaml --loglevel=${DEBUG_LOGLEVEL:-2} file: /etc/origin/master/master.env # Proxy configuration # See https://docs.openshift.com/container-platform/3.10/install_config/http_proxies.html DEBUG_LOGLEVEL=4 file: /etc/origin/master/master-config.yaml admissionConfig: pluginConfig: BuildDefaults: configuration: apiVersion: v1 env: [] kind: BuildDefaultsConfig resources: limits: {} requests: {} BuildOverrides: configuration: apiVersion: v1 kind: BuildOverridesConfig openshift.io/ImagePolicy: configuration: apiVersion: v1 executionRules: - matchImageAnnotations: - key: images.openshift.io/deny-execution value: 'true' name: execution-denied onResources: - resource: pods - resource: builds reject: true skipOnResolutionFailure: true kind: ImagePolicyConfig aggregatorConfig: proxyClientInfo: certFile: aggregator-front-proxy.crt keyFile: aggregator-front-proxy.key apiLevels: - v1 apiVersion: v1 authConfig: requestHeader: clientCA: front-proxy-ca.crt clientCommonNames: - aggregator-front-proxy extraHeaderPrefixes: - X-Remote-Extra- groupHeaders: - X-Remote-Group usernameHeaders: - X-Remote-User controllerConfig: election: lockName: openshift-master-controllers serviceServingCert: signer: certFile: service-signer.crt keyFile: service-signer.key controllers: '*' corsAllowedOrigins: - (?i)//127\\.0\\.0\\.1(:|\\z) - (?i)//localhost(:|\\z) - (?i)//192\\.168\\.58\\.31(:|\\z) - (?i)//kubernetes\\.default(:|\\z) - (?i)//kubernetes\\.default\\.svc\\.cluster\\.local(:|\\z) - (?i)//kubernetes(:|\\z) - (?i)//openshift\\.default(:|\\z) - (?i)//master01(:|\\z) - (?i)//openshift\\.default\\.svc(:|\\z) - (?i)//172\\.30\\.0\\.1(:|\\z) - (?i)//openshift\\.default\\.svc\\.cluster\\.local(:|\\z) - (?i)//kubernetes\\.default\\.svc(:|\\z) - (?i)//openshift(:|\\z) dnsConfig: bindAddress: 0.0.0.0:8053 bindNetwork: tcp4 etcdClientInfo: ca: master.etcd-ca.crt certFile: master.etcd-client.crt keyFile: master.etcd-client.key urls: - https://master01:2379 etcdStorageConfig: kubernetesStoragePrefix: kubernetes.io kubernetesStorageVersion: v1 openShiftStoragePrefix: openshift.io openShiftStorageVersion: v1 imageConfig: format: docker.io/openshift/origin-${component}:${version} latest: false imagePolicyConfig: internalRegistryHostname: docker-registry.default.svc:5000 kind: MasterConfig kubeletClientInfo: ca: ca-bundle.crt certFile: master.kubelet-client.crt keyFile: master.kubelet-client.key port: 10250 kubernetesMasterConfig: apiServerArguments: storage-backend: - etcd3 storage-media-type: - application/vnd.kubernetes.protobuf controllerArguments: cluster-signing-cert-file: - /etc/origin/master/ca.crt cluster-signing-key-file: - /etc/origin/master/ca.key masterCount: 1 masterIP: 192.168.58.31 podEvictionTimeout: null proxyClientInfo: certFile: master.proxy-client.crt keyFile: master.proxy-client.key schedulerArguments: null schedulerConfigFile: /etc/origin/master/scheduler.json servicesNodePortRange: '' servicesSubnet: 172.30.0.0/16 staticNodeNames: [] masterClients: externalKubernetesClientConnectionOverrides: acceptContentTypes: application/vnd.kubernetes.protobuf,application/json burst: 400 contentType: application/vnd.kubernetes.protobuf qps: 200 externalKubernetesKubeConfig: '' openshiftLoopbackClientConnectionOverrides: acceptContentTypes: application/vnd.kubernetes.protobuf,application/json burst: 600 contentType: application/vnd.kubernetes.protobuf qps: 300 openshiftLoopbackKubeConfig: openshift-master.kubeconfig masterPublicURL: https://master01:8443 networkConfig: clusterNetworks: - cidr: 10.128.0.0/14 hostSubnetLength: 9 externalIPNetworkCIDRs: - 0.0.0.0/0 networkPluginName: redhat/openshift-ovs-subnet serviceNetworkCIDR: 172.30.0.0/16 oauthConfig: assetPublicURL: https://master01:8443/console/ grantConfig: method: auto identityProviders: - challenge: true login: true m","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:5:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#1-api-server"},{"categories":["OpenShift"],"content":" *.2 scheduler","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:5:2","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#2-scheduler"},{"categories":["OpenShift"],"content":" *.3 controller启动命令 #!/bin/bash set -euo pipefail if [[ -f /etc/origin/master/master.env ]]; then set -o allexport source /etc/origin/master/master.env fi exec openshift start master controllers --config=/etc/origin/master/master-config.yaml --listen=https://0.0.0.0:8444 --loglevel=${DEBUG_LOGLEVEL:-2} file: /etc/origin/master/master.env file: /etc/origin/master/master-config.yaml ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:5:3","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#3-controller"},{"categories":["OpenShift"],"content":" *、[cclinux ocp 公司版] 安装","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:6:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#cclinux-ocp-公司版-安装"},{"categories":["OpenShift"],"content":" 流程梳理【cclinux-ocp】 | ProcessOn免费在线作图,在线流程图,在线思维导图 | ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:6:1","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#流程梳理"},{"categories":["OpenShift"],"content":" *、[cclinux ocp 公司版] master 节点服务启动详情kubec ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:7:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#cclinux-ocp-公司版-master-节点服务启动详情"},{"categories":["OpenShift"],"content":" *、相关学习资料 https://docs.openshift.com/container-platform/4.10/welcome/index.html ","date":"2023-05-16","objectID":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/:8:0","series":["OpenShift初识"],"tags":["openshift"],"title":"openshift 认识以及部署测试","uri":"/202305161335-openshift-%E8%AE%A4%E8%AF%86%E4%BB%A5%E5%8F%8A%E9%83%A8%E7%BD%B2%E6%B5%8B%E8%AF%95/#相关学习资料"},{"categories":["生活记录"],"content":" 规划区 梳理一下整体要学习的内容？ gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 文档迁移 b7.openshift文档:13:00, 1h b8.工作性质的文档: 4h section 博客 a1.整理我的workspace:1h section 习惯 算法每日一题: 1h 双周赛:22:30, 90m ","date":"2023-05-13","objectID":"/2023-05-13/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-13 日记录","uri":"/2023-05-13/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 ","date":"2023-05-13","objectID":"/2023-05-13/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-13 日记录","uri":"/2023-05-13/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 ","date":"2023-05-13","objectID":"/2023-05-13/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-13 日记录","uri":"/2023-05-13/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） ","date":"2023-05-13","objectID":"/2023-05-13/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-13 日记录","uri":"/2023-05-13/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： ","date":"2023-05-13","objectID":"/2023-05-13/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-13 日记录","uri":"/2023-05-13/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天","date":"2023-05-13","objectID":"/2023-05-13/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-13 日记录","uri":"/2023-05-13/#记录区-明天"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#读书记录 #ddia https://github.com/Vonng/ddia ","date":"2023-05-12","objectID":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:0:0","series":["读书记录"],"tags":["ddia"],"title":"读 DDIA 留下的一些记录","uri":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 一、可靠性、可维护性和可扩展性先进的程序可以分成： 数据密集型 计算密集型 可靠性：系统在困境的情况下仍可工作 可伸缩：有办法应对系统的增长 可维护：不同的人在不同的声明周期，都能高效的在系统上工作 一个系统通常需要满足： 功能性需求：它应该做什么 非功能性需求：安全性、可靠性、可伸缩、可扩展等等 ","date":"2023-05-12","objectID":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:1:0","series":["读书记录"],"tags":["ddia"],"title":"读 DDIA 留下的一些记录","uri":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#一可靠性可维护性和可扩展性"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 1.1 可靠 “故障” 与 “失效” 故障fault：系统部分状态偏离标准 失效failure：系统整体功能停止服务 应该尽量让系统能够有更好的容错性（fault-tolerant）（当然想要容忍所有的错误情况是不现实的） “阻止错误” 与 ”容忍错误“ 有容忍手段：通常我们更倾向于容忍错误 没有容忍手段：如果没有治疗的方法，防止胜于容忍 ","date":"2023-05-12","objectID":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:1:1","series":["读书记录"],"tags":["ddia"],"title":"读 DDIA 留下的一些记录","uri":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#11-可靠"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 1.2 可伸缩可伸缩性用来描述系统应对负载增长能力 如何描述负载？ 负载参数：这个负载参数不是固定的，通常取决于系统的架构，可能是每秒向 web 服务器发出的请求、数据库的读写、缓存命中率等 如何描述性能？ 应对负载的方法？ 两种伸缩方式 描述 横向伸缩 将负载分布到多台小机器 纵向伸缩 转向更大的机器 这两种方式通常需要根据具体场景组合运行，没有一种万金油的方法 ","date":"2023-05-12","objectID":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:1:2","series":["读书记录"],"tags":["ddia"],"title":"读 DDIA 留下的一些记录","uri":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#12-可伸缩"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 1.3 可维护软件的大部分开销可能不在系统最初的开发阶段，而是在持续的维护阶段 为了减少维护遗留系统的痛苦，在设计之初就应该尽量考虑减少维护期间的痛苦 通常考虑三个设计原则： 可操作性 简单性 可演化性（开闭） ","date":"2023-05-12","objectID":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:1:3","series":["读书记录"],"tags":["ddia"],"title":"读 DDIA 留下的一些记录","uri":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#13-可维护"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 数据模型 与 查询语言 flowchart TD subgraph 选择一个数据模型是非常重要的 direction BT d[数据模型]--\u003e|影响着|soft[上层的软件功能] end 后面的内容先粗度一下，之后再补充记录 ","date":"2023-05-12","objectID":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:2:0","series":["读书记录"],"tags":["ddia"],"title":"读 DDIA 留下的一些记录","uri":"/202305121926-%E8%AF%BB-ddia-%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#数据模型-与-查询语言"},{"categories":["数据结构与算法"],"content":"#leetcode 废弃 使用新站点记录 128. 最长连续序列 // 思路1. 排序 + 双指针 // o(nlogn) + o(n) // // 如何在 o(n) 时间复杂度之内完成？ // 先遍历一遍，把 num 都放入map ，用来标记数组中存在这个数(appeared) // 再遍历一遍，如果该数能够作为数组的起点，就持续 +1 直到数组中不存在这个数，记录长度 // 前面使用 o(n) 空间复杂度来换取了 o(1) 的查找效率，最差情况下也就是整个数组不连续，也是 o(n) func longestConsecutive(nums []int) int { if len(nums) == 0 { return 0 } appeared := map[int]bool{} for _, num := range nums { appeared[num] = true } maxLen := math.MinInt for _, num := range nums { if !appeared[num-1] { cnt := 0 for appeared[num] { num++ cnt++ } maxLen = max(maxLen, cnt) } } return maxLen } func max(a, b int) int { if a \u003c b { return b } return a } ","date":"2023-05-12","objectID":"/202305121759-t128-%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/:0:0","series":["leetcode"],"tags":[],"title":"t128 最长连续序列","uri":"/202305121759-t128-%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/#"},{"categories":["数据结构与算法"],"content":"#leetcode 废弃 使用新站点记录 128. 最长连续序列 // 思路1. 排序 + 双指针 // o(nlogn) + o(n) // // 如何在 o(n) 时间复杂度之内完成？ // 先遍历一遍，把 num 都放入map ，用来标记数组中存在这个数(appeared) // 再遍历一遍，如果该数能够作为数组的起点，就持续 +1 直到数组中不存在这个数，记录长度 // 前面使用 o(n) 空间复杂度来换取了 o(1) 的查找效率，最差情况下也就是整个数组不连续，也是 o(n) func longestConsecutive(nums []int) int { if len(nums) == 0 { return 0 } appeared := map[int]bool{} for _, num := range nums { appeared[num] = true } maxLen := math.MinInt for _, num := range nums { if !appeared[num-1] { cnt := 0 for appeared[num] { num++ cnt++ } maxLen = max(maxLen, cnt) } } return maxLen } func max(a, b int) int { if a \u003c b { return b } return a } ","date":"2023-05-12","objectID":"/202305121759-t128-%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/:0:0","series":["leetcode"],"tags":[],"title":"t128 最长连续序列","uri":"/202305121759-t128-%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97/#128-最长连续序列httpsleetcodecnproblemslongest-consecutive-sequence"},{"categories":["Golang"],"content":"#Golang ","date":"2023-05-12","objectID":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/:0:0","series":["Golang语言使用"],"tags":["goroutine","内存泄漏"],"title":"关于 goroutine 内存泄漏的一些思考","uri":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/#"},{"categories":["Golang"],"content":" 为什么会内存泄漏内存泄漏是指 GC 没有办法不被使用的空间，内存无法释放，最终导致内存不足或者占满 为什么会内存泄漏，可能会有这些原因： 无限循环 循环引用，两个对象存在互相引用的情况会导致这两个对象最终都无法被回收 请求的资源被占用，一直阻塞 未关闭的通道，如果一个协程往一个未关闭的通道发送数据，但是一直没有被接受，就会一直阻塞 … ","date":"2023-05-12","objectID":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/:1:0","series":["Golang语言使用"],"tags":["goroutine","内存泄漏"],"title":"关于 goroutine 内存泄漏的一些思考","uri":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/#为什么会内存泄漏"},{"categories":["Golang"],"content":" 如何判断一个 goroutine 是否内存泄漏如何使用 pprof 排查 ","date":"2023-05-12","objectID":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/:2:0","series":["Golang语言使用"],"tags":["goroutine","内存泄漏"],"title":"关于 goroutine 内存泄漏的一些思考","uri":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/#如何判断一个-goroutine-是否内存泄漏"},{"categories":["Golang"],"content":" 场景 ❌ 下面的代码会启动一个协程来处理一个请求，尽管当这个请求被取消，这个协程还是会一直存在，直到处理结束（谁又知道结没结束呢） func users(req *Request) { // 启动一个 goroutine 来处理请求 go func() { // 处理请求... }() } ✅ 使用 context 来控制这个协程的生命周期（你不停也得停） func users(ctx context.Context, req *Request) { // 启动一个 goroutine 来处理请求 go func(ctx context.Context) { // 处理请求... }(ctx) } ","date":"2023-05-12","objectID":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/:3:0","series":["Golang语言使用"],"tags":["goroutine","内存泄漏"],"title":"关于 goroutine 内存泄漏的一些思考","uri":"/202305121500-%E5%85%B3%E4%BA%8E-goroutine-%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F%E7%9A%84%E4%B8%80%E4%BA%9B%E6%80%9D%E8%80%83/#场景"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#ChatGPT ","date":"2023-05-12","objectID":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/:0:0","series":["ChatGPT"],"tags":[],"title":"ChatGPT 实际使用的一些提示词记录","uri":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 开发 我想在网上搜索关于 “” 的知识，请问我应该用什么关键字来搜索比较好 请对以下代码进行CodeReview，结合 Golang 的语言特性，指出代码中可能存在的问题，包括但不仅限于代码风格、潜在bug、性能问题、代码可读性、代码安全性等问题。 如果可以，请在保持原有代码逻辑的情况下优化下以下代码，尽可能提升代码的可读性、可维护性、性能……，并给出优化的理由。 ","date":"2023-05-12","objectID":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/:1:0","series":["ChatGPT"],"tags":[],"title":"ChatGPT 实际使用的一些提示词记录","uri":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/#开发"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 面试 我想让你充当 Golang 开发工程师面试官，你可能会想要对面试者进行全面的评估，包括算法编程能力、计算机基础知识、线上生产问题定位以及系统设计等方面。在聊天中，你可以根据以下方向提问： 算法笔试：给面试者出一道或几道 Golang 编程题，要求他们用 Golang 实现解决方案，以检验他们的编程能力和算法能力 计算机基础知识：询问面试者关于操作系统、计算机网络、数据结构、算法、数据库、mysql等基础知识，以确保他们具备扎实的计算机基础。 数据库：询问面试者一些实际场景下如何优化效率的问题，以评估他们对于数据库的熟悉程度。 Kubernetes：询问面试者跟 Kubernetes 相关的问题，以评估他们有能够使用 kubernetes 进行开发、运维、问题定位的能力。 线上生产问题定位：给面试者一个模拟的线上问题，要求他们描述如何定位、诊断和解决问题，以评估他们的问题分析能力和解决能力。 系统设计：让面试者设计一个简单的分布式系统和服务，要求他们考虑到性能、可扩展性、容错性等方面，以评估他们的系统设计能力。 通过这些问题，你可以全面地了解面试者的技能和知识，以便判断他们是否适合担任 Golang 开发工程师这一职位。 ","date":"2023-05-12","objectID":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/:2:0","series":["ChatGPT"],"tags":[],"title":"ChatGPT 实际使用的一些提示词记录","uri":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/#面试"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 做总结、摘要 我们将开启新一轮的问答，接下来我要提供给你通过 “xxx @ number” 来编号的数段文章，请你先记住这些文章，当我开始提问，你再根据记住的这些内容来回答，可以吗 ","date":"2023-05-12","objectID":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/:3:0","series":["ChatGPT"],"tags":[],"title":"ChatGPT 实际使用的一些提示词记录","uri":"/202305121433-chatgpt-%E4%B8%80%E4%BA%9B%E6%8F%90%E7%A4%BA%E8%AF%8D%E8%AE%B0%E5%BD%95/#做总结摘要"},{"categories":["Kubernetes"],"content":"#k8s https://kubernetes.io/zh-cn/docs/concepts/overview/working-with-objects/finalizers/ func (r *VolcanoBackendReconciler) Reconcile(ctx context.Context, req ctrl.Request) (ctrl.Result, error) { l := log.FromContext(ctx) l.Info(\"the vcb reconcile is triggered...\") vcb := new(operatorv1.VolcanoBackend) if err := r.Get(ctx, req.NamespacedName, vcb); err != nil { l.Error(err, \"unable to fetch VolcanoBackend\") return ctrl.Result{}, client.IgnoreNotFound(err) } // 默认 vcb，创建 volcano 相关资源 if vcb.Name == vc_operator.DftVolcanoBackend \u0026\u0026 vcb.Namespace == vc_operator.DftVolcanoBackendNS { // 默认资源需要有我们的 finalizer，如果没有，需要添加 if vcb.ObjectMeta.DeletionTimestamp.IsZero() { if !controllerutil.ContainsFinalizer(vcb, config.VolcanoResourcesFinalizer) { controllerutil.AddFinalizer(vcb, config.VolcanoResourcesFinalizer) if err := r.Update(ctx, vcb); err != nil { l.Error(err, \"failed to update default vcb\") return ctrl.Result{}, err } l.Info(\"default vcb add finalizer success\") } } else { // 默认 vcb 正在被删除 if controllerutil.ContainsFinalizer(vcb, config.VolcanoResourcesFinalizer) { err := r.deleteVolcanoResources(ctx) if err != nil { l.Error(err, \"failed to delete volcano resources\") return ctrl.Result{}, err } l.Info(\"clean volcano resources success\") controllerutil.RemoveFinalizer(vcb, config.VolcanoResourcesFinalizer) if err := r.Update(ctx, vcb); err != nil { l.Error(err, \"failed to update default vcb\") return ctrl.Result{}, err } l.Info(\"remove finalizer from default vcb success\") } return ctrl.Result{}, nil } err := r.reconcileVolcanoResources(ctx, l) if err != nil { l.Error(err, \"volcano resources reconcile failed\") return ctrl.Result{}, err } l.Info(\"volcano resources reconcile success\") } return ctrl.Result{}, nil } ","date":"2023-05-12","objectID":"/202305121405-finalizer-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/:0:0","series":["kubernetes代码实践"],"tags":["finalizer"],"title":"finalizer 简单实践记录","uri":"/202305121405-finalizer-%E7%AE%80%E5%8D%95%E5%AE%9E%E8%B7%B5%E8%AE%B0%E5%BD%95/#"},{"categories":["Docker"],"content":"#docker docker pull alpine:latest --platform=linux/arm64 # 指定镜像架构 docker inspect 镜像 # arm64 docker pull alpine:latest --platform=linux/arm64 docker tag alpine:latest image.cestc.cn/ceake/alpine:latest-arm64 docker push image.cestc.cn/ceake/alpine:latest-arm64 # amd64 docker pull alpine:latest --platform=linux/amd64 docker tag alpine:latest image.cestc.cn/ceake/alpine:latest-amd64 docker push image.cestc.cn/ceake/alpine:latest-amd64 # manifest create docker manifest create --insecure image.cestc.cn/ceake/alpine:latest-multiArch image.cestc.cn/ceake/alpine-arm64:latest image.cestc.cn/ceake/alpine-amd64:latest # mark arm \u0026 amd docker manifest annotate --arch \"arm64\" image.cestc.cn/ceake/alpine:latest-multiArch image.cestc.cn/ceake/alpine-arm64:latest docker manifest annotate --arch \"amd64\" image.cestc.cn/ceake/alpine:latest-multiArch image.cestc.cn/ceake/alpine-amd64:latest # manifest push multi-arch image docker manifest push image.cestc.cn/ceake/alpine:latest-multiArch ","date":"2023-05-12","objectID":"/202305121338-docker-%E5%A4%9A%E6%9E%B6%E6%9E%84%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/:0:0","series":["Docker镜像制作"],"tags":["docker"],"title":"Docker 多架构镜像制作","uri":"/202305121338-docker-%E5%A4%9A%E6%9E%B6%E6%9E%84%E9%95%9C%E5%83%8F%E5%88%B6%E4%BD%9C/#"},{"categories":["Linux"],"content":"#linux l # 查看源码 b 3 # 打上断点 r # 运行 c # 继续执行，到下个断点 n # 单步执行，不进入函数 s # 进入函数 x/\u003cn/f/u\u003e 地址 # 查看地址的值 n:是正整数，表示需要显示的内存单元的个数，即从当前地址向后显示n个内存单元的内容， 一个内存单元的大小由第三个参数u定义。 f:表示addr指向的内存内容的输出格式，s对应输出字符串，此处需特别注意输出整型数据的格式： x 按十六进制格式显示变量. d 按十进制格式显示变量。 u 按十进制格式显示无符号整型。 o 按八进制格式显示变量。 t 按二进制格式显示变量。 a 按十六进制格式显示变量。 c 按字符格式显示变量。 f 按浮点数格式显示变量。 u:就是指以多少个字节作为一个内存单元-unit,默认为4。u还可以用被一些字符表示: 如b=1 byte, h=2 bytes,w=4 bytes,g=8 bytes. \u003caddr\u003e:表示内存地址。 ","date":"2023-05-12","objectID":"/202305121314-gdb-%E8%B0%83%E8%AF%95/:0:0","series":["Linux命令使用"],"tags":[],"title":"gdb 调试","uri":"/202305121314-gdb-%E8%B0%83%E8%AF%95/#"},{"categories":["项目管理"],"content":"#Git ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:0:0","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#"},{"categories":["项目管理"],"content":" 了解概念 工作区：本地看到的目录 暂存区：stage 或者叫 index 版本库： HEAD : 实际是指向 master 的一个游标，如图出现 HEAD 的命令也可以用 master 代替 执行 git add ，index 目录树更新，工作区的修改内容被写入到 objects 中的一个新对象，新对象 id 记录在 index 的文件索引中 git commit 时，master 分支做相应的更新 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:1:0","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#了解概念"},{"categories":["项目管理"],"content":" 常用命令","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:0","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#常用命令"},{"categories":["项目管理"],"content":" git help $ git --help usage: git [--version] [--help] [-C \u003cpath\u003e] [-c \u003cname\u003e=\u003cvalue\u003e] [--exec-path[=\u003cpath\u003e]] [--html-path] [--man-path] [--info-path] [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare] [--git-dir=\u003cpath\u003e] [--work-tree=\u003cpath\u003e] [--namespace=\u003cname\u003e] [--super-prefix=\u003cpath\u003e] [--config-env=\u003cname\u003e=\u003cenvvar\u003e] \u003ccommand\u003e [\u003cargs\u003e] 这些是在不同情况下常用的Git命令: 开始一个工作区 (see also: git help tutorial) clone 克隆一个版本库到一个新的目录中 init 创建一个空的Git仓库或重新初始化一个现有的仓库 围绕当前的变化开展工作 (see also: git help everyday) add 将文件内容添加到索引中 mv 移动或重命名一个文件、一个目录或一个符号链接（symlink） restore 恢复工作树文件 rm 从工作树和索引中删除文件 sparse-checkout 初始化和修改 sparse-checkout 审查历史和统计 (see also: git help revisions) bisect 使用二进制搜索来查找引入错误的提交 diff Show changes between commits, commit and working tree, etc grep 打印与模式相匹配的行 log 显示提交日志 show 显示各种类型的对象 status 显示工作树状态 增长、标记和调整你的共同历史 branch 列出、创建或删除分支 commit 记录对存储库的更改 merge 将两个或更多的发展历史连接在一起 rebase 在另一个基础提示之上重新提交 reset 将当前的HEAD复位到指定的状态 switch 切换分支 tag 创建、列出、删除或验证一个用GPG签名的标签对象 协同合作 (see also: git help workflows) fetch 从另一个资源库下载 objects 和 refs pull 从另一个版本库或本地分支获取并与之整合 push 更新远程相关 objects 和 refs 'git help -a' and 'git help -g' list available subcommands and some concept guides. See 'git help \u003ccommand\u003e' or 'git help \u003cconcept\u003e' to read about a specific subcommand or concept. See 'git help git' for an overview of the system. ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:1","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#git-help"},{"categories":["项目管理"],"content":" diff","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:2","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#diff"},{"categories":["项目管理"],"content":" log git log --oneline # -n 显示最近 n 条提交记录 git log --oneline -5 # 显示最近5条提交 # --after 指定时间之后的提交；--before 指定时间之前的ti'ji git log --oneline --after=2022-06-01 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:3","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#log"},{"categories":["项目管理"],"content":" reflog ## 查看分支是从哪个分支创建出来的 git reflog show \u003c分支名\u003e git reflog --date=local | grep \u003c分支名\u003e ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:4","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#reflog"},{"categories":["项目管理"],"content":" branch git branch # 查看本地分支情况 git branch -a # 查看所有分支 git branch \u003c分支名\u003e // 创建分支，新的分支数据与当前分支的数据相同 git checkout \u003c分支名\u003e // 切换分支 git branch -d # 删除本地分支 git push origin -d task-print # 删除远端分支 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:5","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#branch"},{"categories":["项目管理"],"content":" cherry-pick git cherry-pick 7fa7894 # (7fa7894, 9f0d518] git cherry-pick 7fa7894..9f0d518 # [7fa7894, 9f0d518] git cherry-pick 7fa7894^..9f0d518 # 打开编辑器，编辑提交信息 -e # 在提交信息的末尾追加 cherry pick 来源 commit -x # 继续操作 --continue # 放弃合并回到操作前的样子 --abort # 退出，但是不回到操作前的样子 --quit ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:6","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#cherry-pick"},{"categories":["项目管理"],"content":" checkout git checkout -b 分支名 remotes/origin/分支名 # 拉取远程的分支到本地 git checkout -b 分支名 # 创建并切换到分支 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:7","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#checkout"},{"categories":["项目管理"],"content":" reset git reset [--soft | --mixed | --hard] [HEAD] ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:8","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#reset"},{"categories":["项目管理"],"content":" fetch git fetch [alias] git merge [alias]/[branch] git checkout -b master origin/master # 本地没有 master 分支，拉取远程的 master 分支 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:9","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#fetch"},{"categories":["项目管理"],"content":" pullgit pull 其实就是 git fetch 和 git merge FETCH_HEAD 的简写 git pull \u003c远程主机名\u003e \u003c远程分支名\u003e:\u003c本地分支名\u003e // 将远程主机 origin 的分支拉取到本地，并于本地的分支合并 git pull \u003c远程主机名\u003e \u003c远程分支\u003e // 默认合并到当前分支 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:10","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#pull"},{"categories":["项目管理"],"content":" push git push \u003c远程主机名\u003e \u003c本地分支名\u003e:\u003c远程分支名\u003e git push \u003c远程主机名\u003e \u003c本地分支名\u003e // \u003c本地分支名\u003e = \u003c远程分支名\u003e ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:11","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#push"},{"categories":["项目管理"],"content":" 添加远程仓库 git remote -v # 查看本仓库的远程仓库列表 git remote add B ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:2:12","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#添加远程仓库"},{"categories":["项目管理"],"content":" 场景","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:0","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#场景"},{"categories":["项目管理"],"content":" fetch ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:1","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#fetch-1"},{"categories":["项目管理"],"content":" merge request 从 master 同时拉出来两个分支 task1、task2 master /\\ task1 task2 task1 与 task2 在同一个文件的同一个位置各加了一个方法，两个分支同时向 master 提了个 mr 先合入 task2 的 mr 这时 task1 的 mr 就会有冲突，如何解决？ step1. fetch 同步代码 step2. rebase，上游分支选择 master，开始 rebase，解决出现的冲突 step3. 强制 push 到 task1 分支 命令行操作: git fetch git rebase origin/master # 解决冲突 ... git add 文件 git rebase --continue git push origin task1:task1 --force ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:2","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#merge-request"},{"categories":["项目管理"],"content":" rebase 理解 https://www.yiibai.com/git/git_rebase.html # 当前处于 task4 分支，执行 git rebase origin/master # **相当于把在 task4 分支的提交重新创建，放到 origin/master 的提交之后** # 老的提交被丢弃 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:3","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#rebase-理解"},{"categories":["项目管理"],"content":" cherry-pick git cherry-pick hash1..hash2 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:4","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#cherry-pick-1"},{"categories":["项目管理"],"content":" 合并 commit git rebase -i ie. $ git log --oneline 3f9a1c2 (HEAD -\u003e bugfix-1-temp) 2 \u0026 3 b86fd5c 1 71df3ef (origin/bugfix-1-temp, origin/bugfix-1, bugfix-1) 1 3aa9ee7 Merge branch 'master' of code.cestc.cn:honghuiqiang/git-practice # 如果需要合并前两个 commit， -i 指向第三个 commit git rebase -i 71df3ef $ git log --oneline 04beace (HEAD -\u003e bugfix-1-temp) 1 \u0026 2 \u0026 3 71df3ef (origin/bugfix-1-temp, origin/bugfix-1, bugfix-1) 1 ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:5","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#合并-commit"},{"categories":["项目管理"],"content":" 基于已有工程创建新的 git 仓库 git init git remote add origin http://xxxx.git git add . git commit -m \"init project.\" git push -u origin master ","date":"2023-05-12","objectID":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/:3:6","series":["Git"],"tags":[],"title":"Git 常用操作","uri":"/202305121326-git-%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C/#基于已有工程创建新的-git-仓库"},{"categories":["Golang"],"content":"#gorm #Golang ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:0:0","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#"},{"categories":["Golang"],"content":" 一、基本用法","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:0","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#一基本用法"},{"categories":["Golang"],"content":" 1.1 创建与 mysql 的连接 require ( gorm.io/driver/mysql v1.0.5 gorm.io/gorm v1.21.3 ) // createConn 创建与 myslq 的连接 func createConn() (db *gorm.DB, err error) { dsn := \"root:APTX4869@tcp(127.0.0.1:3306)/db_gorm_test?charset=utf8mb4\u0026parseTime=True\u0026loc=Local\" db, err = gorm.Open(mysql.Open(dsn), \u0026gorm.Config{}) if err != nil { log.Println(\"create db connection failed.\") return nil, err } return } ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:1","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#11-创建与-mysql-的连接"},{"categories":["Golang"],"content":" 1.2 增删改查 1.2.1 增加记录 增加单条记录、批量增加记录 type Role struct { RoleId string `json:\"role_id\"` Name string `json:\"name\"` } func (role *Role) Create(db *gorm.DB) error { // 创建 role 记录 if result := db.Create(\u0026role); result.Error != nil { return errors.New(\"create role error\") } return nil } func CreateBatch(db *gorm.DB, roles []Role) error { if tx := db.Create(\u0026roles); tx.Error != nil { return errors.New(\"create role batch error\") } return nil } 可以根据 map 来创建 func CreateByMapTest(db *gorm.DB) error { db.Model(\u0026Role{}).Create(map[string]interface{}{\"RoleId\": \"role-mapdf\", \"Name\": \"roleMap\"}) return nil } 使用 Model type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { u.ID = utils.GenerateId(\"user\", 10) u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} return } func CreateUseModel() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := \u0026models.User{Name: \"honghuiqiang\"} db.Create(\u0026user) } 关联创建 type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string CreditCard CreditCard } type CreditCard struct { ID string Number string UserId string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { if len(u.ID) == 0 { u.ID = utils.GenerateId(\"user\", 10) } u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} u.CreditCard.ID = utils.GenerateId(\"cc\", 10) u.CreditCard.UserId = u.ID return } func CreateAssociation() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := models.User{Name: \"honghuiqiang2\", CreditCard: models.CreditCard{Number: \"904566722\"}} db.Create(\u0026user) } 1.2.2 删除记录 删除一条记录 db.Where(\"role_id = ?\", \"role-9j1t3\").Delete(\u0026models.Role{}) 删除多条记录 ids := []string{ \"role-sdftf\", \"role-sdjfu\", } db.Debug().Where(\"role_id IN ?\", ids).Delete([]models.Role{}) // DELETE FROM `roles` WHERE role_id IN ('role-sdftf','role-sdjfu') 软删除 模型需包含 gorm.DeletedAt 字段 type Model struct { ID string `gorm:\"primarykey\" json:\"id\"` CreatedAt time.Time `json:\"created_at\"` UpdatedAt time.Time `json:\"updated_at\"` DeletedAt gorm.DeletedAt `gorm:\"index\" json:\"deleted_at\"` } type User struct { Model Name string `json:\"name\"` StorageProtocolType string `json:\"storage_protocol_type\" gorm:\"default:iscsi;comment:'存储协议类型'\"` } db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // UPDATE `users` SET `deleted_at`='2021-10-14 17:22:57.853' WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL 软删除之后，将不能以正常方式查找到该记录，可以使用 Unscoped 来查找 db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:0] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL ORDER BY `users`.`id` LIMIT 1 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:1] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' ORDER BY `users`.`id` LIMIT 1 永久删除 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // [rows:1] DELETE FROM `users` WHERE id = 'user-9mucs0t3zr' 1.2.3 修改记录 更新记录的全部字段 即使字段是零值也会更新到数据库 var findUser models.User db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Find(\u0026findUser) findUser.Name = \"modify-name\" db.Debug().Save(\u0026findUser) // [rows:1] UPDATE `users` SET `created_at`='2021-10-14 10:21:07',`updated_at`='2021-10-14 17:41:26.304',`deleted_at`=NULL,`name`='modify-name' WHERE `id` = 'user-5pu8tlxpg5' 更新指定字段 // 更新单个字段 db.Model(\u0026models.User{}).Where(\"id = ?\", \"user-5pu8tlxpg5\").Update(\"qq\", \"904566722\") // 更新多个字段 db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Updates(models.User{Name: \"hhq\", QQ: \"123\"}) // [rows:1] UPDATE `users` SET `updated_at`='2021-10-14 17:50:14.392',`name`='hhq',`qq`='123' WHERE id = 'user-5pu8tlxpg5' 1.2.4 查询记录 搜索单个对象 First Take Last 查询数据库时添加了 LIMIT 1 条件 没找到： ErrRecordNotFound db.W","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:2","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#12-增删改查"},{"categories":["Golang"],"content":" 1.2 增删改查 1.2.1 增加记录 增加单条记录、批量增加记录 type Role struct { RoleId string `json:\"role_id\"` Name string `json:\"name\"` } func (role *Role) Create(db *gorm.DB) error { // 创建 role 记录 if result := db.Create(\u0026role); result.Error != nil { return errors.New(\"create role error\") } return nil } func CreateBatch(db *gorm.DB, roles []Role) error { if tx := db.Create(\u0026roles); tx.Error != nil { return errors.New(\"create role batch error\") } return nil } 可以根据 map 来创建 func CreateByMapTest(db *gorm.DB) error { db.Model(\u0026Role{}).Create(map[string]interface{}{\"RoleId\": \"role-mapdf\", \"Name\": \"roleMap\"}) return nil } 使用 Model type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { u.ID = utils.GenerateId(\"user\", 10) u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} return } func CreateUseModel() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := \u0026models.User{Name: \"honghuiqiang\"} db.Create(\u0026user) } 关联创建 type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string CreditCard CreditCard } type CreditCard struct { ID string Number string UserId string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { if len(u.ID) == 0 { u.ID = utils.GenerateId(\"user\", 10) } u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} u.CreditCard.ID = utils.GenerateId(\"cc\", 10) u.CreditCard.UserId = u.ID return } func CreateAssociation() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := models.User{Name: \"honghuiqiang2\", CreditCard: models.CreditCard{Number: \"904566722\"}} db.Create(\u0026user) } 1.2.2 删除记录 删除一条记录 db.Where(\"role_id = ?\", \"role-9j1t3\").Delete(\u0026models.Role{}) 删除多条记录 ids := []string{ \"role-sdftf\", \"role-sdjfu\", } db.Debug().Where(\"role_id IN ?\", ids).Delete([]models.Role{}) // DELETE FROM `roles` WHERE role_id IN ('role-sdftf','role-sdjfu') 软删除 模型需包含 gorm.DeletedAt 字段 type Model struct { ID string `gorm:\"primarykey\" json:\"id\"` CreatedAt time.Time `json:\"created_at\"` UpdatedAt time.Time `json:\"updated_at\"` DeletedAt gorm.DeletedAt `gorm:\"index\" json:\"deleted_at\"` } type User struct { Model Name string `json:\"name\"` StorageProtocolType string `json:\"storage_protocol_type\" gorm:\"default:iscsi;comment:'存储协议类型'\"` } db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // UPDATE `users` SET `deleted_at`='2021-10-14 17:22:57.853' WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL 软删除之后，将不能以正常方式查找到该记录，可以使用 Unscoped 来查找 db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:0] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL ORDER BY `users`.`id` LIMIT 1 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:1] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' ORDER BY `users`.`id` LIMIT 1 永久删除 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // [rows:1] DELETE FROM `users` WHERE id = 'user-9mucs0t3zr' 1.2.3 修改记录 更新记录的全部字段 即使字段是零值也会更新到数据库 var findUser models.User db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Find(\u0026findUser) findUser.Name = \"modify-name\" db.Debug().Save(\u0026findUser) // [rows:1] UPDATE `users` SET `created_at`='2021-10-14 10:21:07',`updated_at`='2021-10-14 17:41:26.304',`deleted_at`=NULL,`name`='modify-name' WHERE `id` = 'user-5pu8tlxpg5' 更新指定字段 // 更新单个字段 db.Model(\u0026models.User{}).Where(\"id = ?\", \"user-5pu8tlxpg5\").Update(\"qq\", \"904566722\") // 更新多个字段 db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Updates(models.User{Name: \"hhq\", QQ: \"123\"}) // [rows:1] UPDATE `users` SET `updated_at`='2021-10-14 17:50:14.392',`name`='hhq',`qq`='123' WHERE id = 'user-5pu8tlxpg5' 1.2.4 查询记录 搜索单个对象 First Take Last 查询数据库时添加了 LIMIT 1 条件 没找到： ErrRecordNotFound db.W","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:2","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#121-增加记录"},{"categories":["Golang"],"content":" 1.2 增删改查 1.2.1 增加记录 增加单条记录、批量增加记录 type Role struct { RoleId string `json:\"role_id\"` Name string `json:\"name\"` } func (role *Role) Create(db *gorm.DB) error { // 创建 role 记录 if result := db.Create(\u0026role); result.Error != nil { return errors.New(\"create role error\") } return nil } func CreateBatch(db *gorm.DB, roles []Role) error { if tx := db.Create(\u0026roles); tx.Error != nil { return errors.New(\"create role batch error\") } return nil } 可以根据 map 来创建 func CreateByMapTest(db *gorm.DB) error { db.Model(\u0026Role{}).Create(map[string]interface{}{\"RoleId\": \"role-mapdf\", \"Name\": \"roleMap\"}) return nil } 使用 Model type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { u.ID = utils.GenerateId(\"user\", 10) u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} return } func CreateUseModel() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := \u0026models.User{Name: \"honghuiqiang\"} db.Create(\u0026user) } 关联创建 type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string CreditCard CreditCard } type CreditCard struct { ID string Number string UserId string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { if len(u.ID) == 0 { u.ID = utils.GenerateId(\"user\", 10) } u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} u.CreditCard.ID = utils.GenerateId(\"cc\", 10) u.CreditCard.UserId = u.ID return } func CreateAssociation() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := models.User{Name: \"honghuiqiang2\", CreditCard: models.CreditCard{Number: \"904566722\"}} db.Create(\u0026user) } 1.2.2 删除记录 删除一条记录 db.Where(\"role_id = ?\", \"role-9j1t3\").Delete(\u0026models.Role{}) 删除多条记录 ids := []string{ \"role-sdftf\", \"role-sdjfu\", } db.Debug().Where(\"role_id IN ?\", ids).Delete([]models.Role{}) // DELETE FROM `roles` WHERE role_id IN ('role-sdftf','role-sdjfu') 软删除 模型需包含 gorm.DeletedAt 字段 type Model struct { ID string `gorm:\"primarykey\" json:\"id\"` CreatedAt time.Time `json:\"created_at\"` UpdatedAt time.Time `json:\"updated_at\"` DeletedAt gorm.DeletedAt `gorm:\"index\" json:\"deleted_at\"` } type User struct { Model Name string `json:\"name\"` StorageProtocolType string `json:\"storage_protocol_type\" gorm:\"default:iscsi;comment:'存储协议类型'\"` } db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // UPDATE `users` SET `deleted_at`='2021-10-14 17:22:57.853' WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL 软删除之后，将不能以正常方式查找到该记录，可以使用 Unscoped 来查找 db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:0] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL ORDER BY `users`.`id` LIMIT 1 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:1] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' ORDER BY `users`.`id` LIMIT 1 永久删除 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // [rows:1] DELETE FROM `users` WHERE id = 'user-9mucs0t3zr' 1.2.3 修改记录 更新记录的全部字段 即使字段是零值也会更新到数据库 var findUser models.User db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Find(\u0026findUser) findUser.Name = \"modify-name\" db.Debug().Save(\u0026findUser) // [rows:1] UPDATE `users` SET `created_at`='2021-10-14 10:21:07',`updated_at`='2021-10-14 17:41:26.304',`deleted_at`=NULL,`name`='modify-name' WHERE `id` = 'user-5pu8tlxpg5' 更新指定字段 // 更新单个字段 db.Model(\u0026models.User{}).Where(\"id = ?\", \"user-5pu8tlxpg5\").Update(\"qq\", \"904566722\") // 更新多个字段 db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Updates(models.User{Name: \"hhq\", QQ: \"123\"}) // [rows:1] UPDATE `users` SET `updated_at`='2021-10-14 17:50:14.392',`name`='hhq',`qq`='123' WHERE id = 'user-5pu8tlxpg5' 1.2.4 查询记录 搜索单个对象 First Take Last 查询数据库时添加了 LIMIT 1 条件 没找到： ErrRecordNotFound db.W","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:2","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#122-删除记录"},{"categories":["Golang"],"content":" 1.2 增删改查 1.2.1 增加记录 增加单条记录、批量增加记录 type Role struct { RoleId string `json:\"role_id\"` Name string `json:\"name\"` } func (role *Role) Create(db *gorm.DB) error { // 创建 role 记录 if result := db.Create(\u0026role); result.Error != nil { return errors.New(\"create role error\") } return nil } func CreateBatch(db *gorm.DB, roles []Role) error { if tx := db.Create(\u0026roles); tx.Error != nil { return errors.New(\"create role batch error\") } return nil } 可以根据 map 来创建 func CreateByMapTest(db *gorm.DB) error { db.Model(\u0026Role{}).Create(map[string]interface{}{\"RoleId\": \"role-mapdf\", \"Name\": \"roleMap\"}) return nil } 使用 Model type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { u.ID = utils.GenerateId(\"user\", 10) u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} return } func CreateUseModel() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := \u0026models.User{Name: \"honghuiqiang\"} db.Create(\u0026user) } 关联创建 type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string CreditCard CreditCard } type CreditCard struct { ID string Number string UserId string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { if len(u.ID) == 0 { u.ID = utils.GenerateId(\"user\", 10) } u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} u.CreditCard.ID = utils.GenerateId(\"cc\", 10) u.CreditCard.UserId = u.ID return } func CreateAssociation() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := models.User{Name: \"honghuiqiang2\", CreditCard: models.CreditCard{Number: \"904566722\"}} db.Create(\u0026user) } 1.2.2 删除记录 删除一条记录 db.Where(\"role_id = ?\", \"role-9j1t3\").Delete(\u0026models.Role{}) 删除多条记录 ids := []string{ \"role-sdftf\", \"role-sdjfu\", } db.Debug().Where(\"role_id IN ?\", ids).Delete([]models.Role{}) // DELETE FROM `roles` WHERE role_id IN ('role-sdftf','role-sdjfu') 软删除 模型需包含 gorm.DeletedAt 字段 type Model struct { ID string `gorm:\"primarykey\" json:\"id\"` CreatedAt time.Time `json:\"created_at\"` UpdatedAt time.Time `json:\"updated_at\"` DeletedAt gorm.DeletedAt `gorm:\"index\" json:\"deleted_at\"` } type User struct { Model Name string `json:\"name\"` StorageProtocolType string `json:\"storage_protocol_type\" gorm:\"default:iscsi;comment:'存储协议类型'\"` } db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // UPDATE `users` SET `deleted_at`='2021-10-14 17:22:57.853' WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL 软删除之后，将不能以正常方式查找到该记录，可以使用 Unscoped 来查找 db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:0] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL ORDER BY `users`.`id` LIMIT 1 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:1] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' ORDER BY `users`.`id` LIMIT 1 永久删除 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // [rows:1] DELETE FROM `users` WHERE id = 'user-9mucs0t3zr' 1.2.3 修改记录 更新记录的全部字段 即使字段是零值也会更新到数据库 var findUser models.User db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Find(\u0026findUser) findUser.Name = \"modify-name\" db.Debug().Save(\u0026findUser) // [rows:1] UPDATE `users` SET `created_at`='2021-10-14 10:21:07',`updated_at`='2021-10-14 17:41:26.304',`deleted_at`=NULL,`name`='modify-name' WHERE `id` = 'user-5pu8tlxpg5' 更新指定字段 // 更新单个字段 db.Model(\u0026models.User{}).Where(\"id = ?\", \"user-5pu8tlxpg5\").Update(\"qq\", \"904566722\") // 更新多个字段 db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Updates(models.User{Name: \"hhq\", QQ: \"123\"}) // [rows:1] UPDATE `users` SET `updated_at`='2021-10-14 17:50:14.392',`name`='hhq',`qq`='123' WHERE id = 'user-5pu8tlxpg5' 1.2.4 查询记录 搜索单个对象 First Take Last 查询数据库时添加了 LIMIT 1 条件 没找到： ErrRecordNotFound db.W","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:2","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#123-修改记录"},{"categories":["Golang"],"content":" 1.2 增删改查 1.2.1 增加记录 增加单条记录、批量增加记录 type Role struct { RoleId string `json:\"role_id\"` Name string `json:\"name\"` } func (role *Role) Create(db *gorm.DB) error { // 创建 role 记录 if result := db.Create(\u0026role); result.Error != nil { return errors.New(\"create role error\") } return nil } func CreateBatch(db *gorm.DB, roles []Role) error { if tx := db.Create(\u0026roles); tx.Error != nil { return errors.New(\"create role batch error\") } return nil } 可以根据 map 来创建 func CreateByMapTest(db *gorm.DB) error { db.Model(\u0026Role{}).Create(map[string]interface{}{\"RoleId\": \"role-mapdf\", \"Name\": \"roleMap\"}) return nil } 使用 Model type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { u.ID = utils.GenerateId(\"user\", 10) u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} return } func CreateUseModel() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := \u0026models.User{Name: \"honghuiqiang\"} db.Create(\u0026user) } 关联创建 type Model struct { ID string `gorm:\"primarykey\"` CreatedAt time.Time UpdatedAt time.Time DeletedAt sql.NullTime `gorm:\"index\"` } type User struct { Model Name string CreditCard CreditCard } type CreditCard struct { ID string Number string UserId string } func (u *User) BeforeCreate(tx *gorm.DB) (err error) { if len(u.ID) == 0 { u.ID = utils.GenerateId(\"user\", 10) } u.CreatedAt = time.Now() u.UpdatedAt = time.Now() u.DeletedAt = sql.NullTime{} u.CreditCard.ID = utils.GenerateId(\"cc\", 10) u.CreditCard.UserId = u.ID return } func CreateAssociation() { db, err := createConn() if err != nil { log.Println(\"open db failed.\") } user := models.User{Name: \"honghuiqiang2\", CreditCard: models.CreditCard{Number: \"904566722\"}} db.Create(\u0026user) } 1.2.2 删除记录 删除一条记录 db.Where(\"role_id = ?\", \"role-9j1t3\").Delete(\u0026models.Role{}) 删除多条记录 ids := []string{ \"role-sdftf\", \"role-sdjfu\", } db.Debug().Where(\"role_id IN ?\", ids).Delete([]models.Role{}) // DELETE FROM `roles` WHERE role_id IN ('role-sdftf','role-sdjfu') 软删除 模型需包含 gorm.DeletedAt 字段 type Model struct { ID string `gorm:\"primarykey\" json:\"id\"` CreatedAt time.Time `json:\"created_at\"` UpdatedAt time.Time `json:\"updated_at\"` DeletedAt gorm.DeletedAt `gorm:\"index\" json:\"deleted_at\"` } type User struct { Model Name string `json:\"name\"` StorageProtocolType string `json:\"storage_protocol_type\" gorm:\"default:iscsi;comment:'存储协议类型'\"` } db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // UPDATE `users` SET `deleted_at`='2021-10-14 17:22:57.853' WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL 软删除之后，将不能以正常方式查找到该记录，可以使用 Unscoped 来查找 db.Debug().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:0] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' AND `users`.`deleted_at` IS NULL ORDER BY `users`.`id` LIMIT 1 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").First(\u0026findUser) // [rows:1] SELECT * FROM `users` WHERE id = 'user-9mucs0t3zr' ORDER BY `users`.`id` LIMIT 1 永久删除 db.Debug().Unscoped().Where(\"id = ?\", \"user-9mucs0t3zr\").Delete(\u0026models.User{}) // [rows:1] DELETE FROM `users` WHERE id = 'user-9mucs0t3zr' 1.2.3 修改记录 更新记录的全部字段 即使字段是零值也会更新到数据库 var findUser models.User db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Find(\u0026findUser) findUser.Name = \"modify-name\" db.Debug().Save(\u0026findUser) // [rows:1] UPDATE `users` SET `created_at`='2021-10-14 10:21:07',`updated_at`='2021-10-14 17:41:26.304',`deleted_at`=NULL,`name`='modify-name' WHERE `id` = 'user-5pu8tlxpg5' 更新指定字段 // 更新单个字段 db.Model(\u0026models.User{}).Where(\"id = ?\", \"user-5pu8tlxpg5\").Update(\"qq\", \"904566722\") // 更新多个字段 db.Debug().Where(\"id = ?\", \"user-5pu8tlxpg5\").Updates(models.User{Name: \"hhq\", QQ: \"123\"}) // [rows:1] UPDATE `users` SET `updated_at`='2021-10-14 17:50:14.392',`name`='hhq',`qq`='123' WHERE id = 'user-5pu8tlxpg5' 1.2.4 查询记录 搜索单个对象 First Take Last 查询数据库时添加了 LIMIT 1 条件 没找到： ErrRecordNotFound db.W","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:2","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#124-查询记录"},{"categories":["Golang"],"content":" 1.3 钩子 BeforeSave`、`AfterSave`、`BeforeCreate`、`AfterCreate`、`BeforeDelete`、`AfterDelete`、`BeforeUpdate`、`AfterUpdate 1.3.1 BeforeCreate \u0026\u0026 AfterCreate BeforeCreate // BeforeCreate 创建之前做的动作，为记录生成id func (role *Role) BeforeCreate(tx *gorm.DB) (err error) { role.RoleId = utils.GenerateId(\"role\", 10) return } 跳过钩子方法：使用会话模式 DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026user) 1.3.2 BeforeSave \u0026\u0026 AfterSave 1.3.3 BeforeDelete \u0026\u0026 AfterDelete BeforeDelete func (role *Role) BeforeDelete(tx *gorm.DB) (err error) { var findRole Role tx.Debug().Where(\"role_id = ?\", role.RoleId).First(\u0026findRole) // SELECT * FROM `roles` WHERE role_id = 'role-fsi21' ORDER BY `roles`.`role_id` LIMIT 1 if findRole.Name == \"Admin\" { return errors.New(fmt.Sprintf(\"delete role Admin failed\")) } return } func DeleteTest() { db, err := CreateConn() if err != nil { log.Println(\"create connection failed.\") } db.Debug().Delete(\u0026models.Role{RoleId: \"role-fsi21\"}) } 1.3.4 BeforeUpdate \u0026\u0026 AfterUpdate","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:3","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#13-钩子"},{"categories":["Golang"],"content":" 1.3 钩子 BeforeSave`、`AfterSave`、`BeforeCreate`、`AfterCreate`、`BeforeDelete`、`AfterDelete`、`BeforeUpdate`、`AfterUpdate 1.3.1 BeforeCreate \u0026\u0026 AfterCreate BeforeCreate // BeforeCreate 创建之前做的动作，为记录生成id func (role *Role) BeforeCreate(tx *gorm.DB) (err error) { role.RoleId = utils.GenerateId(\"role\", 10) return } 跳过钩子方法：使用会话模式 DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026user) 1.3.2 BeforeSave \u0026\u0026 AfterSave 1.3.3 BeforeDelete \u0026\u0026 AfterDelete BeforeDelete func (role *Role) BeforeDelete(tx *gorm.DB) (err error) { var findRole Role tx.Debug().Where(\"role_id = ?\", role.RoleId).First(\u0026findRole) // SELECT * FROM `roles` WHERE role_id = 'role-fsi21' ORDER BY `roles`.`role_id` LIMIT 1 if findRole.Name == \"Admin\" { return errors.New(fmt.Sprintf(\"delete role Admin failed\")) } return } func DeleteTest() { db, err := CreateConn() if err != nil { log.Println(\"create connection failed.\") } db.Debug().Delete(\u0026models.Role{RoleId: \"role-fsi21\"}) } 1.3.4 BeforeUpdate \u0026\u0026 AfterUpdate","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:3","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#131-beforecreate--aftercreate"},{"categories":["Golang"],"content":" 1.3 钩子 BeforeSave`、`AfterSave`、`BeforeCreate`、`AfterCreate`、`BeforeDelete`、`AfterDelete`、`BeforeUpdate`、`AfterUpdate 1.3.1 BeforeCreate \u0026\u0026 AfterCreate BeforeCreate // BeforeCreate 创建之前做的动作，为记录生成id func (role *Role) BeforeCreate(tx *gorm.DB) (err error) { role.RoleId = utils.GenerateId(\"role\", 10) return } 跳过钩子方法：使用会话模式 DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026user) 1.3.2 BeforeSave \u0026\u0026 AfterSave 1.3.3 BeforeDelete \u0026\u0026 AfterDelete BeforeDelete func (role *Role) BeforeDelete(tx *gorm.DB) (err error) { var findRole Role tx.Debug().Where(\"role_id = ?\", role.RoleId).First(\u0026findRole) // SELECT * FROM `roles` WHERE role_id = 'role-fsi21' ORDER BY `roles`.`role_id` LIMIT 1 if findRole.Name == \"Admin\" { return errors.New(fmt.Sprintf(\"delete role Admin failed\")) } return } func DeleteTest() { db, err := CreateConn() if err != nil { log.Println(\"create connection failed.\") } db.Debug().Delete(\u0026models.Role{RoleId: \"role-fsi21\"}) } 1.3.4 BeforeUpdate \u0026\u0026 AfterUpdate","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:3","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#132-beforesave---aftersave"},{"categories":["Golang"],"content":" 1.3 钩子 BeforeSave`、`AfterSave`、`BeforeCreate`、`AfterCreate`、`BeforeDelete`、`AfterDelete`、`BeforeUpdate`、`AfterUpdate 1.3.1 BeforeCreate \u0026\u0026 AfterCreate BeforeCreate // BeforeCreate 创建之前做的动作，为记录生成id func (role *Role) BeforeCreate(tx *gorm.DB) (err error) { role.RoleId = utils.GenerateId(\"role\", 10) return } 跳过钩子方法：使用会话模式 DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026user) 1.3.2 BeforeSave \u0026\u0026 AfterSave 1.3.3 BeforeDelete \u0026\u0026 AfterDelete BeforeDelete func (role *Role) BeforeDelete(tx *gorm.DB) (err error) { var findRole Role tx.Debug().Where(\"role_id = ?\", role.RoleId).First(\u0026findRole) // SELECT * FROM `roles` WHERE role_id = 'role-fsi21' ORDER BY `roles`.`role_id` LIMIT 1 if findRole.Name == \"Admin\" { return errors.New(fmt.Sprintf(\"delete role Admin failed\")) } return } func DeleteTest() { db, err := CreateConn() if err != nil { log.Println(\"create connection failed.\") } db.Debug().Delete(\u0026models.Role{RoleId: \"role-fsi21\"}) } 1.3.4 BeforeUpdate \u0026\u0026 AfterUpdate","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:3","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#133-beforedelete--afterdelete"},{"categories":["Golang"],"content":" 1.3 钩子 BeforeSave`、`AfterSave`、`BeforeCreate`、`AfterCreate`、`BeforeDelete`、`AfterDelete`、`BeforeUpdate`、`AfterUpdate 1.3.1 BeforeCreate \u0026\u0026 AfterCreate BeforeCreate // BeforeCreate 创建之前做的动作，为记录生成id func (role *Role) BeforeCreate(tx *gorm.DB) (err error) { role.RoleId = utils.GenerateId(\"role\", 10) return } 跳过钩子方法：使用会话模式 DB.Session(\u0026gorm.Session{SkipHooks: true}).Create(\u0026user) 1.3.2 BeforeSave \u0026\u0026 AfterSave 1.3.3 BeforeDelete \u0026\u0026 AfterDelete BeforeDelete func (role *Role) BeforeDelete(tx *gorm.DB) (err error) { var findRole Role tx.Debug().Where(\"role_id = ?\", role.RoleId).First(\u0026findRole) // SELECT * FROM `roles` WHERE role_id = 'role-fsi21' ORDER BY `roles`.`role_id` LIMIT 1 if findRole.Name == \"Admin\" { return errors.New(fmt.Sprintf(\"delete role Admin failed\")) } return } func DeleteTest() { db, err := CreateConn() if err != nil { log.Println(\"create connection failed.\") } db.Debug().Delete(\u0026models.Role{RoleId: \"role-fsi21\"}) } 1.3.4 BeforeUpdate \u0026\u0026 AfterUpdate","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:1:3","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#134-beforeupdate--afterupdate"},{"categories":["Golang"],"content":" 二、关联","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:2:0","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#二关联"},{"categories":["Golang"],"content":" 2.1 belongs to一个用户属于一家公司 type User struct { Model Name string `json:\"name\"` QQ string `json:\"qq\"` // 一个用户属于一个公司 CompanyId string `json:\"company_id\"` Company Company } type Company struct { Id string `json:\"id\"` Name string `json:\"name\"` } func (c *Company) TableName() string { return \"company\" } func BelongsToTest() { companyId := utils.GenerateId(\"company\", 5) user := models.User{ Model: models.Model{ID: utils.GenerateId(\"user\", 5)}, Name: \"洪惠强\", QQ: \"904566722\", CompanyId: companyId, Company: models.Company{Id: companyId, Name: \"中国电子系统技术有限公司\"}, } db, err := base.CreateConn() if err != nil { log.Println(\"open db failed.\") } db.Debug().Create(\u0026user) // [rows:1] INSERT INTO `company` (`id`,`name`) VALUES ('company-3gs3u','中国电子系统技术有限公司') ON DUPLICATE KEY UPDATE `id`=`id` // [rows:1] INSERT INTO `users` (`id`,`created_at`,`updated_at`,`deleted_at`,`name`,`qq`,`company_id`) VALUES ('user-3gs3u','2021-10-15 10:26:00.312','2021-10-15 10:26:00.312',NULL,'洪惠强','904566722','company-3gs3u') user2 := models.User{ Model: models.Model{ID: utils.GenerateId(\"user\", 5)}, Name: \"陈之能\", QQ: \"unknown\", CompanyId: \"company-3gs3u\", Company: models.Company{Id: \"company-3gs3u\", Name: \"中国系统\"}, } db.Debug().Create(\u0026user2) // [rows:0] INSERT INTO `company` (`id`,`name`) VALUES ('company-3gs3u','中国系统') ON DUPLICATE KEY UPDATE `id`=`id` // [rows:1] INSERT INTO `users` (`id`,`created_at`,`updated_at`,`deleted_at`,`name`,`qq`,`company_id`) VALUES ('user-ys4cf','2021-10-15 10:34:50.196','2021-10-15 10:34:50.196',NULL,'陈之能','unknown','company-3gs3u') } ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:2:1","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#21-belongs-to"},{"categories":["Golang"],"content":" 2.2 has one一个用户有一张卡 type User struct { Model Name string `json:\"name\"` QQ string `json:\"qq\"` // has one CreditCard CreditCard } type CreditCard struct { ID string Number string UserId string } ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#22-has-one"},{"categories":["Golang"],"content":" 2.3 has many一个用户拥有多张卡 type User struct { Model Name string `json:\"name\"` QQ string `json:\"qq\"` // has one CreditCards []CreditCard } type CreditCard struct { ID string Number string UserId string } ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:2:3","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#23-has-many"},{"categories":["Golang"],"content":" 2.4 many to many多对多关系需要中间表 // 一个 user 可以说多种语言 // 一种 language 可以由多个 user 说 // 中间表 users_languages type User struct { models.Model Name string `json:\"name\"` Languages []Language `gorm:\"many2many:users_languages\" json:\"languages\"` } type Language struct { models.Model Name string Users []User `gorm:\"many2many:users_languages\" json:\"users\"` } func ManyToManyTest() { db, err := base.CreateConn() if err != nil { log.Println(\"open db failed.\") } // 会自动生成中间表 db.Set(\"gorm:table_options\", \"ENGINE=InnoDB\").AutoMigrate(\u0026User{}, \u0026Language{}) user := User{ Model: models.Model{ ID: utils.GenerateId(\"user\", 10), }, Name: \"小洪\", Languages: []Language{ {Model:models.Model{ID: utils.GenerateId(\"lg\", 10)}, Name: \"英语\"}, {Model:models.Model{ID: utils.GenerateId(\"lg\", 11)}, Name: \"中文\"}, }, } db.Debug().Create(\u0026user) // [rows:2] INSERT INTO `languages` (`id`,`created_at`,`updated_at`,`deleted_at`,`name`) VALUES ('lg-wgvnn84a70','2021-10-15 14:39:46.204','2021-10-15 14:39:46.204',NULL,'英语'),('lg-wgvnn84a70y','2021-10-15 14:39:46.204','2021-10-15 14:39:46.204',NULL,'中文') ON DUPLICATE KEY UPDATE `id`=`id` // [rows:2] INSERT INTO `users_languages` (`user_id`,`language_id`) VALUES ('user-wgvnn84a70','lg-wgvnn84a70'),('user-wgvnn84a70','lg-wgvnn84a70y') ON DUPLICATE KEY UPDATE `user_id`=`user_id` // [rows:1] INSERT INTO `users` (`id`,`created_at`,`updated_at`,`deleted_at`,`name`) VALUES ('user-wgvnn84a70','2021-10-15 14:39:46.195','2021-10-15 14:39:46.195',NULL,'小洪') } func ManyToManyFindTest() { db, err := base.CreateConn() if err != nil { log.Println(\"open db failed.\") } var findUsers []User var findLanguages []Language LanguageCondition := \u0026Language{Model: models.Model{ID: \"lg-5wb85aj644\"}} userCondition := \u0026User{Model: models.Model{ID: \"user-5wb85aj644\"}} // 查找使用某语言的所有用户 db.Debug().Model(\u0026LanguageCondition).Association(\"Users\").Find(\u0026findUsers) // [rows:1] SELECT `users`.`id`,`users`.`created_at`,`users`.`updated_at`,`users`.`deleted_at`,`users`.`name` FROM `users` JOIN `users_languages` ON `users_languages`.`user_id` = `users`.`id` AND `users_languages`.`language_id` = 'lg-5wb85aj644' WHERE `users`.`deleted_at` IS NULL // 查找某用户使用的语言 db.Debug().Model(\u0026userCondition).Association(\"Languages\").Find(\u0026findLanguages) // [rows:2] SELECT `languages`.`id`,`languages`.`created_at`,`languages`.`updated_at`,`languages`.`deleted_at`,`languages`.`name` FROM `languages` JOIN `users_languages` ON `users_languages`.`language_id` = `languages`.`id` AND `users_languages`.`user_id` = 'user-5wb85aj644' WHERE `languages`.`deleted_at` IS NULL marshalFindUsers, err := json.Marshal(findUsers) marshalFindLgs, err := json.Marshal(findLanguages) fmt.Println(string(marshalFindUsers)) fmt.Println(string(marshalFindLgs)) } ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:2:4","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#24-many-to-many"},{"categories":["Golang"],"content":" 三、声明模型 - 标签 colume type bool、int、uint、float、string、time、bytes serializer size primaryKey unique default precision scale not null autoIncrement autoIncrementIncrement embedded embeddedPrefix autoCreateTime autoUpdateTime index uniqueIndex check \u003c - comment ","date":"2023-05-12","objectID":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/:3:0","series":["Golang辅助开发框架"],"tags":[],"title":"Gorm 基本使用","uri":"/202305121339-gorm-%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/#三声明模型---标签"},{"categories":["Kubernetes"],"content":"#k8s ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:0:0","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#"},{"categories":["Kubernetes"],"content":" 简单了解","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:1:0","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#简单了解"},{"categories":["Kubernetes"],"content":" 特点 基于容器技术 有自我修复能力 水平伸缩 自动化部署、扩展 服务发现和负载均衡 … ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:1:1","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#特点"},{"categories":["Kubernetes"],"content":" master 节点相关组件 kube-apiserver kube-controller-manaer kube-scheduler 上述组件完成了集群的 pod 调度、弹性伸缩、资源管理、安全控制等功能 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:1:2","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#master-节点相关组件"},{"categories":["Kubernetes"],"content":" 数据库层面如何扩展功能 方法 优点 缺点 方法1. 数据库表预留一个很长的备注字段，之后扩展的内容以某种格式（xml、json、字符串拼接等）存入 代码改动小，风险小 不美观 方法2. 直接修改数据库表 代码改动大，风险大 比较美观 通常的做法是结合两种方法，刚开始引入特性的时候使用方法1，较小风险，等特性稳定之后，使用方法2进行重构，使代码美观。 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:1:3","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#数据库层面如何扩展功能"},{"categories":["Kubernetes"],"content":" 一些概念","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:0","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#一些概念"},{"categories":["Kubernetes"],"content":" Master - 集群的控制节点master 节点上运行关键进程： kube-controller-manager：资源对象的自动化控制 kube-apiserver：提供 HTTP Rest 接口的关键服务进程，相当于集群的入口，控制资源的增删改查等都要经过它 kube-scheduler：资源调度 etcd：保存所有资源对象的数据 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:1","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#master---集群的控制节点"},{"categories":["Kubernetes"],"content":" Node - 工作负载节点node 节点上运行的关键进程： kubelet：负责 pod 容器的创建、起停 kube-proxy：实现负载均衡的关键组件 docker engine：容器的管理 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:2","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#node---工作负载节点"},{"categories":["Kubernetes"],"content":" Pod pause 根容器的两个功能： 关联该 pod 内容器的状态 与其他容器共享 IP、挂载的 Volume Pod 类型： 普通 Pod 静态 Pod 特点1. 存放位置：静态pod没有被放到 etcd 中，而是在某个 node 的一个具体文件 特点2. 调度策略：只在对应的 node 上启动 File: Pod-template.yaml apiVersion: v1 kind: Pod metadata: name: string # pod 名称 namespace: string # 命名空间 labels: # 标签 name: string annotations: # 注释 - name: string spec: containers: - name: string # 容器 名称 image: string # 容器使用镜像 imagePullPolicy: [Always | Never | IfNotPresent] # 镜像拉取策略 command: []string # 为容器定义命令 args: []string # 为容器定义参数 # 以上定义的命令和参数会覆盖容器镜像(image)提供的默认命令和参数，如果只指定了 args，则将参数将配合默认命令使用 workingDir: string # 指定容器工作目录 volumeMounts: - name: string # 名称，可以理解为在本文件中的 volume 对象 id mountPath: string # 挂载到容器内的路径 readOnly: boolean ports: - name: string containerPort: int hostPort: int # 大多数容器不需要这个。要在主机上公开的端口号 protocol: [TCP | UDP | SCTP] env: - name: string value: string - name: string valueFrom: configMapKeyRef: name: string key: string resources: # 指定容器需要的每种资源的数量，调度程序会利用此信息来决定将 Pod 放在那个节点上 limits: # 最小数值 cpu: string memory: string requests: # 峰值负载情况下资源占用的最大量 cpu: string memory: string livenessProbe: # 存活探针 exec: command: []string # 在容器内执行的命令行，工作目录是 \"/\" httpGet: host: string # 连接到的主机名，默认是 pod 的 IP port: number path: string scheme: string # 连接到主机的方案，默认 HTTP httpHeaders: - name: string value: string tcpSocket: host: string port: string initialDelaySeconds: 0 # 启动容器后 \u003c---- 秒数 ----\u003e 启动可用性探测 timeoutSeconds: 1 periodSeconds: 1 # 多久执行一次探测 successThreshold: 1 # 失败后被认为是成功的最小连续成功次数 failureThreshold: 1 # 成功后被视为失败的最小连续失败次数。默认为3，最小值为1 securityContext: # 定义容器的权限和访问控制设置 （Pod 也有 securityContext，如果两者有相同字段，容器优先） privileged: boolean # 是否特权模式运行容器，特权容器中的进程基本上等同于主机上的 root procMount: string allowPrivilegeEscalation: boolean # 控制一个进程是否可以获得比其父进程更多的权限 capabilities: Object # 运行容器时要添加/删除的能力 readOnlyRootFilesystem: boolean # 容器是否有一个只读的根文件系统 runAsGroup: integer # 用于运行容器进程的入口的 GID runAsNonRoot: boolean # 容器必须以非 root 用户的身份运行， 为 true 时，kubelet 将在运行的时候验证镜像，确保不会以 UID 0 （root）用户的身份运行，如果以 root 用户运行，则无法启动容器 runAsUser: integer # 运行容器进程的 UID seLinuxOptions: Object windowsOptions: Object restartPolicy: [Always | OnFailure | Never] # pod 内容器的重启策略 nodeSelector: map[string]string # 须与 node 的标签相匹配，以便此 pod 在节点上调度 imagePullSecrets: - name: string hostNetwork: boolean # 使用主机的网络命名空间，请求主机网络 volumes: # 属于 pod 的容器可以挂载的卷列表 - name: string hostPath: path: string # 主机上的目录路径，如果是链接，会链接到真实路径 type: [\"\" | DirectoryOrCreate | Directory | FileOrCreate | File | Socket | CharDevice | BlockDevice] emptyDir: # 临时目录，分享 pod 的声明周期 medium: string sizeLimit: string secret: # 填充这个卷的 secret secretName: string items: - key: string path: string optional: boolean defaultMode: integer configMap: name: string items: - key: string path: string iscsi: # 一个 iscsi 磁盘资源，连接到一个 kubelet 的主机上，然后暴露给 pod chapAuthDiscovery: boolean # 是否支持iSCSI发现CHAP认证 chapAuthSession: boolean # 是否支持 iSCSI 会话 CHAP 认证 initiatorName: string # 自定义启动器名称 iqn: string lun: integer targetPortal: string portals: []string readOnly: boolean ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:3","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#pod"},{"categories":["Kubernetes"],"content":" RC （Replication Controller）、RS（Replication Set）两者的区别就是 RS 支持集合的 label selector 滚动升级（保持副本数量不变，每停一个旧版本的pod，同时启动一个新版本的pod） ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:4","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#rc-replication-controllerrsreplication-set"},{"categories":["Kubernetes"],"content":" Deployment内部是使用 RS 来实现的 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:5","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#deployment"},{"categories":["Kubernetes"],"content":" HPA（Horizontal Pod Autoscaler）Pod 水平自动扩缩容 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:6","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#hpahorizontal-pod-autoscaler"},{"categories":["Kubernetes"],"content":" StatefulSet区别于 RC、Deployment、DaemonSet、Job 面向无状态服务 StatefulSet为有状态服务 sts 控制的副本启停顺序受控 采用持久化存储卷（PV or PVC） Headless Service 与配合使用 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:7","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#statefulset"},{"categories":["Kubernetes"],"content":" Service RS、Service、Pod 之间的关系： 关系详情： Service 与 微服务？每个 Service 就相当于一个 微服务： Service 很好的解决了 k8s 服务发现的问题 pod+ip 组成的 endpoint 虽然可以访问到服务，但是 pod 一重启，这个 endpoint 随之改变，而在 service 的整个生命周期内，它的 ip 是不变的，只要将 Service 的名称与ip做一个 dns 域名映射便可用域名访问服务 一次实践的截图： ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:8","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#service"},{"categories":["Kubernetes"],"content":" Volumek8s 的支持多种类型的 volume： GlusterFS Ceph 其他分布式文件系统 ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:9","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#volume"},{"categories":["Kubernetes"],"content":" Persistent Volume（PV）集群中某个网络存储对应的一块存储 与 Persistent Volume Claim（PVC）起到了类似的作用 … ","date":"2023-05-12","objectID":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/:2:10","series":["kubernetes初识"],"tags":[],"title":"Kubernetes 一些基础概念","uri":"/202305121348-kubernetes-%E4%B8%80%E4%BA%9B%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5/#persistent-volumepv"},{"categories":["Linux"],"content":"#linux ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:0:0","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#"},{"categories":["Linux"],"content":" 一、基本操作","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:0","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#一基本操作"},{"categories":["Linux"],"content":" 查看系统、cpu信息 # 查看系统架构 arch # 查看系统内核信息 uname -a # 查看系统内核版本 cat /proc/version # 查看当前用户环境变量 env # 显示CPU info的信息 cat /proc/cpuinfo # 查看有几个逻辑cpu, 包括cpu型号 cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c # 查看有几颗cpu,每颗分别是几核 cat /proc/cpuinfo | grep physical | uniq -c # 查看当前CPU运行在32bit还是64bit模式下, 如果是运行在32bit下也不代表CPU不支持64bit getconf LONG_BIT # 结果大于0, 说明支持64bit计算. lm指long mode, 支持lm则是64bit cat /proc/cpuinfo | grep flags | grep ' lm ' | wc -l cat /proc/meminfo # 检验内存使用 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:1","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#查看系统cpu信息"},{"categories":["Linux"],"content":" 罗列设备 # 罗列 pci 设备 lspci -tv ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:2","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#罗列设备"},{"categories":["Linux"],"content":" sshkey # 创建sshkey ssh-keygen -t rsa -C your_email@example.com #id_rsa.pub 的内容拷贝到要控制的服务器的 home/username/.ssh/authorized_keys 中,如果没有则新建(.ssh权限为700, authorized_keys权限为600) ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:3","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#sshkey"},{"categories":["Linux"],"content":" 命令别名 # 在各个用户的.bash_profile中添加重命名配置 alias ll='ls -alF' ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:4","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#命令别名"},{"categories":["Linux"],"content":" 同步服务器时间 sudo ntpdate -u ntp.api.bz ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:5","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#同步服务器时间"},{"categories":["Linux"],"content":" 后台运行命令 # 后台运行,并且有nohup.out输出 nohup xxx \u0026 # 后台运行, 不输出任何日志 nohup xxx \u003e /dev/null \u0026 # 后台运行, 并将错误信息做标准输出到日志中 nohup xxx \u003eout.log 2\u003e\u00261 \u0026 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:6","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#后台运行命令"},{"categories":["Linux"],"content":" 查看命令路径 #显示一个二进制文件或可执行文件的完整路径 which \u003c命令\u003e #显示一个二进制文件、源码或man的位置 whereis \u003c命令\u003e ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:7","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#查看命令路径"},{"categories":["Linux"],"content":" 查看域名路由表 nslookup google.com ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:8","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#查看域名路由表"},{"categories":["Linux"],"content":" 最近登录信息列表 last -n 5 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:9","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#最近登录信息列表"},{"categories":["Linux"],"content":" 设置固定ip ifconfig em1 192.168.5.177 netmask 255.255.255.0 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:1:10","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#设置固定ip"},{"categories":["Linux"],"content":" 磁盘、文件、目录相关操作","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:0","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#磁盘文件目录相关操作"},{"categories":["Linux"],"content":" vim #normal模式下 g表示全局, x表示查找的内容, y表示替换后的内容 :%s/x/y/g #normal模式下 0 # 光标移到行首(数字0) $ # 光标移至行尾 shift + g # 跳到文件最后 gg # 跳到文件头 # 显示行号 :set nu # 去除行号 :set nonu # 检索 /xxx(检索内容) # 从头检索, 按n查找下一个 ?xxx(检索内容) # 从尾部检索 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:1","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#vim"},{"categories":["Linux"],"content":" 磁盘、文件目录基本信息 mount # 查看磁盘挂载情况 df # 查看磁盘分区信息 df -h df -lh df -h 路径 du -H -h # 查看目录及子目录大小 du -sh * # 查看当前目录下各个文件, 文件夹占了多少空间, 不会递归 du -sh dir1 #估算目录 'dir1' 已经使用的磁盘空间' ls -lSr |more #以尺寸大小排列文件和目录 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:2","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#磁盘文件目录基本信息"},{"categories":["Linux"],"content":" fdisk ############ 创建一个分区 fdisk /dev/sdb Command (m for help): m Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-20971519, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-20971519, default 20971519): 1G Value out of range. Last sector, +sectors or +size{K,M,G} (2048-20971519, default 20971519): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 实践-删除分区 遇到设备繁忙的问题 → 解决：使用 lsof 命令查看正在使用该设备的程序，关闭程序再尝试 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:3","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#fdisk"},{"categories":["Linux"],"content":" fdisk ############ 创建一个分区 fdisk /dev/sdb Command (m for help): m Command action a toggle a bootable flag b edit bsd disklabel c toggle the dos compatibility flag d delete a partition g create a new empty GPT partition table G create an IRIX (SGI) partition table l list known partition types m print this menu n add a new partition o create a new empty DOS partition table p print the partition table q quit without saving changes s create a new empty Sun disklabel t change a partition's system id u change display/entry units v verify the partition table w write table to disk and exit x extra functionality (experts only) Command (m for help): n Partition type: p primary (0 primary, 0 extended, 4 free) e extended Select (default p): p Partition number (1-4, default 1): 1 First sector (2048-20971519, default 2048): Using default value 2048 Last sector, +sectors or +size{K,M,G} (2048-20971519, default 20971519): 1G Value out of range. Last sector, +sectors or +size{K,M,G} (2048-20971519, default 20971519): +1G Partition 1 of type Linux and of size 1 GiB is set Command (m for help): w The partition table has been altered! Calling ioctl() to re-read partition table. Syncing disks. 实践-删除分区 遇到设备繁忙的问题 → 解决：使用 lsof 命令查看正在使用该设备的程序，关闭程序再尝试 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:3","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#实践-删除分区"},{"categories":["Linux"],"content":" 查看文件内容 cat file1 #从第一个字节开始正向查看文件的内容 tac file1 #从最后一行开始反向查看一个文件的内容 more file1 #查看一个长文件的内容 less file1 #类似于 'more' 命令，但是它允许在文件中和正向操作一样的反向操作 head -2 file1 #查看一个文件的前两行 tail -2 file1 #查看一个文件的最后两行 tail -f /var/log/messages #实时查看被添加到一个文件中的内容 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:4","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#查看文件内容"},{"categories":["Linux"],"content":" 挂载文件系统 mount /dev/hda2 /mnt/hda2 #挂载一个叫做hda2的盘 - 确定目录 '/ mnt/hda2' 已经存在 umount /dev/hda2 #卸载一个叫做hda2的盘 - 先从挂载点 '/ mnt/hda2' 退出 fuser -km /mnt/hda2 #当设备繁忙时强制卸载 umount -n /mnt/hda2 #运行卸载操作而不写入 /etc/mtab 文件- 当文件为只读或当磁盘写满时非常有用 mount /dev/fd0 /mnt/floppy #挂载一个软盘 mount /dev/cdrom /mnt/cdrom #挂载一个cdrom或dvdrom mount /dev/hdc /mnt/cdrecorder #挂载一个cdrw或dvdrom mount /dev/hdb /mnt/cdrecorder #挂载一个cdrw或dvdrom mount -o loop file.iso /mnt/cdrom #挂载一个文件或ISO镜像文件 mount -t vfat /dev/hda5 /mnt/hda5 #挂载一个Windows FAT32文件系统 mount /dev/sda1 /mnt/usbdisk #挂载一个usb 捷盘或闪存设备 mount -t smbfs -o username=user,password=pass //WinClient/share /mnt/share #挂载一个windows网络共享 mount -t cifs -o username=iaas,password=iaas@123 //10.32.43.2/iaas开发部/cke smb ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:5","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#挂载文件系统"},{"categories":["Linux"],"content":" 文件系统、初始化一个文件系统 badblocks -v /dev/hda1 #检查磁盘hda1上的坏磁块 fsck /dev/hda1 #修复/检查hda1磁盘上linux文件系统的完整性 fsck.ext2 /dev/hda1 #修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck /dev/hda1 #修复/检查hda1磁盘上ext2文件系统的完整性 e2fsck -j /dev/hda1 #修复/检查hda1磁盘上ext3文件系统的完整性 fsck.ext3 /dev/hda1 #修复/检查hda1磁盘上ext3文件系统的完整性 fsck.vfat /dev/hda1 #修复/检查hda1磁盘上fat文件系统的完整性 fsck.msdos /dev/hda1 #修复/检查hda1磁盘上dos文件系统的完整性 dosfsck /dev/hda1 #修复/检查hda1磁盘上dos文件系统的完整性 mkfs /dev/hda1 #在hda1分区创建一个文件系统 mke2fs /dev/hda1 #在hda1分区创建一个linux ext2的文件系统 mke2fs -j /dev/hda1 #在hda1分区创建一个linux ext3(日志型)的文件系统 mkfs -t vfat 32 -F /dev/hda1 #创建一个 FAT32 文件系统 fdformat -n /dev/fd0 #格式化一个软盘 mkswap /dev/hda3 #创建一个swap文件系统 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:6","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#文件系统初始化一个文件系统"},{"categories":["Linux"],"content":" 备份 dump -0aj -f /tmp/home0.bak /home #制作一个 '/home' 目录的完整备份 dump -1aj -f /tmp/home0.bak /home #制作一个 '/home' 目录的交互式备份 restore -if /tmp/home0.bak #还原一个交互式备份 rsync -rogpav --delete /home /tmp #同步两边的目录 rsync -rogpav -e ssh --delete /home ip_address:/tmp #通过SSH通道rsync rsync -az -e ssh --delete ip_addr:/home/public /home/local #通过ssh和压缩将一个远程目录同步到本地目录 rsync -az -e ssh --delete /home/local ip_addr:/home/public #通过ssh和压缩将本地目录同步到远程目录 dd bs=1M if=/dev/hda | gzip | ssh user@ip_addr 'dd of=hda.gz' #通过ssh在远程主机上执行一次备份本地磁盘的操作 dd if=/dev/sda of=/tmp/file1 #备份磁盘内容到一个文件 tar -Puf backup.tar /home/user 执行一次对 '/home/user' #目录的交互式备份操作 ( cd /tmp/local/ \u0026\u0026 tar c . ) | ssh -C user@ip_addr 'cd /home/share/ \u0026\u0026 tar x -p' #通过ssh在远程目录中复制一个目录内容 ( tar c /home ) | ssh -C user@ip_addr 'cd /home/backup-home \u0026\u0026 tar x -p' #通过ssh在远程目录中复制一个本地目录 tar cf - . | (cd /tmp/backup ; tar xf - ) #本地将一个目录复制到另一个地方，保留原有权限及链接 find /home/user1 -name '*.txt' | xargs cp -av --target-directory=/home/backup/ --parents #从一个目录查找并复制所有以 '.txt' 结尾的文件到另一个目录 find /var/log -name '*.log' | tar cv --files-from=- | bzip2 \u003e log.tar.bz2 #查找所有以 '.log' 结尾的文件并做成一个bzip包 dd if=/dev/hda of=/dev/fd0 bs=512 count=1 #做一个将 MBR (Master Boot Record)内容复制到软盘的动作 dd if=/dev/fd0 of=/dev/hda bs=512 count=1 #从已经保存到软盘的备份中恢复MBR内容 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:7","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#备份"},{"categories":["Linux"],"content":" 字符设置和文件格式转换 dos2unix filedos.txt fileunix.txt #将一个文本文件的格式从MSDOS转换成UNIX unix2dos fileunix.txt filedos.txt #将一个文本文件的格式从UNIX转换成MSDOS recode ..HTML \u003c page.txt \u003e page.html #将一个文本文件转换成html recode -l | more #显示所有允许的转换格式 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:8","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#字符设置和文件格式转换"},{"categories":["Linux"],"content":" wc wc -l filename # 查看文件里有多少行 wc -w filename # 看文件里有多少个word wc -L filename # 文件里最长的那一行是多少个字 wc -c # 统计字节数 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:9","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#wc"},{"categories":["Linux"],"content":" 压缩、解压缩 tar czvf xxx.tar 压缩目录 zip -r xxx.zip 压缩目录 tar zxvf xxx.tar # 解压到指定文件夹 tar zxvf xxx.tar -C /xxx/yyy/ unzip xxx.zip bunzip2 file1.bz2 #解压一个叫做 'file1.bz2'的文件 bzip2 file1 #压缩一个叫做 'file1' 的文件 gunzip file1.gz #解压一个叫做 'file1.gz'的文件 gzip file1 #压缩一个叫做 'file1'的文件 gzip -9 file1 #最大程度压缩 rar a file1.rar test_file #创建一个叫做 'file1.rar' 的包 rar a file1.rar file1 file2 dir1 #同时压缩 'file1', 'file2' 以及目录 'dir1' rar x file1.rar #解压rar包 unrar x file1.rar #解压rar包 tar -cvf archive.tar file1 #创建一个非压缩的 tarball tar -cvf archive.tar file1 file2 dir1 #创建一个包含了 'file1', 'file2' 以及 'dir1'的档案文件 tar -tf archive.tar #显示一个包中的内容 tar -xvf archive.tar #释放一个包 tar -xvf archive.tar -C /tmp #将压缩包释放到 /tmp目录下 tar -cvfj archive.tar.bz2 dir1 #创建一个bzip2格式的压缩包 tar -jxvf archive.tar.bz2 #解压一个bzip2格式的压缩包 tar -cvfz archive.tar.gz dir1 #创建一个gzip格式的压缩包 tar -zxvf archive.tar.gz #解压一个gzip格式的压缩包 zip file1.zip file1 #创建一个zip格式的压缩包 zip -r file1.zip file1 file2 dir1 #将几个文件和目录同时压缩成一个zip格式的压缩包 unzip file1.zip #解压一个zip格式压缩包 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:10","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#压缩解压缩"},{"categories":["Linux"],"content":" 拷贝、创建目录 cp xxx.log #复制 cp -f xxx.log # 复制并强制覆盖同名文件 cp -r xxx(源文件夹) yyy(目标文件夹) # 复制文件夹 scp -P ssh端口 username@10.10.10.101:/home/username/xxx /home/xxx # 远程复制 mkdir -p /xxx/yyy/zzz # 级联创建目录 mkdir -p src/{test,main}/{java,resources} # 批量创建文件夹, 会在test,main下都创建java, resources文件夹 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:11","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#拷贝创建目录"},{"categories":["Linux"],"content":" 软链接 #创建一个指向文件或目录的软链接 -\u003e 在选定的位置生成镜像 ln -s source dest #创建一个指向文件或目录的物理链接（硬链接）（绝对地址 -\u003e 在选定的位置生成和源相同的文件） ln source dest ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:12","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#软链接"},{"categories":["Linux"],"content":" grep 检索 grep -v xxx # 反向匹配, 查找不包含xxx的内容 grep -v '^/pre\u003e # 排除所有空行 grep -n “^$” 111.txt # 返回结果 2,则说明第二行是空行 grep -n “^abc” 111.txt # 查询以abc开头的行 grep 'xxx' -n xxx.log # 同时列出该词语出现在文章的第几行 grep 'xxx' -c xxx.log # 计算一下该字串出现的次数 grep 'xxx' -i xxx.log # 比对的时候，不计较大小写的不同 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:13","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#grep-检索"},{"categories":["Linux"],"content":" find find /home/eagleye -name '*.mysql' -print # 在目录下找后缀是.mysql的文件 find /usr -atime 3 –print # 会从 /usr 目录开始往下找，找最近3天之内存取过的文件。 find /usr -ctime 5 –print # 会从 /usr 目录开始往下找，找最近5天之内修改过的文件。 find /doc -user jacky -name 'j*' –print # 会从 /doc 目录开始往下找，找jacky 的、文件名开头是 j的文件。 find /doc \\( -name 'ja*' -o- -name 'ma*' \\) –print # 会从 /doc 目录开始往下找，找寻文件名是 ja 开头或者 ma开头的文件。 # 会从 /doc 目录开始往下找，找到凡是文件名结尾为 bak的文件，把它删除掉。-exec 选项是执行的意思，rm 是删除命令，{ } 表示文件名，“\\;”是规定的命令结尾。 find /doc -name '*bak' -exec rm {} \\; ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:14","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#find"},{"categories":["Linux"],"content":" awk # 用法一 行匹配语句 ps. '' 只能用单引号 awk '{[pattern] action}' filenames ie. awk '{print $1, $10}' test.log # 打印出 test.log 每行的第1项、第10项（如果没有则该项为空）（以 TAB 或者 空格 作为分隔符） awk -F分隔符 '{[pattern] action}' filenames ie. awk -F, '{print $1,$2}' test.log # 以 , 作为分隔符 awk -F '[:,]' '{print $1,$2,$3,$4}' # 先用 : 分割，再用 , 分割 awk -vone=line '{print $1one,$2}' test2.log # 第一项拼接'line'字符 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:15","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#awk"},{"categories":["Linux"],"content":" sed","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:16","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#sed"},{"categories":["Linux"],"content":" rename rename '.repo' '.repo.bak' ./*.repo ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:2:17","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#rename"},{"categories":["Linux"],"content":" 网络","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:3:0","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#网络"},{"categories":["Linux"],"content":" 网络信息统计 netstat -a #列出所有连接 netstat -tnl #列出监听中的连接 nestat -nlpt #获取进程名、进程号以及用户 ID netstat -atnp | grep ESTA #打印active状态的连接 netstat -at/netstat -au #只列出TCP或者UDP ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:3:1","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#网络信息统计"},{"categories":["Linux"],"content":" tcpdump tcpdump -i eth0 #捕获特定网口数据包 tcpdump -c 1000 -i eth0 #捕获特定个数(1000)的包 tcpdump -w a.pcap -i eth0 #将捕获的包保存到文件 tcpdump -r a.pcap #读取pcap格式的包 tcpdump -i eth0 arp #指定捕获包的协议类型 tcpdump -i eth0 post 22 #捕获指定端口 tcpdump -i eth0 dst address and port 22 #捕获特定目标ip+port的包 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:3:2","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#tcpdump"},{"categories":["Linux"],"content":" iptables service iptables status # 查看iptables状态 iptables -I INPUT -s ***.***.***.*** -j DROP # 要封停一个ip iptables -D INPUT -s ***.***.***.*** -j DROP # 要解封一个IP，使用下面这条命令： 备注: 参数-I是表示Insert（添加），-D表示Delete（删除）。后面跟的是规则，INPUT表示入站，***.***.***.***表示要封停的IP，DROP表示放弃连接。 #开启9090端口的访问 /sbin/iptables -I INPUT -p tcp --dport 9090 -j ACCEPT # 防火墙开启、关闭、重启 /etc/init.d/iptables status /etc/init.d/iptables start /etc/init.d/iptables stop /etc/init.d/iptables restart ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:3:3","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#iptables"},{"categories":["Linux"],"content":" 程序","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:4:0","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#程序"},{"categories":["Linux"],"content":" 进程 pidof iscsid # 查看运行 iscsid 的进程号 lsof -i:8080 # 查看使用 8080 端口的程序 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:4:1","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#进程"},{"categories":["Linux"],"content":" rpm rpm -ivh package.rpm #安装一个rpm包 rpm -ivh --nodeeps package.rpm #安装一个rpm包而忽略依赖关系警告 rpm -U package.rpm #更新一个rpm包但不改变其配置文件 rpm -F package.rpm #更新一个确定已经安装的rpm包 rpm -e package_name.rpm #删除一个rpm包 rpm -qa #显示系统中所有已经安装的rpm包 rpm -qa | grep httpd #显示所有名称中包含 \"httpd\" 字样的rpm包 rpm -qi package_name #获取一个已安装包的特殊信息 rpm -qg \"System Environment/Daemons\" #显示一个组件的rpm包 rpm -ql package_name #显示一个已经安装的rpm包提供的文件列表 rpm -qc package_name #显示一个已经安装的rpm包提供的配置文件列表 rpm -q package_name --whatrequires #显示与一个rpm包存在依赖关系的列表 rpm -q package_name --whatprovides #显示一个rpm包所占的体积 rpm -q package_name --scripts #显示在安装/删除期间所执行的脚本l rpm -q package_name --changelog #显示一个rpm包的修改历史 rpm -qf /etc/httpd/conf/httpd.conf #确认所给的文件由哪个rpm包所提供 rpm -qp package.rpm -l #显示由一个尚未安装的rpm包提供的文件列表 rpm --import /media/cdrom/RPM-GPG-KEY #导入公钥数字证书 rpm --checksig package.rpm #确认一个rpm包的完整性 rpm -qa gpg-pubkey #确认已安装的所有rpm包的完整性 rpm -V package_name #检查文件尺寸、 许可、类型、所有者、群组、MD5检查以及最后修改时间 rpm -Va #检查系统中所有已安装的rpm包- 小心使用 rpm -Vp package.rpm #确认一个rpm包还未安装 rpm2cpio package.rpm | cpio --extract --make-directories *bin* #从一个rpm包运行可执行文件 rpm -ivh /usr/src/redhat/RPMS/`arch`/package.rpm #从一个rpm源码安装一个构建好的包 rpmbuild --rebuild package_name.src.rpm #从一个rpm源码构建一个 rpm 包 #安装 rpm -ivh xx.rpm #卸载 rpm -e --nodeps xx.rpm #降级 rpm -Uvh --oldpackage xx.rpm ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:4:2","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#rpm"},{"categories":["Linux"],"content":" yum yum install package_name #下载并安装一个rpm包 yum localinstall package_name.rpm #将安装一个rpm包，使用你自己的软件仓库为你解决所有依赖关系 yum update package_name.rpm #更新当前系统中所有安装的rpm包 yum update package_name #更新一个rpm包 yum remove package_name #删除一个rpm包 yum list #列出当前系统中安装的所有包 yum search package_name #在rpm仓库中搜寻软件包 yum clean packages #清理rpm缓存删除下载的包 yum clean headers #删除所有头文件 yum clean all #删除所有缓存的包和头文件 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:4:3","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#yum"},{"categories":["Linux"],"content":" apt apt-get install package_name #安装/更新一个 deb 包 apt-cdrom install package_name #从光盘安装/更新一个 deb 包 apt-get update #升级列表中的软件包 apt-get upgrade #升级所有已安装的软件 apt-get remove package_name #从系统删除一个deb包 apt-get check #确认依赖的软件仓库正确 apt-get clean #从下载的软件包中清理缓存 apt-cache search searched-package #返回包含所要搜索字符串的软件包名称 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:4:4","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#apt"},{"categories":["Linux"],"content":" wget wget -nd -r -l1 --no-parent http://admin.na.shared.opentlc.com/repos/ocp/3.11.51/rhel-7-server-ose-3.11-rpms/Packages/ ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:4:5","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#wget"},{"categories":["Linux"],"content":" 其他","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:5:0","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#其他"},{"categories":["Linux"],"content":" openssl 生成随机字符串 openssl rand -base64 12 | md5sum | cut -c1-12 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:5:1","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#openssl"},{"categories":["Linux"],"content":" sh #/bin/bash dir=$(dirname $0) # 获取脚本所在的目录 #... ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:5:2","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#sh"},{"categories":["Linux"],"content":" dd 测试写性能 time dd if=/dev/zero of=/test.txt bs=8k count=10000 oflag=direct 测试读性能 time dd if=/test.txt of=/dev/null bs=1M count=100 iflag=direct ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:5:3","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#dd"},{"categories":["Linux"],"content":" fping yum -y install epel-release fping -s -g 192.168.0.1 192.168.0.70 ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:5:4","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#fping"},{"categories":["Linux"],"content":" dlv dlv --listen=:2345 --headless=true --api-version=2 exec ./promApi ","date":"2023-05-12","objectID":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:5:5","series":["Linux命令使用"],"tags":[],"title":"Linux 常用命令","uri":"/202305121301-linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#dlv"},{"categories":["Linux"],"content":"#linux rpm 包下载：https://pkgs.org/ 记录一次在制作基础镜像的时候遇到的 yum 源问题 制作镜像的 dockerfile 如下 执行完图示的命令后，yum 源目录下生成了如下一些文件： 再次执行生成缓存命令的时候，出现了如下错误： cannot prepare internal mirrorlist: No URLs in mirrorlist 查看对应的 repo 文件，到对应的地址下看看： 解决方法： 使用旧的仓库 sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-* sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-* 重新创建缓存，发现有一个地址 404 了，应该也是没有在维护被弃用了： 打开这个网址找找看 发现已经没有相关的 rpm 包了 到对应的 centos 版本下找找： 发现这个版本下是有相关 rpm 包的，所以可以把 yum 源的 8-stream 换掉 问题得到解决。 ","date":"2023-05-12","objectID":"/202305121316-yum-%E6%BA%90%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/:0:0","series":["Linux命令使用"],"tags":[],"title":"yum 源问题记录","uri":"/202305121316-yum-%E6%BA%90%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95/#"},{"categories":["Golang"],"content":"#Golang ","date":"2023-05-12","objectID":"/202305121218-client-go/:0:0","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#"},{"categories":["Golang"],"content":" 一、基本了解","date":"2023-05-12","objectID":"/202305121218-client-go/:1:0","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#一基本了解"},{"categories":["Golang"],"content":" 1.1 基本概念、背景、用途client-go 是用于 Go 客户端与 Kubernetes 集群通信的一个开源项目 ","date":"2023-05-12","objectID":"/202305121218-client-go/:1:1","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#11-基本概念背景用途"},{"categories":["Golang"],"content":" 二、安装流程、使用","date":"2023-05-12","objectID":"/202305121218-client-go/:2:0","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#二安装流程使用"},{"categories":["Golang"],"content":" 2.1 安装 https://github.com/kubernetes/client-go/blob/master/INSTALL.md ","date":"2023-05-12","objectID":"/202305121218-client-go/:2:1","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#21-安装"},{"categories":["Golang"],"content":" 2.2 使用对于 client-go 的使用主要分两种场景： 应用程序运行在集群中的 Pod 中 –\u003e 使用集群内的方式（https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration） or –\u003e 使用集群外的方式（https://github.com/kubernetes/client-go/tree/master/examples/out-of-cluster-client-configuration） 2.2.1 简单使用（进群内外创建ClientSet，并与 Kubernetes API 通信）主要编码步骤 创建 cluster config（调用 InClusterConfig，使用 Pod 内的 token） Pod 内使用 InClusterConfig 创建 cluster config 不是 Pod 内的应用可以使用 kubeconfig 来初始化客户端 通过 cluster config 创建一个 client set 通过 client set 访问 Kubernetes API， 完成业务逻辑编码 2.2.1.1 集群内 https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration 应用程序运行在 Pod 内部的时候，使用安装在 Pod 内部的 /var/run/secrets/kubernetes.io/serviceaccount 路径下的 Service Account token main.go /* Copyright 2016 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ // Note: the example only works with the code within the same release/branch. package main import ( \"context\" \"fmt\" \"time\" \"k8s.io/apimachinery/pkg/api/errors\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/rest\" // // Uncomment to load all auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth\" // // Or uncomment to load specific auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth/azure\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/gcp\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/oidc\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/openstack\" ) func main() { // creates the in-cluster config config, err := rest.InClusterConfig() if err != nil { panic(err.Error()) } // creates the clientset clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err.Error()) } for { // get pods in all the namespaces by omitting namespace // Or specify namespace to get pods in particular namespace pods, err := clientset.CoreV1().Pods(\"\").List(context.TODO(), metav1.ListOptions{}) if err != nil { panic(err.Error()) } fmt.Printf(\"There are %d pods in the cluster\\n\", len(pods.Items)) // Examples for error handling: // - Use helper functions e.g. errors.IsNotFound() // - And/or cast to StatusError and use its properties like e.g. ErrStatus.Message _, err = clientset.CoreV1().Pods(\"default\").Get(context.TODO(), \"example-xxxxx\", metav1.GetOptions{}) if errors.IsNotFound(err) { fmt.Printf(\"Pod example-xxxxx not found in default namespace\\n\") } else if statusError, isStatus := err.(*errors.StatusError); isStatus { fmt.Printf(\"Error getting pod %v\\n\", statusError.ErrStatus.Message) } else if err != nil { panic(err.Error()) } else { fmt.Printf(\"Found example-xxxxx pod in default namespace\\n\") } time.Sleep(10 * time.Second) } } 构建二进制，构建 docker 镜像 go buidl -o app main.go docker build -t 904566722/in-cluster-app:1.0.0 使用该镜像启动一个 Pod apiVersion: v1 kind: ServiceAccount metadata: name: in-cluster-client-go namespace: default --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: in-cluster-client-go rules: - apiGroups: - '*' resources: - '*' verbs: - '*' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: in-cluster-client-go roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: in-cluster-client-go subjects: - kind: ServiceAccount name: in-cluster-client-go namespace: default --- apiVersion: v1 kind: Pod metadata: name: in-cluster-client-go namespace: default spec: serviceAccountName: in-cluster-client-go containers: - image: 904566722/in-cluster-app:1.0.0 imagePullPolicy: IfNotPresent name: client-go restartPolicy: Never 查看 Po","date":"2023-05-12","objectID":"/202305121218-client-go/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#22-使用"},{"categories":["Golang"],"content":" 2.2 使用对于 client-go 的使用主要分两种场景： 应用程序运行在集群中的 Pod 中 –\u003e 使用集群内的方式（https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration） or –\u003e 使用集群外的方式（https://github.com/kubernetes/client-go/tree/master/examples/out-of-cluster-client-configuration） 2.2.1 简单使用（进群内外创建ClientSet，并与 Kubernetes API 通信）主要编码步骤 创建 cluster config（调用 InClusterConfig，使用 Pod 内的 token） Pod 内使用 InClusterConfig 创建 cluster config 不是 Pod 内的应用可以使用 kubeconfig 来初始化客户端 通过 cluster config 创建一个 client set 通过 client set 访问 Kubernetes API， 完成业务逻辑编码 2.2.1.1 集群内 https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration 应用程序运行在 Pod 内部的时候，使用安装在 Pod 内部的 /var/run/secrets/kubernetes.io/serviceaccount 路径下的 Service Account token main.go /* Copyright 2016 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ // Note: the example only works with the code within the same release/branch. package main import ( \"context\" \"fmt\" \"time\" \"k8s.io/apimachinery/pkg/api/errors\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/rest\" // // Uncomment to load all auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth\" // // Or uncomment to load specific auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth/azure\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/gcp\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/oidc\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/openstack\" ) func main() { // creates the in-cluster config config, err := rest.InClusterConfig() if err != nil { panic(err.Error()) } // creates the clientset clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err.Error()) } for { // get pods in all the namespaces by omitting namespace // Or specify namespace to get pods in particular namespace pods, err := clientset.CoreV1().Pods(\"\").List(context.TODO(), metav1.ListOptions{}) if err != nil { panic(err.Error()) } fmt.Printf(\"There are %d pods in the cluster\\n\", len(pods.Items)) // Examples for error handling: // - Use helper functions e.g. errors.IsNotFound() // - And/or cast to StatusError and use its properties like e.g. ErrStatus.Message _, err = clientset.CoreV1().Pods(\"default\").Get(context.TODO(), \"example-xxxxx\", metav1.GetOptions{}) if errors.IsNotFound(err) { fmt.Printf(\"Pod example-xxxxx not found in default namespace\\n\") } else if statusError, isStatus := err.(*errors.StatusError); isStatus { fmt.Printf(\"Error getting pod %v\\n\", statusError.ErrStatus.Message) } else if err != nil { panic(err.Error()) } else { fmt.Printf(\"Found example-xxxxx pod in default namespace\\n\") } time.Sleep(10 * time.Second) } } 构建二进制，构建 docker 镜像 go buidl -o app main.go docker build -t 904566722/in-cluster-app:1.0.0 使用该镜像启动一个 Pod apiVersion: v1 kind: ServiceAccount metadata: name: in-cluster-client-go namespace: default --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: in-cluster-client-go rules: - apiGroups: - '*' resources: - '*' verbs: - '*' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: in-cluster-client-go roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: in-cluster-client-go subjects: - kind: ServiceAccount name: in-cluster-client-go namespace: default --- apiVersion: v1 kind: Pod metadata: name: in-cluster-client-go namespace: default spec: serviceAccountName: in-cluster-client-go containers: - image: 904566722/in-cluster-app:1.0.0 imagePullPolicy: IfNotPresent name: client-go restartPolicy: Never 查看 Po","date":"2023-05-12","objectID":"/202305121218-client-go/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#221-简单使用进群内外创建clientset并与-kubernetes-api-通信"},{"categories":["Golang"],"content":" 2.2 使用对于 client-go 的使用主要分两种场景： 应用程序运行在集群中的 Pod 中 –\u003e 使用集群内的方式（https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration） or –\u003e 使用集群外的方式（https://github.com/kubernetes/client-go/tree/master/examples/out-of-cluster-client-configuration） 2.2.1 简单使用（进群内外创建ClientSet，并与 Kubernetes API 通信）主要编码步骤 创建 cluster config（调用 InClusterConfig，使用 Pod 内的 token） Pod 内使用 InClusterConfig 创建 cluster config 不是 Pod 内的应用可以使用 kubeconfig 来初始化客户端 通过 cluster config 创建一个 client set 通过 client set 访问 Kubernetes API， 完成业务逻辑编码 2.2.1.1 集群内 https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration 应用程序运行在 Pod 内部的时候，使用安装在 Pod 内部的 /var/run/secrets/kubernetes.io/serviceaccount 路径下的 Service Account token main.go /* Copyright 2016 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ // Note: the example only works with the code within the same release/branch. package main import ( \"context\" \"fmt\" \"time\" \"k8s.io/apimachinery/pkg/api/errors\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/rest\" // // Uncomment to load all auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth\" // // Or uncomment to load specific auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth/azure\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/gcp\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/oidc\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/openstack\" ) func main() { // creates the in-cluster config config, err := rest.InClusterConfig() if err != nil { panic(err.Error()) } // creates the clientset clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err.Error()) } for { // get pods in all the namespaces by omitting namespace // Or specify namespace to get pods in particular namespace pods, err := clientset.CoreV1().Pods(\"\").List(context.TODO(), metav1.ListOptions{}) if err != nil { panic(err.Error()) } fmt.Printf(\"There are %d pods in the cluster\\n\", len(pods.Items)) // Examples for error handling: // - Use helper functions e.g. errors.IsNotFound() // - And/or cast to StatusError and use its properties like e.g. ErrStatus.Message _, err = clientset.CoreV1().Pods(\"default\").Get(context.TODO(), \"example-xxxxx\", metav1.GetOptions{}) if errors.IsNotFound(err) { fmt.Printf(\"Pod example-xxxxx not found in default namespace\\n\") } else if statusError, isStatus := err.(*errors.StatusError); isStatus { fmt.Printf(\"Error getting pod %v\\n\", statusError.ErrStatus.Message) } else if err != nil { panic(err.Error()) } else { fmt.Printf(\"Found example-xxxxx pod in default namespace\\n\") } time.Sleep(10 * time.Second) } } 构建二进制，构建 docker 镜像 go buidl -o app main.go docker build -t 904566722/in-cluster-app:1.0.0 使用该镜像启动一个 Pod apiVersion: v1 kind: ServiceAccount metadata: name: in-cluster-client-go namespace: default --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: in-cluster-client-go rules: - apiGroups: - '*' resources: - '*' verbs: - '*' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: in-cluster-client-go roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: in-cluster-client-go subjects: - kind: ServiceAccount name: in-cluster-client-go namespace: default --- apiVersion: v1 kind: Pod metadata: name: in-cluster-client-go namespace: default spec: serviceAccountName: in-cluster-client-go containers: - image: 904566722/in-cluster-app:1.0.0 imagePullPolicy: IfNotPresent name: client-go restartPolicy: Never 查看 Po","date":"2023-05-12","objectID":"/202305121218-client-go/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#2211-集群内"},{"categories":["Golang"],"content":" 2.2 使用对于 client-go 的使用主要分两种场景： 应用程序运行在集群中的 Pod 中 –\u003e 使用集群内的方式（https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration） or –\u003e 使用集群外的方式（https://github.com/kubernetes/client-go/tree/master/examples/out-of-cluster-client-configuration） 2.2.1 简单使用（进群内外创建ClientSet，并与 Kubernetes API 通信）主要编码步骤 创建 cluster config（调用 InClusterConfig，使用 Pod 内的 token） Pod 内使用 InClusterConfig 创建 cluster config 不是 Pod 内的应用可以使用 kubeconfig 来初始化客户端 通过 cluster config 创建一个 client set 通过 client set 访问 Kubernetes API， 完成业务逻辑编码 2.2.1.1 集群内 https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration 应用程序运行在 Pod 内部的时候，使用安装在 Pod 内部的 /var/run/secrets/kubernetes.io/serviceaccount 路径下的 Service Account token main.go /* Copyright 2016 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ // Note: the example only works with the code within the same release/branch. package main import ( \"context\" \"fmt\" \"time\" \"k8s.io/apimachinery/pkg/api/errors\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/rest\" // // Uncomment to load all auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth\" // // Or uncomment to load specific auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth/azure\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/gcp\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/oidc\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/openstack\" ) func main() { // creates the in-cluster config config, err := rest.InClusterConfig() if err != nil { panic(err.Error()) } // creates the clientset clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err.Error()) } for { // get pods in all the namespaces by omitting namespace // Or specify namespace to get pods in particular namespace pods, err := clientset.CoreV1().Pods(\"\").List(context.TODO(), metav1.ListOptions{}) if err != nil { panic(err.Error()) } fmt.Printf(\"There are %d pods in the cluster\\n\", len(pods.Items)) // Examples for error handling: // - Use helper functions e.g. errors.IsNotFound() // - And/or cast to StatusError and use its properties like e.g. ErrStatus.Message _, err = clientset.CoreV1().Pods(\"default\").Get(context.TODO(), \"example-xxxxx\", metav1.GetOptions{}) if errors.IsNotFound(err) { fmt.Printf(\"Pod example-xxxxx not found in default namespace\\n\") } else if statusError, isStatus := err.(*errors.StatusError); isStatus { fmt.Printf(\"Error getting pod %v\\n\", statusError.ErrStatus.Message) } else if err != nil { panic(err.Error()) } else { fmt.Printf(\"Found example-xxxxx pod in default namespace\\n\") } time.Sleep(10 * time.Second) } } 构建二进制，构建 docker 镜像 go buidl -o app main.go docker build -t 904566722/in-cluster-app:1.0.0 使用该镜像启动一个 Pod apiVersion: v1 kind: ServiceAccount metadata: name: in-cluster-client-go namespace: default --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: in-cluster-client-go rules: - apiGroups: - '*' resources: - '*' verbs: - '*' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: in-cluster-client-go roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: in-cluster-client-go subjects: - kind: ServiceAccount name: in-cluster-client-go namespace: default --- apiVersion: v1 kind: Pod metadata: name: in-cluster-client-go namespace: default spec: serviceAccountName: in-cluster-client-go containers: - image: 904566722/in-cluster-app:1.0.0 imagePullPolicy: IfNotPresent name: client-go restartPolicy: Never 查看 Po","date":"2023-05-12","objectID":"/202305121218-client-go/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#2211-集群外"},{"categories":["Golang"],"content":" 2.2 使用对于 client-go 的使用主要分两种场景： 应用程序运行在集群中的 Pod 中 –\u003e 使用集群内的方式（https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration） or –\u003e 使用集群外的方式（https://github.com/kubernetes/client-go/tree/master/examples/out-of-cluster-client-configuration） 2.2.1 简单使用（进群内外创建ClientSet，并与 Kubernetes API 通信）主要编码步骤 创建 cluster config（调用 InClusterConfig，使用 Pod 内的 token） Pod 内使用 InClusterConfig 创建 cluster config 不是 Pod 内的应用可以使用 kubeconfig 来初始化客户端 通过 cluster config 创建一个 client set 通过 client set 访问 Kubernetes API， 完成业务逻辑编码 2.2.1.1 集群内 https://github.com/kubernetes/client-go/tree/master/examples/in-cluster-client-configuration 应用程序运行在 Pod 内部的时候，使用安装在 Pod 内部的 /var/run/secrets/kubernetes.io/serviceaccount 路径下的 Service Account token main.go /* Copyright 2016 The Kubernetes Authors. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */ // Note: the example only works with the code within the same release/branch. package main import ( \"context\" \"fmt\" \"time\" \"k8s.io/apimachinery/pkg/api/errors\" metav1 \"k8s.io/apimachinery/pkg/apis/meta/v1\" \"k8s.io/client-go/kubernetes\" \"k8s.io/client-go/rest\" // // Uncomment to load all auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth\" // // Or uncomment to load specific auth plugins // _ \"k8s.io/client-go/plugin/pkg/client/auth/azure\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/gcp\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/oidc\" // _ \"k8s.io/client-go/plugin/pkg/client/auth/openstack\" ) func main() { // creates the in-cluster config config, err := rest.InClusterConfig() if err != nil { panic(err.Error()) } // creates the clientset clientset, err := kubernetes.NewForConfig(config) if err != nil { panic(err.Error()) } for { // get pods in all the namespaces by omitting namespace // Or specify namespace to get pods in particular namespace pods, err := clientset.CoreV1().Pods(\"\").List(context.TODO(), metav1.ListOptions{}) if err != nil { panic(err.Error()) } fmt.Printf(\"There are %d pods in the cluster\\n\", len(pods.Items)) // Examples for error handling: // - Use helper functions e.g. errors.IsNotFound() // - And/or cast to StatusError and use its properties like e.g. ErrStatus.Message _, err = clientset.CoreV1().Pods(\"default\").Get(context.TODO(), \"example-xxxxx\", metav1.GetOptions{}) if errors.IsNotFound(err) { fmt.Printf(\"Pod example-xxxxx not found in default namespace\\n\") } else if statusError, isStatus := err.(*errors.StatusError); isStatus { fmt.Printf(\"Error getting pod %v\\n\", statusError.ErrStatus.Message) } else if err != nil { panic(err.Error()) } else { fmt.Printf(\"Found example-xxxxx pod in default namespace\\n\") } time.Sleep(10 * time.Second) } } 构建二进制，构建 docker 镜像 go buidl -o app main.go docker build -t 904566722/in-cluster-app:1.0.0 使用该镜像启动一个 Pod apiVersion: v1 kind: ServiceAccount metadata: name: in-cluster-client-go namespace: default --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: name: in-cluster-client-go rules: - apiGroups: - '*' resources: - '*' verbs: - '*' --- apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRoleBinding metadata: name: in-cluster-client-go roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: in-cluster-client-go subjects: - kind: ServiceAccount name: in-cluster-client-go namespace: default --- apiVersion: v1 kind: Pod metadata: name: in-cluster-client-go namespace: default spec: serviceAccountName: in-cluster-client-go containers: - image: 904566722/in-cluster-app:1.0.0 imagePullPolicy: IfNotPresent name: client-go restartPolicy: Never 查看 Po","date":"2023-05-12","objectID":"/202305121218-client-go/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#222-创建更新删除一个-deployment"},{"categories":["Golang"],"content":" 三、代码组织","date":"2023-05-12","objectID":"/202305121218-client-go/:3:0","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#三代码组织"},{"categories":["Golang"],"content":" 3.1 目录结构 ","date":"2023-05-12","objectID":"/202305121218-client-go/:3:1","series":["Golang辅助开发框架"],"tags":[],"title":"client-go","uri":"/202305121218-client-go/#31-目录结构"},{"categories":["Golang"],"content":"#测试 ","date":"2023-05-12","objectID":"/202305121208-ginkgo/:0:0","series":["Golang辅助开发框架"],"tags":[],"title":"ginkgo 简单使用","uri":"/202305121208-ginkgo/#"},{"categories":["Golang"],"content":" 安装、使用安装 go get -u github.com/onsi/ginkgo/v2/ginkgo go get -u github.com/onsi/gomega/... ","date":"2023-05-12","objectID":"/202305121208-ginkgo/:1:0","series":["Golang辅助开发框架"],"tags":[],"title":"ginkgo 简单使用","uri":"/202305121208-ginkgo/#安装使用"},{"categories":["Golang"],"content":" 写作规范","date":"2023-05-12","objectID":"/202305121208-ginkgo/:2:0","series":["Golang辅助开发框架"],"tags":[],"title":"ginkgo 简单使用","uri":"/202305121208-ginkgo/#写作规范"},{"categories":["Golang"],"content":" 组织结构Ginkgo 广泛使用闭包来构建描述性规范层次结构（以代码组织形式的方式来描述代码行为），这个结构层次是使用三种类型的节点来构建的： container node 容器节点 用来组织正在测试的代码的不同方面 例如： Describe、Context、When 通常使用 Describe 使用代码的不同功能，使用 Context 探索每种功能的行为 setup node 设置节点 用来设置规范的状态 例如：BeforeEach subject node 主题节点 用来编写一个规范 container、setup、subject node 形成一个规范树： var _ = Describe(\"Book\", func() { var foxInSocks, lesMis *books.Book // 共享变量（设置节点和主题节点之间共享的变量） BeforeEach(func() { // 设置节点 lesMis = \u0026books.Book{ Title: \"Les Miserables\", Author: \"Victor Hugo\", Pages: 2783, } foxInSocks = \u0026books.Book{ Title: \"Fox In Socks\", Author: \"Dr. Seuss\", Pages: 24, } }) Describe(\"Categorizing books\", func() { Context(\"with more than 300 pages\", func() { It(\"should be a novel\", func() { // 主题节点 gomega.Expect(lesMis.Category(), books.CategoryNovel) }) }) Context(\"with fewer than 300 pages\", func() { It(\"should be a short story\", func() { gomega.Expect(foxInSocks.Category(), books.CategoryShortStory) }) }) }) }) ","date":"2023-05-12","objectID":"/202305121208-ginkgo/:2:1","series":["Golang辅助开发框架"],"tags":[],"title":"ginkgo 简单使用","uri":"/202305121208-ginkgo/#组织结构"},{"categories":["Golang"],"content":" 注意点 一个规范可以设置多个节点，但是只能有一个主题节点 每个规范之间应该是完全独立的，这运行 Ginkgo 打乱顺序，并行运行规范 在容器节点中声明，在设置节点中初始化 断言应该在设置节点或者主题节点中，不应该出现在容器节点 Describe 是 Ginkgo DSL 的一部分，具有描述、闭包的功能；一个 Describe 可理解为一个容器 BeforeEach节点 是Setup 节点节点，其闭包在 It 节点闭包之前运行。当在嵌套的 Container 节点中定义了多个 BeforeEach 节点时，最外层的 BeforeEach 节点闭包首先运行，BeforeEach 会在每个 It 运行之前运行 AfterEach 、DeferCleanup 用于清理或者将环境恢复到之前的状态 Context是 Describe 的别名 - 它生成完全相同类型的 Container 节点 It 是一个规范主题，每个规范都只有一个主题节点 BeforeSuite AfterSuite ","date":"2023-05-12","objectID":"/202305121208-ginkgo/:2:2","series":["Golang辅助开发框架"],"tags":[],"title":"ginkgo 简单使用","uri":"/202305121208-ginkgo/#注意点"},{"categories":["Golang"],"content":" ginkgo cli # 初始化套件（suite） ginkgo bootstrap # 运行 ginkgo # 添加规格（spec） ginkgo generate \u003c规格名\u003e github： https://github.com/onsi/ginkgo github：https://github.com/onsi/gomega ginkgo 文档：https://onsi.github.io/ginkgo/ ","date":"2023-05-12","objectID":"/202305121208-ginkgo/:3:0","series":["Golang辅助开发框架"],"tags":[],"title":"ginkgo 简单使用","uri":"/202305121208-ginkgo/#ginkgo-cli"},{"categories":["Golang"],"content":"#Golang Go 语言的接口相关概念？ Go 语言的接口长什么样？ Go 语言的接口用来做什么？ 与其他语言的接口有什么对比？ ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:0:0","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#"},{"categories":["Golang"],"content":" 一、Go 语言的接口","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:0","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#一go-语言的接口"},{"categories":["Golang"],"content":" 1.1 相关概念 总结： 接口： 方法定义的集合，说明想要做的一系列事情 一个类型可以实现多个接口 Go 语言并不是像 Java 那样传统的面向对象的语言，没有像 Java 中 类、继承之类的概念 如果把方法分为两部分：定义与实现 定义：定义其实就是在说明这个方法想要做什么 实现：实现就具体地说明了怎么做 举个例子： // Sum 求和 // 方法的组成部分： // 1. 定义 // 2. 逻辑 func Sum(a int, b int) int { // 1. 定义（我想要求和） return a + b // 2. 具体逻辑（怎么求和） } 在Go 语言中，接口就是一系列方法定义的集合，用来说明对象具备的行为，接口的概念能够让 Go 做一些面向对象的事情 因此如果把 Go 的接口映射到生活中的话，接口相当于就是划分了一些想要做的事，谁如果有能力能够完成划分的这些事情，谁就相当与实现了这个接口 Go 一个类型可以实现多个接口（能力高的人能够完成更多想要做的事情） ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:1","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#11-相关概念"},{"categories":["Golang"],"content":" 1.2 接口的写法 1.2.1 正常实现 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } // ... 其他接口 例如，一个程序员需要会编码、学习…，一个画家需要会观察、画画… 如果有个人具备程序员跟画家的能力，那么他就能实现这两个接口 type Honghuiqiang struct { Name string } func (h *Honghuiqiang) Coding() string { return \"i can coding...\" } func (h *Honghuiqiang) Study() string { return \"i can study...\" } func (h *Honghuiqiang) Observing() string { return \"i can observing\" } func (h *Honghuiqiang) Painting() string { return \"i can painting...\" } 1.2.2 嵌套接口 其实就是接口的组合 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } type Artist interface { Programmer Painter } Artist 接口就等同于： type Artist interface { Coding() string Study() string Observing() string Painting() string } 1.2.3 空接口","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:2","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#12-接口的写法"},{"categories":["Golang"],"content":" 1.2 接口的写法 1.2.1 正常实现 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } // ... 其他接口 例如，一个程序员需要会编码、学习…，一个画家需要会观察、画画… 如果有个人具备程序员跟画家的能力，那么他就能实现这两个接口 type Honghuiqiang struct { Name string } func (h *Honghuiqiang) Coding() string { return \"i can coding...\" } func (h *Honghuiqiang) Study() string { return \"i can study...\" } func (h *Honghuiqiang) Observing() string { return \"i can observing\" } func (h *Honghuiqiang) Painting() string { return \"i can painting...\" } 1.2.2 嵌套接口 其实就是接口的组合 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } type Artist interface { Programmer Painter } Artist 接口就等同于： type Artist interface { Coding() string Study() string Observing() string Painting() string } 1.2.3 空接口","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:2","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#121-正常实现"},{"categories":["Golang"],"content":" 1.2 接口的写法 1.2.1 正常实现 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } // ... 其他接口 例如，一个程序员需要会编码、学习…，一个画家需要会观察、画画… 如果有个人具备程序员跟画家的能力，那么他就能实现这两个接口 type Honghuiqiang struct { Name string } func (h *Honghuiqiang) Coding() string { return \"i can coding...\" } func (h *Honghuiqiang) Study() string { return \"i can study...\" } func (h *Honghuiqiang) Observing() string { return \"i can observing\" } func (h *Honghuiqiang) Painting() string { return \"i can painting...\" } 1.2.2 嵌套接口 其实就是接口的组合 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } type Artist interface { Programmer Painter } Artist 接口就等同于： type Artist interface { Coding() string Study() string Observing() string Painting() string } 1.2.3 空接口","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:2","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#122-嵌套接口"},{"categories":["Golang"],"content":" 1.2 接口的写法 1.2.1 正常实现 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } // ... 其他接口 例如，一个程序员需要会编码、学习…，一个画家需要会观察、画画… 如果有个人具备程序员跟画家的能力，那么他就能实现这两个接口 type Honghuiqiang struct { Name string } func (h *Honghuiqiang) Coding() string { return \"i can coding...\" } func (h *Honghuiqiang) Study() string { return \"i can study...\" } func (h *Honghuiqiang) Observing() string { return \"i can observing\" } func (h *Honghuiqiang) Painting() string { return \"i can painting...\" } 1.2.2 嵌套接口 其实就是接口的组合 // 程序员接口 type Programmer interface { // 一系列的方法定义，说明这个接口想要做的事情（或者说能够做到的事情） Coding() string Study() string //... } // 画家接口 type Painter interface { Observing() string Painting() string //... } type Artist interface { Programmer Painter } Artist 接口就等同于： type Artist interface { Coding() string Study() string Observing() string Painting() string } 1.2.3 空接口","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:2","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#123-空接口"},{"categories":["Golang"],"content":" 1.3 接口可以用来做什么？ 1.3.1 如何利用接口编写更干净、更具扩展性的代码？ 1.3.1.1 Example 1. 排序 1.3.2 实现多态 多态：一个方法的多种状态 type Stringer interface { Cut(s string) string } type CuterA struct { target string } type CuterB struct { target string } func (a CuterA) Cut(s string) string { return strings.Replace(s, a.target, \"\", -1) } func (b CuterB) Cut(s string) string { return strings.Replace(s, b.target, \"\", -1) } func cut(s string, t Stringer) string { return t.Cut(s) } func P2_1() { var a Stringer = CuterA{target: \"a\"} var b Stringer = CuterB{target: \"b\"} fmt.Println(cut(\"ababab\", a)) fmt.Println(cut(\"ababab\", b)) /* 相同的 cut 方法根据类型的不同体现出不同的行为 rst: bbb aaa */ } ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:3","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#13-接口可以用来做什么"},{"categories":["Golang"],"content":" 1.3 接口可以用来做什么？ 1.3.1 如何利用接口编写更干净、更具扩展性的代码？ 1.3.1.1 Example 1. 排序 1.3.2 实现多态 多态：一个方法的多种状态 type Stringer interface { Cut(s string) string } type CuterA struct { target string } type CuterB struct { target string } func (a CuterA) Cut(s string) string { return strings.Replace(s, a.target, \"\", -1) } func (b CuterB) Cut(s string) string { return strings.Replace(s, b.target, \"\", -1) } func cut(s string, t Stringer) string { return t.Cut(s) } func P2_1() { var a Stringer = CuterA{target: \"a\"} var b Stringer = CuterB{target: \"b\"} fmt.Println(cut(\"ababab\", a)) fmt.Println(cut(\"ababab\", b)) /* 相同的 cut 方法根据类型的不同体现出不同的行为 rst: bbb aaa */ } ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:3","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#131-如何利用接口编写更干净更具扩展性的代码"},{"categories":["Golang"],"content":" 1.3 接口可以用来做什么？ 1.3.1 如何利用接口编写更干净、更具扩展性的代码？ 1.3.1.1 Example 1. 排序 1.3.2 实现多态 多态：一个方法的多种状态 type Stringer interface { Cut(s string) string } type CuterA struct { target string } type CuterB struct { target string } func (a CuterA) Cut(s string) string { return strings.Replace(s, a.target, \"\", -1) } func (b CuterB) Cut(s string) string { return strings.Replace(s, b.target, \"\", -1) } func cut(s string, t Stringer) string { return t.Cut(s) } func P2_1() { var a Stringer = CuterA{target: \"a\"} var b Stringer = CuterB{target: \"b\"} fmt.Println(cut(\"ababab\", a)) fmt.Println(cut(\"ababab\", b)) /* 相同的 cut 方法根据类型的不同体现出不同的行为 rst: bbb aaa */ } ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:3","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#1311-example-1-排序"},{"categories":["Golang"],"content":" 1.3 接口可以用来做什么？ 1.3.1 如何利用接口编写更干净、更具扩展性的代码？ 1.3.1.1 Example 1. 排序 1.3.2 实现多态 多态：一个方法的多种状态 type Stringer interface { Cut(s string) string } type CuterA struct { target string } type CuterB struct { target string } func (a CuterA) Cut(s string) string { return strings.Replace(s, a.target, \"\", -1) } func (b CuterB) Cut(s string) string { return strings.Replace(s, b.target, \"\", -1) } func cut(s string, t Stringer) string { return t.Cut(s) } func P2_1() { var a Stringer = CuterA{target: \"a\"} var b Stringer = CuterB{target: \"b\"} fmt.Println(cut(\"ababab\", a)) fmt.Println(cut(\"ababab\", b)) /* 相同的 cut 方法根据类型的不同体现出不同的行为 rst: bbb aaa */ } ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:3","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#132-实现多态"},{"categories":["Golang"],"content":" 1.4 类型断言既然一个接口可以被多个类型实现，那么就会产生对于接口实际类型的一个判断，即类型断言 比较好的写法应该是这样的： if v, ok := varT.(T); ok { // ... } 结构： 例子： // Stringer is Interface var a Stringer = CuterA{target: \"a\"} var b Stringer = CuterB{target: \"b\"} var s = []Stringer{a, b} for i, c := range s { if v, ok := c.(CuterA); ok { fmt.Printf(\"判断是类型 CuterA 成功(下标: %d; 值: %v)\", i, v) } } /* rst: 判断是类型 CuterA 成功(下标: 0; 值: {a}) */ ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:1:4","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#14-类型断言"},{"categories":["Golang"],"content":" Q\u0026A ","date":"2023-05-12","objectID":"/202305121222-%E6%8E%A5%E5%8F%A3/:2:0","series":["Golang语言使用"],"tags":["接口"],"title":"Golang 接口学习","uri":"/202305121222-%E6%8E%A5%E5%8F%A3/#qa"},{"categories":["Linux"],"content":"#linux ","date":"2023-05-12","objectID":"/202305121256-linux-%E8%B5%B7-nfs-%E6%9C%8D%E5%8A%A1/:0:0","series":["Linux-box"],"tags":["linux","nfs"],"title":"linux 起 nfs 服务","uri":"/202305121256-linux-%E8%B5%B7-nfs-%E6%9C%8D%E5%8A%A1/#"},{"categories":["Linux"],"content":" 安装软件包 yum install rpcbind nfs-utils 创建共享目录 mkdir /home/test chmod -R 777 /home/test/ cd /home/test/ echo \"hello nfs!\" \u003e hello-nfs.txt 修改服务端配置文件 vim /etc/exports # 配置允许的网段以及权限 /home/test 192.168.121.0/24(rw) 开启服务 systemctl start rpcbind systemctl start nfs-server 客户端查看服务端的共享信息 showmount -e 10.253.8.90 创建目录，挂载 mkdir /mnt/test mount 10.253.8.90:/home/test /mnt/test ","date":"2023-05-12","objectID":"/202305121256-linux-%E8%B5%B7-nfs-%E6%9C%8D%E5%8A%A1/:1:0","series":["Linux-box"],"tags":["linux","nfs"],"title":"linux 起 nfs 服务","uri":"/202305121256-linux-%E8%B5%B7-nfs-%E6%9C%8D%E5%8A%A1/#heading"},{"categories":["MySQL"],"content":"#mysql 进入数据库 mysql -uroot -p # login show databases; use db_name; # 选择数据库 show tables; # 显示表 增删改查 select * from table_name; # where 条件查询 # = # \u003c\u003e != # \u003c \u003c= \u003e \u003e= # between a and b # is NULL is not NULL delete from outcome where id=1; update table_name set remark='motify' where id=1; insert into table_name (field1, ...) where (value1, ...); 修改密码 ALTER USER 'root'@'localhost' IDENTIFIED BY '1ASDinnocent'; ","date":"2023-05-12","objectID":"/202305121233-mysql-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/:0:0","series":["MySQL使用"],"tags":["mysql命令"],"title":"MySQL 常用命令","uri":"/202305121233-mysql-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/#"},{"categories":["Golang"],"content":" 一、基本了解 https://github.com/spf13/pflag ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:1:0","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#一基本了解"},{"categories":["Golang"],"content":" 1.1 基本概念pflag 是 Go 的 flag 包的替代品， 实现了 POSIX/GNU 风格的 –flags ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:1:1","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#11-基本概念"},{"categories":["Golang"],"content":" 二、安装、使用","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:0","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#二安装使用"},{"categories":["Golang"],"content":" 2.1 安装go.mod module Go go 1.17 require ( \"github.com/spf13/pflag\" v1.0.5 ) ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:1","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#21-安装"},{"categories":["Golang"],"content":" 2.2 使用导入包 import \"github.com/spf13/pflag\" 2.2.1 简单使用 import ( \"github.com/spf13/pflag\" \"log\" ) const DefaultIP = \"192.168.1.1\" type MyServerOption struct { LogDir string Ip string } func NewServerOption() *MyServerOption { return \u0026MyServerOption{} } func (s *MyServerOption) AddFlags(fs *pflag.FlagSet) { log.Println(fs) fs.StringVar(\u0026s.LogDir, \"log-dir\", s.LogDir, \"服务的日志路径\") fs.StringVar(\u0026s.Ip, \"ip\", DefaultIP, \"服务ip\") // 运行二进制的时候不指定 ip 参数将设置为该默认值 } func main() { s := testpflag.NewServerOption() s.AddFlags(pflag.CommandLine) pflag.Parse() log.Println(s) } [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 pflag: help requested 2.2.2 提供单字母简写 fs.StringVarP(\u0026s.Name, \"name\", \"n\", \"default name\", \"服务名称\") 使用 VarP 的形式绑定参数之后，可以以 “–name” 或者 “-n” 来指定 [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") pflag: help requested 2.2.3 规范化标志的名称(相当于设置别名)使用 FlagSet 的方法 SetNormalizeFunc 允许我们自定义一个函数来翻译标志名，例如一个 “URL” 的标志名可以被翻译为 “url” 规范化前： [root@master pflag]# ./pflag --url=\"hello.com\" unknown flag: --url Usage of ./pflag: --URL string 地址 (default \"hhq.com\") --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") unknown flag: --url 规范化后： ./pflag --url=\"hello.com\" 2022/09/16 02:41:43 \u0026{ 192.168.1.1 default name hello.com} 代码： func main() { s := testpflag.NewServerOption() fs := pflag.CommandLine s.AddFlags(fs) fs.SetNormalizeFunc(CaseInsensitiveFunc) pflag.Parse() log.Println(s) } // CaseInsensitiveFunc 不区分标志名的大小写 func CaseInsensitiveFunc(fs *pflag.FlagSet, name string) pflag.NormalizedName { return pflag.NormalizedName(strings.ToLower(name)) } 2.2.4 弃用一个标志 err := fs.MarkDeprecated(\"bad-flag\", \"这个标志已经弃用,请使用新的标志：--good-flag\") if err != nil { log.Println(\"弃用标志失败\") } 说明弃用 “–bad-flag” 这个标志，如果用户继续使用这个标识，将给出说明 [root@master pflag]# ./pflag --bad-flag=aa Flag --bad-flag has been deprecated, 这个标志已经弃用,请使用新的标志：--good-flag 2022/09/16 02:47:10 \u0026{ 192.168.1.1 default name hhq.com aa} ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:2","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#22-使用"},{"categories":["Golang"],"content":" 2.2 使用导入包 import \"github.com/spf13/pflag\" 2.2.1 简单使用 import ( \"github.com/spf13/pflag\" \"log\" ) const DefaultIP = \"192.168.1.1\" type MyServerOption struct { LogDir string Ip string } func NewServerOption() *MyServerOption { return \u0026MyServerOption{} } func (s *MyServerOption) AddFlags(fs *pflag.FlagSet) { log.Println(fs) fs.StringVar(\u0026s.LogDir, \"log-dir\", s.LogDir, \"服务的日志路径\") fs.StringVar(\u0026s.Ip, \"ip\", DefaultIP, \"服务ip\") // 运行二进制的时候不指定 ip 参数将设置为该默认值 } func main() { s := testpflag.NewServerOption() s.AddFlags(pflag.CommandLine) pflag.Parse() log.Println(s) } [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 pflag: help requested 2.2.2 提供单字母简写 fs.StringVarP(\u0026s.Name, \"name\", \"n\", \"default name\", \"服务名称\") 使用 VarP 的形式绑定参数之后，可以以 “–name” 或者 “-n” 来指定 [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") pflag: help requested 2.2.3 规范化标志的名称(相当于设置别名)使用 FlagSet 的方法 SetNormalizeFunc 允许我们自定义一个函数来翻译标志名，例如一个 “URL” 的标志名可以被翻译为 “url” 规范化前： [root@master pflag]# ./pflag --url=\"hello.com\" unknown flag: --url Usage of ./pflag: --URL string 地址 (default \"hhq.com\") --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") unknown flag: --url 规范化后： ./pflag --url=\"hello.com\" 2022/09/16 02:41:43 \u0026{ 192.168.1.1 default name hello.com} 代码： func main() { s := testpflag.NewServerOption() fs := pflag.CommandLine s.AddFlags(fs) fs.SetNormalizeFunc(CaseInsensitiveFunc) pflag.Parse() log.Println(s) } // CaseInsensitiveFunc 不区分标志名的大小写 func CaseInsensitiveFunc(fs *pflag.FlagSet, name string) pflag.NormalizedName { return pflag.NormalizedName(strings.ToLower(name)) } 2.2.4 弃用一个标志 err := fs.MarkDeprecated(\"bad-flag\", \"这个标志已经弃用,请使用新的标志：--good-flag\") if err != nil { log.Println(\"弃用标志失败\") } 说明弃用 “–bad-flag” 这个标志，如果用户继续使用这个标识，将给出说明 [root@master pflag]# ./pflag --bad-flag=aa Flag --bad-flag has been deprecated, 这个标志已经弃用,请使用新的标志：--good-flag 2022/09/16 02:47:10 \u0026{ 192.168.1.1 default name hhq.com aa} ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:2","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#221-简单使用"},{"categories":["Golang"],"content":" 2.2 使用导入包 import \"github.com/spf13/pflag\" 2.2.1 简单使用 import ( \"github.com/spf13/pflag\" \"log\" ) const DefaultIP = \"192.168.1.1\" type MyServerOption struct { LogDir string Ip string } func NewServerOption() *MyServerOption { return \u0026MyServerOption{} } func (s *MyServerOption) AddFlags(fs *pflag.FlagSet) { log.Println(fs) fs.StringVar(\u0026s.LogDir, \"log-dir\", s.LogDir, \"服务的日志路径\") fs.StringVar(\u0026s.Ip, \"ip\", DefaultIP, \"服务ip\") // 运行二进制的时候不指定 ip 参数将设置为该默认值 } func main() { s := testpflag.NewServerOption() s.AddFlags(pflag.CommandLine) pflag.Parse() log.Println(s) } [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 pflag: help requested 2.2.2 提供单字母简写 fs.StringVarP(\u0026s.Name, \"name\", \"n\", \"default name\", \"服务名称\") 使用 VarP 的形式绑定参数之后，可以以 “–name” 或者 “-n” 来指定 [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") pflag: help requested 2.2.3 规范化标志的名称(相当于设置别名)使用 FlagSet 的方法 SetNormalizeFunc 允许我们自定义一个函数来翻译标志名，例如一个 “URL” 的标志名可以被翻译为 “url” 规范化前： [root@master pflag]# ./pflag --url=\"hello.com\" unknown flag: --url Usage of ./pflag: --URL string 地址 (default \"hhq.com\") --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") unknown flag: --url 规范化后： ./pflag --url=\"hello.com\" 2022/09/16 02:41:43 \u0026{ 192.168.1.1 default name hello.com} 代码： func main() { s := testpflag.NewServerOption() fs := pflag.CommandLine s.AddFlags(fs) fs.SetNormalizeFunc(CaseInsensitiveFunc) pflag.Parse() log.Println(s) } // CaseInsensitiveFunc 不区分标志名的大小写 func CaseInsensitiveFunc(fs *pflag.FlagSet, name string) pflag.NormalizedName { return pflag.NormalizedName(strings.ToLower(name)) } 2.2.4 弃用一个标志 err := fs.MarkDeprecated(\"bad-flag\", \"这个标志已经弃用,请使用新的标志：--good-flag\") if err != nil { log.Println(\"弃用标志失败\") } 说明弃用 “–bad-flag” 这个标志，如果用户继续使用这个标识，将给出说明 [root@master pflag]# ./pflag --bad-flag=aa Flag --bad-flag has been deprecated, 这个标志已经弃用,请使用新的标志：--good-flag 2022/09/16 02:47:10 \u0026{ 192.168.1.1 default name hhq.com aa} ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:2","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#222-提供单字母简写"},{"categories":["Golang"],"content":" 2.2 使用导入包 import \"github.com/spf13/pflag\" 2.2.1 简单使用 import ( \"github.com/spf13/pflag\" \"log\" ) const DefaultIP = \"192.168.1.1\" type MyServerOption struct { LogDir string Ip string } func NewServerOption() *MyServerOption { return \u0026MyServerOption{} } func (s *MyServerOption) AddFlags(fs *pflag.FlagSet) { log.Println(fs) fs.StringVar(\u0026s.LogDir, \"log-dir\", s.LogDir, \"服务的日志路径\") fs.StringVar(\u0026s.Ip, \"ip\", DefaultIP, \"服务ip\") // 运行二进制的时候不指定 ip 参数将设置为该默认值 } func main() { s := testpflag.NewServerOption() s.AddFlags(pflag.CommandLine) pflag.Parse() log.Println(s) } [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 pflag: help requested 2.2.2 提供单字母简写 fs.StringVarP(\u0026s.Name, \"name\", \"n\", \"default name\", \"服务名称\") 使用 VarP 的形式绑定参数之后，可以以 “–name” 或者 “-n” 来指定 [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") pflag: help requested 2.2.3 规范化标志的名称(相当于设置别名)使用 FlagSet 的方法 SetNormalizeFunc 允许我们自定义一个函数来翻译标志名，例如一个 “URL” 的标志名可以被翻译为 “url” 规范化前： [root@master pflag]# ./pflag --url=\"hello.com\" unknown flag: --url Usage of ./pflag: --URL string 地址 (default \"hhq.com\") --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") unknown flag: --url 规范化后： ./pflag --url=\"hello.com\" 2022/09/16 02:41:43 \u0026{ 192.168.1.1 default name hello.com} 代码： func main() { s := testpflag.NewServerOption() fs := pflag.CommandLine s.AddFlags(fs) fs.SetNormalizeFunc(CaseInsensitiveFunc) pflag.Parse() log.Println(s) } // CaseInsensitiveFunc 不区分标志名的大小写 func CaseInsensitiveFunc(fs *pflag.FlagSet, name string) pflag.NormalizedName { return pflag.NormalizedName(strings.ToLower(name)) } 2.2.4 弃用一个标志 err := fs.MarkDeprecated(\"bad-flag\", \"这个标志已经弃用,请使用新的标志：--good-flag\") if err != nil { log.Println(\"弃用标志失败\") } 说明弃用 “–bad-flag” 这个标志，如果用户继续使用这个标识，将给出说明 [root@master pflag]# ./pflag --bad-flag=aa Flag --bad-flag has been deprecated, 这个标志已经弃用,请使用新的标志：--good-flag 2022/09/16 02:47:10 \u0026{ 192.168.1.1 default name hhq.com aa} ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:2","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#223-规范化标志的名称相当于设置别名"},{"categories":["Golang"],"content":" 2.2 使用导入包 import \"github.com/spf13/pflag\" 2.2.1 简单使用 import ( \"github.com/spf13/pflag\" \"log\" ) const DefaultIP = \"192.168.1.1\" type MyServerOption struct { LogDir string Ip string } func NewServerOption() *MyServerOption { return \u0026MyServerOption{} } func (s *MyServerOption) AddFlags(fs *pflag.FlagSet) { log.Println(fs) fs.StringVar(\u0026s.LogDir, \"log-dir\", s.LogDir, \"服务的日志路径\") fs.StringVar(\u0026s.Ip, \"ip\", DefaultIP, \"服务ip\") // 运行二进制的时候不指定 ip 参数将设置为该默认值 } func main() { s := testpflag.NewServerOption() s.AddFlags(pflag.CommandLine) pflag.Parse() log.Println(s) } [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 pflag: help requested 2.2.2 提供单字母简写 fs.StringVarP(\u0026s.Name, \"name\", \"n\", \"default name\", \"服务名称\") 使用 VarP 的形式绑定参数之后，可以以 “–name” 或者 “-n” 来指定 [root@master pflag]# ./pflag --help Usage of ./pflag: --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") pflag: help requested 2.2.3 规范化标志的名称(相当于设置别名)使用 FlagSet 的方法 SetNormalizeFunc 允许我们自定义一个函数来翻译标志名，例如一个 “URL” 的标志名可以被翻译为 “url” 规范化前： [root@master pflag]# ./pflag --url=\"hello.com\" unknown flag: --url Usage of ./pflag: --URL string 地址 (default \"hhq.com\") --ip string 服务ip (default \"192.168.1.1\") --log-dir string 服务的日志路径 -n, --name string 服务名称 (default \"default name\") unknown flag: --url 规范化后： ./pflag --url=\"hello.com\" 2022/09/16 02:41:43 \u0026{ 192.168.1.1 default name hello.com} 代码： func main() { s := testpflag.NewServerOption() fs := pflag.CommandLine s.AddFlags(fs) fs.SetNormalizeFunc(CaseInsensitiveFunc) pflag.Parse() log.Println(s) } // CaseInsensitiveFunc 不区分标志名的大小写 func CaseInsensitiveFunc(fs *pflag.FlagSet, name string) pflag.NormalizedName { return pflag.NormalizedName(strings.ToLower(name)) } 2.2.4 弃用一个标志 err := fs.MarkDeprecated(\"bad-flag\", \"这个标志已经弃用,请使用新的标志：--good-flag\") if err != nil { log.Println(\"弃用标志失败\") } 说明弃用 “–bad-flag” 这个标志，如果用户继续使用这个标识，将给出说明 [root@master pflag]# ./pflag --bad-flag=aa Flag --bad-flag has been deprecated, 这个标志已经弃用,请使用新的标志：--good-flag 2022/09/16 02:47:10 \u0026{ 192.168.1.1 default name hhq.com aa} ","date":"2023-05-12","objectID":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/:2:2","series":["Golang语言使用"],"tags":[],"title":"pflag 包简单使用","uri":"/202305121215-pflag-%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/#224-弃用一个标志"},{"categories":["Linux"],"content":"#linux 参考文档 https://blog.51cto.com/u_11451275/3207840 xfs_growfs /dev/cclinux/root ","date":"2023-05-12","objectID":"/202305121258-%E6%A0%B9%E5%88%86%E5%8C%BA%E6%89%A9%E5%AE%B9/:0:0","series":["Linux-box"],"tags":["linux"],"title":"根分区扩容","uri":"/202305121258-%E6%A0%B9%E5%88%86%E5%8C%BA%E6%89%A9%E5%AE%B9/#"},{"categories":["Golang"],"content":"#代码片段 ","date":"2023-05-12","objectID":"/202305121204-%E6%97%B6%E9%97%B4%E8%BD%AE-%E4%BB%A3%E7%A0%81demo/:0:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"时间轮 代码demo","uri":"/202305121204-%E6%97%B6%E9%97%B4%E8%BD%AE-%E4%BB%A3%E7%A0%81demo/#"},{"categories":["Golang"],"content":" 前置学习go 定时器 ticker 的学习 func UseTicker() { ticker := time.NewTicker(1 * time.Second) done := make(chan bool) // 无缓冲通道 go func() { for { select { case \u003c-done: return case t := \u003c-ticker.C: fmt.Println(\"Tick at\", t) } } }() time.Sleep(5 * time.Second) ticker.Stop() done \u003c- true fmt.Println(\"Ticker stopped\") } ### 运行结果： Tick at 2022-02-16 18:46:43.4509023 +0800 CST m=+1.007881901 Tick at 2022-02-16 18:46:44.4605044 +0800 CST m=+2.017484001 Tick at 2022-02-16 18:46:45.453441 +0800 CST m=+3.010420601 Tick at 2022-02-16 18:46:46.4586463 +0800 CST m=+4.015625901 Tick at 2022-02-16 18:46:47.4515569 +0800 CST m=+5.008536501 Ticker stopped ","date":"2023-05-12","objectID":"/202305121204-%E6%97%B6%E9%97%B4%E8%BD%AE-%E4%BB%A3%E7%A0%81demo/:1:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"时间轮 代码demo","uri":"/202305121204-%E6%97%B6%E9%97%B4%E8%BD%AE-%E4%BB%A3%E7%A0%81demo/#前置学习"},{"categories":["Golang"],"content":" 代码 package practice import ( \"TimeWheel/pkg/models\" \"TimeWheel/pkg/utils\" \"fmt\" \"log\" \"math\" \"sync\" \"time\" ) type TimingHandler func(taskId string) error type TimingWheel struct { slot int interval time.Duration size int // 可存放任务的数量 tasks []sync.Map stop chan struct{} } type TimingTask struct { round int createdAt time.Time // 任务创建时间 callback TimingHandler // 任务执行方法 } // NewTimingWheel 新建一个时间轮 // interval 时间精度 // size tasks（map）容量大小 // 返回一个新建的时间轮，并且开始 scheduler 调度任务，每 interval 的时间间隔做以下操作： // slot+1（在 size 值内做循环） // run(slot)：获取 slot 下标的任务，执行该任务 func NewTimingWheel(interval time.Duration, size int) *TimingWheel { if interval \u003c time.Second { interval = time.Second log.Println(\"最低精度： 1s\") } tw := \u0026TimingWheel{ interval: interval, size: size, tasks: make([]sync.Map, size), stop: make(chan struct{}), } go tw.scheduler() return tw } func (tw *TimingWheel) AddTask(taskId string, callback TimingHandler, delay time.Duration) { select { case \u003c-tw.stop: fmt.Println(\"TimingWheel is stopped\") return default: } if delay \u003c tw.interval { log.Println(\"最小精度：1s\") if delay \u003c= 0 { if err := callback(taskId); err !=nil { log.Println(fmt.Sprintf(\"TimingWheel task [%s] run error: %+v\", taskId, err)) return } log.Println(fmt.Sprintf(\"TimingWheel task [%s] run success, delay: %d\", taskId, delay)) return } } task := \u0026TimingTask{ createdAt: time.Now(), callback: callback, } slot := tw.calcSlot(task, delay) // 计算 slot tw.tasks[slot].Store(taskId, task) // 存入任务 } func (tw *TimingWheel) Stop() { select { case \u003c-tw.stop: log.Println(\"TimingWheel has stopped\") return default: close(tw.stop) } } // calcSlot 计算 slot --\u003e 任务在 tasks 中的下标，设置 task 的 round（轮数） func (tw *TimingWheel) calcSlot(task *TimingTask, delay time.Duration) int { interval := int(tw.interval.Seconds()) // 秒数 roundTime := interval * tw.size // 秒 * size （遍历一轮 tasks 需要的时间） delayT := int(math.Ceil(delay.Seconds())) // 大于或等于 delay 秒数的最小整数 // 如果延时时间 \u003e 遍历一轮 tasks 的时间 // 则需要设置该 task 的轮数 // e.g. 延时时间 = 11，遍历一轮的时间 = 5 // 则 轮数 = 11 / 5 = 2，delay = 1，slot = 1 // 1 2 3 4 0 1 2 3 4 0 1 2 3 4 // ↑ if delayT \u003e roundTime { task.round = delayT / roundTime delayT = delayT % roundTime if delayT == 0 { task.round -- } } return (tw.slot + delayT/interval) % tw.size } func (tw *TimingWheel) scheduler() { // 每指定间隔执行的定时器 ticker := time.NewTicker(tw.interval) defer ticker.Stop() for { select { case \u003c-tw.stop: log.Println(fmt.Sprintf(\"TimingWheel stopped. time: %s\", time.Now().String())) return case \u003c-ticker.C: tw.slot = (tw.slot + 1) % tw.size log.Println(fmt.Sprintf(\"go tw.run(%d)\", tw.slot)) go tw.run(tw.slot) } } } func (tw *TimingWheel) run(slot int) { taskT := tw.tasks[slot] // 遍历 taskT.Range(func(key, value interface{}) bool { taskId := key.(string) task := value.(*TimingTask) // 轮数倒计时 if task.round \u003e 0{ task.round-- return true } go func() { if err := task.callback(taskId); err != nil { log.Println(fmt.Sprintf(\"TimingWheel task [%s] run error: %+v\", taskId, err)) return } log.Println(fmt.Sprintf(\"TimingWheel task [%s] run success\", taskId)) //return }() taskT.Delete(key) return true }) } func TestTimingWheel() { utils.InitDB() utils.InitTable() var SecondTW *TimingWheel SecondTW = NewTimingWheel(time.Second, 10) taskId := utils.GenerateId(\"task\", 10) mainTime := time.Now() fmt.Println(\"main: \", mainTime) delay := 30 SecondTW.AddTask(taskId, func(taskId string) error { //defer SecondTW.Stop() // 执行任务之后，关闭该时间轮 task := \u0026models.Task{ TaskId: taskId, MainTime: mainTime, Delay: delay, } if err := utils.DB.Model(models.Task{}).Create(task).Error; err != nil { log.Println(fmt.Sprintf(\"create task error: %+v\", err)) return err } return nil }, time.Duration(delay)*time.Second) } ","date":"2023-05-12","objectID":"/202305121204-%E6%97%B6%E9%97%B4%E8%BD%AE-%E4%BB%A3%E7%A0%81demo/:2:0","series":["Golang语言使用"],"tags":["代码片段"],"title":"时间轮 代码demo","uri":"/202305121204-%E6%97%B6%E9%97%B4%E8%BD%AE-%E4%BB%A3%E7%A0%81demo/#代码"},{"categories":["Linux"],"content":"#linux ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:0:0","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#"},{"categories":["Linux"],"content":" 主机规划与磁盘分区 ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:1:0","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#主机规划与磁盘分区"},{"categories":["Linux"],"content":" 磁盘分区","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:2:0","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#磁盘分区"},{"categories":["Linux"],"content":" 常见的磁盘接口 IDE（几乎见不到了） SATA SCSI SAS ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:2:1","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#常见的磁盘接口"},{"categories":["Linux"],"content":" 磁盘的组成 盘片（数据存放的位置） 扇区的两种单位：512Bytes、4K Bytes 机械手臂 磁头 主轴马达 ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:2:2","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#磁盘的组成"},{"categories":["Linux"],"content":" 磁盘分区表格式 MBR（Master Boot Record）：第一个扇区存储重要信息 分区的作用？ 两种分区： 主分区（Primary） 扩展分区（Extend） 扩展分区的不同就是能够划分很多的逻辑分区 如果把磁盘分成四个分区，方式只有两种： PPPP 或者 PPPE，Extend 分区只能有一个 为什么 64 Byte的分区表只能记录四组信息？ 一个分区记录需要16Byte 实践 - 给磁盘 sdd 创建 4 个 P 分区 当我想要再多创建一个分区的时候，已经不行了，如果想要创建更多的分区，需要把其中的一个 P 分区换成 E 分区 当我把第四个分区换成 E 分区之后，使用 lsblk 看见的 sdd4 为什么是 1K 大小呢？ E 分区创建之后，不能直接拿来使用，还需要创建逻辑分区 好了，我们现在已经有了 P、E 分区，现在尝试对 P 分区进行挂载，或出现下面的错误： 我们可以看到现在磁盘只创建了分区，并没有文件系统，所以无法进行挂载，在 sdd1 创建文件系统，然后再进行挂载 mount /dev/sdd1 /home/honghuiqiang/sdd1/ 查看挂载情况： 试一下挂载逻辑分区 sdd5，与上面相同 那么 PPPE 这种形式的分区，逻辑分区能够分多少个区？ 为什么能够这么多的区出来，分区记录是怎么被存储的？ 只有 sdd4 是延伸分区，大小为 1K，用来记录逻辑分区的信息，延伸分区本身不能用来做格式化，一个分区记录需要占用 16Byte，那么 1K 大小的延伸分区是不是只能存 1K/16Bype = 64 个分区记录？ 实践2 sdd 8:48 0 20G 0 disk ├─sdd1 8:49 0 5G 0 part ├─sdd2 8:50 0 5G 0 part ├─sdd3 8:51 0 5G 0 part ├─sdd4 8:52 0 1K 0 part ├─sdd5 8:53 0 1G 0 part ├─sdd6 8:54 0 1G 0 part ├─sdd7 8:55 0 10M 0 part ├─sdd8 8:56 0 10M 0 part ├─sdd9 8:57 0 10M 0 part ├─sdd10 8:58 0 10M 0 part ├─sdd11 8:59 0 10M 0 part ├─sdd12 8:60 0 10M 0 part ├─sdd13 8:61 0 10M 0 part ├─sdd14 8:62 0 10M 0 part ├─sdd15 8:63 0 10M 0 part ├─sdd16 259:0 0 10M 0 part ├─sdd17 259:1 0 10M 0 part ├─sdd18 259:2 0 10M 0 part ├─sdd19 259:3 0 10M 0 part ├─sdd20 259:4 0 10M 0 part ├─sdd21 259:5 0 10M 0 part ├─sdd22 259:6 0 10M 0 part ├─sdd23 259:7 0 10M 0 part ├─sdd24 259:8 0 10M 0 part ├─sdd25 259:9 0 10M 0 part ├─sdd26 259:10 0 10M 0 part ├─sdd27 259:11 0 10M 0 part ├─sdd28 259:12 0 10M 0 part ├─sdd29 259:13 0 10M 0 part ├─sdd30 259:14 0 10M 0 part ├─sdd31 259:15 0 10M 0 part ├─sdd32 259:16 0 10M 0 part ├─sdd33 259:17 0 10M 0 part ├─sdd34 259:18 0 10M 0 part ├─sdd35 259:19 0 10M 0 part ├─sdd36 259:20 0 10M 0 part ├─sdd37 259:21 0 10M 0 part ├─sdd38 259:22 0 10M 0 part ├─sdd39 259:23 0 10M 0 part ├─sdd40 259:24 0 10M 0 part ├─sdd41 259:25 0 10M 0 part ├─sdd42 259:26 0 10M 0 part ├─sdd43 259:27 0 10M 0 part ├─sdd44 259:28 0 10M 0 part ├─sdd45 259:29 0 10M 0 part ├─sdd46 259:30 0 10M 0 part ├─sdd47 259:31 0 10M 0 part ├─sdd48 259:32 0 10M 0 part ├─sdd49 259:33 0 10M 0 part ├─sdd50 259:34 0 10M 0 part ├─sdd51 259:35 0 10M 0 part ├─sdd52 259:36 0 10M 0 part ├─sdd53 259:37 0 10M 0 part ├─sdd54 259:38 0 10M 0 part ├─sdd55 259:39 0 10M 0 part ├─sdd56 259:40 0 10M 0 part ├─sdd57 259:41 0 10M 0 part ├─sdd58 259:42 0 10M 0 part ├─sdd59 259:43 0 10M 0 part └─sdd60 259:44 0 10M 0 part 在创建了 60 个分区后，不能继续创建了 那么是谁受到了限制呢？ 删除一个 P 分区 sdd2 之后尝试创建： 提示所有的逻辑分区在使用中，创建出来的是一个 P 分区 删除一个 E 分区 sdd59 之后尝试创建分区： 创建出来的是逻辑分区 这样其实还是没搞明白是谁收到了限制，使用一个新的盘，只创建扩展分区 创建扩展分区的时候指定了100M，为什么创建了90M的分区后就不能在创建了（提示没有剩余空间） 查看一下这九个逻辑分区的详细情况： 发现其实每个分区的地址头尾并不是连续的，中间存在一点缝隙，因此没有办法再分出一个 10M 的分区也就可以解释了，但是新的疑问又来了，为什么中间有存在一点缝隙呢，有用来存储东西吗？ 仔细观察发现每个间隔的大小都是一样的，都是 2049（1.000488…M），为什么是这个数？\\ 先来看这边的单位是怎么算的 Blocks 这边的单位应该是 K 而 Start、End 的单位应该是 512 byte，计算 sde5 的大小应该是： (24575-4096)/2/1024=9.9995117…M 这种分区方式最多能用在多大的磁盘上？ 2T 每一条16byte的分区记录里，有四个字节用来记录分区起始的相对扇区号，这个也就是磁盘大小的上限 4byte = 4 * 8 bit= 32 bit 可以表示的最大数为 2^32 = 4294967296 每个扇区大小为 512 byte 因此最大磁盘大小为 4294967296 / 2 = 2147483648 K ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:2:3","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#磁盘分区表格式"},{"categories":["Linux"],"content":" 磁盘分区表格式 MBR（Master Boot Record）：第一个扇区存储重要信息 分区的作用？ 两种分区： 主分区（Primary） 扩展分区（Extend） 扩展分区的不同就是能够划分很多的逻辑分区 如果把磁盘分成四个分区，方式只有两种： PPPP 或者 PPPE，Extend 分区只能有一个 为什么 64 Byte的分区表只能记录四组信息？ 一个分区记录需要16Byte 实践 - 给磁盘 sdd 创建 4 个 P 分区 当我想要再多创建一个分区的时候，已经不行了，如果想要创建更多的分区，需要把其中的一个 P 分区换成 E 分区 当我把第四个分区换成 E 分区之后，使用 lsblk 看见的 sdd4 为什么是 1K 大小呢？ E 分区创建之后，不能直接拿来使用，还需要创建逻辑分区 好了，我们现在已经有了 P、E 分区，现在尝试对 P 分区进行挂载，或出现下面的错误： 我们可以看到现在磁盘只创建了分区，并没有文件系统，所以无法进行挂载，在 sdd1 创建文件系统，然后再进行挂载 mount /dev/sdd1 /home/honghuiqiang/sdd1/ 查看挂载情况： 试一下挂载逻辑分区 sdd5，与上面相同 那么 PPPE 这种形式的分区，逻辑分区能够分多少个区？ 为什么能够这么多的区出来，分区记录是怎么被存储的？ 只有 sdd4 是延伸分区，大小为 1K，用来记录逻辑分区的信息，延伸分区本身不能用来做格式化，一个分区记录需要占用 16Byte，那么 1K 大小的延伸分区是不是只能存 1K/16Bype = 64 个分区记录？ 实践2 sdd 8:48 0 20G 0 disk ├─sdd1 8:49 0 5G 0 part ├─sdd2 8:50 0 5G 0 part ├─sdd3 8:51 0 5G 0 part ├─sdd4 8:52 0 1K 0 part ├─sdd5 8:53 0 1G 0 part ├─sdd6 8:54 0 1G 0 part ├─sdd7 8:55 0 10M 0 part ├─sdd8 8:56 0 10M 0 part ├─sdd9 8:57 0 10M 0 part ├─sdd10 8:58 0 10M 0 part ├─sdd11 8:59 0 10M 0 part ├─sdd12 8:60 0 10M 0 part ├─sdd13 8:61 0 10M 0 part ├─sdd14 8:62 0 10M 0 part ├─sdd15 8:63 0 10M 0 part ├─sdd16 259:0 0 10M 0 part ├─sdd17 259:1 0 10M 0 part ├─sdd18 259:2 0 10M 0 part ├─sdd19 259:3 0 10M 0 part ├─sdd20 259:4 0 10M 0 part ├─sdd21 259:5 0 10M 0 part ├─sdd22 259:6 0 10M 0 part ├─sdd23 259:7 0 10M 0 part ├─sdd24 259:8 0 10M 0 part ├─sdd25 259:9 0 10M 0 part ├─sdd26 259:10 0 10M 0 part ├─sdd27 259:11 0 10M 0 part ├─sdd28 259:12 0 10M 0 part ├─sdd29 259:13 0 10M 0 part ├─sdd30 259:14 0 10M 0 part ├─sdd31 259:15 0 10M 0 part ├─sdd32 259:16 0 10M 0 part ├─sdd33 259:17 0 10M 0 part ├─sdd34 259:18 0 10M 0 part ├─sdd35 259:19 0 10M 0 part ├─sdd36 259:20 0 10M 0 part ├─sdd37 259:21 0 10M 0 part ├─sdd38 259:22 0 10M 0 part ├─sdd39 259:23 0 10M 0 part ├─sdd40 259:24 0 10M 0 part ├─sdd41 259:25 0 10M 0 part ├─sdd42 259:26 0 10M 0 part ├─sdd43 259:27 0 10M 0 part ├─sdd44 259:28 0 10M 0 part ├─sdd45 259:29 0 10M 0 part ├─sdd46 259:30 0 10M 0 part ├─sdd47 259:31 0 10M 0 part ├─sdd48 259:32 0 10M 0 part ├─sdd49 259:33 0 10M 0 part ├─sdd50 259:34 0 10M 0 part ├─sdd51 259:35 0 10M 0 part ├─sdd52 259:36 0 10M 0 part ├─sdd53 259:37 0 10M 0 part ├─sdd54 259:38 0 10M 0 part ├─sdd55 259:39 0 10M 0 part ├─sdd56 259:40 0 10M 0 part ├─sdd57 259:41 0 10M 0 part ├─sdd58 259:42 0 10M 0 part ├─sdd59 259:43 0 10M 0 part └─sdd60 259:44 0 10M 0 part 在创建了 60 个分区后，不能继续创建了 那么是谁受到了限制呢？ 删除一个 P 分区 sdd2 之后尝试创建： 提示所有的逻辑分区在使用中，创建出来的是一个 P 分区 删除一个 E 分区 sdd59 之后尝试创建分区： 创建出来的是逻辑分区 这样其实还是没搞明白是谁收到了限制，使用一个新的盘，只创建扩展分区 创建扩展分区的时候指定了100M，为什么创建了90M的分区后就不能在创建了（提示没有剩余空间） 查看一下这九个逻辑分区的详细情况： 发现其实每个分区的地址头尾并不是连续的，中间存在一点缝隙，因此没有办法再分出一个 10M 的分区也就可以解释了，但是新的疑问又来了，为什么中间有存在一点缝隙呢，有用来存储东西吗？ 仔细观察发现每个间隔的大小都是一样的，都是 2049（1.000488…M），为什么是这个数？\\ 先来看这边的单位是怎么算的 Blocks 这边的单位应该是 K 而 Start、End 的单位应该是 512 byte，计算 sde5 的大小应该是： (24575-4096)/2/1024=9.9995117…M 这种分区方式最多能用在多大的磁盘上？ 2T 每一条16byte的分区记录里，有四个字节用来记录分区起始的相对扇区号，这个也就是磁盘大小的上限 4byte = 4 * 8 bit= 32 bit 可以表示的最大数为 2^32 = 4294967296 每个扇区大小为 512 byte 因此最大磁盘大小为 4294967296 / 2 = 2147483648 K ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:2:3","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#实践---给磁盘-sdd-创建-4-个-p-分区"},{"categories":["Linux"],"content":" 磁盘分区表格式 MBR（Master Boot Record）：第一个扇区存储重要信息 分区的作用？ 两种分区： 主分区（Primary） 扩展分区（Extend） 扩展分区的不同就是能够划分很多的逻辑分区 如果把磁盘分成四个分区，方式只有两种： PPPP 或者 PPPE，Extend 分区只能有一个 为什么 64 Byte的分区表只能记录四组信息？ 一个分区记录需要16Byte 实践 - 给磁盘 sdd 创建 4 个 P 分区 当我想要再多创建一个分区的时候，已经不行了，如果想要创建更多的分区，需要把其中的一个 P 分区换成 E 分区 当我把第四个分区换成 E 分区之后，使用 lsblk 看见的 sdd4 为什么是 1K 大小呢？ E 分区创建之后，不能直接拿来使用，还需要创建逻辑分区 好了，我们现在已经有了 P、E 分区，现在尝试对 P 分区进行挂载，或出现下面的错误： 我们可以看到现在磁盘只创建了分区，并没有文件系统，所以无法进行挂载，在 sdd1 创建文件系统，然后再进行挂载 mount /dev/sdd1 /home/honghuiqiang/sdd1/ 查看挂载情况： 试一下挂载逻辑分区 sdd5，与上面相同 那么 PPPE 这种形式的分区，逻辑分区能够分多少个区？ 为什么能够这么多的区出来，分区记录是怎么被存储的？ 只有 sdd4 是延伸分区，大小为 1K，用来记录逻辑分区的信息，延伸分区本身不能用来做格式化，一个分区记录需要占用 16Byte，那么 1K 大小的延伸分区是不是只能存 1K/16Bype = 64 个分区记录？ 实践2 sdd 8:48 0 20G 0 disk ├─sdd1 8:49 0 5G 0 part ├─sdd2 8:50 0 5G 0 part ├─sdd3 8:51 0 5G 0 part ├─sdd4 8:52 0 1K 0 part ├─sdd5 8:53 0 1G 0 part ├─sdd6 8:54 0 1G 0 part ├─sdd7 8:55 0 10M 0 part ├─sdd8 8:56 0 10M 0 part ├─sdd9 8:57 0 10M 0 part ├─sdd10 8:58 0 10M 0 part ├─sdd11 8:59 0 10M 0 part ├─sdd12 8:60 0 10M 0 part ├─sdd13 8:61 0 10M 0 part ├─sdd14 8:62 0 10M 0 part ├─sdd15 8:63 0 10M 0 part ├─sdd16 259:0 0 10M 0 part ├─sdd17 259:1 0 10M 0 part ├─sdd18 259:2 0 10M 0 part ├─sdd19 259:3 0 10M 0 part ├─sdd20 259:4 0 10M 0 part ├─sdd21 259:5 0 10M 0 part ├─sdd22 259:6 0 10M 0 part ├─sdd23 259:7 0 10M 0 part ├─sdd24 259:8 0 10M 0 part ├─sdd25 259:9 0 10M 0 part ├─sdd26 259:10 0 10M 0 part ├─sdd27 259:11 0 10M 0 part ├─sdd28 259:12 0 10M 0 part ├─sdd29 259:13 0 10M 0 part ├─sdd30 259:14 0 10M 0 part ├─sdd31 259:15 0 10M 0 part ├─sdd32 259:16 0 10M 0 part ├─sdd33 259:17 0 10M 0 part ├─sdd34 259:18 0 10M 0 part ├─sdd35 259:19 0 10M 0 part ├─sdd36 259:20 0 10M 0 part ├─sdd37 259:21 0 10M 0 part ├─sdd38 259:22 0 10M 0 part ├─sdd39 259:23 0 10M 0 part ├─sdd40 259:24 0 10M 0 part ├─sdd41 259:25 0 10M 0 part ├─sdd42 259:26 0 10M 0 part ├─sdd43 259:27 0 10M 0 part ├─sdd44 259:28 0 10M 0 part ├─sdd45 259:29 0 10M 0 part ├─sdd46 259:30 0 10M 0 part ├─sdd47 259:31 0 10M 0 part ├─sdd48 259:32 0 10M 0 part ├─sdd49 259:33 0 10M 0 part ├─sdd50 259:34 0 10M 0 part ├─sdd51 259:35 0 10M 0 part ├─sdd52 259:36 0 10M 0 part ├─sdd53 259:37 0 10M 0 part ├─sdd54 259:38 0 10M 0 part ├─sdd55 259:39 0 10M 0 part ├─sdd56 259:40 0 10M 0 part ├─sdd57 259:41 0 10M 0 part ├─sdd58 259:42 0 10M 0 part ├─sdd59 259:43 0 10M 0 part └─sdd60 259:44 0 10M 0 part 在创建了 60 个分区后，不能继续创建了 那么是谁受到了限制呢？ 删除一个 P 分区 sdd2 之后尝试创建： 提示所有的逻辑分区在使用中，创建出来的是一个 P 分区 删除一个 E 分区 sdd59 之后尝试创建分区： 创建出来的是逻辑分区 这样其实还是没搞明白是谁收到了限制，使用一个新的盘，只创建扩展分区 创建扩展分区的时候指定了100M，为什么创建了90M的分区后就不能在创建了（提示没有剩余空间） 查看一下这九个逻辑分区的详细情况： 发现其实每个分区的地址头尾并不是连续的，中间存在一点缝隙，因此没有办法再分出一个 10M 的分区也就可以解释了，但是新的疑问又来了，为什么中间有存在一点缝隙呢，有用来存储东西吗？ 仔细观察发现每个间隔的大小都是一样的，都是 2049（1.000488…M），为什么是这个数？\\ 先来看这边的单位是怎么算的 Blocks 这边的单位应该是 K 而 Start、End 的单位应该是 512 byte，计算 sde5 的大小应该是： (24575-4096)/2/1024=9.9995117…M 这种分区方式最多能用在多大的磁盘上？ 2T 每一条16byte的分区记录里，有四个字节用来记录分区起始的相对扇区号，这个也就是磁盘大小的上限 4byte = 4 * 8 bit= 32 bit 可以表示的最大数为 2^32 = 4294967296 每个扇区大小为 512 byte 因此最大磁盘大小为 4294967296 / 2 = 2147483648 K ","date":"2023-05-12","objectID":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/:2:3","series":["Linux命令使用"],"tags":["linux"],"title":"主机规划与磁盘分区","uri":"/202305121240-%E4%B8%BB%E6%9C%BA%E8%A7%84%E5%88%92%E4%B8%8E%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA/#实践2"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#Golang about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-12","objectID":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/:0:0","series":["card"],"tags":["string"],"title":"string 底层存储","uri":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" 底层存储结构 type stringStruct struct { str unsafe.Pointer len int } type Pointer *ArbitraryType type ArbitraryType int str : 指向实际字符串的内存地址 len : 字节数（≠ 字符数） ","date":"2023-05-12","objectID":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/:1:0","series":["card"],"tags":["string"],"title":"string 底层存储","uri":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/#底层存储结构"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" Q\u0026A 变量 a 与 b 在赋值的时候给到了相同的字符串值，底层会指向同一块地址吗（hello的字符串在底层是否只分配一次？）答案是：是。 func main() { a := \"hello\" b := \"hello\" c := b e := \"world\" fmt.Println(\u0026a) fmt.Println(\u0026b) fmt.Println(\u0026c) fmt.Println(\u0026e) fmt.Println(a==b) fmt.Println(b==c) fmt.Println(\"done\") } 两个字符串相加之后如果跟另一个字符串相同，是否指向同一个地址？答案是：否 查看两个不同的pointer指向的内容，都是”hello”，但是是两块不同的存储空间 这说明了字符串连接的 + 操作是低效的，会一直产生临时的字符串 ","date":"2023-05-12","objectID":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/:2:0","series":["card"],"tags":["string"],"title":"string 底层存储","uri":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/#qa"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" Q\u0026A 变量 a 与 b 在赋值的时候给到了相同的字符串值，底层会指向同一块地址吗（hello的字符串在底层是否只分配一次？）答案是：是。 func main() { a := \"hello\" b := \"hello\" c := b e := \"world\" fmt.Println(\u0026a) fmt.Println(\u0026b) fmt.Println(\u0026c) fmt.Println(\u0026e) fmt.Println(a==b) fmt.Println(b==c) fmt.Println(\"done\") } 两个字符串相加之后如果跟另一个字符串相同，是否指向同一个地址？答案是：否 查看两个不同的pointer指向的内容，都是”hello”，但是是两块不同的存储空间 这说明了字符串连接的 + 操作是低效的，会一直产生临时的字符串 ","date":"2023-05-12","objectID":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/:2:0","series":["card"],"tags":["string"],"title":"string 底层存储","uri":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/#变量-a-与-b-在赋值的时候给到了相同的字符串值底层会指向同一块地址吗hello的字符串在底层是否只分配一次"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" Q\u0026A 变量 a 与 b 在赋值的时候给到了相同的字符串值，底层会指向同一块地址吗（hello的字符串在底层是否只分配一次？）答案是：是。 func main() { a := \"hello\" b := \"hello\" c := b e := \"world\" fmt.Println(\u0026a) fmt.Println(\u0026b) fmt.Println(\u0026c) fmt.Println(\u0026e) fmt.Println(a==b) fmt.Println(b==c) fmt.Println(\"done\") } 两个字符串相加之后如果跟另一个字符串相同，是否指向同一个地址？答案是：否 查看两个不同的pointer指向的内容，都是”hello”，但是是两块不同的存储空间 这说明了字符串连接的 + 操作是低效的，会一直产生临时的字符串 ","date":"2023-05-12","objectID":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/:2:0","series":["card"],"tags":["string"],"title":"string 底层存储","uri":"/202305121145-string-%E5%BA%95%E5%B1%82%E5%AD%98%E5%82%A8/#两个字符串相加之后如果跟另一个字符串相同是否指向同一个地址"},{"categories":["Golang"],"content":"#Golang “interface是Go语言中真正的“魔法”，是Go语言的一个创新设计，它只是方法集合，且与实现者之间的关系是隐式的，它让程序各个部分之间的耦合降至最低，同时是连接程序各个部分的“纽带”。隐式的interface实现会不经意间满足依赖抽象、里氏替换、接口隔离等设计原则，这在其他语言中是需要很刻意的设计谋划才能实现的，但在Go interface看来，一切却是自然而然的。” “保持变量声明与使用之间的距离越近越好，或者在第一次使用变量之前声明该变量。” “之所以这么做，可能考虑到的一点是在这个源文件中，仅Cookie方法用到了变量ErrNoCookie。如果一个包级变量在包内部被多处使用，那么这个变量还是放在源文件头部声明比较适合。” “无类型常量是Go语言在语法设计方面的一个“微创新”，也是“追求简单”设计哲学的又一体现，它可以让你的Go代码更加简洁” “Go是对类型安全要求十分严格的编程语言。Go要求，两个类型即便拥有相同的底层类型（underlying type），也仍然是不同的数据类型，不可以被相互比较或混在一个表达式中进行运算” type myInt int func TestA() { var a int = 1 var b myInt = 2 fmt.Println(a+b) // Invalid operation: a+b (mismatched types int and myInt) } 为什么两者命名具有相同的底层类型，但是不让这么操作呢？原因是：【隐式转换的操作所带来的便利性】 \u003c 【带来的诸多问题】 Go语言对于此考虑不仅适用于变量，同样适用于有类型常量： type myInt int func TestB() { const a myInt = 1 var b int = 2 fmt.Println(a+b) // Invalid operation: a+b (mismatched types myInt and int) } 那么既然 Go 出于安全考虑不让进行隐式转换，那么如果要让上面的逻辑得以执行，就必须进行显示类型转换，那么带来的新的问题就是代码变得复杂。为了稍微减轻代码复杂度，无类型常量的作用便显现出来了： const ( A = 1 PI = 3.14 ) func TestC() { var a int = A // 而无需使用 var a int = int(A) 这样的类型转换 var pi32 float32 = PI var pi64 float64 = PI fmt.Println(a, pi32, pi64) } 所以无类型常量用起来就像在使用字面值一样 通常使用常量语法定义枚举常量 常量定义的后两行没有显式给予初始赋值，Go编译器将为其隐式使用第一行的表达式 iota是Go语言的一个预定义标识符，它表示的是const声明块（包括单行声明）中每个常量所处位置在块中的偏移值（从零开始） const ( a = 1 \u003c\u003c iota // 1 \u003c\u003c 0 = 1 b // 1 \u003c\u003c 1 = 2 c // 1 \u003c\u003c 2 = 4 d = iota // 3 e // 4 f = iota * iota // 5 * 5 = 25 g, h = iota, iota + 1 // 6, 7 i, j // 7, 8 ) const ( aa = iota // 0 bb // 1 _ // 2 cc // 3 ) 在一些枚举常量名称与其初始值有强烈对应关系的时候，枚举常量会直接使用显式数值作为常量的初始值 Go的零值初始是递归的，即数组、结构体等类型的零值初始化就是对其组成元素逐一进行零值初始化 按传统的思维，对于值为nil的变量，我们要先为其赋上合理的值后才能使用。但由于Go中的切片类型具备零值可用的特性，我们可以直接对其进行append操作，而不会出现引用nil的错误 不过Go并非所有类型都是零值可用的，并且零值可用也有一定的限制，比如：在append场景下，零值可用的切片类型不能通过下标形式操作数据 在C语言中，数组变量可视为指向数组第一个元素的指针。而在Go语言中传递数组是纯粹的值拷贝，对于元素类型长度较大或元素个数较多的数组，如果直接以数组类型参数传递到函数中会有不小的性能损耗 切片是数组的“描述符” 切片在Go运行时（runtime）层面的内部表示： package runtime type slice struct { array unsafe.Pointer len int cap int } 当切片作为函数参数传递给函数时，实际传递的是切片的内部表示，也就是上面的runtime.slice结构体实例，因此无论切片描述的底层数组有多大，切片作为参数传递带来的性能损耗都是很小且恒定的 这样的append操作有时会给Gopher带来一些困惑，比如通过语法u[low:high]形式进行数组切片化而创建的切片，一旦切片cap触碰到数组的上界，再对切片进行append操作，切片就会和原数组解除绑定 那么如何减少或避免为过多内存分配和复制付出的代价呢？一种有效的方法是根据切片的使用场景对切片的容量规模进行预估，并在创建新切片时将预估出的切片容量数据以cap参数的形式传递给内置函数make 如果可以预估出切片底层数组需要承载的元素数量，强烈建议在创建切片时带上cap参数。 map对value的类型没有限制，但是对key的类型有严格要求：key的类型应该严格定义了作为“ == ”和“!=”两个操作符的操作数时的行为，因此函数、map、切片不能作为map的key类型 总是使用“comma ok”惯用法读取map中的值 我们看到对同一map做多次遍历，遍历的元素次序并不相同。这是因为Go运行时在初始化map迭代器时对起始位置做了随机处理。因此千万不要依赖遍历map所得到的元素次序 和切片的运行时表示相比，map在运行时的表示显然要复杂得多。 如果可能的话，我们最好对map使用规模做出粗略的估算，并使用cap参数对map实例进行初始化 对string进行切片化后，Go编译器会为切片变量重新分配底层存储而不是共用string的底层存储，因此对切片的修改并未对原string的数据产生任何影响 由于Go string是不可变的，因此如果两个字符串的长度不相同，那么无须比较具体字符串数据即可断定两个字符串是不同的。如果长度相同，则要进一步判断数据指针是否指向同一块底层存储数据。如果相同，则两个字符串是等价的；如果不同，则还需进一步比对实际的数据内容 Go语言直接提供了通过反引号构造“所见即所得”的多行字符串的方法： 根据string在运行时的表示可以得到这样一个结论：直接将string类型通过函数/方法参数传入也不会有太多的损耗，因为传入的仅仅是一个“描述符”（一个指向底层只读字节数组的指针和长度），而不是真正的字符串数据 从基准测试的输出结果的第三列，即每操作耗时的数值来看：做了预初始化的strings.Builder连接构建字符串效率最高；带有预初始化的bytes.Buffer和strings.Join这两种方法效率十分接近，分列二三位；未做预初始化的strings.Builder、bytes.Buffer和操作符连接在第三档次；fmt.Sprintf性能最差，排在末尾 Go编译速度快的原因具体体现在以下三方面。 Go要求每个源文件在开头处显式地列出所有依赖的包导入，这样Go编译器不必读取和处理整个文件就可以确定其依赖的包列表。 Go要求包之间不能存在循环依赖，这样一个包的依赖关系便形成了一张有向无环图。由于无环，包可以被单独编译，也可以并行编译。 已编译的Go包对应的目标文件（file_name.o或package_name.a）中不仅记录了该包本身的导出符号信息，还记录了其所依赖包的导出符号信息。这样，Go编译器在编译某包P时，针对P依赖的每个包导入（比如导入包Q），只需读取一个目标文件即可（比如：Q包编译成的目标文件中已经包含Q包的依赖包的导出信息），而无须再读取其他文件中的信息 代码块是代码执行流流转的基本单元，代码执行流总是从一个代码块跳到另一个代码块 if条件控制语句的代码块 这里，伪代码段1的if控制语句的使用方法符合Go语言惯用的“快乐路径”原则。所谓“快乐路径”即成功逻辑的代码执行路径，这个原则要求：当出现错误时，快速返回；成功逻辑不要嵌入if-else语句中；“快乐路径”的执行逻辑在代码布局上始终靠左，这样读者可以一眼看到该函数的正常逻辑流程；“快乐路径”的返回值一般在函数最后一行，就像上面伪代码段1中的那样。如果你的函数实现代码不符合“快乐路径”原则，可以按下面的步骤进行重构：尝试将“正常逻辑”提取出来，放到“快乐路径”中；如果无法做到上一点，很可能是函数内的逻辑过于复杂，可以将深度缩进到if-else语句中的代码析出到一个函数中，再对原函数实施“快乐路径”原则的重构。 goroutine中输出的i、v值都是for range循环结束后的i、v最终值，而不是各个goroutine启动时的i、v值。这是因为goroutine执行的闭包函数引用了它的外层包裹函数中的变量i、v，这样变量i、v在主goroutine和新启动的goroutine之间实现了共享。而i、v值在整个循环过程中是重用的，仅有一份。在for range循环结束后，i = 4，v = 5，因此各个goroutine在等待3秒后进行输出的时候，输出的是i、v的最终值 注意参与迭代的是range表达式的副本 大多数应用","date":"2023-05-12","objectID":"/202305120824-%E8%AF%BBgo%E8%AF%AD%E8%A8%80%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF%E4%BB%8E%E6%96%B0%E6%89%8B%E5%88%B0%E9%AB%98%E6%89%8B%E7%9A%84%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A71%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/:0:0","series":["Golang语言使用"],"tags":["阅读"],"title":"读《Go语言精进之路：从新手到高手的编程思想、方法和技巧1》留下的一些记录","uri":"/202305120824-%E8%AF%BBgo%E8%AF%AD%E8%A8%80%E7%B2%BE%E8%BF%9B%E4%B9%8B%E8%B7%AF%E4%BB%8E%E6%96%B0%E6%89%8B%E5%88%B0%E9%AB%98%E6%89%8B%E7%9A%84%E7%BC%96%E7%A8%8B%E6%80%9D%E6%83%B3%E6%96%B9%E6%B3%95%E5%92%8C%E6%8A%80%E5%B7%A71%E7%95%99%E4%B8%8B%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%B0%E5%BD%95/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#个人记录 about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 ","date":"2023-05-12","objectID":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/:0:0","series":["card"],"tags":["个人记录"],"title":"学习站点收集","uri":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" golang https://pandaychen.github.io/ https://github.com/golang/go/wiki https://draveness.me/ https://golang.design/under-the-hood https://pkg.go.dev/ Go wiki awesome go https://golang.design/go-questions/map/principal/ ","date":"2023-05-12","objectID":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/:1:0","series":["card"],"tags":["个人记录"],"title":"学习站点收集","uri":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/#golang"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" book 《操作系统导论》 https://github.com/Vonng/ddia ","date":"2023-05-12","objectID":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/:2:0","series":["card"],"tags":["个人记录"],"title":"学习站点收集","uri":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/#book"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":" algorithm https://www.hello-algo.com/chapter_tree/avl_tree/ https://www.bookstack.cn/read/hunterhug-goa.c/README.md ","date":"2023-05-12","objectID":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/:3:0","series":["card"],"tags":["个人记录"],"title":"学习站点收集","uri":"/202305120809-%E5%AD%A6%E4%B9%A0%E7%AB%99%E7%82%B9%E6%94%B6%E9%9B%86/#algorithm"},{"categories":["Golang"],"content":"#并行 ","date":"2023-05-12","objectID":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/:0:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"GOMAXPROCS 设置可以同时执行的最大 CPU 数量","uri":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/#"},{"categories":["Golang"],"content":" 简单测试 func HighUseCPU(n int) float64 { numCPU := runtime.NumCPU() if n \u003c= 1 { numCPU = 1 } else if n \u003c numCPU { numCPU = n } else { // pass } //log.Printf(\"set the number of cpu that can run simultaneously: %d\", numCPU) // 设置可以同时执行的最大 CPU 的数量，提高并发的效率 runtime.GOMAXPROCS(numCPU) // 并发测试 startTime := time.Now() var wg sync.WaitGroup for i := 0; i \u003c 16; i++ { wg.Add(1) go func(i int) { defer wg.Done() process() }(i) } wg.Wait() timeSpend := time.Since(startTime).Seconds() //log.Printf(\"time: %f\\n\", timeSpend) return timeSpend } func process() { cnt := 0 for i := 0; i \u003c 1000000; i++ { cnt++ } } 分别进行1、4、8 核的测试（在8核环境上测试）： func TestHighUseCPU(t *testing.T) { var avgOneCpu float64 = 0 for i := 0; i \u003c 100; i++ { avgOneCpu += HighUseCPU(1) } var avgFourCpu float64 = 0 for i := 0; i \u003c 100; i++ { avgFourCpu += HighUseCPU(4) } var avgEightCpu float64 = 0 for i := 0; i \u003c 100; i++ { avgEightCpu += HighUseCPU(8) } log.Printf(\"\\naverage time(1cpu): %f\\naverage time(4cpu): %f\\naverage time(8cpu):%f\\n\", avgOneCpu/100, avgFourCpu/100, avgEightCpu/100) } 测试结果： average time(1cpu): 0.006329 average time(4cpu): 0.001883 average time(8cpu): 0.001284 可以看到设置设置的数值越接近环境的 cpu 核数，并发的效率越高，当然不是固定的，继续增加这个数量可能会带来更好的性能，也可能更坏，可以根据实际场景进行压测 ","date":"2023-05-12","objectID":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/:1:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"GOMAXPROCS 设置可以同时执行的最大 CPU 数量","uri":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/#简单测试"},{"categories":["Golang"],"content":" 源码 // GOMAXPROCS sets the maximum number of CPUs that can be executing// simultaneously and returns the previous setting. It defaults to // the value of runtime.NumCPU. If n \u003c 1, it does not change the current setting. // This call will go away when the scheduler improves. func GOMAXPROCS(n int) int { if GOARCH == \"wasm\" \u0026\u0026 n \u003e 1 { n = 1 // WebAssembly has no threads yet, so only one CPU is possible. } lock(\u0026sched.lock) ret := int(gomaxprocs) unlock(\u0026sched.lock) if n \u003c= 0 || n == ret { return ret } stopTheWorldGC(\"GOMAXPROCS\") // newprocs will be processed by startTheWorld newprocs = int32(n) startTheWorldGC() return ret } 该函数主要用来控制可以同时执行的最大 cpu 数量，默认为系统 cpu 数量（在 webassembly 中是没有线程的，设置为1） todo ","date":"2023-05-12","objectID":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/:2:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"GOMAXPROCS 设置可以同时执行的最大 CPU 数量","uri":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/#源码"},{"categories":["Golang"],"content":" 越大越好？该方法主要用来优化程序的性能，控制 golang 程序执行的并发程度，但是这个值并 不是越大越好 的，举个如下的例子： 执行 1 + 1 的任务 4 个 cpu 设置 GOMAXPROCS 的值为 1000 每个 cpu 分到 250 个任务，为了能够同时运行这 250 个任务，cpu 的时间可能会大量浪费在 上下文切换 的任务上，而不是实际的计算任务 同时每个线程都需要有自己的内存空间，过多的线程也会 给内存带来压力 实际测试： 环境：具有 4 个 cpu 的 centos 给方法多传入一个变量，控制程序创建的协程数量 func HighUseCPU(n int, par int) float64 { numCPU := runtime.NumCPU() if n \u003c= 1 { numCPU = 1 } else { numCPU = n } log.Printf(\"set the number of cpu that can run simultaneously: %d\", numCPU) // 设置可以同时执行的最大 CPU 的数量，提高并发的效率 runtime.GOMAXPROCS(numCPU) // 并发测试 startTime := time.Now() var wg sync.WaitGroup for i := 0; i \u003c par; i++ { wg.Add(1) go func(i int) { defer wg.Done() process() }(i) } wg.Wait() timeSpend := time.Since(startTime).Seconds() return timeSpend } func process() { cnt := 0 for i := 0; i \u003c 100000000; i++ { cnt++ } } 先看一下当协程数量发生变化的时候，花费时间情况是怎么样的 协程数量：4 average time(1cpu): 0.251251 average time(4cpu): 0.095817 average time(8cpu):0.090954 协程数量：8 average time(1cpu): 0.490758 average time(4cpu): 0.189642 average time(8cpu):0.173086 从上面协程数量变化导致的结果来看，随着协程数量的不断上升，cpu 数量设置较小的情况下，时间上升明显，可以看出来为了处理大量并发，cpu 把时间浪费在了上下文切换的时间上，当我把协程数量设置成 16 的时候，时间已经很慢了 ","date":"2023-05-12","objectID":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/:3:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"GOMAXPROCS 设置可以同时执行的最大 CPU 数量","uri":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/#越大越好"},{"categories":["Golang"],"content":" Q\u0026A 我们已经知道 GOMAXPROCS 设置的值并非越大越好，那么什么情况可能会导致这个值比我们预期的要大？ 在 容器 场景下可能会出现这种情况，如果容器中的程序获取到了宿主机的 cpu 数量，比如宿主机有几十核，而容器可能只有两核或者更少 ","date":"2023-05-12","objectID":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/:4:0","series":["Golang语言使用"],"tags":["性能优化"],"title":"GOMAXPROCS 设置可以同时执行的最大 CPU 数量","uri":"/202305120552-gomaxprocs-%E8%AE%BE%E7%BD%AE%E5%8F%AF%E4%BB%A5%E5%90%8C%E6%97%B6%E6%89%A7%E8%A1%8C%E7%9A%84%E6%9C%80%E5%A4%A7-cpu-%E6%95%B0%E9%87%8F/#qa"},{"categories":["Tools-Method"],"content":"#个人记录 博客使用 Doit 主题，对两个功能有很好的支持 ","date":"2023-05-12","objectID":"/202305120524-hugo-%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90%E7%9A%84%E5%8A%9F%E8%83%BD/:0:0","series":["博客建设"],"tags":["个人记录"],"title":"Hugo 博客站点添加评论、网站分析的功能","uri":"/202305120524-hugo-%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90%E7%9A%84%E5%8A%9F%E8%83%BD/#"},{"categories":["Tools-Method"],"content":" 评论功能Doit 支持多种社交和评论系统，这边选用 giscus 新建一个hugo-giscus-common-system 仓库，到 settings / general 设置中开启 discussions 设置： 使用 giscus.app 生成相关配置 安装 giscus app 填入仓库 选择分类 填入 hugo 的 config.toml 配置文件 上面的步骤都完成之后，在下面的 启用 giscus 一栏中会有相应的配置： 对应配置 config.toml ","date":"2023-05-12","objectID":"/202305120524-hugo-%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90%E7%9A%84%E5%8A%9F%E8%83%BD/:1:0","series":["博客建设"],"tags":["个人记录"],"title":"Hugo 博客站点添加评论、网站分析的功能","uri":"/202305120524-hugo-%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90%E7%9A%84%E5%8A%9F%E8%83%BD/#评论功能"},{"categories":["Tools-Method"],"content":" 网站分析直接参考 https://hugodoit.pages.dev/zh-cn/about/#back-to-top 获得id的流程很简单： google baidu 然后在 config.toml 中开启分析功能，并配置 id 即可 查看分析数据： https://analytics.google.com/analytics/web https://tongji.baidu.com/ ","date":"2023-05-12","objectID":"/202305120524-hugo-%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90%E7%9A%84%E5%8A%9F%E8%83%BD/:2:0","series":["博客建设"],"tags":["个人记录"],"title":"Hugo 博客站点添加评论、网站分析的功能","uri":"/202305120524-hugo-%E5%8D%9A%E5%AE%A2%E7%AB%99%E7%82%B9%E6%B7%BB%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%BD%91%E7%AB%99%E5%88%86%E6%9E%90%E7%9A%84%E5%8A%9F%E8%83%BD/#网站分析"},{"categories":["Tools-Method"],"content":"#个人记录 ","date":"2023-05-12","objectID":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/:0:0","series":["博客建设"],"tags":["个人记录"],"title":"如何让 Google 搜索到我们的博客","uri":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/#"},{"categories":["Tools-Method"],"content":" 为什么搜索不到我的博客突然想在 Google 搜索一下自己的博客，但是我发现啥子也搜索不到 （既然已经把写作的内容从本地迁移到了博客，也是因为有以下的原因： 自己的写作工具时常变迁，可能有以下麻烦： 需要迁移文档，一些链接方式可能发生改变 有时候写的文档被遗漏、丢失 如果每写一篇文章就发布到自己的博客，就算之后写作工具发生改变，也可以不进行文档迁移的操作 all in one，把所有的内容放到一个地方，也方便查看 跟广大的网友交流，有时候自己的一些想法、学习内容可能是有差错、或者能够优化的，如果能够得到各路高人的指点，那必定是相当 nice 的，其次，如果自己的总结、方法对别人有些许帮助，分享出去也是一种收获 原因： Google 只能搜索到已经收录的站点，我的博客没有知名度，Google 也不会自动收录 解决： 这种情况下可以自己主动请求让 Google 收录我们的博客 ","date":"2023-05-12","objectID":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/:1:0","series":["博客建设"],"tags":["个人记录"],"title":"如何让 Google 搜索到我们的博客","uri":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/#为什么搜索不到我的博客"},{"categories":["Tools-Method"],"content":" 如何进行操作 查看我们的站点是否被收录 在谷歌搜索栏输入： site:https://honghuiqiang.com 很明显是没有被收录的 提交搜索资源 在 google search console 添加资源，选用 网址前缀 类型 下载上面的 html 文件，更新到站点根目录 往 904566722.github.io 推送该修改： 等待 gh pages 部署完成： 验证就完成了： 生成站点地图（hugo 已自动生成，忽略该步骤） 进入 XML-Sitemaps.com ，输入博客的地址，点击 start ，等待进程结束 点击 view sitemap details 下载 sitemap file 同样上传到站点根目录 这个 sitemap.xml 文件保存的其实就是博客的博文、目录的路径： 到 Google Search Console 提交站点地图 手动请求编入索引 可以测试其中一篇博文 这个就是手动请求编入索引的步骤 以上的步骤完全参照文档：https://zoharandroid.github.io/2019-08-03-%E8%AE%A9%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/ 写的很简洁清楚 ","date":"2023-05-12","objectID":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/:2:0","series":["博客建设"],"tags":["个人记录"],"title":"如何让 Google 搜索到我们的博客","uri":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/#如何进行操作"},{"categories":["Tools-Method"],"content":" 通过 github action 自动发布的 hugo 类型博客需要做什么改动关于 hugo 可以省去上面的关于 sitemap 的操作 只需要在 xxx.github.io 仓库根路径添加 google search verification 的那个 html 文件 可以有多种方式实现这个效果，可以用自己喜欢的方式，也可以参考以下方式： 在源仓库（保存博客md文件的仓库，也是执行 gh action 的仓库）添加一个 extend 文件夹，把对应的 xxx.html（上面的认证文件） 放到这个目录下 修改 gh action 的 yaml 配置脚本 在使用 hugo 命令生成 public 目录之后，把 extend 目录下的内容拷贝到 public 目录 name: deploy on: push: workflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: '0 0 * * *' jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Set up Python uses: actions/setup-python@v2 with: python-version: 3.8 - name: Commit and push if changed run: |- git diff git config --global user.email \"action@github.com\" git config --global user.name \"GitHub Action\" git add -A git commit -m \"ci: update about page (automatically)\" || exit 0 git push - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 0.105.0 extended: true - name: Build Web run: hugo --gc --minify #run: hugo - name: CP Extend Files run: cp ./extend/* ./public - name: Create CNAME run: echo \"honghuiqiang.com\" \u003e public/CNAME - name: Run Pagefind run: npm_config_yes=true npx pagefind --source \"public\" - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} EXTERNAL_REPOSITORY: 904566722/904566722.github.io PUBLISH_BRANCH: hugo PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 至此就完成了所有操作 https://zoharandroid.github.io/2019-08-03-%E8%AE%A9%E8%B0%B7%E6%AD%8C%E6%90%9C%E7%B4%A2%E5%88%B0%E8%87%AA%E5%B7%B1%E7%9A%84%E5%8D%9A%E5%AE%A2/ ","date":"2023-05-12","objectID":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/:3:0","series":["博客建设"],"tags":["个人记录"],"title":"如何让 Google 搜索到我们的博客","uri":"/202305120409-%E5%A6%82%E4%BD%95%E8%AE%A9-google-%E6%90%9C%E7%B4%A2%E5%88%B0%E6%88%91%E4%BB%AC%E7%9A%84%E5%8D%9A%E5%AE%A2/#通过-github-action-自动发布的-hugo-类型博客需要做什么改动"},{"categories":["生活记录"],"content":" 规划区 加个评论系统差不多了，博客就差不多这样好了 整理一下我的电脑工作区 workspace，也就是学习、工作时候的界面布局，还是划分一下大致的区域，养成习惯，整洁一点 整理之前写在本地的文档 把文档迁移到博客的过程中顺便回顾一下笔记的内容，不要单纯复制粘贴 如果还有时间，做一下其他相关知识学习（应该是没有时间） gantt： gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 博客 a1.添加评论系统:done, 03:00, 30m a2.整理我的workspace: 1h a3.google网站收录:done, 1h section 迁移文档 b1.golang的文档:done, 1h b2.mysql文档:done, 20m b3.linux文档:done, 1h b4.之前放在收集箱的文档:done, 5m b5.项目管理文档:done, 40m b6.docker文档:done, 30m b7.kubernetes文档:done, 1h b7.openshift文档: 1h b8.工作性质的文档: 4h section 习惯 算法每日一题:done, 1h 注意以上《工作性质的文档》：因为之前写在本地，所以一些公司隐私性质的内容都卸载里面，放到博客只需要提取其中知识性的内容！ ","date":"2023-05-12","objectID":"/2023-05-12/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-12 日记录","uri":"/2023-05-12/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录(v2.0)打卡状态： ✅ | ❌ 改成使用 todo 列表的形式来表现，每个月的打卡情况在月度总结里面体现 算法每日一题 202305121759 t128 最长连续序列 ","date":"2023-05-12","objectID":"/2023-05-12/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-12 日记录","uri":"/2023-05-12/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 发现两本新的书：操作系统导论、DDIA 一个高质量的博客：https://draveness.me/ ","date":"2023-05-12","objectID":"/2023-05-12/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-12 日记录","uri":"/2023-05-12/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） 今天把规划要迁移的文档大部分迁移了，也做了一些扩展学习，发现了一些不错的博客、书籍。 ","date":"2023-05-12","objectID":"/2023-05-12/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-12 日记录","uri":"/2023-05-12/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： 无（文档迁移） 202305121500 关于 goroutine 内存泄漏的一些思考 202305121926 读 DDIA 留下的一些记录 ","date":"2023-05-12","objectID":"/2023-05-12/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-12 日记录","uri":"/2023-05-12/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天完成剩下的文档迁移 ","date":"2023-05-12","objectID":"/2023-05-12/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-12 日记录","uri":"/2023-05-12/#记录区-明天"},{"categories":["数据结构与算法"],"content":"#leetcode 废弃 使用新站点记录 1016. 子串能表示从 1 到 N 数字的二进制串 // // 思路1. 遍历 n，每个字符串都判断是否是 s 的子串， 如果使用 kmp 算法，时间复杂度是 s 的长度 m // o(n * m) * 数字转二进制字符串的时间 // n's max = 1000000000 n * 每个数字转二进制的时间应该很长，再加上匹配的时间可能会超时 // 假设 n // 15:1111 如果是子串，那么 111、11、1 都是子串 15 7 3 1 // 14:1110 如果是子串，那么 110、10、0 都是子串 // 13:1101 如果是子串，那么 101、1 都是子串 // 12:1100 .. // 11:1011 // 10:1010 // 9:1001 // ... // 1:0001 // // 思路2. 通过上面的分析可以找到一种优化 // 从最大的数开始比较，如果这个数符合，那么持续右移(/2)，放入一个符合条件的 map， // 遍历的时候如果这个数已经被放入 map，就跳过 func queryString(s string, n int) bool { set := map[int]bool{} for num := n; num \u003e= 1; num-- { if _, ok := set[num]; ok { continue } binaryStr := strconv.FormatInt(int64(num), 2) if kmp(s, binaryStr) { tmpNum := num for tmpNum \u003e 0 { set[tmpNum] = true tmpNum /= 2 } } else { return false } } return len(set) == n } func kmp(s, pat string) bool { n, m := len(s), len(pat) i, j := 0, 0 next := getNext(pat) for i \u003c n \u0026\u0026 j \u003c m { for j \u003e 0 \u0026\u0026 pat[j] != s[i] {j = next[j-1]} if pat[j] == s[i] { j++ } i++ } return j == m } func getNext(pat string) []int { i, j, n := 1, 0, len(pat) next := make([]int, n) next[0] = 0 for i \u003c n { for j \u003e 0 \u0026\u0026 pat[j] != pat[i] {j = next[j-1]} if pat[i] == pat[j] { j++ } next[i] = j i++ } return next } ","date":"2023-05-11","objectID":"/202305111537-t1016-%E5%AD%90%E4%B8%B2%E8%83%BD%E8%A1%A8%E7%A4%BA%E4%BB%8E-1-%E5%88%B0-n-%E6%95%B0%E5%AD%97%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%B2/:0:0","series":["leetcode"],"tags":[],"title":"t1016 子串能表示从 1 到 N 数字的二进制串","uri":"/202305111537-t1016-%E5%AD%90%E4%B8%B2%E8%83%BD%E8%A1%A8%E7%A4%BA%E4%BB%8E-1-%E5%88%B0-n-%E6%95%B0%E5%AD%97%E7%9A%84%E4%BA%8C%E8%BF%9B%E5%88%B6%E4%B8%B2/#"},{"categories":["Tools-Method"],"content":"#个人记录 windows 环境 ","date":"2023-05-11","objectID":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/:0:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 Hugo + GitHub Pages 搭建博客记录","uri":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/#"},{"categories":["Tools-Method"],"content":" Hugo 安装依赖/版本： Go 1.20.4（不同的 hugo 依赖的 go 版本可能不同，注意分辨） Hugo v0.91.2-1798BD3F+extended Git 可以直接在 Hugo 已发布的版本 中直接下载二进制文件来运行 可以在环境变量中添加一个专门放自己二进制文件的目录： 将上面下载的 hugo 二进制文件放到上面定义的目录下，就能够直接运行这个命令了 ","date":"2023-05-11","objectID":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/:1:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 Hugo + GitHub Pages 搭建博客记录","uri":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/#hugo-安装"},{"categories":["Tools-Method"],"content":" 生成项目具体可以参考文档：https://gohugo.io/getting-started/quick-start/ hugo new site demo1 # 生成项目结构 cd demo1 git init # 将项目初始化成 git 项目 # 克隆一个主题 git submodule add git@github.com:theNewDynamic/gohugo-theme-ananke.git themes/ananke echo \"theme = 'ananke'\" \u003e\u003e config.toml # 把主题选择写入配置文件，选择上面克隆的主题 hugo new posts/test_post.md # 写一个测试文档 hugo server --buildDrafts # 本地运行 运行之后本地访问 localhost:1313： 项目结构： $ tree -d -L 2 . |-- archetypes |-- content | `-- posts |-- data |-- gohugo-theme-ananke | |-- archetypes | |-- assets | |-- exampleSite | |-- i18n | |-- images | |-- layouts | |-- resources | `-- static |-- layouts |-- public |-- resources | `-- _gen |-- static `-- themes `-- ananke ","date":"2023-05-11","objectID":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/:2:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 Hugo + GitHub Pages 搭建博客记录","uri":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/#生成项目"},{"categories":["Tools-Method"],"content":" 选择主题 挑选喜欢的主题仓库，克隆到 themes 目录下 https://themes.gohugo.io/ 编辑 config.toml 配置文件 ... theme = '主题' 或者比较成熟的主题一般都会有自己的完善的配置文档，直接参照即可，本博客使用 Doit 主题 ","date":"2023-05-11","objectID":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/:3:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 Hugo + GitHub Pages 搭建博客记录","uri":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/#选择主题"},{"categories":["Tools-Method"],"content":" 使用 GitHub Pages 部署站点使用 hugo 命令在自己的博客根目录生成博客站点文件夹 public hugo cd public 新建一个 username.github.io 的仓库，比如我的仓库名为 904566722.github.io ，然后将上面生成的 public 文件夹的内容推送到该仓库 然后就可以使用 username.github.io 来访问该网站了 ","date":"2023-05-11","objectID":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/:4:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 Hugo + GitHub Pages 搭建博客记录","uri":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/#使用-github-pages-部署站点"},{"categories":["Tools-Method"],"content":" 注册域名为了能够使用自己的域名来访问博客，可以注册一个域名，我这边使用腾讯云的域名，购买完成后配置解析： 下一步是在 username.github.io 中配置自己的域名： 配置完成后就可以使用自己的域名来访问网站啦 ","date":"2023-05-11","objectID":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/:5:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 Hugo + GitHub Pages 搭建博客记录","uri":"/202305111342-%E4%BD%BF%E7%94%A8-hugo--github-pages-%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E8%AE%B0%E5%BD%95/#注册域名"},{"categories":["Tools-Method"],"content":"#个人记录 ","date":"2023-05-11","objectID":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/:0:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 GitHub Action 来完成博客自动更新","uri":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/#"},{"categories":["Tools-Method"],"content":" 手动发布流程以编写一篇文档为例： 使用 obsidian 编写文档 执行命令行本地生成 hugo 页面，看看有没有报错、文档编排之类的问题 hugo server -e production --disableFastRender 如果没有问题，需要把相应内容推送到两个仓库：保存md文档的仓库A（本仓库）、保存hugo生成的静态页面的仓库B 可以先推送到仓库A，保存文章 然后执行 hugo 生成静态网页，切到 public 目录，推送内容到仓库B git add . git commit -m \"m/w. desc\" git push hugo cd public git add . git commit -m \"m/w. desc\" git push ","date":"2023-05-11","objectID":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/:1:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 GitHub Action 来完成博客自动更新","uri":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/#手动发布流程"},{"categories":["Tools-Method"],"content":" 自动发布的过程需要使用到 GitHub Action 一段描述： 使用 GitHub Actions 直接在您的存储库中自动化、自定义和执行您的软件开发工作流程。您可以发现、创建和共享操作以执行您喜欢的任何工作，包括 CI/CD，并在完全自定义的工作流中组合操作 那么就可以用来省去手动到 public 目录 commit、push 的操作，实现博客的自动发布。 设定两个事件就差不多了： 当仓库 A 有代码更新（push），执行脚本 定时执行脚本 支持手动执行 flowchart TD %% 重要性的分类 classDef important stroke:red, stroke-width:2px classDef pass stroke:grey, stroke-dasharray: 5,5 %% 流程的分类 classDef success stroke:green %% 解释 classDef stick fill:yellow, stroke:yellow classDef stickImp fill:pink, stroke:pink %% ----主要流程 begin ---- act1(手动推送代码)--\u003erepoA[源仓库] repoA--\u003e|触发GitHub Action|ga[执行源仓库中编写好的\u003cbr\u003e.github/workflow/xxx.yaml 脚本] subgraph sub1[\"GitHub Action 执行机自动完成的操作\"] ga--\u003eautoAct1[拉取源仓库到本地] autoAct1--\u003eautoAct2[执行 hugo 生成 public 目录] autoAct2--\u003eautoAct3[拉取 xxx.github.io 仓库\u003cbr\u003e并执行 git rm -r --ignore-unmatch * 删除所有文件和目录\u003cbr\u003e删除完成之后把生成的 public 目录放到 xxx.github.io] autoAct3--\u003eauto4[commit 并且 push 到 xxx.github.io 仓库] end auto4--\u003epage[GitHub Pages 生成站点] %% ---- 主要流程 end ---- %% 注意一个问题 note1[\"这里的操作会把 xxx.github.io 仓库的域名配置清空(如果有配置的话)\"] note1-.-autoAct3 subgraph sub2 fix1[生成一个 CNAME 文件到 public]--\u003ea[把 public 拷贝到 xxx.github.io] end note1-.-\u003e|如何解决|sub2 sub2-.-auto4 class note1 stickImp flowchart TD %% 重要性的分类 classDef important stroke:red, stroke-width:2px classDef pass stroke:grey, stroke-dasharray: 5,5 %% 流程的分类 classDef success stroke:green %% 解释 classDef stick fill:yellow, stroke:yellow classDef stickImp fill:pink, stroke:pink %% ----主要流程 begin ---- act1(手动推送代码)--\u003erepoA[源仓库] repoA--\u003e|触发GitHub Action|ga[执行源仓库中编写好的 .github/workflow/xxx.yaml 脚本] subgraph sub1[\"GitHub Action 执行机自动完成的操作\"] ga--\u003eautoAct1[拉取源仓库到本地] autoAct1--\u003eautoAct2[执行 hugo 生成 public 目录] autoAct2--\u003eautoAct3[拉取 xxx.github.io 仓库 并执行 git rm -r --ignore-unmatch * 删除所有文件和目录 删除完成之后把生成的 public 目录放到 xxx.github.io] autoAct3--\u003eauto4[commit 并且 push 到 xxx.github.io 仓库] end auto4--\u003epage[GitHub Pages 生成站点] %% ---- 主要流程 end ---- %% 注意一个问题 note1[\"这里的操作会把 xxx.github.io 仓库的域名配置清空(如果有配置的话)\"] note1-.-autoAct3 subgraph sub2 fix1[生成一个 CNAME 文件到 public]--\u003ea[把 public 拷贝到 xxx.github.io] end note1-.-\u003e|如何解决|sub2 sub2-.-auto4 class note1 stickImp ","date":"2023-05-11","objectID":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/:2:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 GitHub Action 来完成博客自动更新","uri":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/#自动发布的过程"},{"categories":["Tools-Method"],"content":" 具体操作 person token 在 GitHub 个人设置里面 settings/developer settings 创建一个 token，这个 token 需要勾选两个权限：repo 和 workflow 然后到源仓库 settings / Secrets and variables 中添加一个 repository variable 变量 然后在源仓库需要添加一个 yaml 脚本 目录：.github/workflows/update-blog.yaml ，脚本内容如下： name: deploy on: # 表示以下情况发生时触发 push: workflow_dispatch: schedule: # Runs everyday at 8:00 AM - cron: '0 0 * * *' jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 with: submodules: true fetch-depth: 0 - name: Set up Python uses: actions/setup-python@v2 with: python-version: 3.8 - name: Commit and push if changed run: |- git diff git config --global user.email \"action@github.com\" git config --global user.name \"GitHub Action\" git add -A git commit -m \"ci: update about page (automatically)\" || exit 0 git push - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 0.105.0 extended: true - name: Build Web #run: hugo --gc --minify run: hugo - name: Create CNAME run: echo \"honghuiqiang.com\" \u003e public/CNAME - name: Run Pagefind run: npm_config_yes=true npx pagefind --source \"public\" - name: Deploy Web uses: peaceiris/actions-gh-pages@v3 with: PERSONAL_TOKEN: ${{ secrets.PERSONAL_TOKEN }} # 上一步中仓库变量的 key EXTERNAL_REPOSITORY: 904566722/904566722.github.io PUBLISH_BRANCH: hugo PUBLISH_DIR: ./public commit_message: ${{ github.event.head_commit.message }} 其中 Create CNAME 动作是为了解决如下问题： 使用 GitHub Action 自动发布博客之后域名无法访问到页面的问题 问题现象： 使用域名 honghuiqiang.com 无法访问到页面（404） 问题产生的原因： 在 904566722.github.io 仓库中，域名的配置是作为仓库中的一个文件存在的，GitHub Action 操作中，把该仓库拉取下来之后会清空目录，这个文件会被清除掉，因此需要多运行一条命令来再次生成域名配置 - name: Create CNAME run: echo \"honghuiqiang.com\" \u003e public/CNAME 至此配置就全部完成了！ 来实际看一下一个 push 之后 github 做的动作： 在 Action 选项卡可以看到流程被触发： 进去能够看到执行机完成的命令，具体做了哪些操作 到此一个 Action 就完成了，可以到 xx.github.io 看到有一个相同 commit msg 的提交 到此就完成了博客的自动更新流程 ","date":"2023-05-11","objectID":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/:3:0","series":["博客建设"],"tags":["个人记录"],"title":"使用 GitHub Action 来完成博客自动更新","uri":"/202305110815-%E4%BD%BF%E7%94%A8-github-action-%E6%9D%A5%E5%AE%8C%E6%88%90%E5%8D%9A%E5%AE%A2%E8%87%AA%E5%8A%A8%E6%9B%B4%E6%96%B0/#具体操作"},{"categories":["生活记录"],"content":" 规划区 gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 博客相关内容 1.梳理规划一天的方法、完成日记模板的创建:done,riji,06:00, 2h 2.完成博客的自动发布系统:done,fabu, after riji, 1h 3.总结文档《使用huog+github pages搭建博客流程》:done,after fabu, 90m 4.golang: 1h section 习惯 算法每日一题:done, 1h gantt（最后要与上面的代码同步）： gantt dateFormat HH:mm axisFormat %H:%M tickInterval 1h title 今天大概要做 section 博客相关内容 1.梳理规划一天的方法、完成日记模板的创建:done,riji,06:00, 2h 2.完成博客的自动发布系统:done,fabu, after riji, 1h 3.总结文档《使用huog+github pages搭建博客流程》:done,after fabu, 90m 4.golang: 1h section 习惯 算法每日一题:done, 1h ","date":"2023-05-11","objectID":"/2023-05-11/:1:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-11 日记录","uri":"/2023-05-11/#规划区"},{"categories":["生活记录"],"content":" 记录区-习惯记录打卡状态： ✅ | ❌ 习惯打卡表 日期 算法 阅读 1 ✅ 2 ✅ 3 ✅ 4 ✅ 5 ✅ 6 ✅ 7 8 ✅ 9 10 11 ✅ 12 ✅ 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 ","date":"2023-05-11","objectID":"/2023-05-11/:2:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-11 日记录","uri":"/2023-05-11/#记录区-习惯记录"},{"categories":["生活记录"],"content":" 记录区-事\u0026物记 重要事记 无 新事物 GitHub Action， 类似于之前工作上的 cdp 的东西 ","date":"2023-05-11","objectID":"/2023-05-11/:3:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-11 日记录","uri":"/2023-05-11/#记录区-事物记"},{"categories":["生活记录"],"content":" 记录区-随手记🎧🎵（挑首歌？local:202305101553 博客音乐嵌入样例 remote:202305101553 博客音乐嵌入样例） 不管什么时间点都适合听这歌 Lessang yyds： ” 我的人生为什么这样，这些都是借口 不要轻易放弃人生这场游戏 在这世上长眠之时毫无留恋 最后，让幸福的大门能够开启 找寻幸福飞了一会 让所有萎靡都能重拾笑容 “ 昨天要完成的工作大体完成了，期间有碰到了一点问题，关于 git lfs 以及 gh pages 域名配置的问题，不过也都顺利解决掉了，本来把 Golang 学习放在晚上，不过太困了很早就睡了，搞得现在就醒了（after day 02:03）…不过也睡不着了，起来写一下昨天没写完的记录区（肚子好饿…😵‍💫） ","date":"2023-05-11","objectID":"/2023-05-11/:4:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-11 日记录","uri":"/2023-05-11/#记录区-随手记"},{"categories":["生活记录"],"content":" 记录区-总结心情打分： 😆 很快乐 🙂 一般快乐 😶 无明显情绪波动 🧐有疑问 😵‍💫 很混乱 😮‍💨叹气 😡 生气 输出内容： 日计划 local：202305110405 怎么来规划一天、做日记录 博客自动发布 local：202305110815 使用 GitHub Action 来完成博客自动更新 remote：202305110815 使用 GitHub Action 来完成博客自动更新 总结了一下博客搭建的过程 local：202305111342 使用 Hugo + GitHub Pages 搭建博客记录 算法每日一题 local：202305111537 t1016 子串能表示从 1 到 N 数字的二进制串 ","date":"2023-05-11","objectID":"/2023-05-11/:5:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-11 日记录","uri":"/2023-05-11/#记录区-总结"},{"categories":["生活记录"],"content":" 记录区-明天 明天加个评论系统差不多了，博客就差不多这样好了 整理一下我的电脑工作区 workspace，也就是学习、工作时候的界面布局，还是划分一下大致的区域，养成习惯，整洁一点 整理之前写在本地的文档 把文档迁移到博客的过程中顺便回顾一下笔记的内容，不要单纯复制粘贴 如果还有时间，做一下其他相关知识学习（应该是没有时间） ","date":"2023-05-11","objectID":"/2023-05-11/:6:0","series":["日规划-记录"],"tags":["个人记录"],"title":"2023-05-11 日记录","uri":"/2023-05-11/#记录区-明天"},{"categories":["Tools-Method"],"content":"一天的规划用什么样的方式来规划与记录？","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/"},{"categories":["Tools-Method"],"content":"#规划 之前可能大多使用windows上便签的方式，随手记录，大概写一下内容。 这篇文章的目的是想再明确一下规划一天的流程，同时希望能够把这些内容也同步到博客 不知道这样更为复杂的方式会不会浪费时间，先试验一下再说，始：2023-05-11 这篇文章应该是需要根据每一天规划方式的改变来不断迭代、规范的 ","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/:0:0","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/#"},{"categories":["Tools-Method"],"content":" 记些什么东西好 ✍基于自己的习惯，对于一天的规划，不喜欢定的太详细，没有可伸缩的空间不好，先确定一些规则： 对于一天要做什么，就写一些大概性的东西，然后在一天的工作、学习过程中基于这些内容，有扩展、有伸缩 这些内容是否要规定时间？ 不写开始时间，就写持续时间（这项任务大概需要多长时间完成） 有了一些基本的规则，来确定一下：一篇日规划的文章中需要包含什么？大体分为两个区域： 规划区：当天开始的时候 | 前一天 做好大致规划，把上面讲到的大概性的东西写一些，规范今天的内容 记录区：当天事情结束的时候做记录 ","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/:1:0","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/#记些什么东西好-"},{"categories":["Tools-Method"],"content":" 规划区可以尝试使用 gantt 图来记录一下（先试用一下，不方便的话后面使用脑图 或者 不用图画的形式来记录也行），最近学习了 mermaid（local 202305100916 mermaid 语法-甘特图 remote 202305100916 mermaid 语法-甘特图），刚好用来练练手 ","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/:1:1","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/#规划区"},{"categories":["Tools-Method"],"content":" 记录区 习惯记录：每天都要去做的事情，可以用来做旧习惯的打卡，也可以来记录新习惯的养成 有没有什么月度表之类的工具？ 事\u0026物记： 重要事件：当天发生的重要的事情，可能来自新闻、一天的工作、生活上 新事物 随手记：杂记一样，可以是天马行空的想法，像写个人日记一样，想怎么记怎么记，不束缚自己的一个板块，🆒！ 总结 情绪 明天？：大概想一下明天要做什么 ","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/:1:2","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/#记录区"},{"categories":["Tools-Method"],"content":" 提高效率为了提高做规划、记录的效率，上面讲到的这些东西应该是要能作为一个 模板 存在的，obsidian 刚好是能够完成这项工作的。 确定日记存放的位置：content/posts/diary 创建模板 日记文件相关设置 ","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/:2:0","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/#提高效率"},{"categories":["Tools-Method"],"content":" 流程 flowchart LR %% 重要性的分类 classDef important stroke:red, stroke-width:2px classDef pass stroke:grey, stroke-dasharray: 5,5 %% 流程的分类 classDef success stroke:green step1[新建一篇笔记]--\u003estep2[在规划区做规划] step2--\u003eday[一天流逝...事情都完成之后] day--\u003estep3[完成记录区的内容] class step2,step3 important class day pass 点击左侧的 打开/创建今天的日记 按钮，根据模板生成对应的日记文件 ","date":"2023-05-11","objectID":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/:3:0","series":["博客建设"],"tags":["个人记录"],"title":"怎么来规划一天、做日记录","uri":"/202305110405-%E6%80%8E%E4%B9%88%E6%9D%A5%E8%A7%84%E5%88%92%E4%B8%80%E5%A4%A9%E5%81%9A%E6%97%A5%E8%AE%B0%E5%BD%95/#流程"},{"categories":["生活记录"],"content":"#博客音乐嵌入样例 ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:0:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#"},{"categories":["生活记录"],"content":" Lessang 寻找幸福 music url=\"/music/finding_happiness/finding-happiness.mp3\" name=\"행복을 찾아서 (寻找幸福)\" artist=\"Leessang (리쌍)/赵贤雅 (조현아)\" cover=\"/music/finding_happiness/lessang.png\" 回想 music url=\"/music/lessang/recall.m4a\" name=\"회상 (Feat. 백지영) (回想)\" artist=\"Leessang (리쌍)/白智英 (백지영)\" cover=\"/music/lessang/recall.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:1:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#lessang"},{"categories":["生活记录"],"content":" IU jam jam (live) music url=\"/music/iu/jamjam(live).m4a\" name=\"잼잼(JAM JAM) (Live)\" artist=\"IU (아이유)\" cover=\"/music/iu/jamjamlive.jpg\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:2:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#iu"},{"categories":["生活记录"],"content":" aurora queendom music url=\"/music/aurora/queendom.m4a\" name=\"Queendom\" artist=\"AURORA\" cover=\"/music/aurora/queendom.jpg\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:3:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#aurora"},{"categories":["生活记录"],"content":" 我的大叔 무지개는 있다 (有彩虹) (Band Ver.) music url=\"/music/myuncle/有彩虹.mp3\" name=\"무지개는 있다 (有彩虹) (Band Ver.)\" artist=\"빈센트 블루 (Vincent Blue)\" cover=\"/music/myuncle/我的大叔.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:4:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#我的大叔"},{"categories":["生活记录"],"content":" 九连真人 music url=\"/music/九连真人/北风.mp3\" name=\"北风\" artist=\"九连真人\" cover=\"/music/九连真人/jiulianzhenren.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:5:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#九连真人"},{"categories":["生活记录"],"content":" amazarashi 無題(Unplugged) music url=\"/music/amazarashi/無題(Unplugged).mp3\" name=\"無題(Unplugged)\" artist=\"amazarashi\" cover=\"/music/amazarashi/wuti.png\" 僕が死のうと思ったのは(曾经我也想过一了百了) music url=\"/music/amazarashi/僕が死のうと思ったのは(曾经我也想过一了百了).mp3\" name=\"僕が死のうと思ったのは(曾经我也想过一了百了)\" artist=\"amazarashi\" cover=\"/music/amazarashi/xuwubing.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:6:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#amazarashi"},{"categories":["生活记录"],"content":" B 热河2018相信未来不插电版 music url=\"/music/B/热河2018相信未来不插电版.mp3\" name=\"热河2018相信未来不插电版\" artist=\"B\" cover=\"/music/B/wuti.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:7:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#b"},{"categories":["生活记录"],"content":" club 8 Love in December music url=\"/music/club8/LoveinDecember.mp3\" name=\"Love in December\" artist=\"club 8\" cover=\"/music/club8/LoveinDecember.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:8:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#club-8"},{"categories":["生活记录"],"content":" Epik High TROT music url=\"/music/epik-high/trot.mp3\" name=\"trot\" artist=\"B\" cover=\"/music/epik-high/trot.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:9:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#epik-high"},{"categories":["生活记录"],"content":" Gary 고장난 선풍기 (故障的电风扇) music url=\"/music/gary/故障的电风扇.mp3\" name=\"故障的电风扇\" artist=\"MC梦 (MC몽)/Gary (개리)/孝琳 (효린)\" cover=\"/music/gary/故障的电风扇.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:10:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#gary"},{"categories":["生活记录"],"content":" 请回答1988 걱정말아요 그대 (你不要担心) music url=\"/music/请回答1988/你不要担心.mp3\" name=\"걱정말아요 그대 (你不要担心)\" artist=\"SoulJa/青山黛玛 (青山テルマ)\" cover=\"/music/请回答1988/你不要担心.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:11:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#请回答1988"},{"categories":["生活记录"],"content":" 五条人 石牌桥 music url=\"/music/五条人/石牌桥.mp3\" name=\"石牌桥\" artist=\"五条人\" cover=\"/music/五条人/石牌桥.png\" 也已晚 music url=\"/music/五条人/夜已晚.mp3\" name=\"夜已晚\" artist=\"五条人\" cover=\"/music/五条人/夜已晚.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:12:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#五条人"},{"categories":["生活记录"],"content":" 徐佳莹 耳边风 music url=\"/music/徐佳莹/耳边风.mp3\" name=\"耳边风\" artist=\"徐佳莹\" cover=\"/music/徐佳莹/耳边风.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:13:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#徐佳莹"},{"categories":["生活记录"],"content":" jay-z Empire State of Mind music url=\"/music/jay-z/EmpireStateOfMind.mp3\" name=\"Empire State of Mind\" artist=\"Jay-Z/Alicia Keys\" cover=\"/music/jay-z/EmpireStateOfMind.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:14:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#jay-z"},{"categories":["生活记录"],"content":" Rachel Platten Fight Song music url=\"/music/RachelPlatten/FightSong.mp3\" name=\"Fight Song\" artist=\"Rachel Platten\" cover=\"/music/RachelPlatten/FightSong.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:15:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#rachel-platten"},{"categories":["生活记录"],"content":" Sophie Zelmani going home music url=\"/music/SophieZelmani/going-home.mp3\" name=\"going home\" artist=\"Sophie Zelmani\" cover=\"/music/SophieZelmani/SophieZelmani.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:16:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#sophie-zelmani"},{"categories":["生活记录"],"content":" Tom Rosenthal Go Solo music url=\"/music/TomRosenthal/GoSolo.mp3\" name=\"Go Solo\" artist=\"Tom Rosenthal\" cover=\"/music/TomRosenthal/GoSolo.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:17:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#tom-rosenthal"},{"categories":["生活记录"],"content":" pure Life Story music url=\"/music/pure/LifeStory.mp3\" name=\"Life Story\" artist=\"Ólafur Arnalds/Nils Frahm\" cover=\"/music/pure/LifeStory.png\" Passionflower music url=\"/music/pure/Passionflower.mp3\" name=\"Passionflower\" artist=\"Jon Gomm\" cover=\"/music/pure/Passionflower.png\" ","date":"2023-05-10","objectID":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/:18:0","series":["音乐"],"tags":[],"title":"博客音乐嵌入样例","uri":"/202305101553-%E5%8D%9A%E5%AE%A2%E9%9F%B3%E4%B9%90%E5%B5%8C%E5%85%A5%E6%A0%B7%E4%BE%8B/#pure"},{"categories":["生活记录"],"content":"#游玩映像 ","date":"2023-05-10","objectID":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/:0:0","series":["影像记录"],"tags":["游玩映像"],"title":"22年的国庆广州游玩映像","uri":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/#"},{"categories":["生活记录"],"content":" Day1. 陈家祠堂、沙面、叉烧… ","date":"2023-05-10","objectID":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/:1:0","series":["影像记录"],"tags":["游玩映像"],"title":"22年的国庆广州游玩映像","uri":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/#day1-陈家祠堂沙面叉烧"},{"categories":["生活记录"],"content":" Day2. 肠粉、长隆 真的帅 ","date":"2023-05-10","objectID":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/:2:0","series":["影像记录"],"tags":["游玩映像"],"title":"22年的国庆广州游玩映像","uri":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/#day2-肠粉长隆"},{"categories":["生活记录"],"content":" Day3. 北园酒家、南越王博物院、中山纪念堂、太古仓码头、夜游珠江 ","date":"2023-05-10","objectID":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/:3:0","series":["影像记录"],"tags":["游玩映像"],"title":"22年的国庆广州游玩映像","uri":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/#day3-北园酒家南越王博物院中山纪念堂太古仓码头夜游珠江"},{"categories":["生活记录"],"content":" Day4. 动物园 ","date":"2023-05-10","objectID":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/:4:0","series":["影像记录"],"tags":["游玩映像"],"title":"22年的国庆广州游玩映像","uri":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/#day4-动物园"},{"categories":["生活记录"],"content":" Day5. 植物园、广东博物馆、石牌桥 ","date":"2023-05-10","objectID":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/:5:0","series":["影像记录"],"tags":["游玩映像"],"title":"22年的国庆广州游玩映像","uri":"/202305101458-22%E5%B9%B4%E7%9A%84%E5%9B%BD%E5%BA%86%E5%B9%BF%E5%B7%9E%E6%B8%B8%E7%8E%A9%E6%98%A0%E5%83%8F/#day5-植物园广东博物馆石牌桥"},{"categories":["生活记录"],"content":"#彩铅 ","date":"2023-05-10","objectID":"/202305101439-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E5%BD%A9%E9%93%85/:0:0","series":["画画"],"tags":["彩铅"],"title":"废了很久的爱好-彩铅","uri":"/202305101439-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E5%BD%A9%E9%93%85/#"},{"categories":["生活记录"],"content":" long long ago… ","date":"2023-05-10","objectID":"/202305101439-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E5%BD%A9%E9%93%85/:1:0","series":["画画"],"tags":["彩铅"],"title":"废了很久的爱好-彩铅","uri":"/202305101439-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E5%BD%A9%E9%93%85/#long-long-ago"},{"categories":["生活记录"],"content":"#树脂 ","date":"2023-05-10","objectID":"/202305101440-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E6%A0%91%E8%84%82%E7%94%BB/:0:0","series":["画画"],"tags":["彩铅"],"title":"废了很久的爱好-树脂画","uri":"/202305101440-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E6%A0%91%E8%84%82%E7%94%BB/#"},{"categories":["生活记录"],"content":" long long ago… ","date":"2023-05-10","objectID":"/202305101440-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E6%A0%91%E8%84%82%E7%94%BB/:1:0","series":["画画"],"tags":["彩铅"],"title":"废了很久的爱好-树脂画","uri":"/202305101440-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E6%A0%91%E8%84%82%E7%94%BB/#long-long-ago"},{"categories":["生活记录"],"content":"#素描 ","date":"2023-05-10","objectID":"/202305101436-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E7%B4%A0%E6%8F%8F/:0:0","series":["画画"],"tags":["素描"],"title":"废了很久的爱好-素描","uri":"/202305101436-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E7%B4%A0%E6%8F%8F/#"},{"categories":["生活记录"],"content":" long long ago… ","date":"2023-05-10","objectID":"/202305101436-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E7%B4%A0%E6%8F%8F/:1:0","series":["画画"],"tags":["素描"],"title":"废了很久的爱好-素描","uri":"/202305101436-%E5%BA%9F%E4%BA%86%E5%BE%88%E4%B9%85%E7%9A%84%E7%88%B1%E5%A5%BD-%E7%B4%A0%E6%8F%8F/#long-long-ago"},{"categories":["生活记录"],"content":"#宠物映像 ","date":"2023-05-10","objectID":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/:0:0","series":["影像记录"],"tags":["我的宠物朋友"],"title":"在我的大学生涯短暂陪伴过我的一只玄凤","uri":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/#"},{"categories":["生活记录"],"content":" 刚来的时候來了一段时间后的样子，长了一点羽毛，给他搞了个架子 ","date":"2023-05-10","objectID":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/:1:0","series":["影像记录"],"tags":["我的宠物朋友"],"title":"在我的大学生涯短暂陪伴过我的一只玄凤","uri":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/#刚来的时候"},{"categories":["生活记录"],"content":" 一次事故 一次意外导致左腿骨折了，还好之后顺利恢复了。 ","date":"2023-05-10","objectID":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/:2:0","series":["影像记录"],"tags":["我的宠物朋友"],"title":"在我的大学生涯短暂陪伴过我的一只玄凤","uri":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/#一次事故"},{"categories":["生活记录"],"content":" later ","date":"2023-05-10","objectID":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/:3:0","series":["影像记录"],"tags":["我的宠物朋友"],"title":"在我的大学生涯短暂陪伴过我的一只玄凤","uri":"/202305101443-%E5%9C%A8%E6%88%91%E7%9A%84%E5%A4%A7%E5%AD%A6%E7%94%9F%E6%B6%AF%E7%9F%AD%E6%9A%82%E9%99%AA%E4%BC%B4%E8%BF%87%E6%88%91%E7%9A%84%E4%B8%80%E5%8F%AA%E7%8E%84%E5%87%A4/#later"},{"categories":["生活记录"],"content":"#听歌月记录 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:0:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#"},{"categories":["生活记录"],"content":" 2022 年度报告 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:1:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#2022-年度报告"},{"categories":["生活记录"],"content":" 2022/12 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:2:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202212"},{"categories":["生活记录"],"content":" 2022/11 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:3:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202211"},{"categories":["生活记录"],"content":" 2022/10 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:4:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202210"},{"categories":["生活记录"],"content":" 2022/09 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:5:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202209"},{"categories":["生活记录"],"content":" 2022/08 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:6:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202208"},{"categories":["生活记录"],"content":" 2022/07 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:7:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202207"},{"categories":["生活记录"],"content":" 2022/06 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:8:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202206"},{"categories":["生活记录"],"content":" 2022/05 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:9:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202205"},{"categories":["生活记录"],"content":" 2022/04 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:10:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202204"},{"categories":["生活记录"],"content":" 2022/03 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:11:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202203"},{"categories":["生活记录"],"content":" 2022/02 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:12:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202202"},{"categories":["生活记录"],"content":" 2022/01 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:13:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202201"},{"categories":["生活记录"],"content":" 2021 年度报告 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:14:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#2021-年度报告"},{"categories":["生活记录"],"content":" 2021/12 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:15:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202112"},{"categories":["生活记录"],"content":" 2021/11 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:16:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202111"},{"categories":["生活记录"],"content":" 2021/10 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:17:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202110"},{"categories":["生活记录"],"content":" 2021/09 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:18:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202109"},{"categories":["生活记录"],"content":" 2021/08 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:19:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202108"},{"categories":["生活记录"],"content":" 2021/07 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:20:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202107"},{"categories":["生活记录"],"content":" 2021/06 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:21:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202106"},{"categories":["生活记录"],"content":" 2021/05 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:22:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202105"},{"categories":["生活记录"],"content":" 2021/04 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:23:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202104"},{"categories":["生活记录"],"content":" 2021/03 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:24:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202103"},{"categories":["生活记录"],"content":" 2021/02 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:25:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202102"},{"categories":["生活记录"],"content":" 2021/01 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:26:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202101"},{"categories":["生活记录"],"content":" 2020/11 ","date":"2023-05-10","objectID":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/:27:0","series":["音乐"],"tags":["听歌月记录"],"title":"听歌月记录","uri":"/202305101357-%E5%90%AC%E6%AD%8C%E6%9C%88%E8%AE%B0%E5%BD%95/#202011"},{"categories":["Tools-Method"],"content":"#mermaid （思维导图在 obsidian v1.2.7 中还没支持） ","date":"2023-05-10","objectID":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/:0:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-思维导图","uri":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/#"},{"categories":["Tools-Method"],"content":" 基本语法思维导图主要通过 缩进 来表示其结构 再配合记住一些关键字即可： mindmap root mindmap root a aa ab b mindmap root a aa ab b ","date":"2023-05-10","objectID":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/:1:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-思维导图","uri":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/#基本语法"},{"categories":["Tools-Method"],"content":" 元素的形状跟流程图表现形状的方法类似 mindmap root((mymind)) id[1.square] id(2.rounded) id((3.circle)) id))4.explode(( id)5.cloud( id{{6.hexagon}} 7.default mindmap root((mymind)) id[1.square] id(2.rounded) id((3.circle)) id))4.explode(( id)5.cloud( id{{6.hexagon}} 7.default ","date":"2023-05-10","objectID":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/:2:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-思维导图","uri":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/#元素的形状"},{"categories":["Tools-Method"],"content":" 文字说明“`文字内容`” mindmap root((mymind)) id[\"`1.square 一些说明性的文字 可能会有换行的需求 这将使用到反单引号 这里同样可以使用表情🥵`\"] id(2.rounded) id((3.circle)) mindmap root((mymind)) id[\"`1.square 一些说明性的文字 可能会有换行的需求 这将使用到反单引号 这里同样可以使用表情🥵`\"] id(2.rounded) id((3.circle)) ","date":"2023-05-10","objectID":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/:3:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-思维导图","uri":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/#文字说明"},{"categories":["Tools-Method"],"content":" 图标::icon() mindmap root((mymind)) id[1.square] ::icon(fas fa-yen-sign) id(2.rounded) id((3.circle)) ::icon(fas fa-circle-notch) id))4.explode(( id)5.cloud( ::icon(fas fa-cloud) id{{6.hexagon}} 7.default mindmap root((mymind)) id[1.square] ::icon(fas fa-yen-sign) id(2.rounded) id((3.circle)) ::icon(fas fa-circle-notch) id))4.explode(( id)5.cloud( ::icon(fas fa-cloud) id{{6.hexagon}} 7.default 看效果感觉做的还不是很好 https://mermaid.js.org/syntax/mindmap.html ","date":"2023-05-10","objectID":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/:4:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-思维导图","uri":"/202305101117-mermaid-%E8%AF%AD%E6%B3%95-%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/#图标"},{"categories":["Tools-Method"],"content":"#个人记录 适合自己的就是最好的 ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:0:0","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#"},{"categories":["Tools-Method"],"content":" 写作","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:0","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#写作"},{"categories":["Tools-Method"],"content":" 我的写作工具 flowchart LR tp[typora]--\u003e|1|vsc[vscode] vsc--\u003etp tp--\u003e|2|nt[notion] nt--\u003etp tp--\u003e|3|ta[the archive] subgraph 支持卡片盒笔记法 ta--\u003e|4|o[\"obsidian(正在使用)\"] end Obsidian之前换过一些工具，就先不记录了，因为前段时间看了卡片盒笔记法，找了一些方便使用这个方法的软件来用，正在使用 Obsidian，记录一下一些常用设置： （为什么这个框框得点两次） 新建文件路径、图片存放位置 适配卡片盒笔记法 一个正常的笔记流程： 新建时间戳笔记 修改文件的相关描述 开始写作 ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:1","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#我的写作工具"},{"categories":["Tools-Method"],"content":" 我的写作工具 flowchart LR tp[typora]--\u003e|1|vsc[vscode] vsc--\u003etp tp--\u003e|2|nt[notion] nt--\u003etp tp--\u003e|3|ta[the archive] subgraph 支持卡片盒笔记法 ta--\u003e|4|o[\"obsidian(正在使用)\"] end Obsidian之前换过一些工具，就先不记录了，因为前段时间看了卡片盒笔记法，找了一些方便使用这个方法的软件来用，正在使用 Obsidian，记录一下一些常用设置： （为什么这个框框得点两次） 新建文件路径、图片存放位置 适配卡片盒笔记法 一个正常的笔记流程： 新建时间戳笔记 修改文件的相关描述 开始写作 ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:1","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#obsidian"},{"categories":["Tools-Method"],"content":" 图床使用 github 保存图片 编辑的时候粘贴的时候都保存到本地 themes/DoIt/assets/images/posts 文件夹中，写作的时候无需做上传图片的操作 但是需要把 ·themes/DoIt/assets/ images/posts 这段内容删除，为的是让 hugo 生成静态页面之后能找到这张图片 这样就能够同时在 博客、obsidian 中看到这张图片 ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:2","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#图床"},{"categories":["Tools-Method"],"content":" 键盘 NIZ 宁芝 84EC(S) Ble好！ 固件、编程软件下载 正常写作、工作问题定位的时候可能会用到一些重复性的输入，复杂的输入，使用编程软件编写对应的宏，提高效率 宏 首先 1.读取配置 放置直接写入覆盖掉了之前的配置，然后进行 自定义的操作，编辑完成之后把配置 写入按键，最后保存一下配置，做个备份。 看下效果： ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:3","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#键盘"},{"categories":["Tools-Method"],"content":" 键盘 NIZ 宁芝 84EC(S) Ble好！ 固件、编程软件下载 正常写作、工作问题定位的时候可能会用到一些重复性的输入，复杂的输入，使用编程软件编写对应的宏，提高效率 宏 首先 1.读取配置 放置直接写入覆盖掉了之前的配置，然后进行 自定义的操作，编辑完成之后把配置 写入按键，最后保存一下配置，做个备份。 看下效果： ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:3","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#niz-宁芝-84ecs-ble"},{"categories":["Tools-Method"],"content":" 音乐嵌入流程 把音乐放到对应的 music 文件夹 编辑调用代码 music url=\"/music/lessang/recall.m4a\" name=\"xxx\" artist=\"xxx\" cover=\"/music/lessang/xxx.png\" 示例： ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:4","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#音乐嵌入流程"},{"categories":["Tools-Method"],"content":" 画图 processon mermaid boardmix whimsical ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:1:5","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#画图"},{"categories":["Tools-Method"],"content":" 下载","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:2:0","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#下载"},{"categories":["Tools-Method"],"content":" 通常下载IDM ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:2:1","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#通常下载"},{"categories":["Tools-Method"],"content":" youtube 视频音频https://youtube.iiilab.com/ ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:2:2","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#youtube-视频音频"},{"categories":["Tools-Method"],"content":" 工作用途 ssh：mobaxterm ftp：winscp ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:3:0","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#工作用途"},{"categories":["Tools-Method"],"content":" 阅读","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:4:0","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#阅读"},{"categories":["Tools-Method"],"content":" RSS inoreader ","date":"2023-05-10","objectID":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/:4:1","series":["工具"],"tags":["个人记录","操作备忘"],"title":"开始记录一些我的工具、便捷操作[持续记录...]","uri":"/202305101151-%E5%BC%80%E5%A7%8B%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E6%88%91%E7%9A%84%E5%B7%A5%E5%85%B7%E4%BE%BF%E6%8D%B7%E6%93%8D%E4%BD%9C/#rss"},{"categories":["Tools-Method"],"content":"#mermaid ","date":"2023-05-10","objectID":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/:0:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-甘特图","uri":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/#"},{"categories":["Tools-Method"],"content":" 先来看一个简单的例子 gantt title simple sample section A task1 :one, 2023-05-10, 1d task2 :two, 2023-05-10, 5h 代码大体由以下几部分组成： 大致分成： gantt 定义区 section 区 任务描述 主要的话还是关于任务信息的写法 ","date":"2023-05-10","objectID":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/:1:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-甘特图","uri":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/#先来看一个简单的例子"},{"categories":["Tools-Method"],"content":" 任务信息 任务名称，描述 :[任务性质], [是否完成], [别名], [开始时间], [持续时间|结束时间] 这些描述字段大都是可选的 属性 值 任务性质 crit - 重要任务 milestone - 里程碑任务 是否完成 active - 激活状态 done - 已完成 别名 最好不要有数字！ 开始时间 格式由 gantt 定义区的 dateFormat 属性指定，例如：dateFormat YYYY-MM-DD 持续时间 数字 + m/h/d/w 可以把一些属性放在任务区外面来写： ","date":"2023-05-10","objectID":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/:2:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-甘特图","uri":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/#任务信息"},{"categories":["Tools-Method"],"content":" gantt 定义区的内容 title 标题 dateFormat 定义输入的日期格式 支持解析的占位符列表 axisFormat x 轴显示格式 https://github.com/d3/d3-time-format/tree/v4.0.0#locale_format tickInterval x 轴刻度 /^([1-9][0-9]*)(minute|hour|day|week|month)$/; displayMode: compact 可以让 gantt 图更紧凑 --- displayMode: compact --- gantt title A Gantt Diagram dateFormat YYYY-MM-DD section Section A task :a1, 2014-01-01, 30d Another task :a2, 2014-01-20, 25d Another one :a3, 2014-02-10, 20d --- displayMode: compact --- gantt ... ","date":"2023-05-10","objectID":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/:3:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-甘特图","uri":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/#gantt-定义区的内容"},{"categories":["Tools-Method"],"content":" 例子 gantt title 项目计划表 section 设计阶段 需求分析:done,a, 2022-01-01, 10d 概要设计:done,b, 2022-01-11, 10d 详细设计:c, 2022-01-21, 10d section 编码阶段 编码:crit,d, 2022-02-01, 28d section 测试阶段 单元测试:e, 2022-03-01, 10d 集成测试:f, 2022-03-11, 10d 系统测试:g, 2022-03-21, 10d gantt title 项目计划表 section 设计阶段 需求分析:done,a, 2022-01-01, 10d 概要设计:done,b, 2022-01-11, 10d 详细设计:c, 2022-01-21, 10d section 编码阶段 编码:crit,d, 2022-02-01, 28d section 测试阶段 单元测试:e, 2022-03-01, 10d 集成测试:f, 2022-03-11, 10d 系统测试:g, 2022-03-21, 10d https://mermaid.js.org/syntax/gantt.html ","date":"2023-05-10","objectID":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/:4:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-甘特图","uri":"/202305100916-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%98%E7%89%B9%E5%9B%BE/#例子"},{"categories":["Tools-Method"],"content":"#mermaid journey title My working day section study 打扫: 3: Me 学习: 3: Me 看 rm: 5: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me journey title My working day section study 打扫: 3: Me 学习: 3: Me 看 rm: 5: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me https://mermaid.js.org/syntax/userJourney.html ","date":"2023-05-10","objectID":"/202305100347-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%A8%E6%88%B7%E6%97%85%E7%A8%8B%E5%9B%BE/:0:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-用户旅程图","uri":"/202305100347-mermaid-%E8%AF%AD%E6%B3%95-%E7%94%A8%E6%88%B7%E6%97%85%E7%A8%8B%E5%9B%BE/#"},{"categories":["Tools-Method"],"content":"#mermaid pie showData title 被收养的宠物 \"Dogs\": 386 \"Cats\": 85 \"Rats\": 15 pie showData title 被收养的宠物 \"Dogs\": 386 \"Cats\": 85 \"Rats\": 15 https://mermaid.js.org/syntax/pie.html ","date":"2023-05-10","objectID":"/202305100200-mermaid-%E8%AF%AD%E6%B3%95-%E9%A5%BC%E5%9B%BE/:0:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-饼图","uri":"/202305100200-mermaid-%E8%AF%AD%E6%B3%95-%E9%A5%BC%E5%9B%BE/#"},{"categories":["Tools-Method"],"content":"#mermaid ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:0:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#"},{"categories":["Tools-Method"],"content":" 消息首先分成 实线 和 虚线 ，然后每种线都有 无箭头、有箭头、带x箭头、空心箭头（异步） 四种箭头 类型 渲染 -\u003e -» -x -) –\u003e –» –x –) ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:1:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#消息"},{"categories":["Tools-Method"],"content":" 序号autonumber sequenceDiagram autonumber rect rgb(191,233,255) a-\u003e\u003eb: hello b-\u003e\u003ec: hi rect rgb(255,106,106) b-\u003e\u003ea: i hate you end end sequenceDiagram autonumber rect rgb(191,233,255) a-\u003e\u003eb: hello b-\u003e\u003ec: hi rect rgb(205,38,38) b-\u003e\u003ea: i hate you end end ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:2:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#序号"},{"categories":["Tools-Method"],"content":" 成员 participant、actor成员可以有超链接 sequenceDiagram %% 定义成员出现的顺序 participant Alice participant Bob Alice-\u003e\u003eBob: Hi Bob Bob-\u003e\u003eAlice: Hi Alice ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:3:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#成员-participantactor"},{"categories":["Tools-Method"],"content":" 两种类型 类型 渲染 participant actor ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:3:1","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#两种类型"},{"categories":["Tools-Method"],"content":" 别名participant/actor 别名 as user01 participant A as Alice ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:3:2","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#别名"},{"categories":["Tools-Method"],"content":" 分组box … end sequenceDiagram box Group 01 actor a actor b end box Another Group actor c actor d end a-\u003eb: hi! b-\u003ec: hello! c-\u003ed: hi! d-\u003ea: so high! sequenceDiagram box Group 01 actor a actor b end box Another Group actor c actor d end a-\u003eb: hi! b-\u003ec: hello! c-\u003ed: hi! d-\u003ea: so high! ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:3:3","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#分组"},{"categories":["Tools-Method"],"content":" 激活-结束 activate … deactivate + / - sequenceDiagram actor a actor b a-\u003e\u003eb: cook activate b b-\u003e\u003ea: done! deactivate b 实现1. sequenceDiagram actor a actor b a-\u003e\u003eb: cook activate b b-\u003e\u003ea: done! deactivate b 实现2. sequenceDiagram a-\u003e\u003e+b: cook begin! b-\u003e\u003e-a: is done! 重复激活： sequenceDiagram a-\u003e\u003e+b: cook 1! a-\u003e\u003e+b: cook 2! b-\u003e\u003e-a: 1 done! b-\u003e\u003e-a: 2 done! sequenceDiagram a-\u003e\u003e+b: cook 1! a-\u003e\u003e+b: cook 2! b-\u003e\u003e-a: 1 done! b-\u003e\u003e-a: 2 done! ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:4:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#激活-结束"},{"categories":["Tools-Method"],"content":" 循环loop 频率 … end sequenceDiagram actor a actor b a-\u003e\u003eb: 你好吗? loop every secs b--\u003e\u003ea: 很好! end sequenceDiagram actor a actor b a-\u003e\u003eb: 你好吗? loop every secs b--\u003e\u003ea: 很好! end ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:5:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#循环"},{"categories":["Tools-Method"],"content":" 分支 sequenceDiagram actor a actor b a-\u003e\u003eb: 你好吗? alt 生病了，很忙... b-\u003e\u003ea: 不好 end alt 很健康 b-\u003e\u003ea: 很好 end sequenceDiagram actor a actor b a-\u003e\u003eb: 你好吗? alt 生病了，很忙... b-\u003e\u003ea: 不好 end alt 很健康 b-\u003e\u003ea: 很好 end ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:6:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#分支"},{"categories":["Tools-Method"],"content":" 并行消息par … and … end 用来表示并行的消息 显然是可以嵌套的 sequenceDiagram actor server actor client1 actor client2 par 响应用户1 server-\u003e\u003eclient1: response and 响应用户2 server-\u003e\u003eclient2: response end client1--\u003e\u003eserver: request next client2--\u003e\u003eserver: request next sequenceDiagram actor server actor client1 actor client2 par 响应用户1 server-\u003e\u003eclient1: response and 响应用户2 server-\u003e\u003eclient2: response end client1--\u003e\u003eserver: request next client2--\u003e\u003eserver: request next ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:7:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#并行消息"},{"categories":["Tools-Method"],"content":" 结果可预见的情况，列举所有情况以一个服务跟数据库建立连接为例，结果无非： 连接成功 连接超时 连接被拒绝 critical … option … option … end sequenceDiagram critical 良好的连接环境 service--\u003eDB: 连接成功 option 网络超时 service--\u003eservice: 登录失败 option 密码错误 service-\u003e\u003eDB: 登录验证 DB-\u003e\u003eservice: 验证失败 end sequenceDiagram critical 良好的连接环境 service--\u003eDB: 连接成功 option 网络超时 service--\u003eservice: 登录失败 option 密码错误 service-\u003e\u003eDB: 登录验证 DB-\u003e\u003eservice: 验证失败 end ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:8:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#结果可预见的情况列举所有情况"},{"categories":["Tools-Method"],"content":" 停止/休息break … end sequenceDiagram Consumer--\u003eAPI: Book something API--\u003eBookingService: Start booking process break when the booking process fails API--\u003eConsumer: show failure end API--\u003eBillingService: Start billing process sequenceDiagram Consumer--\u003eAPI: Book something API--\u003eBookingService: Start booking process break when the booking process fails API--\u003eConsumer: show failure end API--\u003eBillingService: Start billing process ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:9:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#停止休息"},{"categories":["Tools-Method"],"content":" 便签 Note left of Note right of Note over sequenceDiagram actor a actor b actor c Note left of a: 1. Note left of a Note right of b: 2. Note right of b Note over c: 3. Note over c Note over a,b: 4. Note over a,b Note over a: 5. Note over a a-\u003e\u003e+b: cook 1! b-\u003e\u003e-a: done! ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:10:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#便签"},{"categories":["Tools-Method"],"content":" 背景颜色 rect rgb(x,x,x) or rgba(x,x,x) sequenceDiagram rect rgb(191,233,255) a-\u003e\u003eb: hello b-\u003e\u003ec: hi rect rgb(255,106,106) b-\u003e\u003ea: i hate you end end sequenceDiagram rect rgb(191,233,255) a-\u003e\u003eb: hello b-\u003e\u003ec: hi rect rgb(255,106,106) b-\u003e\u003ea: i hate you end end https://mermaid.js.org/syntax/sequenceDiagram.html ","date":"2023-05-10","objectID":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/:11:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-时序图","uri":"/202305100218-mermaid-%E8%AF%AD%E6%B3%95-%E6%97%B6%E5%BA%8F%E5%9B%BE/#背景颜色"},{"categories":["Tools-Method"],"content":"#mermaid ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:0:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#"},{"categories":["Tools-Method"],"content":" 流程图流程图的方向： 水平：LRLeft Right、RLRight Left 垂直：TDTop Down 流程图的组成元素分成两大类： 框框 线 ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#流程图"},{"categories":["Tools-Method"],"content":" 框 A[方形] A(圆角) A{菱形} A([体育场]) A[[子程序]] A[(数据库)] A((圆)) A\u003e就这个形状] A{{六边形}} A[/平行四边形/] A[\\平行四边形\\] A[/平行四边形\\] A[\\平行四边形/] A(((双圆圈))) 框 渲染 a[方形] a(圆角) A{菱形} A([体育场]) A[[子程序]] A[(数据库)] A((圆)) A\u003e就这个形状] A{{六边形}} A[/平行四边形/] … A(((双圆圈))) 填色： %% 1. 类定义 classDef yellow fill:yellow a---b---c %% 2. 把样式给方块 class a yellow graph LR %% 1. 类定义 classDef yellow fill:yellow a---b---c %% 2. 把样式给方块 class a yellow ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:1","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#框"},{"categories":["Tools-Method"],"content":" 线 ---\u003e --- -.-\u003e ==\u003e # 厚 --o --x \u003c--\u003e -- text -- OR A----|text|B -- text --\u003e OR A----\u003e|text|B 看不见的链接：（如果想要改变框框的位置，这可能是有用的） ~~~ 线 渲染 说明 —\u003e — -.-\u003e ==\u003e 比较厚的线 –o –x \u003c–\u003e A–\u003e|text|B ~~~ 两个元素之间空白的连线 ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:2","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#线"},{"categories":["Tools-Method"],"content":" 组合同一行内可以写多个连接 a--\u003eb --\u003ec a--B\u0026c--\u003ed A \u0026 B--\u003e C \u0026 D 上面这行写法可读性可能不太好，不如写成： a --\u003e c \u0026 d b --\u003e c \u0026 d ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:3","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#组合"},{"categories":["Tools-Method"],"content":" 子图 使用 subgraph … end 来划分子图 子图之间可以画线、子图与元素之间可以画线 子图可以用 direction 指定方向(例如 direction LD，放在 subgraph 后面一行) graph TD a---c subgraph one d---c end subgraph two e---f end ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:4","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#子图"},{"categories":["Tools-Method"],"content":" 文本 文本也可以像 Markdown 一样使用星号加粗 ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:5","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#文本"},{"categories":["Tools-Method"],"content":" 注释 %% ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:6","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#注释"},{"categories":["Tools-Method"],"content":" 润色 图标： graph LR a---b[fa:fa-spinner] 类定义 %% 1. 类定义 classDef classname fill:yellow, stroke:yellow, stroke-width: 4px, storoke-dasharray: 5, 5 a---b---c %% 2. 把样式给方块 class a classname fill 用颜色填满元素 stroke 边框颜色 stroke-width 边框宽度 stroke-dasharray 虚线边框 ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:1:7","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#润色"},{"categories":["Tools-Method"],"content":" 例子 flowchart TD %% 重要性的分类 classDef important stroke:red, stroke-width:2px classDef pass stroke:grey, stroke-dasharray: 5,5 %% 流程的分类 classDef success stroke:green %% 解释 classDef stick fill:yellow, stroke:yellow classDef stickImp fill:pink, stroke:pink, color:black a[重要]---b[一般]---c[可忽略] b---d[重要] d---e[成功] f[实现类似便签的效果 对一个元素或者流程节点加以解释] f-.-d class a,d important class c pass class e success class f stickImp classDef important stroke:red, stroke-width:2px classDef pass stroke:grey, stroke-dasharray: 5,5 classDef success stroke:green classDef stick fill:yellow, stroke:yellow classDef stickImp fill:pink, stroke:pink, color:black a[重要]---b[一般]---c[可忽略] b---d[重要] d---e[成功] f[实现类似便签的效果\u003cbr\u003e对一个元素或者流程节点加以解释] f-.-d class a,d important class c pass class e success class f stickImp https://mermaid.js.org/syntax/flowchart.html ","date":"2023-05-09","objectID":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/:2:0","series":["mermaid语法"],"tags":["画图"],"title":"mermaid 语法-流程图","uri":"/202305092142-mermaid-%E8%AF%AD%E6%B3%95-%E6%B5%81%E7%A8%8B%E5%9B%BE/#例子"},{"categories":["Tools-Method"],"content":"最近打算把自己的文档从本地放到博客上，方便自己在线查看。借这个机会好好整理一下自己的写作流","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/"},{"categories":["Tools-Method"],"content":"#myflow 前言：最近打算把自己的文档从本地放到博客上，方便自己在线查看。因此写这篇文档的目的也是想借这个机会好好整理一下自己的写作流 打算从下面几个方面来整理： 之前的一些写作习惯 针对 obsidian的特性、hugo、markdown、卡片盒笔记法这些特性来尝试养成一些新的习惯 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:0:0","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#"},{"categories":["Tools-Method"],"content":" 一、回顾一下之前的写作习惯从大学很早的时候就接触到了 Markdown 的语言，让写作真的变得很方便，可以让写作者专注于内容，而不是排版，这也帮助我养成了做记录的习惯。 （因为这次都把文档放到博客上了，之后的话，本地软件（obsidian）更加侧重来编辑，查看的话多在博客查看吧，在文档的显示风格的考虑上，更加侧重博客的渲染情况。） ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:1:0","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#一回顾一下之前的写作习惯"},{"categories":["Tools-Method"],"content":" 文本显示 关于重点文字如何突出显示首先把内容分一下等级，这里的“内容”范围应该是一个段落，一段文字的范围之内的，而不考虑整篇文章，因为整篇文章的角度来看的话，使用 # 来做结构的切分已经很清晰了。把内容的分级就粗略分成三个等级： 重点 正常 解释说明 整体阅读的时候应该顺着“正常”的内容顺序阅读，“重点”应该能够让自己在视觉上比较好的注意到，“解释说明”作为比较不重要的能容，阅读的时候有时候可以忽略，如果可以偏灰色是最好的 自己在记录的过程中，比较在意的就是怎么让自己在之后回顾的时候比较好的看到重点，首先就是不能太花哨，其次重点需要标记出来，在 Markdown 语法中，我经常用来标记重点的方式就是用反单引号、加粗的方式，但是由于之前写作的软件换过几次，不同的软件、不同的 theme 之间，这两种方式的显示有时候不是那么明显，有时候反单引号看不太出来，有时候加粗看不太出来，所以趁着这次整理，再比较一下这两种方式。 Markdown 语法中，有以下几种方式被设计来强调内容： 粗体 x 渲染情况 obsidian hugo 斜体 x 渲染情况 obsidian hugo 见下方 这是一段包含斜体文字的文本。 删除 x 渲染情况 obsidian hugo 见下方 这是一段包含删除文字的文本。 上面几种方式的组合 删除+粗体：删除的粗体文字 但是除了上面几种方式，我在以往写作的过程中经常会使用到代码的语法（反单引号 ` 的语法）来标注重点，也就是这样的效果。因为在有的主题风格中，代码的显示效果很不错，能够很直观的注意到那段高亮文本，相比上面表现良好的粗体文本，高亮文本可能表现更好，因为在标题比较多、文字段落又比较少的情况下，文本的粗体可能会隐藏在标题的粗体中，肉眼寻找起来也是费力的。 刚好在 DoIt 风格（本博客的风格主题）中，高亮表现不错，就确定代码语法用来突出重点文字吧（虽然在 obsidian 中(我使用的主题风格是 Atom)，反单引号的显示效果并不好，但是考虑到之后阅读多在博客上阅读，就这么决定吧）顺便看一下反单引号+加粗的效果：删除的重点文字 总结：最需要注意的内容，就用反单引号来概括吧！ 关于正常文字的分类显示在一段正常的文本中，可能没有重点，但是可能会有一些不同的类别，比如参杂着一个方法名、文件/文件夹的名称、命令等，之前用来标注这些可能会用上面反单引号的方式，但是在 hugo 中太显眼了，上面已经决定用来显示重点文字了，就得考虑别的方式了。 这类文字应该跟正常文字有相同的显眼程度，感觉比较理想的显示方式应该是类似这样的，就是给文字加一个单纯的、不显眼的背景色，但是 Markdown 本身没有这样的语法，上面效果的实现方式是： \u003cfont style=\"background:#e8e9e4\"\u003e是类似这样的\u003c/font\u003e 是使用 html 的方式来实现的，但是感觉这样的书写方式已经有点违背 Markdown 诞生的初衷了，又让写作变得复杂起来，有点得不偿失，感觉目前对于这一类的文字没有比较好的方案来解决，就先暂定吧。 总结：暂定 第三种等级的解释性文字这种等级的文字段落，感觉最好的应该是灰色的字体，类似这样： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 上面这样的效果是我期待的效果，这种不太重要的文字，可能就是备注一下怕之后忘记，可能第二次第三次我再次阅读的时候如果我还记得我就不会再看这段文字了，这样的颜色可以让我在顺序阅读下来的时候很好的忽略掉，省去大脑、眼睛去甄别重要性的时间，让阅读变得更流畅一些，但是跟上面分类文字的显示一样，这也是用 html 的方式来实现的： \u003cfont color=grey\u003e这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。\u003c/font\u003e 感觉还是不太好，但是感觉会比上面的分类文字的显示更能接受一些，因为像这种解释性的文字通常是： 连在一起的，一片 不那么经常出现 所以相比带来的收益跟效果，还是比较能接受的。（在复制文本的场景下，也会多出来一段 html 代码，也是需要考虑的缺点，虽然这样的场景更少） 总结：所以解释性的文字就这么来显示吧！ ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:1:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#文本显示"},{"categories":["Tools-Method"],"content":" 文本显示 关于重点文字如何突出显示首先把内容分一下等级，这里的“内容”范围应该是一个段落，一段文字的范围之内的，而不考虑整篇文章，因为整篇文章的角度来看的话，使用 # 来做结构的切分已经很清晰了。把内容的分级就粗略分成三个等级： 重点 正常 解释说明 整体阅读的时候应该顺着“正常”的内容顺序阅读，“重点”应该能够让自己在视觉上比较好的注意到，“解释说明”作为比较不重要的能容，阅读的时候有时候可以忽略，如果可以偏灰色是最好的 自己在记录的过程中，比较在意的就是怎么让自己在之后回顾的时候比较好的看到重点，首先就是不能太花哨，其次重点需要标记出来，在 Markdown 语法中，我经常用来标记重点的方式就是用反单引号、加粗的方式，但是由于之前写作的软件换过几次，不同的软件、不同的 theme 之间，这两种方式的显示有时候不是那么明显，有时候反单引号看不太出来，有时候加粗看不太出来，所以趁着这次整理，再比较一下这两种方式。 Markdown 语法中，有以下几种方式被设计来强调内容： 粗体 x 渲染情况 obsidian hugo 斜体 x 渲染情况 obsidian hugo 见下方 这是一段包含斜体文字的文本。 删除 x 渲染情况 obsidian hugo 见下方 这是一段包含删除文字的文本。 上面几种方式的组合 删除+粗体：删除的粗体文字 但是除了上面几种方式，我在以往写作的过程中经常会使用到代码的语法（反单引号 ` 的语法）来标注重点，也就是这样的效果。因为在有的主题风格中，代码的显示效果很不错，能够很直观的注意到那段高亮文本，相比上面表现良好的粗体文本，高亮文本可能表现更好，因为在标题比较多、文字段落又比较少的情况下，文本的粗体可能会隐藏在标题的粗体中，肉眼寻找起来也是费力的。 刚好在 DoIt 风格（本博客的风格主题）中，高亮表现不错，就确定代码语法用来突出重点文字吧（虽然在 obsidian 中(我使用的主题风格是 Atom)，反单引号的显示效果并不好，但是考虑到之后阅读多在博客上阅读，就这么决定吧）顺便看一下反单引号+加粗的效果：删除的重点文字 总结：最需要注意的内容，就用反单引号来概括吧！ 关于正常文字的分类显示在一段正常的文本中，可能没有重点，但是可能会有一些不同的类别，比如参杂着一个方法名、文件/文件夹的名称、命令等，之前用来标注这些可能会用上面反单引号的方式，但是在 hugo 中太显眼了，上面已经决定用来显示重点文字了，就得考虑别的方式了。 这类文字应该跟正常文字有相同的显眼程度，感觉比较理想的显示方式应该是类似这样的，就是给文字加一个单纯的、不显眼的背景色，但是 Markdown 本身没有这样的语法，上面效果的实现方式是： 是类似这样的 是使用 html 的方式来实现的，但是感觉这样的书写方式已经有点违背 Markdown 诞生的初衷了，又让写作变得复杂起来，有点得不偿失，感觉目前对于这一类的文字没有比较好的方案来解决，就先暂定吧。 总结：暂定 第三种等级的解释性文字这种等级的文字段落，感觉最好的应该是灰色的字体，类似这样： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 上面这样的效果是我期待的效果，这种不太重要的文字，可能就是备注一下怕之后忘记，可能第二次第三次我再次阅读的时候如果我还记得我就不会再看这段文字了，这样的颜色可以让我在顺序阅读下来的时候很好的忽略掉，省去大脑、眼睛去甄别重要性的时间，让阅读变得更流畅一些，但是跟上面分类文字的显示一样，这也是用 html 的方式来实现的： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 感觉还是不太好，但是感觉会比上面的分类文字的显示更能接受一些，因为像这种解释性的文字通常是： 连在一起的，一片 不那么经常出现 所以相比带来的收益跟效果，还是比较能接受的。（在复制文本的场景下，也会多出来一段 html 代码，也是需要考虑的缺点，虽然这样的场景更少） 总结：所以解释性的文字就这么来显示吧！ ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:1:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#关于重点文字如何突出显示"},{"categories":["Tools-Method"],"content":" 文本显示 关于重点文字如何突出显示首先把内容分一下等级，这里的“内容”范围应该是一个段落，一段文字的范围之内的，而不考虑整篇文章，因为整篇文章的角度来看的话，使用 # 来做结构的切分已经很清晰了。把内容的分级就粗略分成三个等级： 重点 正常 解释说明 整体阅读的时候应该顺着“正常”的内容顺序阅读，“重点”应该能够让自己在视觉上比较好的注意到，“解释说明”作为比较不重要的能容，阅读的时候有时候可以忽略，如果可以偏灰色是最好的 自己在记录的过程中，比较在意的就是怎么让自己在之后回顾的时候比较好的看到重点，首先就是不能太花哨，其次重点需要标记出来，在 Markdown 语法中，我经常用来标记重点的方式就是用反单引号、加粗的方式，但是由于之前写作的软件换过几次，不同的软件、不同的 theme 之间，这两种方式的显示有时候不是那么明显，有时候反单引号看不太出来，有时候加粗看不太出来，所以趁着这次整理，再比较一下这两种方式。 Markdown 语法中，有以下几种方式被设计来强调内容： 粗体 x 渲染情况 obsidian hugo 斜体 x 渲染情况 obsidian hugo 见下方 这是一段包含斜体文字的文本。 删除 x 渲染情况 obsidian hugo 见下方 这是一段包含删除文字的文本。 上面几种方式的组合 删除+粗体：删除的粗体文字 但是除了上面几种方式，我在以往写作的过程中经常会使用到代码的语法（反单引号 ` 的语法）来标注重点，也就是这样的效果。因为在有的主题风格中，代码的显示效果很不错，能够很直观的注意到那段高亮文本，相比上面表现良好的粗体文本，高亮文本可能表现更好，因为在标题比较多、文字段落又比较少的情况下，文本的粗体可能会隐藏在标题的粗体中，肉眼寻找起来也是费力的。 刚好在 DoIt 风格（本博客的风格主题）中，高亮表现不错，就确定代码语法用来突出重点文字吧（虽然在 obsidian 中(我使用的主题风格是 Atom)，反单引号的显示效果并不好，但是考虑到之后阅读多在博客上阅读，就这么决定吧）顺便看一下反单引号+加粗的效果：删除的重点文字 总结：最需要注意的内容，就用反单引号来概括吧！ 关于正常文字的分类显示在一段正常的文本中，可能没有重点，但是可能会有一些不同的类别，比如参杂着一个方法名、文件/文件夹的名称、命令等，之前用来标注这些可能会用上面反单引号的方式，但是在 hugo 中太显眼了，上面已经决定用来显示重点文字了，就得考虑别的方式了。 这类文字应该跟正常文字有相同的显眼程度，感觉比较理想的显示方式应该是类似这样的，就是给文字加一个单纯的、不显眼的背景色，但是 Markdown 本身没有这样的语法，上面效果的实现方式是： 是类似这样的 是使用 html 的方式来实现的，但是感觉这样的书写方式已经有点违背 Markdown 诞生的初衷了，又让写作变得复杂起来，有点得不偿失，感觉目前对于这一类的文字没有比较好的方案来解决，就先暂定吧。 总结：暂定 第三种等级的解释性文字这种等级的文字段落，感觉最好的应该是灰色的字体，类似这样： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 上面这样的效果是我期待的效果，这种不太重要的文字，可能就是备注一下怕之后忘记，可能第二次第三次我再次阅读的时候如果我还记得我就不会再看这段文字了，这样的颜色可以让我在顺序阅读下来的时候很好的忽略掉，省去大脑、眼睛去甄别重要性的时间，让阅读变得更流畅一些，但是跟上面分类文字的显示一样，这也是用 html 的方式来实现的： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 感觉还是不太好，但是感觉会比上面的分类文字的显示更能接受一些，因为像这种解释性的文字通常是： 连在一起的，一片 不那么经常出现 所以相比带来的收益跟效果，还是比较能接受的。（在复制文本的场景下，也会多出来一段 html 代码，也是需要考虑的缺点，虽然这样的场景更少） 总结：所以解释性的文字就这么来显示吧！ ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:1:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#关于正常文字的分类显示"},{"categories":["Tools-Method"],"content":" 文本显示 关于重点文字如何突出显示首先把内容分一下等级，这里的“内容”范围应该是一个段落，一段文字的范围之内的，而不考虑整篇文章，因为整篇文章的角度来看的话，使用 # 来做结构的切分已经很清晰了。把内容的分级就粗略分成三个等级： 重点 正常 解释说明 整体阅读的时候应该顺着“正常”的内容顺序阅读，“重点”应该能够让自己在视觉上比较好的注意到，“解释说明”作为比较不重要的能容，阅读的时候有时候可以忽略，如果可以偏灰色是最好的 自己在记录的过程中，比较在意的就是怎么让自己在之后回顾的时候比较好的看到重点，首先就是不能太花哨，其次重点需要标记出来，在 Markdown 语法中，我经常用来标记重点的方式就是用反单引号、加粗的方式，但是由于之前写作的软件换过几次，不同的软件、不同的 theme 之间，这两种方式的显示有时候不是那么明显，有时候反单引号看不太出来，有时候加粗看不太出来，所以趁着这次整理，再比较一下这两种方式。 Markdown 语法中，有以下几种方式被设计来强调内容： 粗体 x 渲染情况 obsidian hugo 斜体 x 渲染情况 obsidian hugo 见下方 这是一段包含斜体文字的文本。 删除 x 渲染情况 obsidian hugo 见下方 这是一段包含删除文字的文本。 上面几种方式的组合 删除+粗体：删除的粗体文字 但是除了上面几种方式，我在以往写作的过程中经常会使用到代码的语法（反单引号 ` 的语法）来标注重点，也就是这样的效果。因为在有的主题风格中，代码的显示效果很不错，能够很直观的注意到那段高亮文本，相比上面表现良好的粗体文本，高亮文本可能表现更好，因为在标题比较多、文字段落又比较少的情况下，文本的粗体可能会隐藏在标题的粗体中，肉眼寻找起来也是费力的。 刚好在 DoIt 风格（本博客的风格主题）中，高亮表现不错，就确定代码语法用来突出重点文字吧（虽然在 obsidian 中(我使用的主题风格是 Atom)，反单引号的显示效果并不好，但是考虑到之后阅读多在博客上阅读，就这么决定吧）顺便看一下反单引号+加粗的效果：删除的重点文字 总结：最需要注意的内容，就用反单引号来概括吧！ 关于正常文字的分类显示在一段正常的文本中，可能没有重点，但是可能会有一些不同的类别，比如参杂着一个方法名、文件/文件夹的名称、命令等，之前用来标注这些可能会用上面反单引号的方式，但是在 hugo 中太显眼了，上面已经决定用来显示重点文字了，就得考虑别的方式了。 这类文字应该跟正常文字有相同的显眼程度，感觉比较理想的显示方式应该是类似这样的，就是给文字加一个单纯的、不显眼的背景色，但是 Markdown 本身没有这样的语法，上面效果的实现方式是： 是类似这样的 是使用 html 的方式来实现的，但是感觉这样的书写方式已经有点违背 Markdown 诞生的初衷了，又让写作变得复杂起来，有点得不偿失，感觉目前对于这一类的文字没有比较好的方案来解决，就先暂定吧。 总结：暂定 第三种等级的解释性文字这种等级的文字段落，感觉最好的应该是灰色的字体，类似这样： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 上面这样的效果是我期待的效果，这种不太重要的文字，可能就是备注一下怕之后忘记，可能第二次第三次我再次阅读的时候如果我还记得我就不会再看这段文字了，这样的颜色可以让我在顺序阅读下来的时候很好的忽略掉，省去大脑、眼睛去甄别重要性的时间，让阅读变得更流畅一些，但是跟上面分类文字的显示一样，这也是用 html 的方式来实现的： 这段文字解释了上面这段文字，引出了下面这段文字，这是一段发灰的文字。 感觉还是不太好，但是感觉会比上面的分类文字的显示更能接受一些，因为像这种解释性的文字通常是： 连在一起的，一片 不那么经常出现 所以相比带来的收益跟效果，还是比较能接受的。（在复制文本的场景下，也会多出来一段 html 代码，也是需要考虑的缺点，虽然这样的场景更少） 总结：所以解释性的文字就这么来显示吧！ ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:1:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#第三种等级的解释性文字"},{"categories":["Tools-Method"],"content":" 中英文在文本中遇到中英文混杂的情况，我都会在英文的两边各留一个空格，也不知道是什么时候养成的习惯，也不清楚到底带来了什么好处，就是发觉了有这个 habbit，还蛮 good 吧。 我觉得你说得对。 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:1:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#中英文"},{"categories":["Tools-Method"],"content":" 二、针对 hugo 主题的特性来尝试养成一些新的习惯吧也不要使用过多，还是让 md 文档内容尽量保持原生的语言 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:0","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#二针对-hugo-主题的特性来尝试养成一些新的习惯吧"},{"categories":["Tools-Method"],"content":" 让文本有趣一些 emoji一些可能用得到的 emoji ： 👍 👈 👉 👏 ✍ 🎼 🎵 🎶 🎧 🎸 📽 🎬📷 📸 📔 📖 ❓ ❗ ❌ ✔ ✅ 更多见：webfx emoji 字符注音/说明效果：SASuffix Array 语法： [简写或其他] ^ (说明性文字) 在代码段内也能显示（但这么做不好）： SASuffix Array 分数效果：60/100 语法： [] / [] 打字机 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#让文本有趣一些"},{"categories":["Tools-Method"],"content":" 让文本有趣一些 emoji一些可能用得到的 emoji ： 👍 👈 👉 👏 ✍ 🎼 🎵 🎶 🎧 🎸 📽 🎬📷 📸 📔 📖 ❓ ❗ ❌ ✔ ✅ 更多见：webfx emoji 字符注音/说明效果：SASuffix Array 语法： [简写或其他] ^ (说明性文字) 在代码段内也能显示（但这么做不好）： SASuffix Array 分数效果：60/100 语法： [] / [] 打字机 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#emoji"},{"categories":["Tools-Method"],"content":" 让文本有趣一些 emoji一些可能用得到的 emoji ： 👍 👈 👉 👏 ✍ 🎼 🎵 🎶 🎧 🎸 📽 🎬📷 📸 📔 📖 ❓ ❗ ❌ ✔ ✅ 更多见：webfx emoji 字符注音/说明效果：SASuffix Array 语法： [简写或其他] ^ (说明性文字) 在代码段内也能显示（但这么做不好）： SASuffix Array 分数效果：60/100 语法： [] / [] 打字机 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#字符注音说明"},{"categories":["Tools-Method"],"content":" 让文本有趣一些 emoji一些可能用得到的 emoji ： 👍 👈 👉 👏 ✍ 🎼 🎵 🎶 🎧 🎸 📽 🎬📷 📸 📔 📖 ❓ ❗ ❌ ✔ ✅ 更多见：webfx emoji 字符注音/说明效果：SASuffix Array 语法： [简写或其他] ^ (说明性文字) 在代码段内也能显示（但这么做不好）： SASuffix Array 分数效果：60/100 语法： [] / [] 打字机 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#分数"},{"categories":["Tools-Method"],"content":" 让文本有趣一些 emoji一些可能用得到的 emoji ： 👍 👈 👉 👏 ✍ 🎼 🎵 🎶 🎧 🎸 📽 🎬📷 📸 📔 📖 ❓ ❗ ❌ ✔ ✅ 更多见：webfx emoji 字符注音/说明效果：SASuffix Array 语法： [简写或其他] ^ (说明性文字) 在代码段内也能显示（但这么做不好）： SASuffix Array 分数效果：60/100 语法： [] / [] 打字机 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#打字机"},{"categories":["Tools-Method"],"content":" 让文章内容丰富一些 mermaid 画图markdown 能够使用 mermaid 快速的画图，如果是一些比较简单的图，可以用这个来画一画 mermaid 能够画出什么图？ 饼图 流程 时序 状态 甘特 类 可以看：mermaid系列 嵌入视频这是一个在线的 youtube 视频： 语法： {{\u003c 平台 视频id \u003e}} 平台： youtube bilibili 嵌入音频 丰富的警告系统hugo 扩展了一些 shortcode 丰富了警告的类型，不过也不宜使用太多，看起来太花哨了，引入一个 Bug 的警告应该就差不多了 这是个 bug 具体的语法可以看：https://hugodoit.pages.dev/zh-cn/theme-documentation-extended-shortcodes/#admonition ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#让文章内容丰富一些"},{"categories":["Tools-Method"],"content":" 让文章内容丰富一些 mermaid 画图markdown 能够使用 mermaid 快速的画图，如果是一些比较简单的图，可以用这个来画一画 mermaid 能够画出什么图？ 饼图 流程 时序 状态 甘特 类 可以看：mermaid系列 嵌入视频这是一个在线的 youtube 视频： 语法： {{\u003c 平台 视频id \u003e}} 平台： youtube bilibili 嵌入音频 丰富的警告系统hugo 扩展了一些 shortcode 丰富了警告的类型，不过也不宜使用太多，看起来太花哨了，引入一个 Bug 的警告应该就差不多了 这是个 bug 具体的语法可以看：https://hugodoit.pages.dev/zh-cn/theme-documentation-extended-shortcodes/#admonition ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#mermaid-画图"},{"categories":["Tools-Method"],"content":" 让文章内容丰富一些 mermaid 画图markdown 能够使用 mermaid 快速的画图，如果是一些比较简单的图，可以用这个来画一画 mermaid 能够画出什么图？ 饼图 流程 时序 状态 甘特 类 可以看：mermaid系列 嵌入视频这是一个在线的 youtube 视频： 语法： {{\u003c 平台 视频id \u003e}} 平台： youtube bilibili 嵌入音频 丰富的警告系统hugo 扩展了一些 shortcode 丰富了警告的类型，不过也不宜使用太多，看起来太花哨了，引入一个 Bug 的警告应该就差不多了 这是个 bug 具体的语法可以看：https://hugodoit.pages.dev/zh-cn/theme-documentation-extended-shortcodes/#admonition ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#嵌入视频"},{"categories":["Tools-Method"],"content":" 让文章内容丰富一些 mermaid 画图markdown 能够使用 mermaid 快速的画图，如果是一些比较简单的图，可以用这个来画一画 mermaid 能够画出什么图？ 饼图 流程 时序 状态 甘特 类 可以看：mermaid系列 嵌入视频这是一个在线的 youtube 视频： 语法： {{\u003c 平台 视频id \u003e}} 平台： youtube bilibili 嵌入音频 丰富的警告系统hugo 扩展了一些 shortcode 丰富了警告的类型，不过也不宜使用太多，看起来太花哨了，引入一个 Bug 的警告应该就差不多了 这是个 bug 具体的语法可以看：https://hugodoit.pages.dev/zh-cn/theme-documentation-extended-shortcodes/#admonition ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#嵌入音频"},{"categories":["Tools-Method"],"content":" 让文章内容丰富一些 mermaid 画图markdown 能够使用 mermaid 快速的画图，如果是一些比较简单的图，可以用这个来画一画 mermaid 能够画出什么图？ 饼图 流程 时序 状态 甘特 类 可以看：mermaid系列 嵌入视频这是一个在线的 youtube 视频： 语法： {{\u003c 平台 视频id \u003e}} 平台： youtube bilibili 嵌入音频 丰富的警告系统hugo 扩展了一些 shortcode 丰富了警告的类型，不过也不宜使用太多，看起来太花哨了，引入一个 Bug 的警告应该就差不多了 这是个 bug 具体的语法可以看：https://hugodoit.pages.dev/zh-cn/theme-documentation-extended-shortcodes/#admonition ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#丰富的警告系统"},{"categories":["Tools-Method"],"content":" 让文章结构规整一些","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:3","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#让文章结构规整一些"},{"categories":["Tools-Method"],"content":" 举例子之前自己写例子的时候一直没有一个比较固定的方式，有时候一个例子的篇幅可能比较长，如果跳过这个例子的话还需要定位下一个正文的起点 ❌ 原先： graph TD classDef grey fill:#f0f0ed a[正文1]--\u003eb[例子]--\u003ec[接正文1] class b grey ✅ 期望： graph TD classDef grey fill:#f0f0ed subgraph 顺序阅读 a[正文1]--\u003ec[接正文1] end a[正文1]-.-\u003eb[例子] b[例子]-.-\u003ec[接正文1] class b grey 那么就把例子的内容全部放到一个可折叠的区域里面 这是个例子 - xxxxxxx 例子的内容 这样就能达到上面期望的效果。 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:2:4","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#举例子"},{"categories":["Tools-Method"],"content":" 三、让博客的内容更规整一些为了让博客整体看起来有序一些，做好分类、系列、标签的规划。虽然说这个提前工程实施之后好像有点跟卡片盒笔记法的想法相违背（卡片盒笔记法提倡不做太多整体的规划，而是让笔记之间自然生长出连接规律），但是为了让已有的一些已经固定分类的文章有家可归，可以做适当的分类。 todo：之后还要好好学习一下卡片盒笔记法，让它真正成为自己的一个写作方式，现在感觉知识用上了点表面的东西。 博客主要有三种划分文档的方式：分类 \u003e 系列 \u003e 标签 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:3:0","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#三让博客的内容更规整一些"},{"categories":["Tools-Method"],"content":" 分类 \u0026 系列 算法与数据结构：分成两个系列，偏算法跟偏数据结构的分开 《数据结构》 《算法》 《leetcode》 Golang 本来应该是语言分类，然后往下分 java、go 之类的语言，但是为了让结构层级更浅，把下面一层的内容网上提，把 Golang、Java 等语言单独作为一个分类 《Golang初识》 一些简单使用方式 《Golang为什么》 记录对于Golang的一些疑问，这个“为什么是这样的”以及“这个是什么样的”之类的疑问记录在此，相比于 《Golang初识》中的简单使用，应该是有更进一步的实践或者理解 《GolangBug分析》 记录碰到的bug，或者别人碰到的bug 《Golang代码片段》 记录一些工具类、代码妙用等代码碎片 《Golang底层认知》 《Golang源码学习》 《Golang性能优化》 2023/05/29 重新规划 Golang 的相关系列。前面开设了太多系列，改得更简洁些 《Golang语言使用》 Golang 语言的简单使用、使用上的疑问、碰到的 bug 分析、代码片段都放到这个地方 《Golang底层分析、源码学习》 关于 Golang 的底层相关、源码的学习都放到这个系列 《Golang辅助开发框架》 将之前的专门开设的 Golang框架 分类放到这个系列 Golang框架 《Gin》 《Go-Redis》 《Gorm》 《client-go》 MySQL 《MySQL使用》 《MySQL底层分析》 容器 想想还是不使用这样的分类方式了，整个 Kubernetes 还是比较庞大的，各自拿出来作为一个分类，再把底下的内容分成系列 《Kubernetes》 《Openshift》 Kubernetes 《Kubernetes初识》 这个东西的简单使用方式 《Kubernetes代码实践》 与 k8s 关联比较大的一些代码开发、demo 之类的东西 《Kubernetes问题定位》 记录实际使用 k8s 的过程中碰到的一些问题以及定位过程 《Kubernetes存储篇》 《Kubernetes网络篇》 《Kubernetes源码分析》 OpenShift 《OpenShift初识》 Docker 《Docker命令》 记录一些 docker 常用的操作 项目管理 《Git》 存储 操作系统 计算机网络 Linux 《Linux命令使用》 一些常用命令记录、命令学习等 《Linux学习》 生活记录 《音乐》 🎶 #听歌月记录 #喜欢的live #博客音乐嵌入样例 《FL-Studio》 《练字》 《影像记录》 #游玩映像 #宠物映像 《画画》 #素描 #水彩 #钢笔画 #树脂 《读书记录》 《日规划-记录》 《月规划-记录》 《年度总结》 扩展学习 《扩展学习之ai》：放一些人工智能、深度学习之类的东西 Tools-Method 记录我在写作、学习过程中使用的一些辅助工具、记录方法、写作流等等 #个人记录 《工具》 ：一些好用的工具备忘 如果我现在想写一篇文章，但是不好确定系列，就放到 分类名-box 系列里面，作为这个分类的文章收集箱，如果之后有适合的系列，再整理进去 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:3:1","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#分类--系列"},{"categories":["Tools-Method"],"content":" 标签关于标签如何使用？ 把关于问题分析的文章都放在 问题分析 的标签里 在这里定义一些比较常用的标签： #bugfix - 如果是 bug 定位相关的问题就放在这里 #task - 工作中的一些任务记录 #工作记录 - 工作中产生的偏工作记录性质的文档放在这里 #阅读 - 《读书记录》系列一般都有这个标签 对于一篇文章，还是不要给定太多标签，显得太乱，最好一到两个最重要的标签就好了 hugo Doit 主题中，不能存在标签跟系列一直的情况，否则博客会渲染失败 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:3:2","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#标签"},{"categories":["Tools-Method"],"content":" 目录创建一个 《目录》 系列，用来当作其他文章的索引 ","date":"2023-05-09","objectID":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/:3:3","series":["博客建设"],"tags":["个人记录"],"title":"重新整理一下自己的写作流","uri":"/202305091805-%E9%87%8D%E6%96%B0%E6%95%B4%E7%90%86%E4%B8%80%E4%B8%8B%E8%87%AA%E5%B7%B1%E7%9A%84%E5%86%99%E4%BD%9C%E6%B5%81/#目录"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:0:0","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#"},{"categories":["数据结构与算法"],"content":" 一、KMP 算法用途 在主串 S 中查找模式串 pattern ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:1:0","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#一kmp-算法用途"},{"categories":["数据结构与算法"],"content":" 二、算法流程","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:2:0","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#二算法流程"},{"categories":["数据结构与算法"],"content":" 2.1 举例说明1S=“aabaabaac”, pattern=“aabaac” 主串中存在模式串，应该返回起始下标 -3 step1 首先定义两个下标 i 和 j，分别指向 S 和 pattern 中待比较的字符 注意点：（后续解释） i 不会回头（时间复杂度O(N)） j 左侧的字符一定是已经经过比较的（j 是会回头的） step2 当 S[i] == pattern[j]，i、j 均右移，继续往下比较 step3 当 S[i] != pattern[j]，i 不动，j 以一定的模式进行转移，具体见下面的场景：（local 202304262152 KMP 算法之-获取 next 数组 remote 202304262152 KMP 算法之-获取 next 数组） （假设截取模式串 [0, j-1] 为 pattern‘） 当发现当前比较的字符不同时： 模式串找到 pattern’ 中最长的相同前后缀（假设为 comFix），如上图中的 B 和 C 那么主串在下标 i 之前也必定有一个 comFix（由于 j 前面的字符一定的经过比较的），也就是上图中的 A 所以 A = B = C，那么就可以把 j 的位置移动到 C 的下一个位置，这样就能够保证在 i 不回头的情况下，j 左边的字符都是已经经过比较的 step4 进而继续往下比较 那么 KMP 的伪代码就很容易能够写出来： N M 为 S pattern 的长度 for i \u003c N \u0026\u0026 j \u003c M { 字符不同 循环：根据转移模式更新 j 直到字符相同，或者已经是模式串的首字符 if 字符相同 j++ i++ 否则 i++ } 能够找到则 j == len(pattern) return i - M + 1 否则没有找到 return -1 ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:2:1","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#21-举例说明1"},{"categories":["数据结构与算法"],"content":" 2.1 举例说明1S=“aabaabaac”, pattern=“aabaac” 主串中存在模式串，应该返回起始下标 -3 step1 首先定义两个下标 i 和 j，分别指向 S 和 pattern 中待比较的字符 注意点：（后续解释） i 不会回头（时间复杂度O(N)） j 左侧的字符一定是已经经过比较的（j 是会回头的） step2 当 S[i] == pattern[j]，i、j 均右移，继续往下比较 step3 当 S[i] != pattern[j]，i 不动，j 以一定的模式进行转移，具体见下面的场景：（local 202304262152 KMP 算法之-获取 next 数组 remote 202304262152 KMP 算法之-获取 next 数组） （假设截取模式串 [0, j-1] 为 pattern‘） 当发现当前比较的字符不同时： 模式串找到 pattern’ 中最长的相同前后缀（假设为 comFix），如上图中的 B 和 C 那么主串在下标 i 之前也必定有一个 comFix（由于 j 前面的字符一定的经过比较的），也就是上图中的 A 所以 A = B = C，那么就可以把 j 的位置移动到 C 的下一个位置，这样就能够保证在 i 不回头的情况下，j 左边的字符都是已经经过比较的 step4 进而继续往下比较 那么 KMP 的伪代码就很容易能够写出来： N M 为 S pattern 的长度 for i \u003c N \u0026\u0026 j \u003c M { 字符不同 循环：根据转移模式更新 j 直到字符相同，或者已经是模式串的首字符 if 字符相同 j++ i++ 否则 i++ } 能够找到则 j == len(pattern) return i - M + 1 否则没有找到 return -1 ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:2:1","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#step1-首先定义两个下标-i-和-j分别指向-s-和-pattern-中待比较的字符"},{"categories":["数据结构与算法"],"content":" 2.1 举例说明1S=“aabaabaac”, pattern=“aabaac” 主串中存在模式串，应该返回起始下标 -3 step1 首先定义两个下标 i 和 j，分别指向 S 和 pattern 中待比较的字符 注意点：（后续解释） i 不会回头（时间复杂度O(N)） j 左侧的字符一定是已经经过比较的（j 是会回头的） step2 当 S[i] == pattern[j]，i、j 均右移，继续往下比较 step3 当 S[i] != pattern[j]，i 不动，j 以一定的模式进行转移，具体见下面的场景：（local 202304262152 KMP 算法之-获取 next 数组 remote 202304262152 KMP 算法之-获取 next 数组） （假设截取模式串 [0, j-1] 为 pattern‘） 当发现当前比较的字符不同时： 模式串找到 pattern’ 中最长的相同前后缀（假设为 comFix），如上图中的 B 和 C 那么主串在下标 i 之前也必定有一个 comFix（由于 j 前面的字符一定的经过比较的），也就是上图中的 A 所以 A = B = C，那么就可以把 j 的位置移动到 C 的下一个位置，这样就能够保证在 i 不回头的情况下，j 左边的字符都是已经经过比较的 step4 进而继续往下比较 那么 KMP 的伪代码就很容易能够写出来： N M 为 S pattern 的长度 for i \u003c N \u0026\u0026 j \u003c M { 字符不同 循环：根据转移模式更新 j 直到字符相同，或者已经是模式串的首字符 if 字符相同 j++ i++ 否则 i++ } 能够找到则 j == len(pattern) return i - M + 1 否则没有找到 return -1 ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:2:1","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#step2-当-si--patternjij-均右移继续往下比较"},{"categories":["数据结构与算法"],"content":" 2.1 举例说明1S=“aabaabaac”, pattern=“aabaac” 主串中存在模式串，应该返回起始下标 -3 step1 首先定义两个下标 i 和 j，分别指向 S 和 pattern 中待比较的字符 注意点：（后续解释） i 不会回头（时间复杂度O(N)） j 左侧的字符一定是已经经过比较的（j 是会回头的） step2 当 S[i] == pattern[j]，i、j 均右移，继续往下比较 step3 当 S[i] != pattern[j]，i 不动，j 以一定的模式进行转移，具体见下面的场景：（local 202304262152 KMP 算法之-获取 next 数组 remote 202304262152 KMP 算法之-获取 next 数组） （假设截取模式串 [0, j-1] 为 pattern‘） 当发现当前比较的字符不同时： 模式串找到 pattern’ 中最长的相同前后缀（假设为 comFix），如上图中的 B 和 C 那么主串在下标 i 之前也必定有一个 comFix（由于 j 前面的字符一定的经过比较的），也就是上图中的 A 所以 A = B = C，那么就可以把 j 的位置移动到 C 的下一个位置，这样就能够保证在 i 不回头的情况下，j 左边的字符都是已经经过比较的 step4 进而继续往下比较 那么 KMP 的伪代码就很容易能够写出来： N M 为 S pattern 的长度 for i \u003c N \u0026\u0026 j \u003c M { 字符不同 循环：根据转移模式更新 j 直到字符相同，或者已经是模式串的首字符 if 字符相同 j++ i++ 否则 i++ } 能够找到则 j == len(pattern) return i - M + 1 否则没有找到 return -1 ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:2:1","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#step3-当-si--patternji-不动j-以一定的模式进行转移具体见下面的场景"},{"categories":["数据结构与算法"],"content":" 2.1 举例说明1S=“aabaabaac”, pattern=“aabaac” 主串中存在模式串，应该返回起始下标 -3 step1 首先定义两个下标 i 和 j，分别指向 S 和 pattern 中待比较的字符 注意点：（后续解释） i 不会回头（时间复杂度O(N)） j 左侧的字符一定是已经经过比较的（j 是会回头的） step2 当 S[i] == pattern[j]，i、j 均右移，继续往下比较 step3 当 S[i] != pattern[j]，i 不动，j 以一定的模式进行转移，具体见下面的场景：（local 202304262152 KMP 算法之-获取 next 数组 remote 202304262152 KMP 算法之-获取 next 数组） （假设截取模式串 [0, j-1] 为 pattern‘） 当发现当前比较的字符不同时： 模式串找到 pattern’ 中最长的相同前后缀（假设为 comFix），如上图中的 B 和 C 那么主串在下标 i 之前也必定有一个 comFix（由于 j 前面的字符一定的经过比较的），也就是上图中的 A 所以 A = B = C，那么就可以把 j 的位置移动到 C 的下一个位置，这样就能够保证在 i 不回头的情况下，j 左边的字符都是已经经过比较的 step4 进而继续往下比较 那么 KMP 的伪代码就很容易能够写出来： N M 为 S pattern 的长度 for i \u003c N \u0026\u0026 j \u003c M { 字符不同 循环：根据转移模式更新 j 直到字符相同，或者已经是模式串的首字符 if 字符相同 j++ i++ 否则 i++ } 能够找到则 j == len(pattern) return i - M + 1 否则没有找到 return -1 ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:2:1","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#step4-进而继续往下比较"},{"categories":["数据结构与算法"],"content":" 三、具体实现 func getNext(pat string) []int { n := len(pat) next := make([]int, n) for l, cur := 0, 1; cur \u003c n; cur ++ { // 不想等需要根据前面得到的 next，更新 l // 直到相等或者 l == 0 for l \u003e 0 \u0026\u0026 pat[l] != pat[cur] {l = next[l-1]} if pat[cur] == pat[l] { l++ } next[cur] = l } return next } func KMP(s, pat string) int { n, m := len(s), len(pat) next := getNext(pat) i, j := 0, 0 for i \u003c n \u0026\u0026 j \u003c m { for j \u003e 0 \u0026\u0026 pat[j] != s[i] {j = next[j-1]} if s[i] == pat[j] { j++ } i++ } if j == m { return i - m } else { return -1 } } ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:3:0","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#三具体实现"},{"categories":["数据结构与算法"],"content":" 四、一些习题 https://leetcode.cn/problems/repeated-substring-pattern/ 知乎专栏. 《KMP 算法详解》. 见于 2023年4月26日. https://zhuanlan.zhihu.com/p/83334559. 《KMP算法》. 收入 维基百科，自由的百科全书, 2022年7月8日. https://zh.wikipedia.org/w/index.php?title=KMP%E7%AE%97%E6%B3%95\u0026oldid=72556055. ","date":"2023-05-09","objectID":"/202304262036-kmp-%E7%AE%97%E6%B3%95/:4:0","series":["算法"],"tags":["kmp"],"title":"KMP算法","uri":"/202304262036-kmp-%E7%AE%97%E6%B3%95/#四一些习题"},{"categories":["数据结构与算法"],"content":"#算法 KMP 算法中 j 的转移是通过一个保存 j 转移信息的数组 next 来实现的，那么如何获得这个数组是 KMP 算法的关键 首先根据 KMP 的工作流程可知，next 中保存的其实是最长公共前后缀的长度，也可以理解为最长公共前后缀中前缀的下一个下标 next[i] 保存了 pattern[0,i] 这个字符串最长公共前后缀的长度 举个例子说明：pattern = “aabaac” 推导过程： 子串 最长公共前后缀 next a 无(长度为1没有前缀与后缀) 0 aa a 1 aab 无 0 aaba a 1 aabaa aa 2 aabaac 无 0 如何在 O(M) 的时间复杂度内获得这个 next 数组？ 使用两个指针，从头开始遍历 pattern： len：记录了最长公共前后缀的长度（初始 0） cur：子串结尾（初始 1） 首先初始化 next[0] = 0，所有的模式串都符合 判断 pattern[cur] == pattern[len]； 说明存在相同前后缀，那么将 len++，next[cur] = len（说明子串 pattern[0, cur] 的最长公共前缀长度为 len） 再将 cur++，继续判断下一个子串 当 pattern[cur] != pattern[len] 说明当前的子串是不存在公共前后缀的，那么将 len 重置 len = next[len-1]（找子串[0, len-1]的最大相同前后缀，直到首字符的位置 或者 pattern[len] == pattern[cur]）， end 继续右移动 这个步骤往往是容易出错的，看下面的一个例子 重复以上过程，直到获取整个 next 数组 一个错误例子： func getNext(pat string) []int { n := len(pat) next := make([]int, n) for l, cur := 0, 1; cur \u003c n; cur ++ { if pat[cur] == pat[l] { l++ } else { // error l = 0 } next[cur] = l } return next } 测试例： pat=“afdabeafdaf” getNext() = [0 0 0 1 0 0 1 2 3 4 0], want [0 0 0 1 0 0 1 2 3 4 2] 正确实现： func getNext(pat string) []int { n := len(pat) next := make([]int, n) for l, cur := 0, 1; cur \u003c n; cur ++ { // 不相等需要根据前面得到的 next，更新 l // 直到相等或者 l == 0 for l \u003e 0 \u0026\u0026 pat[l] != pat[cur] {l = next[l-1]} if pat[cur] == pat[l] { l++ } next[cur] = l } return next } ","date":"2023-05-09","objectID":"/202304262152-kmp-%E7%AE%97%E6%B3%95%E4%B9%8B-%E8%8E%B7%E5%8F%96-next-%E6%95%B0%E7%BB%84/:0:0","series":["算法"],"tags":["kmp"],"title":"KMP算法之-获取next数组","uri":"/202304262152-kmp-%E7%AE%97%E6%B3%95%E4%B9%8B-%E8%8E%B7%E5%8F%96-next-%E6%95%B0%E7%BB%84/#"},{"categories":["数据结构与算法"],"content":"#leetcode 废弃 使用新站点记录 希望能有成长，在此记录 ","date":"2023-05-09","objectID":"/202304301159-leetcode-%E5%91%A8%E8%B5%9B%E5%8F%82%E5%8A%A0%E8%AE%B0%E5%BD%95/:0:0","series":["leetcode"],"tags":["个人记录"],"title":"Leetcode 周赛记录","uri":"/202304301159-leetcode-%E5%91%A8%E8%B5%9B%E5%8F%82%E5%8A%A0%E8%AE%B0%E5%BD%95/#"},{"categories":["数据结构与算法"],"content":" 第一场周赛 本着就做两题的心态来的，结果也算是完成了两题，不过过程还是不尽人意，第一道简单题就wa了五次，还是有点小紧张 第二道题思考的有点久，其实就是要在一个乱序的二维数组中快速找到一个数在第几行第几列的需求，如果这些数被保证在一个不大的范围内，那么可以直接做num2Idx[数字]=下标 这样的一个映射，就能快速找到对应数字在二维数组中的下标了 不过结果也还算是符合预期了，再接再厉吧 ","date":"2023-05-09","objectID":"/202304301159-leetcode-%E5%91%A8%E8%B5%9B%E5%8F%82%E5%8A%A0%E8%AE%B0%E5%BD%95/:1:0","series":["leetcode"],"tags":["个人记录"],"title":"Leetcode 周赛记录","uri":"/202304301159-leetcode-%E5%91%A8%E8%B5%9B%E5%8F%82%E5%8A%A0%E8%AE%B0%E5%BD%95/#第一场周赛"},{"categories":["数据结构与算法"],"content":" 第二场 这周的题目比较简单，花了四十分钟做了下前三题，也没遇到啥问题。 最后一题是图的问题，好多知识都忘记了，就不做了，之后回顾一下图的知识再来挑战吧 ","date":"2023-05-09","objectID":"/202304301159-leetcode-%E5%91%A8%E8%B5%9B%E5%8F%82%E5%8A%A0%E8%AE%B0%E5%BD%95/:2:0","series":["leetcode"],"tags":["个人记录"],"title":"Leetcode 周赛记录","uri":"/202304301159-leetcode-%E5%91%A8%E8%B5%9B%E5%8F%82%E5%8A%A0%E8%AE%B0%E5%BD%95/#第二场"},{"categories":["数据结构与算法"],"content":"一些题目记录一下","date":"2023-05-09","objectID":"/202304201936-leetcode%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95/","series":["leetcode"],"tags":["个人记录"],"title":"leetcode 做题记录 ","uri":"/202304201936-leetcode%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95/"},{"categories":["数据结构与算法"],"content":"#算法 废弃 使用新站点记录 记录一些比较有意义的题目 题目 备注 2023.04.18 119 滚动数组 121 169 map的使用，数组中元素的计数 219 滑动窗口 283 双指针 303 在初始化方法中做预处理操作，减少频繁调用的方法中所做的工作量 414 使用了前面双指针的思路；也可以使用类似滑动窗口的思路，维护一个大小为3的有序集合 488 dfs 2023.04.19 496-下一个更大元素I 单调栈，（Go本身没有栈的库，但是通过数组很方便实现[[content/posts/go/golang-code-demo/202304201957 栈]]） 2023.04.20 506-相对名次 深拷贝[[202304201947 深浅拷贝]]、go基本元素类型的降序排序 561-数组拆分 在于题目的分析，用贪心的方式来分析 556-重塑矩阵 二维数组的一维表示（m*n矩阵的第x个元素坐标：x/n，x%n） 594-最长和谐子序 错太多次了；移动窗口；数组计数，联想下标计数法 2023.04.21 674-最长连续递增序列 滑动窗口 744-寻找比目标字母大的最小字母 二分查找[[202304212107 二分查找]] 746-爬楼梯 动态规划 747 求数组的第一第二大的数 2023.04.22 1027-最长等差数列 动态规划[todo] 2023.04.23 1105-填充书架 动态规划 942-增减字符串匹配 贪心算法 914-卡牌分组 最大公约数 2023.04.24 1163 按字典序排在最后的子串【难】 后缀数组、sa-is算法（[[202304241453 后缀数组与SA-IS算法]]） 2023.04.25 125-验证回文 168-Excel表名称 26进制 2023.04.26 1031-两个非重叠子数组的最大和 动态规划+滑动窗口 综合题目 392-判断子序列 动态规划 459-重复的子字符串 KMP算法 680-验证回文 贪心 2023.04.29 剑指 Offer II 083. 没有重复元素集合的全排列 字典序 2023.04.24 2023.04.24 2023.04.24 2023.04.24 2023.04.24 2023.04.24 2023.04.24 总结一些分类出来 数组计数 数组找第几 位运算 ","date":"2023-05-09","objectID":"/202304201936-leetcode%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95/:0:0","series":["leetcode"],"tags":["个人记录"],"title":"leetcode 做题记录 ","uri":"/202304201936-leetcode%E5%81%9A%E9%A2%98%E8%AE%B0%E5%BD%95/#"},{"categories":["扩展学习"],"content":"#ChatGPT ","date":"2023-05-09","objectID":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/:0:0","series":["ChatGPT"],"tags":[],"title":"openai 使用实践","uri":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/#"},{"categories":["扩展学习"],"content":" 一、目前互联网上已经存在的开放的站点 https://openai.com/ 官方网站，但是大部分亚洲 IP 已经被拦截，无法使用。但是可以挂 VPN （直连）到官网申请 api key，再套个 web 的外壳来使用，或者通过 jupyter notebook 来使用也可以 申请 api key 是不需要付费的，但是目前免费使用的额度只有 5 美元，超过需额外充值或者购买 ChatGPT Plus 版本 https://chatgptmirror.com/ 国内的一个镜像站点，需要收费 基于 GPT3.5turbo 和 GPT4 http://chat.gptforlove.com/ 免费 版本：ChatGPT 3.5 支持连续对话 https://chat.jinshutuan.com/ 免费 版本：非 OpenAI GTP 3.5+ 不支持连续对话 https://chatgpt.peterdavehello.org/ 免费 https://jiehan.tech/708 付费 基于 GPT3.5turbo 和 GPT4 更多站点可以参考 chatgpt-sites ","date":"2023-05-09","objectID":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/:1:0","series":["ChatGPT"],"tags":[],"title":"openai 使用实践","uri":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/#一目前互联网上已经存在的开放的站点"},{"categories":["扩展学习"],"content":" 二、关于如何在 openai 官网申请 api key可以参考该篇文章：https://bysocket.com/openai-services-are-not-available-in-your-country/ ","date":"2023-05-09","objectID":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/:2:0","series":["ChatGPT"],"tags":[],"title":"openai 使用实践","uri":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/#二关于如何在-openai-官网申请-api-key"},{"categories":["扩展学习"],"content":" 三、如何更好地使用 ChatGPT 来为自己工作","date":"2023-05-09","objectID":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/:3:0","series":["ChatGPT"],"tags":[],"title":"openai 使用实践","uri":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/#三如何更好地使用-chatgpt-来为自己工作"},{"categories":["扩展学习"],"content":" 3.1《ChatGPT Prompt Engineering for Developers》课程学习用好提示词是关键 笔记产出：[[202305062133 面向开发者的 ChatGPT 提示工程]] ","date":"2023-05-09","objectID":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/:3:1","series":["ChatGPT"],"tags":[],"title":"openai 使用实践","uri":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/#31chatgpt-prompt-engineering-for-developers课程学习"},{"categories":["扩展学习"],"content":" 3.2 ChatGPT 中文调教指南《PlexPt/awesome-chatgpt-prompts-zh: ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。》. 见于 2023年5月7日. https://github.com/PlexPt/awesome-chatgpt-prompts-zh. ","date":"2023-05-09","objectID":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/:3:2","series":["ChatGPT"],"tags":[],"title":"openai 使用实践","uri":"/202305070711-openai-%E4%BD%BF%E7%94%A8%E5%AE%9E%E8%B7%B5/#32-chatgpt-中文调教指南"},{"categories":["Kubernetes"],"content":"#k8s ","date":"2023-05-09","objectID":"/202305080937-operator/:0:0","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#"},{"categories":["Kubernetes"],"content":" 一、概述operator 对于 k8s 来说，是一种扩展机制，开发人员可以通过 CRD，来扩展 k8s API operator 通过监视和管理 CRD，来执行一系列被预定的操作，这些操作被编写在 reconcile 逻辑里面，通过 CRD 的增加、删除、更新，可以触发不同的逻辑，在这些逻辑里面也可以对 k8s 原有的资源进行操作，比如 pod、configmap、service 等等 对于运维人员来说，operator 也是相当有用的，operator 可以负责用来做一些更高级的操作，比如扩缩容、集群的备份、恢复等操作，可以减轻运维人员的压力 ","date":"2023-05-09","objectID":"/202305080937-operator/:1:0","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#一概述"},{"categories":["Kubernetes"],"content":" 二、名词解释、Operator 的工作流程","date":"2023-05-09","objectID":"/202305080937-operator/:2:0","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#二名词解释operator-的工作流程"},{"categories":["Kubernetes"],"content":" 2.1 名词解释 GroupVersionKind GVK 是用来描述一个 kubernetes api 对象的标准 将 GroupVersionKind 拆分成三个部分来理解： Group Version Kind 在 Kubernetes 环境中可以通过命令查看： kubectl api-resources kubectl explain [kind] GroupVersionResource GroupVersionResource 和 GroupVersionKind 都是 Kubernetes API 中用于标识资源的数据结构，它们之间有一定的关系。 GroupVersionResource 由三个部分组成：group、version 和 resource。它用于唯一地标识 Kubernetes API 中的一个资源，并指定客户端对该资源执行 CRUD 操作的方式。 GroupVersionKind 也由三个部分组成：group、version 和 kind。它用于描述 Kubernetes API 中的一个对象，其中 kind 表示对象的类型，例如 Pod、Service 或 Deployment。 可以看出，GroupVersionResource 和 GroupVersionKind 的区别在于最后一个部分。GroupVersionResource 的最后一个部分是资源的名称，而 GroupVersionKind 的最后一个部分是对象的类型。但是，它们都包含了相同的前两个部分：group 和 version。这意味着，通过 GroupVersionKind 可以推断出对应的 GroupVersionResource，反之亦然。 因此，GroupVersionResource 和 GroupVersionKind 是紧密相关的概念，它们都是 Kubernetes API 中用于标识资源和对象的重要数据结构。 scheme scheme 提供了 kubernetes api 对象的序列化、反序列化的功能 在 operator 中，scheme 提供了向 kubernetes api 注册自定义对象的功能 所以每个 operator 都需要 scheme，提供了 go type 与 Kind 的映射，operator 才能与kubernetes api 更好的交互 Manager Cache、informer cache负责： 缓存 kubernetes api 对象 版本控制 索引 informer负责： 监听 kubernetes api 中的事件 当 controller 想要访问某个 api 资源，首先查找 cache 中是否存在，如果不存在再往 kuberntes api 中查找，cache 能够减少访问 kuberntes api 的次数，减轻 io 压力 为了保证缓存中的资源与 kuberntes api 中的资源保持一致，informer 需要监听 kubernetes api 中的事件，如果 kuberntes api 中的资源发生改变，cache 中也要同步变化，保证数据一致性 cache 还提供了对象的索引，提高查找效率。由于api 资源对象是具备版本的，因此 cache 也需要提供版本控制的功能，保证与 kuberntes api 中的资源是同一个版本 informer 是基于 cache 完成的一个高级组件，两者相互协作，都是为了让客户端更好的访问api 对象资源，cache主要用来做缓存、版本控制、索引的功能，informer 主要监听 kuberntes api 中的事件，更新缓存中的资源 这边顺便了解一下 ListAndWatch 机制： 与 Informer 类似，ListAndWatch 的作用也是为了让客户端或者控制器更好的获取 k8s 资源，它的大致工作流程如下： 使用 List 操作，从 Kubernetes API 获取全部的资源对象并保存 然后监听 kuberntes api 中的事件，如果对象发生更新，则对自己保存的对象也做相应更新 ","date":"2023-05-09","objectID":"/202305080937-operator/:2:1","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#21-名词解释"},{"categories":["Kubernetes"],"content":" 2.2 operator 工作流程例如当一个 CRD 创建，会经过什么样的流程 一个 crd 资源创建，首先 kubernetes api 会监听到这个资源的创建，informer 会从 kuberntes api 收到这个事件，并获取对应的 crd 资源，将这个资源反序列化成对应的 go type，然后触发控制器中的 reconcile 逻辑，完成预定的操作 动画演示[^1] crd 创建请求发送到 API Server API Server 校验请求是否合法，是否有创建这个资源的权限 通过 API Server 后，到达准入控制器（Admission Controller），根据 crd 对应的校验规则进行 crd 资源的校验。此外 Admission Controller 还可能对资源进行修改操作 至此，crd 的创建已经被允许，一个 crd 实例被创建，并保存到 etcd 中 Controller Manager 启动对应的 Controller Controller 执行相应的 reconcile 逻辑，会监听 crd 的变化，并执行相应的逻辑 ","date":"2023-05-09","objectID":"/202305080937-operator/:2:2","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#22-operator-工作流程"},{"categories":["Kubernetes"],"content":" 三、实践 创建 operator 项目的两个脚手架： kubebuilder OperatorSDK 该实践使用 kubebuilder 来完成，可参考： kubebuilder quick start 环境信息： go1.17.10 kubelet v1.19.4 docker 20.10.12 kubebuilder 3.4.0 kustomize v4.5.4 初始化项目 kubebuilder init --domain example.com --repo demo.domain/demo-operator kubebuilder create api --group demo --version v1 --kind Demo 修改api/v1/xxx_types.go make manifests 会生成对应的 crd yaml 文件 ./ ├── ... ├── config .. ├── crd ├── bases └── demo.example.com_demoes.yaml 构建 operator 镜像 docker build -t 904566722/kubebuilder-demo-operator:1.0.0 . docker push 904566722/kubebuilder-demo-operator:1.0.0 部署 crd make install # $(KUSTOMIZE) build config/crd | kubectl apply -f - 部署 rbac 相关 yaml kubectl apply -f config/rbac/ 创建 manager controller 修改 image 为上面制作的 operator 镜像 kubectl apply -f config/manager/manager.yaml pod 成功运行之后，创建 cr 实例 apiVersion: demo.example.com/v1 kind: Demo metadata: name: demo-sample spec: size: 19 type: demo config_map_name: demo kubectl apply -f config/samples/demo_v1_demo.yaml operator 监听到 Demo kind 资源的创建，出发 reconcile： ","date":"2023-05-09","objectID":"/202305080937-operator/:3:0","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#三实践"},{"categories":["Kubernetes"],"content":" 参考资料 Kubernetes Operator 开发教程 kustomization管理k8s对象 ","date":"2023-05-09","objectID":"/202305080937-operator/:0:0","series":["kubernetes初识"],"tags":["operator"],"title":"operator","uri":"/202305080937-operator/#参考资料"},{"categories":["Golang"],"content":"#Golang 在使用 for-range 遍历 string 中每个字符的时候，取出来的值是什么类型？ func isAlienSorted(words []string, order string) bool { // 首先要将 order 顺序映射成数值，来做比较 orderNums := make(map[rune]int, len(order)) for i, ch := range order { fmt.Println(reflect.TypeOf(order[i])) // uint8 fmt.Printf(\"%c\", order[i]) fmt.Println(reflect.TypeOf(ch)) // int32 fmt.Printf(\"%c\", ch) orderNums[ch] = i } return false } 对比：在遍历字符串的时候，有两种获取值的方式，如上面代码中的 ch、order[id]（索引的方式） ch 实际上的类型是 int32（与 rune 相同，应该是考虑到 string 中如果存储了中文字符，能够直接使用 “%c” 的表达式将这个中文输出） order[i] 实际上的类型是 uint8 （与 byte 相同，也就是一个字符的大小，占一个字节，但没法输出中文字符） ","date":"2023-05-09","objectID":"/202304231751-string-%E9%81%8D%E5%8E%86/:0:0","series":["Golang语言使用"],"tags":["string"],"title":"string 遍历中不同取值方式的一点区别","uri":"/202304231751-string-%E9%81%8D%E5%8E%86/#"},{"categories":["灵感、文献笔记（非永久笔记）"],"content":"#Golang #struct about card 这是一个临时性的卡片文章，之后可能: 针对该卡片进行扩展，形成文章 与已有文章关联，组织到其他文章 删除 直接看一个例子，熟悉 struct 的简单使用： // ** struct practice type person struct { name string age int32 } func structPractice() { people := \u0026person{ name: \"索隆不喝酒\", age: 20, } fmt.Println(people) // \u0026{索隆不喝酒 20} fmt.Println(*people) // {索隆不喝酒 20} fmt.Println(\u0026people) // 0x1400000e038 fmt.Printf(\"[value]\\tname:%s\\tage:%d\\n\", people.name, people.age) // [value] name:索隆不喝酒 age:20 fmt.Printf(\"[value]\\tname:%s\\tage:%d\\n\", (*people).name, (*people).age) // [value] name:索隆不喝酒 age:20 fmt.Printf(\"[addr]\\tname:%d\\tage:%d\\n\", \u0026people.name, \u0026people.age) // [addr] name:1374389584016 age:1374389584032 } struct 存在方法集的概念，即所属于一个类型的方法的集合 （local 202304241738 struct 方法集 remote 202304241738 struct 方法集） ","date":"2023-05-09","objectID":"/202304241633-struct/:0:0","series":["card"],"tags":["struct"],"title":"struct","uri":"/202304241633-struct/#"},{"categories":["Golang"],"content":"#Golang #struct Go 语言中 struct 存在方法集（method set）的概念，看下面一段代码 type T struct { a int } func (t T) M1() { t.a++ } func (t *T) M2() { t.a++ } func structPractice2() { var t1 T var t2 = \u0026T{} fmt.Println(reflect.TypeOf(t1)) // T fmt.Println(reflect.TypeOf(t2)) // *T t1.M1() t1.M2() // (\u0026t1).M2() t2.M1() // (*t2).M1() t2.M2() } 变量 类型 方法集 t1 T {M1} t2 *T {M1,M2} 那么为什么 t1.M2() 不报错？ 可以看到 t1 的方法集只有 M1，M2方法的接收者类型是 *T 但是为什么 t1.M2() 这段代码不报错，这是由于 Go 语言提供的语法糖，Go 的编译器判断 t1 的类型为 T，跟 M2 方法的接收者不一致，自动转化成了 (\u0026t1).M2()；同理可解释 t2.M1() 那么既然存在这样的语法糖，来看看这样调用是不是可行的： T{}.M2() // Cannot call a pointer method on 'T{}' (\u0026T{}).M2()//OK (\u0026T{}).M1()//ok 会直接报错：无法通过 T{} 来调用一个指针方法 原因其实是上面提到的语法糖有一个前提： T 类型的实例，需要是可被取地址的（addressable） 《为什么这个T类型实例无法调用*T类型的方法 | Tony Bai》. 见于 2023年4月24日. https://tonybai.com/2022/02/27/go-addressable/. 鸟窝. 《go addressable 详解》, 2018年2月27日. https://colobu.com/2018/02/27/go-addressable/. 吴润写字的地方. 《Golang 不可寻址的理解》, 2021年11月12日. http://www.wu.run/2021/11/12/not-addressable-in-golang/index.html. ","date":"2023-05-09","objectID":"/202304241738-struct-%E6%96%B9%E6%B3%95%E9%9B%86/:0:0","series":["Golang语言使用"],"tags":["struct"],"title":"struct 方法集概念","uri":"/202304241738-struct-%E6%96%B9%E6%B3%95%E9%9B%86/#"},{"categories":["Golang"],"content":"#Golang #unsafe 概念：Pointer 表示一个指针，可以指向任何类型 四个特殊操作： 任何类型的指针值 可转化为 Pointer Pointer 可转化为 任何类型的指针值 uintptr 可转化为 Pointer Pointer 可转化为 uinptr 由于以上四个特性，Pointer 能够实现让程序绕过类型系统，读写任意内存（使用时需格外小心） ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:0:0","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#"},{"categories":["Golang"],"content":" 下面列举 unsafe 包中列举的 unsafe.Pointer 使用的六种场景","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:0","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#下面列举-unsafe-包中列举的-unsafepointer-使用的六种场景"},{"categories":["Golang"],"content":" （1）*T1 –\u003e Pointer –\u003e *T2需要满足要求： T2 不大于 T1 T1、T2 共享相同的内存布局 (local 202304242150 内存布局 remote 202304242150 内存布局) 则这种转换是允许的 例子1. 一个 float64 值转为 uint64 的值 func float64bits(f float64) uint64 { return *(*uint64)(unsafe.Pointer(\u0026f)) } 另外一个例子，将字符串转换为字节切片，首先我们看一下在 64 位系统中两者的尺寸 var s string var bs []byte fmt.Println(unsafe.Sizeof(s)) // 16 fmt.Println(unsafe.Sizeof(bs)) // 24 字符串 16 字节 字节切片 24 字节 字符串与字节切片的内存布局类似，且字节切片的尺寸不小于字符串的尺寸，因此将字节切片转到字符串是安全的，让我们来看实现： func byteSlice2String(bs []byte) string { return *(*string)(unsafe.Pointer(\u0026bs)) } 这种实现的优点是避免了底层对字节序列的一次开辟和复制 而如果要用此方式来实现从 string 到 []byte 则是不安全的： // 这种转换是不安全的 func string2Bytes(s string) []byte { return *(*[]byte)(unsafe.Pointer(\u0026s)) } ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:1","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#1t1----pointer----t2"},{"categories":["Golang"],"content":" （2）Pointer –\u003e uintptr （用途少）从指针转到 uintptr 类型实际上产生了一个没有指针语义的整数（代表指针指向值的内存地址，只是一个整数，不是引用），所以这种情况下，再将 uintptr 转回指针是无效的，通常的用法是将这个 uintptr 打印出来 即使uintptr保存了某个对象的地址，如果对象移动，垃圾收集器也不会更新该uintptr的值，也不会阻止该对象被回收 下面的情况说明了从 uintptr 转到 Pointer 的可能场景 ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:2","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#2pointer----uintptr-用途少"},{"categories":["Golang"],"content":" （3）算数运算 （Pointer –\u003e uintptr –\u003e 运算 –\u003e Pointer）这种操作通常是用来访问： 结构的字段 数组的元素 一个例子： // ** 通过 uintptr 来访问结构中的字段、数组的元素 ** type T struct { a int16 arr [3]int32 } func uintptr2PointerPractice() { // unsafe.Sizeof(T{}.a) // 2 M := unsafe.Offsetof(T{}.arr) // 4 N := unsafe.Sizeof(T{}.arr[0]) // 4 fmt.Println(unsafe.Sizeof(T{}.a)) // 2 fmt.Println(unsafe.Sizeof(T{}.arr)) // 3 * 4 = 12 fmt.Println(unsafe.Sizeof(T{})) // 16 t := \u0026T{ arr: [3]int32{1, 2, 3}, } // 直接访问 t.arr 的最后一个元素 tp := unsafe.Pointer(t) // 先将 t 转为非安全指针 // 将 uintptr 进行算数运算后再转为非安全指针 arrp := unsafe.Pointer(uintptr(tp) + M + N + N) // 将非安全指针转为数组元素类型指针 ans := (*int32)(arrp) // ans := (*int32)(unsafe.Pointer(uintptr(tp) + M + N + N)) fmt.Println(*ans) // output: 3 } 特别注意在这种场景下，可能会发生的很隐秘的 bug： func uintptr2PointerPractice2() { // unsafe.Sizeof(T{}.a) // 2 M := unsafe.Offsetof(T{}.arr) // 4 N := unsafe.Sizeof(T{}.arr[0]) // 4 t := T{ arr: [3]int32{1, 2, 3}, } uptr := uintptr(unsafe.Pointer(\u0026t)) + M + N + N // 中间其他操作 elemP := (*int32)(unsafe.Pointer(uptr)) fmt.Println(*elemP) // output: 3 } 前面提到了，虽然 uintptr 保存了 t 的地址的值，但是并不会阻止垃圾回收机制将 t 回收，所以在中间其他操作的时候，一旦 t 被回收，后面的地址将指向不可预测的内容。 实际上，像 Goland 编码工具在编码的时候就会给出提示： ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:3","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#3算数运算-pointer----uintptr----运算----pointer"},{"categories":["Golang"],"content":" （4）Pointer –\u003e uintptr –\u003e syscall在 syscall 系统调用中，可能会根据调用的具体实现将 uintptr 重新转为指针 注意：转换必须在调用的表达式中出现，在系统调用期间隐式转换为指针之前，uintptr 不能保存在变量中 正确： syscall.Syscall(SYS_READ, uintptr(fd), uintptr(unsafe.Pointer(p)), uintptr(n)) 错误 u := uintptr(unsafe.Pointer(p)) // p 所引用的对象可能在这个时候被垃圾回收，或者 p 的地址发生改变 syscall.Syscall(SYS_READ, uintptr(fd), u, uintptr(n)) ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:4","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#4pointer----uintptr----syscall"},{"categories":["Golang"],"content":" （5）将 reflect.Value.Pointer 或者 reflect.Value.UnsafeAddr 的结果从 uintptr 转到 Pointer","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:5","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#5将-reflectvaluepointer-或者-reflectvalueunsafeaddr-的结果从-uintptr-转到-pointer"},{"categories":["Golang"],"content":" （6）将一个reflect.SliceHeader或者reflect.StringHeader值的Data字段转换为非类型安全指针，以及其逆转换首先我们来看reflect.SliceHeader 和 reflect.StringHeader 的定义： // StringHeader是字符串的运行时表示形式。 // 它不能安全或可移植地使用，并且它的表示可能在以后的版本中更改。 // 此外，Data字段不足以保证它引用的数据不会被垃圾收集， // 因此程序必须保留一个单独的、类型正确的指向底层数据的指针。 type StringHeader struct { Data uintptr Len int } // SliceHeader是切片的运行时表示。 // 它不能安全或可移植地使用，并且它的表示可能在以后的版本中更改。 // 此外，Data字段不足以保证它引用的数据不会被垃圾收集， // 因此程序必须保留一个单独的、类型正确的指向底层数据的指针。 type SliceHeader struct { Data uintptr Len int Cap int } 一个使用 StringHeader 的例子： func uintptrPractice4() { a := [...]byte{'a', 'b', 'c', 'd', 'e'} b := \"java\" hdr := (*reflect.StringHeader)(unsafe.Pointer(\u0026b)) hdr.Data = uintptr(unsafe.Pointer(\u0026a)) hdr.Len = len(a) // 至此，a 和 b 共享底层的字节序列 a[1], a[2], a[3], a[4] = 'a', 'a', 'a', 'a' fmt.Println(b) // out: aaaaa } 将字符串指针转为*StringHeader，从而可以对字符串的内部进行修改 ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:1:6","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#6将一个reflectsliceheader或者reflectstringheader值的data字段转换为非类型安全指针以及其逆转换"},{"categories":["Golang"],"content":" 总结下 uintptr 和 Pointer 的区别 Pointer：通用类型指针，不可以参与指针运算 uintptr：用于指针运算，不持有对象，会被垃圾回收 《非类型安全指针 -Go语言101》. 见于 2023年4月25日. https://gfw.go101.org/article/unsafe.html. ","date":"2023-05-09","objectID":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/:2:0","series":["Golang底层分析、源码学习"],"tags":["unsafe包"],"title":"unsafe.Pointer 的六种使用场景","uri":"/202304241708-unsafe.pointer-%E7%9A%84%E5%85%AD%E7%A7%8D%E4%BD%BF%E7%94%A8%E5%9C%BA%E6%99%AF/#总结下-uintptr-和-pointer-的区别"},{"categories":["数据结构与算法"],"content":"#算法 递归能够解决的问题的特点： 原问题能够分解成一个更小的与原问题解决思路相同的子问题 递归的步骤： 拆分问题，找使用子问题解决原问题的方法（原问题与子问题的关系） 找子问题的解决方法，当与原问题的解决方法一致，便能够递归 结束的条件 时间复杂度 可以将编码的过程总结为： 1. 定义方法 2. 写明结束条件 3. 根据原问题、子问题之间的逻辑关系写主要的递归逻辑 递归存在的问题： 栈溢出 重复计算 ","date":"2023-05-09","objectID":"/202304300007-%E9%80%92%E5%BD%92/:0:0","series":["算法"],"tags":["递归"],"title":"递归","uri":"/202304300007-%E9%80%92%E5%BD%92/#"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:0:0","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#"},{"categories":["数据结构与算法"],"content":" 二叉搜索树概述二叉搜索树：左子树所有节点的值 \u003c 根节点 \u003c 右子树所有节点的值 比如： 二叉搜索树的相关操作： 构建 判断 删除节点 增加节点 ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:1:0","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#二叉搜索树概述"},{"categories":["数据结构与算法"],"content":" 相关操作","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:0","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#相关操作"},{"categories":["数据结构与算法"],"content":" 判断是否是二叉搜索树递归实现 // 递归实现 // 从二叉搜索树当前节点的值可以推出左右节点的取值区间，递归判断每个节点即可 func isValidBST(root *TreeNode) bool { if root == nil { return true } return jud(root, math.MinInt, math.MaxInt) } func jud(root *TreeNode, start, end int) bool { if root == nil { return true } if root.Val \u003c= start || root.Val \u003e= end { return false } return jud(root.Left, start, root.Val) \u0026\u0026 jud(root.Right, root.Val, end) } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:1","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#判断是否是二叉搜索树"},{"categories":["数据结构与算法"],"content":" 插入节点递归实现 func insertIntoBST(root *TreeNode, val int) *TreeNode { if root == nil { return \u0026TreeNode{ Val: val, } } if val \u003c root.Val { root.Left = insertIntoBST(root.Left, val) } else { root.Right = insertIntoBST(root.Right, val) } return root } 非递归实现 func insertIntoBST2(root *TreeNode, val int) *TreeNode { if root == nil { return \u0026TreeNode{ Val: val, } } pre := root tmpRoot := root for tmpRoot != nil { if val \u003c tmpRoot.Val { pre = tmpRoot tmpRoot = tmpRoot.Left } else { pre = tmpRoot tmpRoot = tmpRoot.Right } } newNode := \u0026TreeNode{Val: val} if val \u003c pre.Val { pre.Left = newNode } else { pre.Right = newNode } return root } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:2","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#插入节点"},{"categories":["数据结构与算法"],"content":" 删除节点 // 如果找到该节点，有四种情况： // 没有左节点，直接将右子树代替该节点的位置 // 没有右节点，直接将左子树代替该节点的位置 // 均有左右节点，根据中序节点的性质，当前的序列为：左子树、当前节点、右子树的最左节点 // 删除当前节点之后，为了保持中序，需要将左子树嫁接到右子树的最左节点的左节点，然后将右子树的根节点替换当前节点的位置 // 均没有左右节点（叶子节点），直接删除该节点 func deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } var curParent *TreeNode = nil cur := root for cur != nil \u0026\u0026 cur.Val != key { curParent = cur if key \u003c cur.Val { cur = cur.Left } else { cur = cur.Right } } // not found if cur == nil { return root } if cur.Left != nil \u0026\u0026 cur.Right != nil { rightMinNode := cur.Right for rightMinNode.Left != nil { rightMinNode = rightMinNode.Left } rightMinNode.Left = cur.Left cur = cur.Right } else if cur.Left != nil { cur = cur.Left } else if cur.Right != nil { cur = cur.Right } else { cur = nil } if curParent == nil { return cur } if curParent.Left != nil \u0026\u0026 curParent.Left.Val == key { curParent.Left = cur } else { curParent.Right = cur } return root } 2023/05/23 重新回顾一下删除节点的操作，二叉搜索树的节点删除可以根据删除节点的子树数量分为三种情况来讨论： 没有子树 只有一棵子树 有两棵子树 没有子树 有一棵子树 有两棵子树step1. 找到目标节点 step2. 将 目标节点的子树数量变成 1 step3. 用右子树根节点代替目标节点位置 总结： 子树数量 操作 0 直接删除 1 子树代替目标节点 2 重新构建子树，使其只有一颗子树，然后使用上面方法 有两棵子树的情况下，有多种方式来重建子树使用「嫁接」的方式实现： // delete 使用「嫁接」的方式来删除 func (bst *binarySearchTree) delete(val int) { tgt := bst.root if tgt == nil { return } var parent *treeNode = nil for tgt != nil { // 找到目标节点（待删除节点） if tgt.val == val { break } parent = tgt if val \u003c tgt.val { tgt = tgt.left } else { tgt = tgt.right } } // 不存在 if tgt == nil { return } // 不存在子树或者只有一棵子树的情况 // - 若存在子树，则使用子树代替待删除节点即可 // - 否则直接将待删除节点删除 if tgt.left == nil || tgt.right == nil { if tgt.left == nil { tgt = tgt.left } else { tgt = tgt.right } // 存在两棵子树的情况 // child 为右节点根节点 } else { tmp := tgt.right // 将待删除节点的左子树嫁接到右子树的最左节点 for tmp.left != nil { tmp = tmp.left } tmp.left = tgt.left tgt = tgt.right } if parent == nil { bst.root = tgt return } if parent.left != nil \u0026\u0026 parent.left.val == val { parent.left = tgt } else { parent.right = tgt } } 使用「后继节点」替代待删除节点： /* 删除节点 */func (bst *binarySearchTree) remove2(num int) { cur := bst.root // 若树为空，直接提前返回 if cur == nil { return } // 待删除节点之前的节点位置 var pre *treeNode = nil // 循环查找，越过叶节点后跳出 for cur != nil { if cur.val == num { break } pre = cur if cur.val \u003c num { // 待删除节点在右子树中 cur = cur.right } else { // 待删除节点在左子树中 cur = cur.right } } // 若无待删除节点，则直接返回 if cur == nil { return } // 子节点数为 0 或 1 if cur.left == nil || cur.right == nil { var child *treeNode = nil // 取出待删除节点的子节点 if cur.left != nil { child = cur.left } else { child = cur.right } // 将子节点替换为待删除节点 if pre.left == cur { pre.left = child } else { pre.right = child } // 子节点数为 2 } else { // 获取中序遍历中待删除节点 cur 的下一个节点 tmp := cur.right for tmp.left != nil { tmp = tmp.left } // 递归删除节点 tmp bst.remove2(tmp.val) // 用 tmp 覆盖 cur cur.val = tmp.val } } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:3","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#删除节点"},{"categories":["数据结构与算法"],"content":" 删除节点 // 如果找到该节点，有四种情况： // 没有左节点，直接将右子树代替该节点的位置 // 没有右节点，直接将左子树代替该节点的位置 // 均有左右节点，根据中序节点的性质，当前的序列为：左子树、当前节点、右子树的最左节点 // 删除当前节点之后，为了保持中序，需要将左子树嫁接到右子树的最左节点的左节点，然后将右子树的根节点替换当前节点的位置 // 均没有左右节点（叶子节点），直接删除该节点 func deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } var curParent *TreeNode = nil cur := root for cur != nil \u0026\u0026 cur.Val != key { curParent = cur if key \u003c cur.Val { cur = cur.Left } else { cur = cur.Right } } // not found if cur == nil { return root } if cur.Left != nil \u0026\u0026 cur.Right != nil { rightMinNode := cur.Right for rightMinNode.Left != nil { rightMinNode = rightMinNode.Left } rightMinNode.Left = cur.Left cur = cur.Right } else if cur.Left != nil { cur = cur.Left } else if cur.Right != nil { cur = cur.Right } else { cur = nil } if curParent == nil { return cur } if curParent.Left != nil \u0026\u0026 curParent.Left.Val == key { curParent.Left = cur } else { curParent.Right = cur } return root } 2023/05/23 重新回顾一下删除节点的操作，二叉搜索树的节点删除可以根据删除节点的子树数量分为三种情况来讨论： 没有子树 只有一棵子树 有两棵子树 没有子树 有一棵子树 有两棵子树step1. 找到目标节点 step2. 将 目标节点的子树数量变成 1 step3. 用右子树根节点代替目标节点位置 总结： 子树数量 操作 0 直接删除 1 子树代替目标节点 2 重新构建子树，使其只有一颗子树，然后使用上面方法 有两棵子树的情况下，有多种方式来重建子树使用「嫁接」的方式实现： // delete 使用「嫁接」的方式来删除 func (bst *binarySearchTree) delete(val int) { tgt := bst.root if tgt == nil { return } var parent *treeNode = nil for tgt != nil { // 找到目标节点（待删除节点） if tgt.val == val { break } parent = tgt if val \u003c tgt.val { tgt = tgt.left } else { tgt = tgt.right } } // 不存在 if tgt == nil { return } // 不存在子树或者只有一棵子树的情况 // - 若存在子树，则使用子树代替待删除节点即可 // - 否则直接将待删除节点删除 if tgt.left == nil || tgt.right == nil { if tgt.left == nil { tgt = tgt.left } else { tgt = tgt.right } // 存在两棵子树的情况 // child 为右节点根节点 } else { tmp := tgt.right // 将待删除节点的左子树嫁接到右子树的最左节点 for tmp.left != nil { tmp = tmp.left } tmp.left = tgt.left tgt = tgt.right } if parent == nil { bst.root = tgt return } if parent.left != nil \u0026\u0026 parent.left.val == val { parent.left = tgt } else { parent.right = tgt } } 使用「后继节点」替代待删除节点： /* 删除节点 */func (bst *binarySearchTree) remove2(num int) { cur := bst.root // 若树为空，直接提前返回 if cur == nil { return } // 待删除节点之前的节点位置 var pre *treeNode = nil // 循环查找，越过叶节点后跳出 for cur != nil { if cur.val == num { break } pre = cur if cur.val \u003c num { // 待删除节点在右子树中 cur = cur.right } else { // 待删除节点在左子树中 cur = cur.right } } // 若无待删除节点，则直接返回 if cur == nil { return } // 子节点数为 0 或 1 if cur.left == nil || cur.right == nil { var child *treeNode = nil // 取出待删除节点的子节点 if cur.left != nil { child = cur.left } else { child = cur.right } // 将子节点替换为待删除节点 if pre.left == cur { pre.left = child } else { pre.right = child } // 子节点数为 2 } else { // 获取中序遍历中待删除节点 cur 的下一个节点 tmp := cur.right for tmp.left != nil { tmp = tmp.left } // 递归删除节点 tmp bst.remove2(tmp.val) // 用 tmp 覆盖 cur cur.val = tmp.val } } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:3","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#没有子树"},{"categories":["数据结构与算法"],"content":" 删除节点 // 如果找到该节点，有四种情况： // 没有左节点，直接将右子树代替该节点的位置 // 没有右节点，直接将左子树代替该节点的位置 // 均有左右节点，根据中序节点的性质，当前的序列为：左子树、当前节点、右子树的最左节点 // 删除当前节点之后，为了保持中序，需要将左子树嫁接到右子树的最左节点的左节点，然后将右子树的根节点替换当前节点的位置 // 均没有左右节点（叶子节点），直接删除该节点 func deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } var curParent *TreeNode = nil cur := root for cur != nil \u0026\u0026 cur.Val != key { curParent = cur if key \u003c cur.Val { cur = cur.Left } else { cur = cur.Right } } // not found if cur == nil { return root } if cur.Left != nil \u0026\u0026 cur.Right != nil { rightMinNode := cur.Right for rightMinNode.Left != nil { rightMinNode = rightMinNode.Left } rightMinNode.Left = cur.Left cur = cur.Right } else if cur.Left != nil { cur = cur.Left } else if cur.Right != nil { cur = cur.Right } else { cur = nil } if curParent == nil { return cur } if curParent.Left != nil \u0026\u0026 curParent.Left.Val == key { curParent.Left = cur } else { curParent.Right = cur } return root } 2023/05/23 重新回顾一下删除节点的操作，二叉搜索树的节点删除可以根据删除节点的子树数量分为三种情况来讨论： 没有子树 只有一棵子树 有两棵子树 没有子树 有一棵子树 有两棵子树step1. 找到目标节点 step2. 将 目标节点的子树数量变成 1 step3. 用右子树根节点代替目标节点位置 总结： 子树数量 操作 0 直接删除 1 子树代替目标节点 2 重新构建子树，使其只有一颗子树，然后使用上面方法 有两棵子树的情况下，有多种方式来重建子树使用「嫁接」的方式实现： // delete 使用「嫁接」的方式来删除 func (bst *binarySearchTree) delete(val int) { tgt := bst.root if tgt == nil { return } var parent *treeNode = nil for tgt != nil { // 找到目标节点（待删除节点） if tgt.val == val { break } parent = tgt if val \u003c tgt.val { tgt = tgt.left } else { tgt = tgt.right } } // 不存在 if tgt == nil { return } // 不存在子树或者只有一棵子树的情况 // - 若存在子树，则使用子树代替待删除节点即可 // - 否则直接将待删除节点删除 if tgt.left == nil || tgt.right == nil { if tgt.left == nil { tgt = tgt.left } else { tgt = tgt.right } // 存在两棵子树的情况 // child 为右节点根节点 } else { tmp := tgt.right // 将待删除节点的左子树嫁接到右子树的最左节点 for tmp.left != nil { tmp = tmp.left } tmp.left = tgt.left tgt = tgt.right } if parent == nil { bst.root = tgt return } if parent.left != nil \u0026\u0026 parent.left.val == val { parent.left = tgt } else { parent.right = tgt } } 使用「后继节点」替代待删除节点： /* 删除节点 */func (bst *binarySearchTree) remove2(num int) { cur := bst.root // 若树为空，直接提前返回 if cur == nil { return } // 待删除节点之前的节点位置 var pre *treeNode = nil // 循环查找，越过叶节点后跳出 for cur != nil { if cur.val == num { break } pre = cur if cur.val \u003c num { // 待删除节点在右子树中 cur = cur.right } else { // 待删除节点在左子树中 cur = cur.right } } // 若无待删除节点，则直接返回 if cur == nil { return } // 子节点数为 0 或 1 if cur.left == nil || cur.right == nil { var child *treeNode = nil // 取出待删除节点的子节点 if cur.left != nil { child = cur.left } else { child = cur.right } // 将子节点替换为待删除节点 if pre.left == cur { pre.left = child } else { pre.right = child } // 子节点数为 2 } else { // 获取中序遍历中待删除节点 cur 的下一个节点 tmp := cur.right for tmp.left != nil { tmp = tmp.left } // 递归删除节点 tmp bst.remove2(tmp.val) // 用 tmp 覆盖 cur cur.val = tmp.val } } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:3","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#有一棵子树"},{"categories":["数据结构与算法"],"content":" 删除节点 // 如果找到该节点，有四种情况： // 没有左节点，直接将右子树代替该节点的位置 // 没有右节点，直接将左子树代替该节点的位置 // 均有左右节点，根据中序节点的性质，当前的序列为：左子树、当前节点、右子树的最左节点 // 删除当前节点之后，为了保持中序，需要将左子树嫁接到右子树的最左节点的左节点，然后将右子树的根节点替换当前节点的位置 // 均没有左右节点（叶子节点），直接删除该节点 func deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } var curParent *TreeNode = nil cur := root for cur != nil \u0026\u0026 cur.Val != key { curParent = cur if key \u003c cur.Val { cur = cur.Left } else { cur = cur.Right } } // not found if cur == nil { return root } if cur.Left != nil \u0026\u0026 cur.Right != nil { rightMinNode := cur.Right for rightMinNode.Left != nil { rightMinNode = rightMinNode.Left } rightMinNode.Left = cur.Left cur = cur.Right } else if cur.Left != nil { cur = cur.Left } else if cur.Right != nil { cur = cur.Right } else { cur = nil } if curParent == nil { return cur } if curParent.Left != nil \u0026\u0026 curParent.Left.Val == key { curParent.Left = cur } else { curParent.Right = cur } return root } 2023/05/23 重新回顾一下删除节点的操作，二叉搜索树的节点删除可以根据删除节点的子树数量分为三种情况来讨论： 没有子树 只有一棵子树 有两棵子树 没有子树 有一棵子树 有两棵子树step1. 找到目标节点 step2. 将 目标节点的子树数量变成 1 step3. 用右子树根节点代替目标节点位置 总结： 子树数量 操作 0 直接删除 1 子树代替目标节点 2 重新构建子树，使其只有一颗子树，然后使用上面方法 有两棵子树的情况下，有多种方式来重建子树使用「嫁接」的方式实现： // delete 使用「嫁接」的方式来删除 func (bst *binarySearchTree) delete(val int) { tgt := bst.root if tgt == nil { return } var parent *treeNode = nil for tgt != nil { // 找到目标节点（待删除节点） if tgt.val == val { break } parent = tgt if val \u003c tgt.val { tgt = tgt.left } else { tgt = tgt.right } } // 不存在 if tgt == nil { return } // 不存在子树或者只有一棵子树的情况 // - 若存在子树，则使用子树代替待删除节点即可 // - 否则直接将待删除节点删除 if tgt.left == nil || tgt.right == nil { if tgt.left == nil { tgt = tgt.left } else { tgt = tgt.right } // 存在两棵子树的情况 // child 为右节点根节点 } else { tmp := tgt.right // 将待删除节点的左子树嫁接到右子树的最左节点 for tmp.left != nil { tmp = tmp.left } tmp.left = tgt.left tgt = tgt.right } if parent == nil { bst.root = tgt return } if parent.left != nil \u0026\u0026 parent.left.val == val { parent.left = tgt } else { parent.right = tgt } } 使用「后继节点」替代待删除节点： /* 删除节点 */func (bst *binarySearchTree) remove2(num int) { cur := bst.root // 若树为空，直接提前返回 if cur == nil { return } // 待删除节点之前的节点位置 var pre *treeNode = nil // 循环查找，越过叶节点后跳出 for cur != nil { if cur.val == num { break } pre = cur if cur.val \u003c num { // 待删除节点在右子树中 cur = cur.right } else { // 待删除节点在左子树中 cur = cur.right } } // 若无待删除节点，则直接返回 if cur == nil { return } // 子节点数为 0 或 1 if cur.left == nil || cur.right == nil { var child *treeNode = nil // 取出待删除节点的子节点 if cur.left != nil { child = cur.left } else { child = cur.right } // 将子节点替换为待删除节点 if pre.left == cur { pre.left = child } else { pre.right = child } // 子节点数为 2 } else { // 获取中序遍历中待删除节点 cur 的下一个节点 tmp := cur.right for tmp.left != nil { tmp = tmp.left } // 递归删除节点 tmp bst.remove2(tmp.val) // 用 tmp 覆盖 cur cur.val = tmp.val } } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:3","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#有两棵子树"},{"categories":["数据结构与算法"],"content":" 删除节点 // 如果找到该节点，有四种情况： // 没有左节点，直接将右子树代替该节点的位置 // 没有右节点，直接将左子树代替该节点的位置 // 均有左右节点，根据中序节点的性质，当前的序列为：左子树、当前节点、右子树的最左节点 // 删除当前节点之后，为了保持中序，需要将左子树嫁接到右子树的最左节点的左节点，然后将右子树的根节点替换当前节点的位置 // 均没有左右节点（叶子节点），直接删除该节点 func deleteNode(root *TreeNode, key int) *TreeNode { if root == nil { return nil } var curParent *TreeNode = nil cur := root for cur != nil \u0026\u0026 cur.Val != key { curParent = cur if key \u003c cur.Val { cur = cur.Left } else { cur = cur.Right } } // not found if cur == nil { return root } if cur.Left != nil \u0026\u0026 cur.Right != nil { rightMinNode := cur.Right for rightMinNode.Left != nil { rightMinNode = rightMinNode.Left } rightMinNode.Left = cur.Left cur = cur.Right } else if cur.Left != nil { cur = cur.Left } else if cur.Right != nil { cur = cur.Right } else { cur = nil } if curParent == nil { return cur } if curParent.Left != nil \u0026\u0026 curParent.Left.Val == key { curParent.Left = cur } else { curParent.Right = cur } return root } 2023/05/23 重新回顾一下删除节点的操作，二叉搜索树的节点删除可以根据删除节点的子树数量分为三种情况来讨论： 没有子树 只有一棵子树 有两棵子树 没有子树 有一棵子树 有两棵子树step1. 找到目标节点 step2. 将 目标节点的子树数量变成 1 step3. 用右子树根节点代替目标节点位置 总结： 子树数量 操作 0 直接删除 1 子树代替目标节点 2 重新构建子树，使其只有一颗子树，然后使用上面方法 有两棵子树的情况下，有多种方式来重建子树使用「嫁接」的方式实现： // delete 使用「嫁接」的方式来删除 func (bst *binarySearchTree) delete(val int) { tgt := bst.root if tgt == nil { return } var parent *treeNode = nil for tgt != nil { // 找到目标节点（待删除节点） if tgt.val == val { break } parent = tgt if val \u003c tgt.val { tgt = tgt.left } else { tgt = tgt.right } } // 不存在 if tgt == nil { return } // 不存在子树或者只有一棵子树的情况 // - 若存在子树，则使用子树代替待删除节点即可 // - 否则直接将待删除节点删除 if tgt.left == nil || tgt.right == nil { if tgt.left == nil { tgt = tgt.left } else { tgt = tgt.right } // 存在两棵子树的情况 // child 为右节点根节点 } else { tmp := tgt.right // 将待删除节点的左子树嫁接到右子树的最左节点 for tmp.left != nil { tmp = tmp.left } tmp.left = tgt.left tgt = tgt.right } if parent == nil { bst.root = tgt return } if parent.left != nil \u0026\u0026 parent.left.val == val { parent.left = tgt } else { parent.right = tgt } } 使用「后继节点」替代待删除节点： /* 删除节点 */func (bst *binarySearchTree) remove2(num int) { cur := bst.root // 若树为空，直接提前返回 if cur == nil { return } // 待删除节点之前的节点位置 var pre *treeNode = nil // 循环查找，越过叶节点后跳出 for cur != nil { if cur.val == num { break } pre = cur if cur.val \u003c num { // 待删除节点在右子树中 cur = cur.right } else { // 待删除节点在左子树中 cur = cur.right } } // 若无待删除节点，则直接返回 if cur == nil { return } // 子节点数为 0 或 1 if cur.left == nil || cur.right == nil { var child *treeNode = nil // 取出待删除节点的子节点 if cur.left != nil { child = cur.left } else { child = cur.right } // 将子节点替换为待删除节点 if pre.left == cur { pre.left = child } else { pre.right = child } // 子节点数为 2 } else { // 获取中序遍历中待删除节点 cur 的下一个节点 tmp := cur.right for tmp.left != nil { tmp = tmp.left } // 递归删除节点 tmp bst.remove2(tmp.val) // 用 tmp 覆盖 cur cur.val = tmp.val } } ","date":"2023-05-09","objectID":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/:2:3","series":["数据结构"],"tags":["树"],"title":"二叉搜索树","uri":"/202305040442-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/#有两棵子树的情况下有多种方式来重建子树"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202304300231-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:0:0","series":["算法"],"tags":["排序算法"],"title":"归并排序","uri":"/202304300231-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/#"},{"categories":["数据结构与算法"],"content":" 归并排序的思想归并排序是一种采用了递归思想的排序，采用递归（local 202304300007 递归 remote 202304300007 递归）的思想来分析就是： 原问题 \u0026 解决方法 原问题：将 nums 排序 解决办法：将数组 nums 分成两个序列 nums1、nums2，将 nums1、nums2 排序后合并 子问题 \u0026 解决方法 子问题：将 nums1、nums2 排序 解决办法：两个子数组都能够通过原问题的解决办法解决 结束条件：当数组不能再划分（长度=1） 时间复杂度： 合并的平均时间复杂度O(n) x 拆分的深度 logn = O(nlogn) ","date":"2023-05-09","objectID":"/202304300231-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:1:0","series":["算法"],"tags":["排序算法"],"title":"归并排序","uri":"/202304300231-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/#归并排序的思想"},{"categories":["数据结构与算法"],"content":" 实现Golang： // 1. 定义方法：将左右两个已经有序的序列合并成一个序列（原问题得解：原数组有序） // 2. 子问题：左右的数组需要有序，与原问题解决方法相同 // 3. 结束条件：数组的长度为 1 func mergeSort(nums []int) []int { // 结束条件 if len(nums) \u003c= 1 { return nums } // 子问题关系 mid := len(nums) / 2 left := mergeSort(nums[:mid]) right := mergeSort(nums[mid:]) // 方法定义 return merge(left, right) } // 将两个有序数组合并 func merge(nums1, nums2 []int) []int { n1, n2 := len(nums1), len(nums2) nums := make([]int, n1 + n2) i, j, idx := 0, 0, 0 for i \u003c n1 \u0026\u0026 j \u003c n2 { if nums1[i] \u003c nums2[j] { nums[idx] = nums1[i] i++ } else { nums[idx] = nums2[j] j++ } idx++ } for ; i \u003c n1; i++ { nums[idx] = nums1[i] idx++ } for ; j \u003c n2; j++ { nums[idx] = nums2[j] idx++ } return nums } 1.《图解排序算法(四)之归并排序 - dreamcatcher-cx - 博客园》. 见于 2023年4月30日. https://www.cnblogs.com/chengxiao/p/6194356.html. ","date":"2023-05-09","objectID":"/202304300231-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/:2:0","series":["算法"],"tags":["排序算法"],"title":"归并排序","uri":"/202304300231-%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/#实现"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/:0:0","series":["算法"],"tags":[],"title":"后缀数组与SA-IS算法","uri":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/#"},{"categories":["数据结构与算法"],"content":" 一、后缀数组概念：将 s 的所有后缀排序后的数组 见下面的一个例子： ","date":"2023-05-09","objectID":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/:1:0","series":["算法"],"tags":[],"title":"后缀数组与SA-IS算法","uri":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/#一后缀数组"},{"categories":["数据结构与算法"],"content":" 在 Go 中获得后缀数组的方法 type Index struct { _ []byte sa []int32 } func lastSubstring3(s string) string { index := suffixarray.New([]byte(s)) idx := (*Index)(unsafe.Pointer(index)) fmt.Println(idx.sa) // s=\"aabaaaab\" output:[3 4 5 0 6 1 7 2] return \"\" } 思考： unsafe.Pointer 的使用 (local 202304241708 unsafe.Pointer 的六种使用场景 remote 202304241708 unsafe.Pointer 的六种使用场景) 为什么是 (*Index) 这样的写法？ 顺便复习下 struct 结构体（local 202304241633 struct remote 202304241633 struct） ","date":"2023-05-09","objectID":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/:1:1","series":["算法"],"tags":[],"title":"后缀数组与SA-IS算法","uri":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/#在-go-中获得后缀数组的方法"},{"categories":["数据结构与算法"],"content":" 二、SA-IS 算法概念：（Suffix Array Induce Sort；SA-IS） todo 参考资料： 《诱导排序与SA-IS算法 - riteme.site》. 见于 2023年4月24日. https://riteme.site/blog/2016-6-19/sais.html. 第一次接触到后缀数组以及SA-IS算法是在leetcode每日一题（1163.按字典序排在最后的字串）中 ","date":"2023-05-09","objectID":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/:2:0","series":["算法"],"tags":[],"title":"后缀数组与SA-IS算法","uri":"/202304241453-%E5%90%8E%E7%BC%80%E6%95%B0%E7%BB%84%E4%B8%8Esa-is%E7%AE%97%E6%B3%95/#二sa-is-算法"},{"categories":["数据结构与算法"],"content":"#算法 复习一下基本的排序算法 有几种基本的排序算法： 冒泡排序 选择排序 插入排序 希尔排序（递减增量的排序；插入排序的改进版本） 归并排序 快速排序 桶排序 堆排序 计数排序 基数排序 ","date":"2023-05-09","objectID":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:0:0","series":["算法"],"tags":["排序算法"],"title":"基本的排序算法","uri":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#"},{"categories":["数据结构与算法"],"content":" 一、冒泡步骤： 一直往前走，比较相邻两个数，大数往后放 func bubbleSort(nums []int) { if len(nums) \u003c= 1 { return } // nums: 6 10 2 4 7 3 2 1 2 // loop1 j (loop2每进行一轮往前移，直到1) // loop2 i for j := len(nums)-1; j \u003e= 1; j--{ for i := 0; i \u003c j; i++ { if nums[i] \u003e nums[i+1] { swap(\u0026nums[i], \u0026nums[i+1]) } } } } 时间复杂度分析：O(n^2) 第一轮比较 n-1 次 第二轮比较 n-2 次 …. 第n-1轮比较 1 次 1 + 2 + … + (n-1) = n (n-1 + 1) / 2 ","date":"2023-05-09","objectID":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:1:0","series":["算法"],"tags":["排序算法"],"title":"基本的排序算法","uri":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#一冒泡"},{"categories":["数据结构与算法"],"content":" 二、选择排序步骤： 每次从未排序找最小 func selectSort(nums []int) { for i := 0; i \u003c len(nums)-1; i++ { minIdx := i for j := i+1; j \u003c len(nums); j++ { if nums[j] \u003c nums[i] { minIdx = j } } swap(\u0026nums[i], \u0026nums[minIdx]) } } 时间复杂度也是 O(n^2) ","date":"2023-05-09","objectID":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:2:0","series":["算法"],"tags":["排序算法"],"title":"基本的排序算法","uri":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#二选择排序"},{"categories":["数据结构与算法"],"content":" 三、插入排序步骤： 从已排序找合适的位置 func insertSort(nums []int) { // nums 1 2 5 3 4 // i (i极其右边为一个 未排序的序列) // j=i-1 (j 负责往前找大于等于cur的值) for i := 1; i \u003c len(nums); i++ { cur := nums[i] j := i-1 for ; j\u003e=0 \u0026\u0026 nums[j]\u003ecur; j-- { nums[j+1] = nums[j] } // 由于 j 当前的位置小于或者等于cur or 越界 // 故把前面一个位置，给到cur（前面的数已经往前前的位置移动） nums[j+1] = cur } } ","date":"2023-05-09","objectID":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:3:0","series":["算法"],"tags":["排序算法"],"title":"基本的排序算法","uri":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#三插入排序"},{"categories":["数据结构与算法"],"content":" 四、归并排序（local 202304300231 归并排序 remote 202304300231 归并排序） ","date":"2023-05-09","objectID":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:4:0","series":["算法"],"tags":["排序算法"],"title":"基本的排序算法","uri":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#四归并排序"},{"categories":["数据结构与算法"],"content":" 五、快速排序（local 202304300312 快速排序 remote 202304300312 快速排序） ","date":"2023-05-09","objectID":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/:5:0","series":["算法"],"tags":["排序算法"],"title":"基本的排序算法","uri":"/202304291858-%E5%9F%BA%E6%9C%AC%E7%9A%84%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/#五快速排序"},{"categories":["扩展学习"],"content":"#ChatGPT ","date":"2023-05-09","objectID":"/202305070218-%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%BB%80%E4%B9%88%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%BD%BF%E7%94%A8-openai/:0:0","series":["ChatGPT"],"tags":["jupyter"],"title":"可以在什么平台上使用 openai","uri":"/202305070218-%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%BB%80%E4%B9%88%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%BD%BF%E7%94%A8-openai/#"},{"categories":["扩展学习"],"content":" 一、使用 jupyter notebook前置： 安装 python 安装 jupyter notebook 加载环境、定义方法： import openai import os from dotenv import load_dotenv, find_dotenv _ = load_dotenv(find_dotenv()) openai.api_key = 'sk-xxxxx' def get_completion(prompt, model=\"gpt-3.5-turbo\"): messages = [{\"role\": \"user\", \"content\": prompt}] response = openai.ChatCompletion.create( model=model, messages=messages, temperature=0, # this is the degree of randomness of the model's output ) return response.choices[0].message[\"content\"] 使用时传入 prompt 参数： prompt = f\"\"\" She no went to the market 上面这句英文存在什么样的语法错误 \"\"\" response = get_completion(prompt) print(response) 效果： 在线演示：https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/2/guidelines ","date":"2023-05-09","objectID":"/202305070218-%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%BB%80%E4%B9%88%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%BD%BF%E7%94%A8-openai/:1:0","series":["ChatGPT"],"tags":["jupyter"],"title":"可以在什么平台上使用 openai","uri":"/202305070218-%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%BB%80%E4%B9%88%E5%B9%B3%E5%8F%B0%E4%B8%8A%E4%BD%BF%E7%94%A8-openai/#一使用-jupyter-notebook"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:0:0","series":["算法"],"tags":["排序算法"],"title":"快速排序","uri":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/#"},{"categories":["数据结构与算法"],"content":" 快速排序的思想快速排序采用了分治的思想，可以通过递归来实现 ","date":"2023-05-09","objectID":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:1:0","series":["算法"],"tags":["排序算法"],"title":"快速排序","uri":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/#快速排序的思想"},{"categories":["数据结构与算法"],"content":" 步骤 原问题 \u0026 解决办法 原问题：nums 数组排序 解决办法：选一个元素作为基准，将小于基准的数放到左边，大于基准的数放到右边（分区间） 子问题 \u0026 解决办法 子问题：左右区间的排序 解决办法：同原问题 结束条件：数组只有一个元素 ","date":"2023-05-09","objectID":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:2:0","series":["算法"],"tags":["排序算法"],"title":"快速排序","uri":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/#步骤"},{"categories":["数据结构与算法"],"content":" 实现 // nums 数组排序 func quickSort(nums []int, start, end int) { // 结束条件 if start \u003e= end { return } // 子问题关系 pivot := partition(nums, start, end) quickSort(nums, start, pivot) quickSort(nums, pivot+1, end) return } func partition(nums []int, start, end int) int { if start == end { } pivot := start idx := start + 1 for i := start+1; i \u003c= end; i++ { if nums[i] \u003c nums[pivot] { swap(\u0026nums[i], \u0026nums[idx]) idx++ } } swap(\u0026nums[pivot], \u0026nums[idx-1]) return idx-1 } 《1.6 快速排序 | 菜鸟教程》. 见于 2023年4月30日. https://www.runoob.com/w3cnote/quick-sort-2.html. ","date":"2023-05-09","objectID":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/:3:0","series":["算法"],"tags":["排序算法"],"title":"快速排序","uri":"/202304300312-%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/#实现"},{"categories":["扩展学习"],"content":"#ChatGPT 该篇笔记源于课程：https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/ ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:0:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#"},{"categories":["扩展学习"],"content":" 一、包含什么内容？两个产出： 使用大型语言模型（Large Language Model，LLM）快速构建功能强大的应用程序 构建两项能力： 学习创新 创造价值 了解 LLM 的工作原理 提示工程的最佳实践 如何编写有效的提示（两个原则） 如何设计好的提示 如何构建自己的聊天机器人 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:1:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#一包含什么内容"},{"categories":["扩展学习"],"content":" 二、提示词准则","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:2:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#二提示词准则"},{"categories":["扩展学习"],"content":" 2.1 指令要清晰 输入清晰 输出清晰 过程清晰 输入要清晰 清楚表明我想要的是什么？以此引导模型产出更符合我们期待的结果，避免跑题。注意清晰 != 简短，如果较长的描述更能准确表达我们的意图，那么这是必要的。 一些帮助符号： “” ``` --- \u003c\u003e … 有时候为了能够更清晰的表明意图，我们可以使用一些符号来辅佐说明。 例子： 你现在作为一名学生，需要对我的提问做出回答，ChatGPT Prompt Engineering for Developers 这门课讲述了什么 “您应该清晰且尽可能具体地表达您希望模型执行的操作，这将引导模型达到所预期的输出，并减少不相关的输出，或者不正确的输出。不要把写一个清晰的提示和写一个简短的提示混为一谈，许多情况下，较长的提示为模型提供了更清晰的背景，这可能会导致更加详细和相关的产出” 将由双引号限定的文字概括成一句话 上面的例子中，我们使用到了双引号来界定应该要总结的内容，引导模型产生我们想要的输出，当然这只是一个简单的例子，实际中可以更灵活地来使用 输出要清晰 上面的提到了如何更清晰地告诉模型应该输入的内容，下面我们应该告诉模型我们想要什么样的结果，我们可以结构化我们的输出，有时候我们可以将输出格式化为 html、json、markdown 等格式 看这样的一个例子 当然，更多时候 json 的 key 应该是英文，我们可以接着告诉 gpt： 有时候我们可能没有办法一次就描述清楚我们想要的，那么我们就可以继续补充，这是一个迭代的过程 过程要清晰 在处理的过程中，我们可以指定模型一些判断条件 看下面的例子 “泡一杯茶很简单！ 首先，你需要让水沸腾。 发生这种情况时， 拿一个杯子，在里面放一个茶包。 一旦水足够热，只需将其倒在茶包上即可。 让它静置一会儿。 再过几分钟，取出茶包。 如果你喜欢，可以加点糖或者牛奶调味。 就是这样！ 你有了自己的美味的一杯茶来享受。” 将上面由双引号限定的文本以下面的格式来重写： 第一步 - ... 第二步 - ... 第三步 - ... 第N步 - ... 如果文本不包含顺序指示，那么只需要写上“没有提供步骤” 上面的文本识别到了顺序指示，因此将文本以分步的形式重新组织了，同样的处理方式，我们来看另外一段文本： 今天阳光明媚，鸟儿们在唱歌。这是一个美丽的日子，可以去公园里散步。树木在微风中轻轻摇曳。 一些人正在野餐，而另一些人正在玩游戏或只是在草地上放松。这是一个 这是一个完美的日子，可以花时间在户外，欣赏自然之美。 将上面由双引号限定的文本以下面的格式来重写： 第一步 - ... 第二步 - ... 第三步 - ... 第N步 - ... 如果文本不包含指令序列，那么只需要写上“没有提供步骤” 可以看到通过判断，达到了我们想要的结果 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:2:1","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#21-指令要清晰"},{"categories":["扩展学习"],"content":" 2.2 给模型思考的时间 指定步骤来完成任务 看这样一个例子： “在一个迷人的村庄里，兄妹杰克和吉尔出发去山顶的井里取水。他们一边唱着欢快的歌，一边爬山，但不幸的是，杰克绊倒在石头上，从山上滚了下来，吉尔也跟着摔倒。虽然有些受伤，但他们还是回家受到安慰的拥抱。尽管遭遇了不幸，但他们的冒险精神仍然没有消失，他们继续愉快地探索。” 执行下面的动作： 1 - 用一句话总结上面引号括起来的文本 2 - 将第一步得到的总结翻译成韩语 3 - 在韩语总结中列出每个名字 用换行把每一步的答案分开 在这个例子中，我们想要完成的并不只是一种操作，我们对于一段文本可能想做好几件事，那么就可以分成几个步骤，告诉模型分别要做什么 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:2:2","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#22-给模型思考的时间"},{"categories":["扩展学习"],"content":" * 模型的限制在模型训练的过程中，并不会完美的记住自己接触的每个信息，因此它对自己的知识边界并不是十分了解，这意味着它可能会尝试回答一些晦涩难懂的问题，并且可以编造一些听起来很有道理，但实际上并不真实的事情，如下面的例子 这并不是真实的，但看起来非常真实，这是非常危险的，也是模型已知的一个问题 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:2:3","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#-模型的限制"},{"categories":["扩展学习"],"content":" 三、提示词的迭代由于某些原因，我们第一次获得的结果可能对于我们来说并不是有效、有用的，但是我们可以通过获得的结果，反复完善我们的提示词，一步步走向我们的想要的结果。 因此迭代的过程可以分为以下几步： 先试试 分析结果，是否符合我们预期 给出清楚的说明（指示），给模型更多时间思考 完善提示语 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:3:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#三提示词的迭代"},{"categories":["扩展学习"],"content":" 四、总结摘要例子1： 把以下产品评论进行总结，总结的字数不超过30个字。 产品评论：\"我为女儿的生日买了这只熊猫毛绒玩具，她非常喜欢，并且随身携带。它摸起来很软，非常可爱，脸上还有友好的表情。但是，相对于价格来说，它有点小了。我认为可能会有其他同样价位但更大的选择。它比预期提前一天到达，所以在把它送给女儿之前，我自己先玩了一下。\" 如果把上面的任务稍微修改一下， 你的任务是对一个电子商务网站的产品评论生成一个简短的摘要，以反馈给航运部门。 把以下产品评论进行总结，总结的字数不超过30个字, 重点放在提到产品运输和交付的任何方面。 产品评论：\"我为女儿的生日买了这只熊猫毛绒玩具，她非常喜欢，并且随身携带。它摸起来很软，非常可爱，脸上还有友好的表情。但是，相对于价格来说，它有点小了。我认为可能会有其他同样价位但更大的选择。它比预期提前一天到达，所以在把它送给女儿之前，我自己先玩了一下。\" 我们可以根据想要总结的方式，要求它提取不同的信息 再来看一个可能实际中更能碰倒的例子： # review for a standing lamp review_1 = \"\"\" Needed a nice lamp for my bedroom, and this one \\ had additional storage and not too high of a price \\ point. Got it fast - arrived in 2 days. The string \\ to the lamp broke during the transit and the company \\ happily sent over a new one. Came within a few days \\ as well. It was easy to put together. Then I had a \\ missing part, so I contacted their support and they \\ very quickly got me the missing piece! Seems to me \\ to be a great company that cares about their customers \\ and products. \"\"\" # review for an electric toothbrush review_2 = \"\"\" My dental hygienist recommended an electric toothbrush, \\ which is why I got this. The battery life seems to be \\ pretty impressive so far. After initial charging and \\ leaving the charger plugged in for the first week to \\ condition the battery, I've unplugged the charger and \\ been using it for twice daily brushing for the last \\ 3 weeks all on the same charge. But the toothbrush head \\ is too small. I’ve seen baby toothbrushes bigger than \\ this one. I wish the head was bigger with different \\ length bristles to get between teeth better because \\ this one doesn’t. Overall if you can get this one \\ around the $50 mark, it's a good deal. The manufactuer's \\ replacements heads are pretty expensive, but you can \\ get generic ones that're more reasonably priced. This \\ toothbrush makes me feel like I've been to the dentist \\ every day. My teeth feel sparkly clean! \"\"\" # review for a blender review_3 = \"\"\" So, they still had the 17 piece system on seasonal \\ sale for around $49 in the month of November, about \\ half off, but for some reason (call it price gouging) \\ around the second week of December the prices all went \\ up to about anywhere from between $70-$89 for the same \\ system. And the 11 piece system went up around $10 or \\ so in price also from the earlier sale price of $29. \\ So it looks okay, but if you look at the base, the part \\ where the blade locks into place doesn’t look as good \\ as in previous editions from a few years ago, but I \\ plan to be very gentle with it (example, I crush \\ very hard items like beans, ice, rice, etc. in the \\ blender first then pulverize them in the serving size \\ I want in the blender then switch to the whipping \\ blade for a finer flour, and use the cross cutting blade \\ first when making smoothies, then use the flat blade \\ if I need them finer/less pulpy). Special tip when making \\ smoothies, finely cut and freeze the fruits and \\ vegetables (if using spinach-lightly stew soften the \\ spinach then freeze until ready for use-and if making \\ sorbet, use a small to medium sized food processor) \\ that you plan to use that way you can avoid adding so \\ much ice if at all-when making your smoothie. \\ After about a year, the motor was making a funny noise. \\ I called customer service but the warranty expired \\ already, so I had to buy another one. FYI: The overall \\ quality has gone done in these types of products, so \\ they are kind of counting on brand recognition and \\ consumer loyalty to maintain sales. Got it in about \\ two days. \"\"\" reviews = [review_1, review_2, review_3, review_4] 你的任务是将上面的每个review分别做总结，总结以下面的格式输出： 1. 2. 将总结翻译成中文 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:4:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#四总结摘要"},{"categories":["扩展学习"],"content":" 五、AI 推理提取情绪信息 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:5:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#五ai-推理"},{"categories":["扩展学习"],"content":" 六、AI 转译 翻译 语法纠正、校对 格式转换（json、html、markdown…） 语气转换 （语气转换）不同的邮件对象可能需要不同的语气或者书面语，看下面的例子 将下面的内容从俚语转换成一封商务信函： “伙计，我是乔，看看这个立灯的规格。” ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:6:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#六ai-转译"},{"categories":["扩展学习"],"content":" 七、扩写（文案生成）扩写是指将一篇较短的文本进行扩写的工作，比如一套指示或者一个主题列表，生成一个较长的文本，如电子邮件或者文章。 例子：通过一名客户对于产品的评论生成一封回复邮件 你是一个客户服务的AI助理，你的任务是给一个有价值的客户发送电子邮件回复。 邮件的内容需要基于用户的评价，如果用户的情绪是积极的或者中性的，感谢他们的评论，如果情绪是负面的，则表示歉意，并建议他们可以联系客服。 确保使用用户评论中的具体细节。 用简明和专业的语气来写。 在邮件中署名：“AI 客户代理” 客户的评论：\"他们在11月份仍在季节性销售中以约49美元的价格销售17件套装，折扣约为一半，但出于某些原因（称其为价格抬高），到了12月的第二周，同样的系统的价格都涨到了约70-89美元左右。 11件套装的价格也比之前的29美元涨了大约10美元左右。 看起来还不错，但如果您看底座，锁定刀片的部分看起来与几年前的先前版本不太一样，但我打算非常小心（例如，我将像豆子，冰，米饭等非常硬的物品先放入搅拌机中压碎，然后把它们粉碎成我想要的食用量，然后切换到搅拌餐的鞭打刀，以获得更细的面粉，并在制作冰沙时先使用交叉切割刀，然后如果需要更细/较少纤维的话，再使用平刀）。制作冰沙的特殊提示：将要使用的水果和蔬菜切碎并冷冻（如果使用菠菜-轻轻煮软菠菜然后冷冻直到使用-如果制作雪泥，请使用小到中型食品处理器），以此来避免添加掉太多冰块。大约一年后，马达发出奇怪的噪音。我打电话给客服，但保修已经过期了，所以我不得不再买一个。 FYI：这些产品的整体质量已经下降，所以他们在品牌认知和消费者忠诚度上进行营销。大约两天后收到了产品。\" ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:7:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#七扩写文案生成"},{"categories":["扩展学习"],"content":" temperaturetemperature 作为模型的一个参数，将影响模型输出的随机性 显然：越低 temperature 意味着越高可靠性，越高 temperature 意味着越高创意性 ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:7:1","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#temperature"},{"categories":["扩展学习"],"content":" 八、聊天机器人待补充… 《ChatGPT Prompt Engineering for Developers》. 见于 2023年5月7日. https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/. 二次元的Datawhale. 《【专业翻译，配套代码笔记】01.课程介绍_哔哩哔哩_bilibili》. 见于 2023年5月7日. https://www.bilibili.com/video/BV1Bo4y1A7FU/. ","date":"2023-05-09","objectID":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/:8:0","series":["ChatGPT"],"tags":["提示词"],"title":"面向开发者的 ChatGPT 提示工程","uri":"/202305062133-%E9%9D%A2%E5%90%91%E5%BC%80%E5%8F%91%E8%80%85%E7%9A%84-chatgpt-%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/#八聊天机器人"},{"categories":["Golang"],"content":"#Golang 问题：两个数据有相同的内存布局，应该满足什么条件？ ","date":"2023-05-09","objectID":"/202304242150-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/:0:0","series":["Golang底层分析、源码学习"],"tags":["内存布局"],"title":"内存布局","uri":"/202304242150-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/#"},{"categories":["Golang"],"content":" 类型对齐保证出于对程序性能的考虑，每个类型都会有对应的对齐保证，根据该类型是否被作为结构字段，对齐保证分为两类： 字段对齐保证 一般对齐保证 说法：如果一个类型的对齐保证为N，那么就说这个类型是 N 字节对齐的 这两类对齐保证对应的获取方式： unsafe.Alignof(t) （编译的时候估值） reflect.TypeOf(t).Align() reflect.TypeOf(t).FieldAlign() type X struct { c int32 d int64 } func getAlignmentGuarantee() { var a int32 // 使用 unsafe.Alignof() fmt.Println(unsafe.Alignof(a)) // 4 （获取 int32 的一般对齐保证） fmt.Println(unsafe.Alignof(X{}.c)) // 4 （获取 int32 的字段对齐保证） fmt.Println(unsafe.Alignof(X{}.d)) // 8 fmt.Println(unsafe.Alignof(X{})) // 8 // 使用 reflect.TypeOf(a).Align() 以及 reflect.TypeOf(a).FieldAlign() fmt.Println(reflect.TypeOf(a).Align()) // 4 fmt.Println(reflect.TypeOf(a).FieldAlign()) // 4 } 注意上面程序的输出并不是固定的，相同的编译器在不同的架构上、不同的编译器在相同的架构上，都有可能产生不同的输出 Go 编译器中，对类型对齐保证要求： unsafe.Alignof(t) \u003e= 1 unsafe.Alignof(结构) = 结构体字段的字段对齐保证的最大值 unsafe.Alignof(数组) = unsafe.Alignof(元素类型) ","date":"2023-05-09","objectID":"/202304242150-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/:0:0","series":["Golang底层分析、源码学习"],"tags":["内存布局"],"title":"内存布局","uri":"/202304242150-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/#类型对齐保证"},{"categories":["Golang"],"content":" 结构体的字节填充为了能够让结构体的尺寸为类型对齐保证的 N 倍，有时候需要对结构进行字节补齐，看下面的一个例子，展示了两个内容： 结构体尺寸的计算 结构体的字节填充 // 假设在 64 位机器上的情况 type T1 struct { a int8 // 为了让 b 能够8字节对齐，这里要填充 7 个字节 b int64 c int16 // 前面一共的尺寸为 1 + 7 + 8 + 2 = 18 个字节 // 为了让 T1 的尺寸为 8 的倍数，这里需要填充 24 - 18 = 6 个字节 } // 因此 T1 类型的尺寸为 24 个字节 type T2 struct { a int8 // 为了让 b 能够 2 字节对齐，这里填充 1 字节 b int16 // 为了让 c 能够 8 字节对齐，这里填充 4 字节 c int64 // 前面一共 1 + 1 + 2 + 4 + 8 = 16 字节，因此这里不需要再填充 } // 因此 T2 类型的尺寸为 16 个字节 从上面这个例子可以看到，尽管 T1 跟 T2 拥有一样的字段类型，但因为排列的不同，导致字节填充的数量不同，因此其尺寸也不同。 问题：[[202304242320 一个零尺寸的类型有没有可能影响到结构体的尺寸]] 《内存布局 -Go语言101》. 见于 2023年4月24日. https://gfw.go101.org/article/memory-layout.html. 《The Go Programming Language Specification - The Go Programming Language》. 见于 2023年4月24日. https://go.dev/ref/spec. The Go Programming Language Specification 中文：https://github.com/saberuster/Go-Language-Specification ","date":"2023-05-09","objectID":"/202304242150-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/:0:0","series":["Golang底层分析、源码学习"],"tags":["内存布局"],"title":"内存布局","uri":"/202304242150-%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/#结构体的字节填充"},{"categories":["Golang"],"content":"#Golang ","date":"2023-05-09","objectID":"/202304201947-%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/:0:0","series":["Golang语言使用"],"tags":[],"title":"深浅拷贝","uri":"/202304201947-%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/#"},{"categories":["Golang"],"content":" 深浅拷贝的区别 深拷贝：两个对象不共享内存，各自分开 值类型的数据都是深拷贝，Int、Float、String、Bool、Struct 浅拷贝：两个对象指向同一个地址 引用类型的都是浅拷贝，Slice、Map ","date":"2023-05-09","objectID":"/202304201947-%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/:1:0","series":["Golang语言使用"],"tags":[],"title":"深浅拷贝","uri":"/202304201947-%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/#深浅拷贝的区别"},{"categories":["Golang"],"content":" 如果是 Slice 切片类型，想做深拷贝怎么办（使用 copy 方法） score := []int{1,2,3} scoreTmp := make([]int, len(score)) copy(scoreTmp, score) 注意点： 目的切面需要提前申请空间（一般与源切片等长，若更小，只拷贝部分，若更大，剩余空间补齐类型默认值） 若源切片存的是引用，则拷贝过去之后，目的切片保存的是跟源切片一样的引用（二维数组的拷贝），因此想二维数组如果要深拷贝需要二重循环 ","date":"2023-05-09","objectID":"/202304201947-%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/:2:0","series":["Golang语言使用"],"tags":[],"title":"深浅拷贝","uri":"/202304201947-%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/#如果是-slice-切片类型想做深拷贝怎么办使用-copy-方法"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:0:0","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#"},{"categories":["数据结构与算法"],"content":" 一些基本概念树四度： 度 节点的度：节点拥有的子节点数量 树的度：节点的度的最大值 深度：根节点到当前节点的距离 高度：根节点到最低节点的距离 树的实际应用： 帮助分析时间复杂度 搜索 排序 路径查找 ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:1:0","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#一些基本概念"},{"categories":["数据结构与算法"],"content":" 几种常见的树 二叉树 满二叉树 完全二叉树 二叉搜索树 （local 202305040442 二叉搜索树 remote 202305040442 二叉搜索树） 平衡二叉搜索树 线段树 平衡树 B 树 红黑树 ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:2:0","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#几种常见的树"},{"categories":["数据结构与算法"],"content":" 树的遍历方式深度：前序（DLR）、中序（LDR）、后序（LRD） 广度：层序遍历 ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:3:0","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#树的遍历方式"},{"categories":["数据结构与算法"],"content":" 前序遍历用递归的思想可以将问题看作： 访问跟节点 前序遍历左节点 前序遍历右节点 // 前序遍历: 访问根节点，以前序遍历的方式访问左节点，以前序遍历的方式访问右节点 func pOrder(root *treeNode) { // end if root == nil { return } fmt.Printf(\"%d \", root.val) pOrder(root.left) pOrder(root.right) return } 使用栈实现： 将根节点入栈 出栈，加入右节点跟左节点 重复以上操作，直到栈空 func pOrderStack(root *treeNode) { if root == nil { return } var st []*treeNode st = append(st, root) var pnt []int for len(st) \u003e 0 { // pop cur := st[len(st)-1] st = st[:len(st)-1] pnt = append(pnt, cur.val) // judge left\\right if cur.right != nil { st = append(st, cur.right) } if cur.left != nil { st = append(st, cur.left) } } fmt.Println(pnt) } ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:3:1","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#前序遍历"},{"categories":["数据结构与算法"],"content":" 中序遍历递归实现： // 按中序遍历访问左节点，访问节点元素，按中序遍历访问右节点 func ldrOrder(root *treeNode) { if root == nil { return } ldrOrder(root.left) fmt.Printf(\"%d \", root.val) ldrOrder(root.right) return } 栈实现： 从根节点开始入栈，一直往左，直到最左叶子节点 出栈，访问节点 将右节点当作步骤1的根节点（若存在） func ldrOrderStack(root *treeNode) { if root == nil { return } var st []*treeNode cur := root // 找到最左叶子节点 for cur != nil { st = append(st, cur) cur = cur.left } // 出栈，访问元素 // 如果存在右节点，继续入栈，直到最左叶子节点 var pnt []int for len(st) \u003e 0 { cur := st[len(st)-1] st = st[:len(st)-1] pnt = append(pnt, cur.val) tmp := cur.right for tmp != nil { st = append(st, tmp) tmp = tmp.left } } return } // 代码优化 func ldrOrderStack2(root *treeNode) { if root == nil { return } var st []*treeNode // 出栈，访问元素 // 如果存在右节点，继续入栈，直到最左叶子节点 var pnt []int tmp := root for len(st) \u003e 0 || tmp != nil { // 入栈直到最左节点 for tmp != nil { st = append(st, tmp) tmp = tmp.left } // 出栈，访问节点元素 tmp = st[len(st)-1] st = st[:len(st)-1] pnt = append(pnt, tmp.val) // 继续找右节点的最左叶子节点 tmp = tmp.right } return } ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:3:2","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#中序遍历"},{"categories":["数据结构与算法"],"content":" 后续遍历递归实现： func lrdOrder(root *treeNode) { if root == nil { return } lrdOrder(root.left) lrdOrder(root.right) fmt.Printf(\"%d \", root.val) return } 栈实现： 从根节点开始入栈，直到最左节点 获取栈顶，判断右节点 右节点不存在：访问该节点，出栈 右节点已经访问过：访问该节点，出栈 右节点未访问，进入步骤3 将该右节点当作步骤1的根节点 func lrdOrderStack(root *treeNode) { var st []*treeNode tmpRoot := root pre := root for len(st) \u003e 0 || tmpRoot != nil { for tmpRoot != nil { st = append(st, tmpRoot) tmpRoot = tmpRoot.left } tmpRoot = st[len(st)-1] // 当节点右节点为空 或者 右子树已经访问过的情况下，访问根节点 if tmpRoot.right == nil || tmpRoot.right == pre { fmt.Printf(\"%d \", tmpRoot.val) pre = tmpRoot tmpRoot = nil // 将当前节点标记为空，避免下一个循环又将该节点入栈 st = st[:len(st)-1] } else { // 右节点还没访问，后序遍历右节点 tmpRoot = tmpRoot.right } } return } ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:3:3","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#后续遍历"},{"categories":["数据结构与算法"],"content":" 层序遍历层序遍历使用队列实现： func levelOrder(root *treeNode) { if root == nil { return } var queue []*treeNode queue = append(queue, root) for len(queue) \u003e 0 { cur := queue[0] queue = queue[1:] fmt.Printf(\"%d \", cur.val) if cur.left != nil { queue = append(queue, cur.left) } if cur.right != nil { queue = append(queue, cur.right) } } return } ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:3:4","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#层序遍历"},{"categories":["数据结构与算法"],"content":" 遍历的复杂度 遍历 时间复杂度 空间复杂度 先序 O(n) 递归调用的时间复杂度为O(1)，递归调用的次数为数中节点的数量n 栈实现的空间复杂度为：O(h) h为数的高度 在较差的情况下，h = n；如果是平衡二叉树，h = logn 中序 O(n) 同上 后序 O(n) 同上 层序 O(n) O(w) w 为树的宽度 ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:3:5","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#遍历的复杂度"},{"categories":["数据结构与算法"],"content":" 树的一些常见问题（local 202305021918 树问题-路径求和 remote 202305021918 树问题-路径求和） （local 202305031652 树问题-判断子树 remote 202305031652 树问题-判断子树） 《02.二叉树的遍历知识》. 见于 2023年4月30日. https://algo.itcharge.cn/07.Tree/01.Binary-Tree/02.Binary-Tree-Traverse/. https://algo.itcharge.cn/07.Tree/01.Binary-Tree/01.Binary-Tree-Basic/ ","date":"2023-05-09","objectID":"/202304300709-%E6%A0%91/:4:0","series":["数据结构"],"tags":["树"],"title":"树","uri":"/202304300709-%E6%A0%91/#树的一些常见问题"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202305021918-%E6%A0%91%E9%97%AE%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%B1%82%E5%92%8C/:0:0","series":["算法"],"tags":["树"],"title":"树问题-路径求和","uri":"/202305021918-%E6%A0%91%E9%97%AE%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%B1%82%E5%92%8C/#"},{"categories":["数据结构与算法"],"content":" 方法一、使用广度优先搜索（层次遍历）思路： 二叉树的层次遍历使用一个队列来保存每一层的节点，再增加一个队列，用来保存从根节点到当前节点的路径上的和 ","date":"2023-05-09","objectID":"/202305021918-%E6%A0%91%E9%97%AE%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%B1%82%E5%92%8C/:1:0","series":["算法"],"tags":["树"],"title":"树问题-路径求和","uri":"/202305021918-%E6%A0%91%E9%97%AE%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%B1%82%E5%92%8C/#方法一使用广度优先搜索层次遍历"},{"categories":["数据结构与算法"],"content":" 方法二、递归思路： 原问题：是否存在从当前节点（根节点）到叶子节点的路径，和为 sum 子问题：是否存在从当前节点（根节点的子节点）到叶子节点的路径，和为 sum - val（父节点的值） 结束条件：当前节点为叶子节点 func hasPathSum(root *TreeNode, targetSum int) bool { if root == nil { return false } return havePathToLeaf(root, targetSum) } func havePathToLeaf(root *TreeNode, tgtSum int) bool { // end if root.Left == nil \u0026\u0026 root.Right == nil { return root.Val == tgtSum } have1, have2 := false, false if root.Left != nil { have1 = havePathToLeaf(root.Left, tgtSum - root.Val) } if root.Right != nil { have2 = havePathToLeaf(root.Right, tgtSum - root.Val) } return have1 || have2 } ","date":"2023-05-09","objectID":"/202305021918-%E6%A0%91%E9%97%AE%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%B1%82%E5%92%8C/:2:0","series":["算法"],"tags":["树"],"title":"树问题-路径求和","uri":"/202305021918-%E6%A0%91%E9%97%AE%E9%A2%98-%E8%B7%AF%E5%BE%84%E6%B1%82%E5%92%8C/#方法二递归"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202305031652-%E6%A0%91%E9%97%AE%E9%A2%98-%E5%88%A4%E6%96%AD%E5%AD%90%E6%A0%91/:0:0","series":["算法"],"tags":["树"],"title":"树问题-判断子树","uri":"/202305031652-%E6%A0%91%E9%97%AE%E9%A2%98-%E5%88%A4%E6%96%AD%E5%AD%90%E6%A0%91/#"},{"categories":["数据结构与算法"],"content":" 方法1. 递归子问题是：判断左右子树是否会等于预期的子树（判断左右子树是否相等的问题也可以递归来实现） // 判断根节点为起始的树与目标树是否相同 // 如果不相同，递归判断左子树和右子树 func isSubtree(root *TreeNode, subRoot *TreeNode) bool { if root == nil \u0026\u0026 subRoot == nil { return true } if root == nil { return false } if isSameTree(root, subRoot) { return true } return isSubtree(root.Left, subRoot) || isSubtree(root.Right, subRoot) } func isSameTree(p *TreeNode, q *TreeNode) bool { if p == nil \u0026\u0026 q == nil { return true } if p == nil || q == nil { return false } if p.Val != q.Val { return false } return isSameTree(p.Left, q.Left) \u0026\u0026 isSameTree(p.Right, q.Right) } ","date":"2023-05-09","objectID":"/202305031652-%E6%A0%91%E9%97%AE%E9%A2%98-%E5%88%A4%E6%96%AD%E5%AD%90%E6%A0%91/:1:0","series":["算法"],"tags":["树"],"title":"树问题-判断子树","uri":"/202305031652-%E6%A0%91%E9%97%AE%E9%A2%98-%E5%88%A4%E6%96%AD%E5%AD%90%E6%A0%91/#方法1-递归"},{"categories":["数据结构与算法"],"content":" 方法2. dfs（先序） + kmp（local 202304262036 KMP 算法 remote 202304262036 KMP 算法） 设主树s，子树t，主树的先序序列 ss，子树的先序序列 tt 利用先序序列的性质： 如果A.【 t 是 s 的子树】 那么B.【ss 中 包含 tt】 可以知道 B 是 A 的必要条件，是没有办法从 B 推出 A 的，原因是什么呢，假设主树：[4, 5]，子树：[4, nil, 5]，这种情况下的先序序列都是 4 5，但是两颗树是不一样的 但是我们可以通过补充两个代表空的左右节点来解决这个问题 // 通过树的先序遍历 // 补充树的每个节点，让度为2，输出树的先序遍历 // 判断主树的序列包含子树的序列 func isSubtree2(root *TreeNode, subRoot *TreeNode) bool { nums1 := dlrNums(root) nums2 := dlrNums(subRoot) return kmpSearch(nums1, nums2) } const lrNilVal = -10001 var leftNilNode = TreeNode{ Val: lrNilVal, } var rightNilNode = TreeNode{ Val: lrNilVal, } func dlrNums(root *TreeNode) []int { var nums []int if root == nil { return nums } var st []*TreeNode st = append(st, root) tmpRoot := root for len(st) \u003e 0 { // pop tmpRoot = st[len(st) - 1] st = st[:len(st) - 1] // visit nums = append(nums, tmpRoot.Val) if tmpRoot.Val != lrNilVal \u0026\u0026 tmpRoot.Left == nil { tmpRoot.Left = \u0026leftNilNode } if tmpRoot.Val != lrNilVal \u0026\u0026 tmpRoot.Right == nil { tmpRoot.Right = \u0026rightNilNode } if tmpRoot.Right != nil { st = append(st, tmpRoot.Right) } if tmpRoot.Left != nil { st = append(st, tmpRoot.Left) } } return nums } // i // nums a a b a a b a a c // pat // j func kmpSearch(nums, pat []int) bool { next := getNext(pat) j := 0 for i := 0; j \u003c len(pat) \u0026\u0026 i \u003c len(nums); i++ { for ; j \u003e 0 \u0026\u0026 nums[i] != pat[j]; j = next[j-1]{} if nums[i] == pat[j] { j++ } } return j == len(pat) } func getNext(pat []int) []int { next := make([]int, len(pat)) next[0] = 0 for l, j := 0, 1 ; j \u003c len(pat); j++ { for l \u003e 0 \u0026\u0026 pat[l] != pat[j] {l = next[l-1]} if pat[l] == pat[j] { l++ } next[j] = l } return next } ","date":"2023-05-09","objectID":"/202305031652-%E6%A0%91%E9%97%AE%E9%A2%98-%E5%88%A4%E6%96%AD%E5%AD%90%E6%A0%91/:2:0","series":["算法"],"tags":["树"],"title":"树问题-判断子树","uri":"/202305031652-%E6%A0%91%E9%97%AE%E9%A2%98-%E5%88%A4%E6%96%AD%E5%AD%90%E6%A0%91/#方法2-dfs先序--kmp"},{"categories":["数据结构与算法"],"content":"#算法 ","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:0:0","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#"},{"categories":["数据结构与算法"],"content":" 一、基本概念定义：G = (V, E) 图的分类 边是否有方向： 有向图 无向图 图中是否有环： 有环图 无环图 连通图和非连通图 连通图 非连通图 边是否有权重 有权图 无权图 ","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:1:0","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#一基本概念"},{"categories":["数据结构与算法"],"content":" 二、图的表示 顺序 链式 一个无向图的例子，展示如何用「邻接矩阵」和「邻接表」来表示一个图： 邻接矩阵中保存着很多不存在的边，由于二维数组的连续性，会浪费很多空间，但是查询速度快 O(1)；在邻接表中，采用了一个数组来保存图的所有点，每个元素扩展成一个链表，只保存存在的边，节省空间，但是查询效率 O(n)，可以通过一些手段来优化这个链表，比如将链表转化为 AVL 或者 红黑树，查询效率能够优化到 O(logn)，或者采用哈希表，再将时间复杂度降至 O(1) 五种树的存储方式的比较： 操作 邻接矩阵 边集数组 邻接表 链式前向星 哈希表实现邻接表 图的初始化 n^2 m n+m n+m 查某条边是否存在 1 m TD(vi) TD(vi) 遍历某个点的所有边 n m TD(vi) TD(vi) 遍历整张图 n^2 nm n+m n+m 空间复杂度 n m n+m n+m ","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:2:0","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#二图的表示"},{"categories":["数据结构与算法"],"content":" 2.1 邻接矩阵（ 二维数组）","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:2:1","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#21-邻接矩阵-二维数组"},{"categories":["数据结构与算法"],"content":" 2.2 边集数组","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:2:2","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#22-边集数组"},{"categories":["数据结构与算法"],"content":" 2.3 邻接表（数组+链式结构）实现1. // 邻接点 type AdjNode struct { AdjN int // 邻接点标号 Weight int //顶点到该邻接点的权重 Next *AdjNode } // 顶点 type VNode struct { Val int FirstAdjNode *AdjNode } type Graph struct { VNum int ENum int VNodes []VNode } type Edge struct { V1, V2 int Weight int } func InitGraph(VertexNum int) *Graph { g := \u0026Graph{ VNum: VertexNum, ENum: 0, VNodes: make([]VNode, VertexNum), } //for _, vnode := range g.VNodes { //vnode.Val = //} return g } func InsertEdge(graph *Graph, e *Edge) { v1VNode := graph.VNodes[e.V1-1] // 假设 v1 节点存储在下标 0 的位置 // 新建一个 v2 的邻接点 v2Adj := \u0026AdjNode{ AdjN: e.V2, Weight: e.Weight, Next: v1VNode.FirstAdjNode, } v1VNode.FirstAdjNode = v2Adj // 如果是无向图，还需要添加从 v2 到 v1 的连接 v2VNode := graph.VNodes[e.V2-1] v1Adj := \u0026AdjNode{ AdjN: e.V1, Weight: e.Weight, Next: v2VNode.FirstAdjNode, } v2VNode.FirstAdjNode = v1Adj } func BuildGraph(vnum int, v1s, v2s []int, weight []int) *Graph { graph := InitGraph(vnum) for i := 0; i \u003c len(v1s); i++ { e := \u0026Edge{ V1: v1s[i], V2: v2s[i], Weight: weight[i], } InsertEdge(graph, e) } return graph } func test1() { vnum := 4 v1s := []int{1,1,3,1} v2s := []int{2,3,4,4} weights := []int{1,2,3,4} graph := BuildGraph(vnum, v1s, v2s, weights) for i, vnode := range graph.VNodes { adj := vnode.FirstAdjNode for adj != nil { fmt.Printf(\"(%d,%d) 权重 %d \\n\",i+1, adj.AdjN, adj.Weight) adj = adj.Next } } } 2023/05/24 重新回顾 使用 map 来实现 type vertex struct { val int } /* 基于邻接表实现的无向图 */ type graphAdjMp struct { adjMp map[vertex]map[vertex]struct{} } func (g *graphAdjMp) addVertex(v vertex) { if _, ok := g.adjMp[v]; ok { // 该顶点已经存在，无需重复加入 return } // 新加一个节点，以及初始化一个链表 g.adjMp[v] = map[vertex]struct{}{} } func (g *graphAdjMp) deleteVertex(v vertex) { if _, ok := g.adjMp[v]; !ok { // 节点是不存在的 return } /* 1.删除顶点 */ delete(g.adjMp, v) /* 2.删除其他顶点中与之存在的关联 */ for _, rt := range g.adjMp { delete(rt, v) } } func (g *graphAdjMp) addEdge(v1, v2 vertex) { _, ok1 := g.adjMp[v1] _, ok2 := g.adjMp[v2] if !ok1 || !ok2 || v1 == v2 { log.Fatal(\"add edge error\") } g.adjMp[v1][v2] = struct{}{} g.adjMp[v2][v1] = struct{}{} } func (g *graphAdjMp) deleteEdge(v1, v2 vertex) { _, ok1 := g.adjMp[v1] _, ok2 := g.adjMp[v2] if !ok1 || !ok2 || v1 == v2 { log.Fatal(\"delete edge error\") } delete(g.adjMp[v1], v2) delete(g.adjMp[v2], v1) } // newGraphAdjMp 使用边来初始化一个图 // edges 的形式应该是 [(v1,v2),(v1,v3)...] func newGraphAdjMp(edges [][]vertex) *graphAdjMp { g := \u0026graphAdjMp{ adjMp: make(map[vertex]map[vertex]struct{}), } for _, e := range edges { g.addVertex(e[0]) g.addVertex(e[1]) g.addEdge(e[0], e[1]) } return g } func (g *graphAdjMp) print() { if g.adjMp == nil { fmt.Println(\"graph is nil\") } for vt, toMp := range g.adjMp { fmt.Print(\"vertex#\", vt, \"have edge: \") for toVt := range toMp { fmt.Print(\"(\", vt.val, toVt.val, \")\") } fmt.Println() } } 测试： func TestGraphAdjMp() { edges := [][]vertex { {vertex{val: 1},vertex{val: 2}}, {vertex{val: 1},vertex{val: 3}}, {vertex{val: 2},vertex{val: 1}}, {vertex{val: 2},vertex{val: 4}}, {vertex{val: 2},vertex{val: 5}}, {vertex{val: 3},vertex{val: 1}}, {vertex{val: 3},vertex{val: 4}}, {vertex{val: 4},vertex{val: 3}}, {vertex{val: 4},vertex{val: 2}}, {vertex{val: 4},vertex{val: 5}}, } g := newGraphAdjMp(edges) g.print() g.deleteEdge(vertex{val: 1}, vertex{val: 3}) fmt.Println(\"delete edge(1,3)\") g.print() g.addEdge(vertex{val: 3}, vertex{val: 5}) fmt.Println(\"delete edge(5,3)\") g.print() g.addVertex(vertex{val: 6}) fmt.Println(\"add vertex 6\") g.print() g.deleteVertex(vertex{val: 4}) fmt.Println(\"delete vertex 4\") g.print() } out: vertex#{1}have edge: (1 2)(1 3) vertex#{2}have edge: (2 1)(2 4)(2 5) vertex#{3}have edge: (3 4)(3 1) vertex#{4}have edge: (4 5)(4 2)(4 3) vertex#{5}have edge: (5 2)(5 4) delete edge(1,3) vertex#{1}have edge: (1 2) vertex#{2}have edge: (2 1)(2 4)(2 5) vertex#{3}have edge: (3 4) vertex#{4}have edge: (4 3)(4 5)(4 2) vertex#{5}have edge: (5 2)(5 4) delete edge(5,3) vertex#{1}have edge: (1 2) vertex#{2}have edge: (2 1)(2 4)(2 5) vertex#{3}have edge: (3 4)(3 5) vertex#{4}have edge: (4 2)(4 3)(4","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:2:3","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#23-邻接表数组链式结构"},{"categories":["数据结构与算法"],"content":" 2.4 链式前向星（数组+静态链表）","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:2:4","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#24-链式前向星数组静态链表"},{"categories":["数据结构与算法"],"content":" 2.5 哈希表实现邻接表 https://www.hello-algo.com/chapter_graph/graph_operations/#922 ","date":"2023-05-09","objectID":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/:2:5","series":["数据结构"],"tags":["图"],"title":"图基础","uri":"/202305040737-%E5%9B%BE%E5%9F%BA%E7%A1%80/#25-哈希表实现邻接表"},{"categories":["Kubernetes"],"content":"#k8s #问题定位 ","date":"2023-05-09","objectID":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/:0:0","series":["kubernetes问题定位"],"tags":["问题定位"],"title":"问题定位：Evicted","uri":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/#"},{"categories":["Kubernetes"],"content":" 问题现场 kubectl -n product-ebs get pod -o wide | grep vtype-xxx 扎到了一个状态为 Evicted 的 pod ","date":"2023-05-09","objectID":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/:1:0","series":["kubernetes问题定位"],"tags":["问题定位"],"title":"问题定位：Evicted","uri":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/#问题现场"},{"categories":["Kubernetes"],"content":" 问题分析通过现场可以看到 pod 原先的节点，所以可以查看一下节点的日志 接着就发现了节点有磁盘压力，kubelet 主动终止 pod 以回收节点上的资源，以此来保证节点的稳定 ","date":"2023-05-09","objectID":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/:2:0","series":["kubernetes问题定位"],"tags":["问题定位"],"title":"问题定位：Evicted","uri":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/#问题分析"},{"categories":["Kubernetes"],"content":" 学习","date":"2023-05-09","objectID":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/:3:0","series":["kubernetes问题定位"],"tags":["问题定位"],"title":"问题定位：Evicted","uri":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/#学习"},{"categories":["Kubernetes"],"content":" 可能导致节点压力的因素有什么cpu、内存、磁盘空间… ","date":"2023-05-09","objectID":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/:3:1","series":["kubernetes问题定位"],"tags":["问题定位"],"title":"问题定位：Evicted","uri":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/#可能导致节点压力的因素有什么"},{"categories":["Kubernetes"],"content":" kubelet 是如何做出驱逐的决定的 分析这个问题的步骤： 回答这个问题需要了解 Kubernetes 中 kubelet 组件以及 Eviction API，再结合节点资源使用情况等因素来判断是否要驱逐 Pod。具体的分析步骤如下： 了解 Kubernetes 中 kubelet 组件和 Eviction API 的作用和原理。 确认 kubelet 是否开启了 Eviction 功能。 判断当前节点资源（如内存、CPU、磁盘空间）使用情况是否达到了预定义的阈值，若达到或超出，则根据优先级逻辑对 Pod 进行驱逐操作。 产生这个问题的原因： 在 Kubernetes 下，由于各种原因（如资源紧缺，节点故障等），kubelet 可能会决定驱逐一些 Pod 以保证集群正常运转，因此了解 kubelet 决策的原因和方式对于提高 Kubernetes 集群的稳定性和安全性非常重要。 这个问题的答案： kubelet 驱逐 Pod 是通过以下步骤进行的： kubelet 定期与 kube-apiserver 通信，获取当前 Node 上的 Pod 列表信息。 kubelet 根据容器的 QoS 类别（Guaranteed \u003e Burstable \u003e BestEffort） 和优先级（pod priority/Preemption）进行排序。（Preemption 时过程中，kubelet 不会限制一些特定 Pod 从来不被驱逐。） kubelet 判断当前 Node 是否处于 out of memory 或者 DiskPressure 的状态，如果是的话，则使用相应的 Eviction API 驱逐 Pod。 如果还没有达到阈值，则尝试驱逐优先级最低的 Pod。如果此时节点有足够的资源可供使用，则该操作不会执行。否则，kubelet 将继续驱逐优先级下一个较低的 Pod 直到可以保证目标阈值。 如果使用上述步骤无法满足 Eviction 要求（如Pod 强占资源），kubelet 可能会强制删除其他 Pod 以便为当前占用的 Pod 腾出资源。 需要注意的是，kubelet 是被动的进行驱逐操作的，即只有在当前节点资源使用情况达到或超过了预设的阈值时才会进行驱逐，而这些阈值可以通过修改 Kubernetes 集群中的参数来调整。 容器的 QoS： kubectl describe pod \u003cpod-name\u003e | grep QoS 该命令会列出 Pod 的详细信息，并在结果中搜索 QoS 相关的部分。 Kubernetes 中的 QoS (Quality of Service) 是一个特性，它用来管理节点上运行的 Pod 的资源分配和调度。在 Kubernetes 中，QoS 有三种级别： Guaranteed：这种类型的 Pod 被保证能够获得所请求的 CPU 和内存资源。如果节点上的资源不足，优先级较低的 Pod 将被暂停或驱逐。 Burstable：这种类型的 Pod 具有最小的 CPU 和内存要求，但可以在需要时进行扩展，以获得更多资源。当节点上的资源不足时，Burstable Pod 可能会受到限制，但不会被完全暂停或驱逐。 BestEffort：这种类型的 Pod 不会被保证任何资源。它们将尽力在节点上占用尽可能少的资源，并且在节点资源不足时首先被削减或删除。 QoS 主要的作用是帮助 Kubernetes 管理资源，确保相同级别的 Pod 在节点上得到公平的资源分配，并且在资源不足的情况下，根据其级别的不同，采取适当的措施以保持节点的健康状态。 ","date":"2023-05-09","objectID":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/:3:2","series":["kubernetes问题定位"],"tags":["问题定位"],"title":"问题定位：Evicted","uri":"/202305080553-%E9%97%AE%E9%A2%98%E5%AE%9A%E4%BD%8D-evicted/#kubelet-是如何做出驱逐的决定的"},{"categories":["Kubernetes"],"content":"#k8s ","date":"2023-05-09","objectID":"/202305080545-kubernetes-%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/:0:0","series":["kubernetes初识"],"tags":["实操"],"title":"在 vmware 上本地搭建 kubernetes 集群","uri":"/202305080545-kubernetes-%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/#"},{"categories":["Kubernetes"],"content":" 一、环境准备 关闭防火墙 systemctl stop firewalld systemctl disable firewalld 关闭 selinux sed -i 's/enforcing/disabled/' /etc/selinux/config 关闭 swap sed -ri 's/.*swap.*/#\u0026/' /etc/fstab 添加 hosts cat \u003e\u003e /etc/hosts \u003c\u003c EOF 192.168.108.132 centos7-master 192.168.108.130 centos7-node1 EOF 设置网桥参数 cat \u003e /etc/sysctl.d/k8s.conf \u003c\u003c EOF net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 EOF sysctl --system # 生效 时间同步 yum install ntpdate -y # 没有的 ntpdate 则安装 ntpdate time.windows.com # 同步时间 ","date":"2023-05-09","objectID":"/202305080545-kubernetes-%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/:1:0","series":["kubernetes初识"],"tags":["实操"],"title":"在 vmware 上本地搭建 kubernetes 集群","uri":"/202305080545-kubernetes-%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/#一环境准备"},{"categories":["Kubernetes"],"content":" 二、安装 安装 Docker、kubeadm、kubelet、kubectl Docker 安装 wget https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo -O /etc/yum.repos.d/docker-ce.repo # 更新 docker 的 yum 源 yum install docker-ce-19.03.13 -y 配置镜像 mkdir /etc/docker cat \u003c\u003c EOF \u003e /etc/docker/daemon.json { \"registry-mirrors\": [\"https://kfwkfulq.mirror.aliyuncs.com\"] } EOF systemctl enable docker.service 添加 k8s 的yum源 cat \u003e /etc/yum.repos.d/kubernetes.repo \u003c\u003c EOF [kubernetes] name=Kubernetes baseurl=https://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=0 repo_gpgcheck=0 gpgkey=https://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg https://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg EOF 安装 kubeadm、kubelet、kubectl yum install kubelet-1.19.4 kubeadm-1.19.4 kubectl-1.19.4 -y systemctl enable kubelet.service # 开启服务 重启 centos 部署 master 节点 kubeadm init --apiserver-advertise-address=【master服务器ip地址】 --image-repository registry.aliyuncs.com/google_containers --kubernetes-version v1.19.4 --service-cidr=10.96.0.0/12 --pod-network-cidr=10.244.0.0/16 mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config 添加 node 节点 kubeadm join 192.168.108.132:6443 --token d99d8g.3wr8skktnv3m9e46 \\ --discovery-token-ca-cert-hash sha256:0ba36403007aa7ef77b174a65a8e3de27bcbcac9fbb5b2bb31c337a565d4e16 部署网络插件 wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml kubectl apply -f kube-flannel.yml ","date":"2023-05-09","objectID":"/202305080545-kubernetes-%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/:2:0","series":["kubernetes初识"],"tags":["实操"],"title":"在 vmware 上本地搭建 kubernetes 集群","uri":"/202305080545-kubernetes-%E5%B9%B3%E5%8F%B0%E6%90%AD%E5%BB%BA/#二安装"},{"categories":["数据结构与算法"],"content":"#算法 用途：给定一个数组，返回基于字典序的下一个数组排列 四个步骤： 找上坡 找大于且最小 交换 倒序 Go 实现： func nextDicArr(nums []int) []int { if len(nums) \u003c= 1 { return } pos := -1 for i := len(nums)-2; i \u003e= 0; i-- { if nums[i] \u003c nums[i+1] { pos = i break } } // 没找到上坡（左值小于右值），说明已经是降序排列 if pos == -1 { for i,n := 0,len(nums); i \u003c n/2; i++ { nums[i], nums[n-i-1] = nums[n-i-1], nums[i] } return nums } // 找到 pos，接着找右边大于该值的最小值（也就是第一个大于标记的值） biggerThanPos := -1 for i := len(nums)-1; i \u003e= pos+1; i-- { if nums[i] \u003e nums[pos] { biggerThanPos = i break } } nums[pos], nums[biggerThanPos] = nums[biggerThanPos], nums[pos] // 剩下的倒序 for i,n,cnt := pos+1, len(nums),0; i \u003c (n + pos+1)/2; i++ { nums[i], nums[n-cnt-1] = nums[n-cnt-1], nums[i] cnt++ } return nums } 习题练习： https://leetcode.cn/problems/VvJkup/ 《字典序算法详解_HappyRocking的博客-CSDN博客》. 见于 2023年4月29日. https://blog.csdn.net/HappyRocking/article/details/83619392. ","date":"2023-05-09","objectID":"/202304290644-%E5%AD%97%E5%85%B8%E5%BA%8F%E7%AE%97%E6%B3%95/:0:0","series":["算法"],"tags":["字典序"],"title":"字典序算法","uri":"/202304290644-%E5%AD%97%E5%85%B8%E5%BA%8F%E7%AE%97%E6%B3%95/#"},{"categories":null,"content":" 这是一个由 Hugo 驱动的偏 个人记录 性质的个人博客 🌐 博客的名称：HHQ Records 创建时间：2023/05/09 🙋‍♂️ 博客的主人：HHQ Slogan：Out of the comfort zone 我的QQ：904566722 这个博客什么都记，记录一下自己的成长。 ","date":"2019-08-02","objectID":"/about/:0:0","series":null,"tags":null,"title":"关于","uri":"/about/#"}]